<div id="dlpage">
    <h1>Computer Science </h1>
    <h2>New submissions</h2>
    <div class="list-dateline">Submissions received from Fri 3 May 24 to Mon 6 May 24, announced Tue, 7 May 24</div>
    <ul>
        <li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
        <li><a href="#item681">Cross-lists</a></li>
        <li><a href="#item744">Replacements</a></li>
    </ul>
    <small>[ total of 1195 entries: <b>1-1195</b> ]</small><br>
    <small>[ showing up to 2000 entries per page: <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font
            color="#999999">more</font> ]</small><br>
    <h3>New submissions for Tue, 7 May 24</h3>
    <dl>
        <dt><a name="item1">[1]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02288"
                    title="Abstract">arXiv:2405.02288</a> [<a href="/pdf/2405.02288" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02288" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Prospective Role of Foundation Models in Advancing Autonomous
                    Vehicles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Jianhua Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+B">Bingzhao Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+J">Jincheng Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jianhao Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chu%2C+H">Hongqing Chu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Q">Qiankun Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gong%2C+X">Xun Gong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+Y">Yi Chang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tseng%2C+H+E">H. Eric Tseng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jie Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 36 pages,5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

                </div>
                <p class="mathjax">With the development of artificial intelligence and breakthroughs in deep
                    learning, large-scale Foundation Models (FMs), such as GPT, CLIP, etc., have
                    achieved remarkable results in many fields including natural language
                    processing and computer vision. The application of FMs in autonomous driving
                    holds considerable promise. For example, they can contribute to enhance scene
                    understanding and reasoning. By pre-training on rich linguistic and visual
                    data, FMs can understand and interpret various elements in a driving scene, and
                    provide cognitive reasoning to give linguistic and action commands for driving
                    decisions and planning. Furthermore, FMs can augment data based on its
                    understanding of driving scenarios to provide feasible scenes of those rare
                    occurrences in the long tail distribution that are unlikely to be encountered
                    during routine driving and data collection. The enhancement can subsequently
                    lead to the improvement in the accuracy and reliability of autonomous driving
                    systems. Another testament to the potential of FMs applications lies in the
                    development of World Models, exemplified by the DREAMER series, which showcase
                    the ability to comprehend physical laws and dynamics. Learning from massive
                    data under the paradigm of self-supervised learning, World Model can generate
                    unseen yet plausible driving environment, facilitating the enhancement in the
                    prediction of road users behavior and the off-line training of driving
                    strategies. In this paper, we synthesize the applications and future trends of
                    FMs in autonomous driving. By utilizing the powerful capabilities of FMs, we
                    strive to tackle the potential issues stemming from the long-tail distribution
                    in autonomous driving, consequently advancing overall safety in this domain.
                </p>
            </div>
        </dd>
        <dt><a name="item2">[2]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02289"
                    title="Abstract">arXiv:2405.02289</a> [<a href="/pdf/2405.02289" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02289" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TSDiT: Traffic Scene Diffusion Models With Transformers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+C">Chen Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+T">Tianyu Shi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">In this paper, we introduce a novel approach to trajectory generation for
                    autonomous driving, combining the strengths of Diffusion models and
                    Transformers. First, we use the historical trajectory data for efficient
                    preprocessing and generate action latent using a diffusion model with
                    DiT(Diffusion with Transformers) Blocks to increase scene diversity and
                    stochasticity of agent actions. Then, we combine action latent, historical
                    trajectories and HD Map features and put them into different transformer
                    blocks. Finally, we use a trajectory decoder to generate future trajectories of
                    agents in the traffic scene. The method exhibits superior performance in
                    generating smooth turning trajectories, enhancing the model's capability to fit
                    complex steering patterns. The experimental results demonstrate the
                    effectiveness of our method in producing realistic and diverse trajectories,
                    showcasing its potential for application in autonomous vehicle navigation
                    systems.
                </p>
            </div>
        </dd>
        <dt><a name="item3">[3]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02290"
                    title="Abstract">arXiv:2405.02290</a> [<a href="/pdf/2405.02290" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02290" title="Download PostScript">ps</a>, <a href="/format/2405.02290"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Wheel Odometry-Based Localization for Autonomous Wheelchair
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Paryanto%2C+P">P Paryanto</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pratama%2C+R+R">Rakha Rahmadani Pratama</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saputra%2C+R+P">Roni Permana Saputra</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages, 10 figures, 3 tables
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> 2023 International Conference on Radar, Antenna,
                    Microwave,
                    Electronics, and Telecommunications (ICRAMET), Bandung, Indonesia, 2023, pp.
                    357-362
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Localization is a fundamental requirement for an autonomous vehicle system.
                    One of the most often used systems for autonomous vehicle localization is the
                    global positioning system (GPS). Nevertheless, the functionality of GPS is
                    strongly dependent on the availability of satellites, making it unreliable in
                    some situations. As a result, autonomous vehicles must possess autonomous
                    self-localization capabilities to ensure their independent operation. Odometry
                    techniques are employed to achieve vehicle localization by predicting the
                    vehicle position and orientation based on sensor measurements of the vehicle
                    motion. One of the approaches employed in odometry is known as wheel odometry.
                    Wheel odometry has a lower degree of reliance on the surrounding environment
                    than visual odometry and laser odometry. This study aims to evaluate the
                    performance of wheel odometry implementation for an autonomous wheelchair in
                    the context of the localization process. The differential drive kinematic model
                    is employed to determine the predicted pose of a wheelchair. This prediction is
                    derived from the measurement of the linear and angular velocity of the
                    wheelchair. Several experiments have been conducted to evaluate the performance
                    of wheel odometry-based localization. Prior to experimenting, calibration
                    procedures have also been performed to ensure accurate measurements of the
                    sensor.
                </p>
            </div>
        </dd>
        <dt><a name="item4">[4]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02291"
                    title="Abstract">arXiv:2405.02291</a> [<a href="/pdf/2405.02291" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02291" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bundling and Tumbling in Bacterial-inspired Bi-flagellated
                    Soft Robots for Attitude Adjustment
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hao%2C+Z">Zhuonan Hao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zalavadia%2C+S">Siddharth Zalavadia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jawed%2C+M+K">Mohammad Khalid Jawed</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">We create a mechanism inspired by bacterial swimmers, featuring two flexible
                    flagella with individual control over rotation speed and direction in viscous
                    fluid environments. Using readily available materials, we design and fabricate
                    silicone-based helical flagella. To simulate the robot's motion, we develop a
                    physics-based computational tool, drawing inspiration from computer graphics.
                    The framework incorporates the Discrete Elastic Rod method, modeling the
                    flagella as Kirchhoff's elastic rods, and couples it with the Regularized
                    Stokeslet Segments method for hydrodynamics, along with the Implicit Contact
                    Model to handle contact. This approach effectively captures polymorphic
                    phenomena like bundling and tumbling. Our study reveals how these emergent
                    behaviors affect the robot's attitude angles, demonstrating its ability to
                    self-reorient in both simulations and experiments. We anticipate that this
                    framework will enhance our understanding of the directional change capabilities
                    of flagellated robots, potentially stimulating further exploration on
                    microscopic robot mobility.
                </p>
            </div>
        </dd>
        <dt><a name="item5">[5]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02292"
                    title="Abstract">arXiv:2405.02292</a> [<a href="/pdf/2405.02292" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02292" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ALOHA 2: An Enhanced Low-Cost Hardware for Bimanual
                    Teleoperation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=ALOHA+2+Team">ALOHA 2 Team</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Aldaco%2C+J">Jorge Aldaco</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Armstrong%2C+T">Travis Armstrong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baruch%2C+R">Robert Baruch</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bingham%2C+J">Jeff Bingham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+S">Sanky Chan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Draper%2C+K">Kenneth Draper</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dwibedi%2C+D">Debidatta Dwibedi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Finn%2C+C">Chelsea Finn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Florence%2C+P">Pete Florence</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goodrich%2C+S">Spencer Goodrich</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gramlich%2C+W">Wayne Gramlich</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hage%2C+T">Torr Hage</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Herzog%2C+A">Alexander Herzog</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hoech%2C+J">Jonathan Hoech</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+T">Thinh Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Storz%2C+I">Ian Storz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tabanpour%2C+B">Baruch Tabanpour</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Takayama%2C+L">Leila Takayama</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tompson%2C+J">Jonathan Tompson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wahid%2C+A">Ayzaan Wahid</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wahrburg%2C+T">Ted Wahrburg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+S">Sichun Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yaroshenko%2C+S">Sergey Yaroshenko</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zakka%2C+K">Kevin Zakka</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+T+Z">Tony Z. Zhao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Project website: aloha-2.github.io
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Diverse demonstration datasets have powered significant advances in robot
                    learning, but the dexterity and scale of such data can be limited by the
                    hardware cost, the hardware robustness, and the ease of teleoperation. We
                    introduce ALOHA 2, an enhanced version of ALOHA that has greater performance,
                    ergonomics, and robustness compared to the original design. To accelerate
                    research in large-scale bimanual manipulation, we open source all hardware
                    designs of ALOHA 2 with a detailed tutorial, together with a MuJoCo model of
                    ALOHA 2 with system identification. See the project website at
                    aloha-2.github.io.
                </p>
            </div>
        </dd>
        <dt><a name="item6">[6]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02293"
                    title="Abstract">arXiv:2405.02293</a> [<a href="/pdf/2405.02293" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02293" title="Download PostScript">ps</a>, <a href="/format/2405.02293"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Modified OSD Algorithm with Reduced Gaussian Elimination
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fossorier%2C+M">Marc Fossorier</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shakiba-Herfeh%2C+M">Mahdi Shakiba-Herfeh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huazi Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 2 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">In this paper, the OSD algorithm is modified to perform a limited GE with
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-1-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1"
                                style="width: 11.982em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 9.957em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1009.84em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-4" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-5"><span
                                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-6"
                                                            style="font-family: MathJax_Math-italic;">N<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.987em;"><span
                                                            class="mn" id="MathJax-Span-7"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-8"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">min</span><span
                                                class="mo" id="MathJax-Span-9"
                                                style="font-family: MathJax_Main;">{</span><span class="mi"
                                                id="MathJax-Span-10"
                                                style="font-family: MathJax_Math-italic;">R</span><span class="mo"
                                                id="MathJax-Span-11" style="font-family: MathJax_Main;">,</span><span
                                                class="mn" id="MathJax-Span-12"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">1</span><span
                                                class="mo" id="MathJax-Span-13"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mi" id="MathJax-Span-14"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">R</span><span
                                                class="msubsup" id="MathJax-Span-15"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.07em, 1000.41em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mo" id="MathJax-Span-16"
                                                            style="font-family: MathJax_Main;">}</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-17"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-18"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-1">O(N^3 \min\{R, 1-R\}^3)</script> complexity for an
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-2-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-19"
                                style="width: 3.649em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.012em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.9em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-20"><span class="mo" id="MathJax-Span-21"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-22" style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="mo" id="MathJax-Span-23"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-24"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="mo" id="MathJax-Span-25"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-2">(N,K)</script> linear block code of rate
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-3-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-26"
                                style="width: 5.327em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.401em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.4em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-27"><span class="mi" id="MathJax-Span-28"
                                                style="font-family: MathJax_Math-italic;">R</span><span class="mo"
                                                id="MathJax-Span-29"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mi" id="MathJax-Span-30"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="texatom" id="MathJax-Span-31"><span class="mrow"
                                                    id="MathJax-Span-32"><span class="mo" id="MathJax-Span-33"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="mi" id="MathJax-Span-34"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-3">R=K/N</script>.
                </p>
            </div>
        </dd>
        <dt><a name="item7">[7]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02295"
                    title="Abstract">arXiv:2405.02295</a> [<a href="/pdf/2405.02295" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02295" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Neural Additive Image Model: Interpretation through
                    Interpolation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Reuter%2C+A">Arik Reuter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thielmann%2C+A">Anton Thielmann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saefken%2C+B">Benjamin Saefken</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Understanding how images influence the world, interpreting which effects
                    their semantics have on various quantities and exploring the reasons behind
                    changes in image-based predictions are highly difficult yet extremely
                    interesting problems. By adopting a holistic modeling approach utilizing Neural
                    Additive Models in combination with Diffusion Autoencoders, we can effectively
                    identify the latent hidden semantics of image effects and achieve full
                    intelligibility of additional tabular effects. Our approach offers a high
                    degree of flexibility, empowering us to comprehensively explore the impact of
                    various image characteristics. We demonstrate that the proposed method can
                    precisely identify complex image effects in an ablation study. To further
                    showcase the practical applicability of our proposed model, we conduct a case
                    study in which we investigate how the distinctive features and attributes
                    captured within host images exert influence on the pricing of Airbnb rentals.
                </p>
            </div>
        </dd>
        <dt><a name="item8">[8]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02296"
                    title="Abstract">arXiv:2405.02296</a> [<a href="/pdf/2405.02296" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02296" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Möbius Transform for Mitigating Perspective Distortions in
                    Representation Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chhipa%2C+P+C">Prakash Chandra Chhipa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chippa%2C+M+S">Meenakshi Subhash Chippa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=De%2C+K">Kanjar De</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saini%2C+R">Rajkumar Saini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liwicki%2C+M">Marcus Liwicki</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shah%2C+M">Mubarak Shah</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Perspective distortion (PD) causes unprecedented changes in shape, size,
                    orientation, angles, and other spatial relationships of visual concepts in
                    images. Precisely estimating camera intrinsic and extrinsic parameters is a
                    challenging task that prevents synthesizing perspective distortion.
                    Non-availability of dedicated training data poses a critical barrier to
                    developing robust computer vision methods. Additionally, distortion correction
                    methods make other computer vision tasks a multi-step approach and lack
                    performance. In this work, we propose mitigating perspective distortion (MPD)
                    by employing a fine-grained parameter control on a specific family of M\"obius
                    transform to model real-world distortion without estimating camera intrinsic
                    and extrinsic parameters and without the need for actual distorted data. Also,
                    we present a dedicated perspectively distorted benchmark dataset, ImageNet-PD,
                    to benchmark the robustness of deep learning models against this new dataset.
                    The proposed method outperforms on existing benchmarks, ImageNet-E and
                    ImageNet-X. Additionally, it significantly improves performance on ImageNet-PD
                    while consistently performing on standard data distribution. Further, our
                    method shows improved performance on three PD-affected real-world applications:
                    crowd counting, fisheye image recognition, and person re-identification. We
                    will release source code, dataset, and models for foster further research.
                </p>
            </div>
        </dd>
        <dt><a name="item9">[9]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02297"
                    title="Abstract">arXiv:2405.02297</a> [<a href="/pdf/2405.02297" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02297" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Employing Universal Voting Schemes for Improved Visual Place
                    Recognition Performance
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Waheed%2C+M">Maria Waheed</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Milford%2C+M">Michael Milford</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+X">Xiaojun Zhai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fasli%2C+M">Maria Fasli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McDonald-Maier%2C+K">Klaus McDonald-Maier</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ehsan%2C+S">Shoaib Ehsan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a
                        href="/abs/2305.05705">arXiv:2305.05705</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Visual Place Recognition has been the subject of many endeavours utilizing
                    different ensemble approaches to improve VPR performance. Ideas like
                    multi-process fusion, Fly-Inspired Voting Units, SwitchHit or Switch-Fuse
                    involve combining different VPR techniques together, utilizing different
                    strategies. However, a major aspect often common to many of these strategies is
                    voting. Voting is an extremely relevant topic to explore in terms of its
                    application and significance for any ensemble VPR setup. This paper analyses
                    several voting schemes to maximise the place detection accuracy of a VPR
                    ensemble set up and determine the optimal voting schemes for selection. We take
                    inspiration from a variety of voting schemes that are widely employed in fields
                    such as politics and sociology and it is evident via empirical data that the
                    selection of the voting method influences the results drastically. The paper
                    tests a wide variety of voting schemes to present the improvement in the VPR
                    results for several data sets. We aim to determine whether a single optimal
                    voting scheme exists or, much like in other fields of research, the selection
                    of a voting technique is relative to its application and environment. We
                    propose a ranking of these different voting methods from best to worst which
                    allows for better selection. While presenting our results in terms of voting
                    method's performance bounds, in form of radar charts, PR curves to showcase the
                    difference in performance and a comparison methodology using a McNemar test
                    variant to determine the statistical significance of the differences. This test
                    is performed to further confirm the reliability of outcomes and draw
                    comparisons for better and informed selection a voting technique.
                </p>
            </div>
        </dd>
        <dt><a name="item10">[10]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02298"
                    title="Abstract">arXiv:2405.02298</a> [<a href="/pdf/2405.02298" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02298" title="Download PostScript">ps</a>, <a href="/format/2405.02298"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Development and Validation of an Artificial Neural Network
                    for the Recognition of Custom Dataset with YOLOv4
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Veysi%2C+P">P. Veysi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Adeli%2C+M">M. Adeli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Naziri%2C+N+P">N. Peirov Naziri</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>

                </div>
                <p class="mathjax">The expanding applications, utilized by more users, enhance hardware
                    performance and further develop cloud systems for big data processing. This
                    leads to numerous unexplored deep learning applications, especially in advanced
                    computer vision for object recognition. Deep learning in image processing
                    encompasses varied tasks from recognizing elements with diverse shapes and
                    sizes to complex element classification, coping with varying backgrounds and
                    lighting conditions, and text recognition. Its advantages lie in robust setup
                    and high performance for recognizing complex elements. This work aims to
                    develop a deep learning-based detection system for automated recognition of
                    assembly components differing in geometry, size, contour, or color.
                    Implementing the YOLOv4 algorithm, the system detects components based on their
                    characteristics. Testing with 13 components involves capturing them in
                    different orientations, numbers, individual parts, or assembled groups using a
                    Raspberry Pi microcontroller and camera. Evaluation focuses on correct object
                    recognition, confidence values, different compositions, distances between
                    objects, and environmental factors affecting system quality. Results show
                    positive object recognition across all scenarios, irrespective of orientation
                    or number of objects. Even densely packed objects are correctly recognized with
                    high confidence (97-100%). Lighting conditions don't significantly impact
                    results, and all objects are properly labeled. The developed system is suitable
                    for real-time two-dimensional component detection, with potential for extension
                    to three-dimensional analysis using multiple cameras with varied positioning
                    and views.
                </p>
            </div>
        </dd>
        <dt><a name="item11">[11]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02299"
                    title="Abstract">arXiv:2405.02299</a> [<a href="/pdf/2405.02299" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02299" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Reinforcement Learning for Modelling Protein Complexes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+T">Tao Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Ziqi Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=You%2C+J">Jiaxuan You</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zi%2C+C">Chenyi Zi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yan Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chen Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jia Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> International Conference on Learning Representations (ICLR
                    2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">AlphaFold can be used for both single-chain and multi-chain protein structure
                    prediction, while the latter becomes extremely challenging as the number of
                    chains increases. In this work, by taking each chain as a node and assembly
                    actions as edges, we show that an acyclic undirected connected graph can be
                    used to predict the structure of multi-chain protein complexes (a.k.a., protein
                    complex modelling, PCM). However, there are still two challenges: 1) The huge
                    combinatorial optimization space of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-35"
                                style="width: 3.07em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.549em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1002.55em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-36"><span class="msubsup"
                                                id="MathJax-Span-37"><span
                                                    style="display: inline-block; position: relative; width: 2.549em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-38"
                                                            style="font-family: MathJax_Math-italic;">N<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.987em;"><span
                                                            class="texatom" id="MathJax-Span-39"><span class="mrow"
                                                                id="MathJax-Span-40"><span class="mi"
                                                                    id="MathJax-Span-41"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">N<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                    class="mo" id="MathJax-Span-42"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-43"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">2</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-4">N^{N-2}</script> (<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-44"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-45"><span class="mi" id="MathJax-Span-46"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-5">N</script> is the number of chains) for
                    the PCM problem can easily lead to high computational cost. 2) The scales of
                    protein complexes exhibit distribution shift due to variance in chain numbers,
                    which calls for the generalization in modelling complexes of various scales. To
                    address these challenges, we propose GAPN, a Generative Adversarial Policy
                    Network powered by domain-specific rewards and adversarial loss through policy
                    gradient for automatic PCM prediction. Specifically, GAPN learns to efficiently
                    search through the immense assembly space and optimize the direct docking
                    reward through policy gradient. Importantly, we design an adversarial reward
                    function to enhance the receptive field of our model. In this way, GAPN will
                    simultaneously focus on a specific batch of complexes and the global assembly
                    rules learned from complexes with varied chain numbers. Empirically, we have
                    achieved both significant accuracy (measured by RMSD and TM-Score) and
                    efficiency improvements compared to leading PCM softwares. GAPN outperforms the
                    state-of-the-art method (MoLPC) with up to 27% improvement in TM-Score, with a
                    speed-up of 600 times. Our code is released at
                    \url{https://github.com/ft2023/GAPN}.
                </p>
            </div>
        </dd>
        <dt><a name="item12">[12]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02301"
                    title="Abstract">arXiv:2405.02301</a> [<a href="/pdf/2405.02301" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02301" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TFCounter:Polishing Gems for Training-Free Object Counting
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ting%2C+P">Pan Ting</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jianfeng Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+W">Wenhao Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenlong Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaoying Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jinlu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+B">Binqiang Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14pages,11 figuers
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Object counting is a challenging task with broad application prospects in
                    security surveillance, traffic management, and disease diagnosis. Existing
                    object counting methods face a tri-fold challenge: achieving superior
                    performance, maintaining high generalizability, and minimizing annotation
                    costs. We develop a novel training-free class-agnostic object counter,
                    TFCounter, which is prompt-context-aware via the cascade of the essential
                    elements in large-scale foundation models. This approach employs an iterative
                    counting framework with a dual prompt system to recognize a broader spectrum of
                    objects varying in shape, appearance, and size. Besides, it introduces an
                    innovative context-aware similarity module incorporating background context to
                    enhance accuracy within messy scenes. To demonstrate cross-domain
                    generalizability, we collect a novel counting dataset named BIKE-1000,
                    including exclusive 1000 images of shared bicycles from Meituan. Extensive
                    experiments on FSC-147, CARPK, and BIKE-1000 datasets demonstrate that
                    TFCounter outperforms existing leading training-free methods and exhibits
                    competitive results compared to trained counterparts.
                </p>
            </div>
        </dd>
        <dt><a name="item13">[13]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02302"
                    title="Abstract">arXiv:2405.02302</a> [<a href="/pdf/2405.02302" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02302" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Democratization of Wealth Management: Hedged Mutual Fund
                    Blockchain Protocol
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kashyap%2C+R">Ravi Kashyap</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Computational Finance (q-fin.CP); Portfolio Management (q-fin.PM); Risk
                    Management (q-fin.RM); Trading and Market Microstructure (q-fin.TR)

                </div>
                <p class="mathjax">We develop several innovations designed to bring the best practices of
                    traditional investment funds to the blockchain landscape. Our innovations
                    combine the superior mechanisms of mutual funds and hedge funds. Specifically,
                    we illustrate how fund prices can be updated regularly like mutual funds and
                    performance fees can be charged like hedge funds. We show how mutually hedged
                    blockchain investment funds can operate with investor protection schemes - high
                    water marks - and measures to offset trading slippage when redemptions happen.
                    We provide detailed steps - including mathematical formulations and instructive
                    pointers - to implement these ideas as blockchain smart contracts. We discuss
                    how our designs overcome several blockchain bottlenecks and how we can make
                    smart contracts smarter. We provide numerical illustrations of several
                    scenarios related to the mechanisms we have tailored for blockchain
                    implementation.
                    <br>The concepts we have developed for blockchain implementation can also be
                    useful in traditional financial funds to calculate performance fees in a
                    simplified manner. We highlight two main issues with the operation of mutual
                    funds and hedge funds and show how blockchain technology can alleviate those
                    concerns. The ideas developed here illustrate on one hand, how blockchain can
                    solve many issues faced by the traditional world and on the other hand, how
                    many innovations from traditional finance can benefit decentralized finance and
                    speed its adoption. This becomes an example of symbiosis between decentralized
                    and traditional finance - bringing these two realms closer and breaking down
                    barriers between such artificial distinctions - wherein the future will be
                    about providing better risk adjusted wealth appreciation opportunities to end
                    customers through secure, reliable, accessible and transparent services -
                    without getting too caught up about how such services are being rendered.
                </p>
            </div>
        </dd>
        <dt><a name="item14">[14]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02303"
                    title="Abstract">arXiv:2405.02303</a> [<a href="/pdf/2405.02303" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02303" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhanced Thermal Management in High-Temperature Applications:
                    Design and Optimization of a Water-Cooled Forced Convection System in a Hollow Cuboid Vapour Chamber
                    Using COMSOL and MATLAB
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Colelough%2C+b+C">brandon Curtis Colelough</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages, 52 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">This report details the design and optimisation of a water-cooled forced
                    convection heat dissipation system for use in high-temperature applications
                    (ranges between 700 degrees - 1000 degrees K). A hollow cuboid vapour chamber
                    model was investigated. The space within the hollow cuboid was used as the
                    design space. COMSOL, a FEM software product was used to solve for the physical
                    parameters of each geometry for the heat dissipation system design space.
                    COMSOL in conjunction with MATLAB was used for the parametric and density-based
                    topology optimisation of the geometric design in the design space. The goal of
                    the optimization is the minimisation of a temperature gradient over the design
                    space. This allows the heat to be evenly spread throughout the designed mesh
                    which allows for more effective cooling. To reduce the computational time
                    needed to solve and optimise each geometry in 3D, a 2D representation was
                    created for the front and rear faces of the hollow cuboid setup. These 2D face
                    designs were then extrapolated into 3D over the length of the hollow cube and
                    COMSOL was used to find a solution for each model. This report also proposes a
                    use case for this system wherein it would be used in conjunction with MGA and
                    thermometric technology within coal-fired power stations for the extraction and
                    storage of waste heat for later use.
                </p>
            </div>
        </dd>
        <dt><a name="item15">[15]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02305"
                    title="Abstract">arXiv:2405.02305</a> [<a href="/pdf/2405.02305" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02305" title="Download PostScript">ps</a>, <a href="/format/2405.02305"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Inserting Faces inside Captions: Image Captioning with
                    Attention Guided Merging
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tevissen%2C+Y">Yannis Tevissen</a> (ARMEDIA-SAMOVAR,
                    ML),
                    <a href="/search/cs?searchtype=author&amp;query=Guetari%2C+K">Khalil Guetari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tassel%2C+M">Marine Tassel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kerleroux%2C+E">Erwan Kerleroux</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Petitpont%2C+F">Frédéric Petitpont</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL);
                    Image and Video Processing (eess.IV)

                </div>
                <p class="mathjax">Image captioning models are widely used to describe recent and archived
                    pictures with the objective of improving their accessibility and retrieval.
                    Yet, these approaches tend to be inefficient and biased at retrieving people's
                    names. In this work we introduce AstroCaptions, a dataset for the image
                    captioning task. This dataset specifically contains thousands of public
                    fig-ures that are complex to identify for a traditional model. We also propose
                    a novel post-processing method to insert identified people's names inside the
                    caption using explainable AI tools and the grounding capabilities of
                    vi-sion-language models. The results obtained with this method show
                    signifi-cant improvements of captions quality and a potential of reducing
                    halluci-nations. Up to 93.2% of the persons detected can be inserted in the
                    image captions leading to improvements in the BLEU, ROUGE, CIDEr and METEOR
                    scores of each captioning model.
                </p>
            </div>
        </dd>
        <dt><a name="item16">[16]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02310"
                    title="Abstract">arXiv:2405.02310</a> [<a href="/pdf/2405.02310" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02310" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Simulating the aftermath of Northern European Enclosure Dam
                    (NEED) break and flooding of European coast
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Maczuga%2C+P">Paweł Maczuga</a>,
                    <a href="/search/cs?searchtype=author&amp;query=%C5%81o%C5%9B%2C+M">Marcin Łoś</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Valseth%2C+E">Eirik Valseth</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Serra%2C+A+O">Albert Oliver Serra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Siwik%2C+L">Leszek Siwik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Celaya%2C+E+A">Elisabede Alberdi Celaya</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Paszy%C5%84ska%2C+A">Anna Paszyńska</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Paszy%C5%84ski%2C+M">Maciej Paszyński</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 24 pages, 32 figures, 1 table
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA); Atmospheric and Oceanic
                    Physics (physics.ao-ph)

                </div>
                <p class="mathjax">The Northern European Enclosure Dam (NEED) is a hypothetical project to
                    prevent flooding in European countries following the rising ocean level due to
                    melting arctic glaciers. This project involves the construction of two large
                    dams between Scotland and Norway, as well as England and France. The
                    anticipated cost of this project is 250 to 500 billion euros. In this paper, we
                    present the simulation of the aftermath of flooding on the European coastline
                    caused by a catastrophic break of this hypothetical dam. From our simulation
                    results, we can observe that there is a traveling wave after the accident, with
                    a velocity of around 10 kilometers per hour, raising the sea level permanently
                    inside the dammed region. This observation implies a need to construct
                    additional dams or barriers protecting the northern coastline of the
                    Netherlands and the interior of the Baltic Sea. Our simulations have been
                    obtained using the following building blocks. First, a graph transformation
                    model was applied to generate an adaptive mesh approximating the topography of
                    the Earth. We employ the composition graph grammar model for breaking
                    triangular elements in the mesh without the generation of hanging nodes.
                    Second, the wave equation is formulated in a spherical latitude-longitude
                    system of coordinates and solved by a high-order time integration scheme using
                    the generalized <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-6-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-47"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-48"><span class="mi" id="MathJax-Span-49"
                                                style="font-family: MathJax_Math-italic;">α</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-6">\alpha</script> method.
                </p>
            </div>
        </dd>
        <dt><a name="item17">[17]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02312"
                    title="Abstract">arXiv:2405.02312</a> [<a href="/pdf/2405.02312" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02312" title="Download PostScript">ps</a>, <a href="/format/2405.02312"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> YOLOv5 vs. YOLOv8 in Marine Fisheries: Balancing Class
                    Detection and Instance Count
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Masum%2C+M+I">Mahmudul Islam Masum</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sarwat%2C+A">Arif Sarwat</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Riggs%2C+H">Hugo Riggs</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boymelgreen%2C+A">Alicia Boymelgreen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dey%2C+P">Preyojon Dey</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 25 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

                </div>
                <p class="mathjax">This paper presents a comparative study of object detection using YOLOv5 and
                    YOLOv8 for three distinct classes: artemia, cyst, and excrement. In this
                    comparative study, we analyze the performance of these models in terms of
                    accuracy, precision, recall, etc. where YOLOv5 often performed better in
                    detecting Artemia and cysts with excellent precision and accuracy. However,
                    when it came to detecting excrement, YOLOv5 faced notable challenges and
                    limitations. This suggests that YOLOv8 offers greater versatility and
                    adaptability in detection tasks while YOLOv5 may struggle in difficult
                    situations and may need further fine-tuning or specialized training to enhance
                    its performance. The results show insights into the suitability of YOLOv5 and
                    YOLOv8 for detecting objects in challenging marine environments, with
                    implications for applications such as ecological research.
                </p>
            </div>
        </dd>
        <dt><a name="item18">[18]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02314"
                    title="Abstract">arXiv:2405.02314</a> [<a href="/pdf/2405.02314" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02314" title="Download PostScript">ps</a>, <a href="/format/2405.02314"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A geometric framework for interstellar discourse on
                    fundamental physical structures
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Esposito%2C+G">Giampiero Esposito</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fionda%2C+V">Valeria Fionda</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 2 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Computation and Language (cs.CL)

                </div>
                <p class="mathjax">This paper considers the possibility that abstract thinking and advanced
                    synthesis skills might encourage extraterrestrial civilizations to accept
                    communication with mankind on Earth. For this purpose, a notation not relying
                    upon the use of alphabet and numbers is proposed, in order to denote just some
                    basic geometric structures of current physical theories: vector fields,
                    one-form fields, and tensor fields of arbitrary order. An advanced civilization
                    might appreciate the way here proposed to achieve a concise description of
                    electromagnetism and general relativity, and hence it might accept the
                    challenge of responding to our signals. The abstract symbols introduced in this
                    paper to describe the basic structures of physical theories are encoded into
                    black and white bitmap images that can be easily converted into short bit
                    sequences and modulated on a carrier wave for radio transmission.
                </p>
            </div>
        </dd>
        <dt><a name="item19">[19]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02316"
                    title="Abstract">arXiv:2405.02316</a> [<a href="/pdf/2405.02316" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02316" title="Download PostScript">ps</a>, <a href="/format/2405.02316"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Cloud-Edge Framework for Energy-Efficient Event-Driven
                    Control: An Integration of Online Supervised Learning, Spiking Neural Networks and Local Plasticity
                    Rules
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Ahmadvand%2C+R">Reza Ahmadvand</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Sharif%2C+S+S">Sarah Safura Sharif</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Banad%2C+Y+M">Yaser Mike Banad</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages, 19 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and
                    Evolutionary Computing (cs.NE)

                </div>
                <p class="mathjax">This paper presents a novel cloud-edge framework for addressing computational
                    and energy constraints in complex control systems. Our approach centers around
                    a learning-based controller using Spiking Neural Networks (SNN) on physical
                    plants. By integrating a biologically plausible learning method with local
                    plasticity rules, we harness the efficiency, scalability, and low latency of
                    SNNs. This design replicates control signals from a cloud-based controller
                    directly on the plant, reducing the need for constant plant-cloud
                    communication. The plant updates weights only when errors surpass predefined
                    thresholds, ensuring efficiency and robustness in various conditions. Applied
                    to linear workbench systems and satellite rendezvous scenarios, including
                    obstacle avoidance, our architecture dramatically lowers normalized tracking
                    error by 96% with increased network size. The event-driven nature of SNNs
                    minimizes energy consumption, utilizing only about 111 nJ (0.3% of conventional
                    computing requirements). The results demonstrate the system's adjustment to
                    changing work environments and its efficient use of computational and energy
                    resources, with a moderate increase in energy consumption of 27.2% and 37% for
                    static and dynamic obstacles, respectively, compared to non-obstacle scenarios.
                </p>
            </div>
        </dd>
        <dt><a name="item20">[20]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02317"
                    title="Abstract">arXiv:2405.02317</a> [<a href="/pdf/2405.02317" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02317" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Long-term Human Participation Assessment In Collaborative
                    Learning Environments Using Dynamic Scene Analysis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+W">Wenjing Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tran%2C+P">Phuong Tran</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Celed%C3%B3n-Pattichis%2C+S">Sylvia
                        Celedón-Pattichis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pattichis%2C+M+S">Marios S. Pattichis</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

                </div>
                <p class="mathjax">The paper develops datasets and methods to assess student participation in
                    real-life collaborative learning environments. In collaborative learning
                    environments, students are organized into small groups where they are free to
                    interact within their group. Thus, students can move around freely causing
                    issues with strong pose variation, move out and re-enter the camera scene, or
                    face away from the camera. We formulate the problem of assessing student
                    participation into two subproblems: (i) student group detection against strong
                    background interference from other groups, and (ii) dynamic participant
                    tracking within the group. A massive independent testing dataset of 12,518,250
                    student label instances, of total duration of 21 hours and 22 minutes of
                    real-life videos, is used for evaluating the performance of our proposed method
                    for student group detection. The proposed method of using multiple image
                    representations is shown to perform equally or better than YOLO on all video
                    instances. Over the entire dataset, the proposed method achieved an F1 score of
                    0.85 compared to 0.80 for YOLO. Following student group detection, the paper
                    presents the development of a dynamic participant tracking system for assessing
                    student group participation through long video sessions. The proposed dynamic
                    participant tracking system is shown to perform exceptionally well, missing a
                    student in just one out of 35 testing videos. In comparison, a state of the art
                    method fails to track students in 14 out of the 35 testing videos. The proposed
                    method achieves 82.3% accuracy on an independent set of long, real-life
                    collaborative videos.
                </p>
            </div>
        </dd>
        <dt><a name="item21">[21]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02318"
                    title="Abstract">arXiv:2405.02318</a> [<a href="/pdf/2405.02318" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02318" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> NL2FOL: Translating Natural Language to First-Order Logic for
                    Logical Fallacy Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lalwani%2C+A">Abhinav Lalwani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chopra%2C+L">Lovish Chopra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hahn%2C+C">Christopher Hahn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Trippel%2C+C">Caroline Trippel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Z">Zhijing Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sachan%2C+M">Mrinmaya Sachan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer
                    Science (cs.LO)

                </div>
                <p class="mathjax">Logical fallacies are common errors in reasoning that undermine the logic of
                    an argument. Automatically detecting logical fallacies has important
                    applications in tracking misinformation and validating claims. In this paper,
                    we design a process to reliably detect logical fallacies by translating natural
                    language to First-order Logic (FOL) step-by-step using Large Language Models
                    (LLMs). We then utilize Satisfiability Modulo Theory (SMT) solvers to reason
                    about the validity of the formula and classify inputs as either a fallacy or
                    valid statement. Our model also provides a novel means of utilizing LLMs to
                    interpret the output of the SMT solver, offering insights into the
                    counter-examples that illustrate why a given sentence is considered a logical
                    fallacy. Our approach is robust, interpretable and does not require training
                    data or fine-tuning. We evaluate our model on a mixed dataset of fallacies and
                    valid sentences. The results demonstrate improved performance compared to
                    end-to-end LLMs, with our classifier achieving an F1-score of 71\% on the Logic
                    dataset. The approach is able to generalize effectively, achieving an F1-score
                    of 73% on the challenge set, LogicClimate, outperforming state-of-the-art
                    models by 21% despite its much smaller size.
                </p>
            </div>
        </dd>
        <dt><a name="item22">[22]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02320"
                    title="Abstract">arXiv:2405.02320</a> [<a href="/pdf/2405.02320" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02320" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A SER-based Device Selection Mechanism in Multi-bits
                    Quantization Federated Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+P">Pengcheng Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+E">Erwu Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+R">Rui Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">The quality of wireless communication will directly affect the performance of
                    federated learning (FL), so this paper analyze the influence of wireless
                    communication on FL through symbol error rate (SER). In FL system,
                    non-orthogonal multiple access (NOMA) can be used as the basic communication
                    framework to reduce the communication congestion and interference caused by
                    multiple users, which takes advantage of the superposition characteristics of
                    wireless channels. The Minimum Mean Square Error (MMSE) based serial
                    interference cancellation (SIC) technology is used to recover the gradient of
                    each terminal node one by one at the receiving end. In this paper, the gradient
                    parameters are quantized into multiple bits to retain more gradient information
                    to the maximum extent and to improve the tolerance of transmission errors. On
                    this basis, we designed the SER-based device selection mechanism (SER-DSM) to
                    ensure that the learning performance is not affected by users with bad
                    communication conditions, while accommodating as many users as possible to
                    participate in the learning process, which is inclusive to a certain extent.
                    The experiments show the influence of multi-bit quantization of gradient on FL
                    and the necessity and superiority of the proposed SER-based device selection
                    mechanism.
                </p>
            </div>
        </dd>
        <dt><a name="item23">[23]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02321"
                    title="Abstract">arXiv:2405.02321</a> [<a href="/pdf/2405.02321" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02321" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Accelerating Medical Knowledge Discovery through Automated
                    Knowledge Graph Generation and Enrichment
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Khalid%2C+M">Mutahira Khalid</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rahman%2C+R">Raihana Rahman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abbas%2C+A">Asim Abbas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kumari%2C+S">Sushama Kumari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wajahat%2C+I">Iram Wajahat</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bukhari%2C+S+A+C">Syed Ahmad Chan Bukhari</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Information Retrieval (cs.IR)

                </div>
                <p class="mathjax">Knowledge graphs (KGs) serve as powerful tools for organizing and
                    representing structured knowledge. While their utility is widely recognized,
                    challenges persist in their automation and completeness. Despite efforts in
                    automation and the utilization of expert-created ontologies, gaps in
                    connectivity remain prevalent within KGs. In response to these challenges, we
                    propose an innovative approach termed ``Medical Knowledge Graph Automation
                    (M-KGA)". M-KGA leverages user-provided medical concepts and enriches them
                    semantically using BioPortal ontologies, thereby enhancing the completeness of
                    knowledge graphs through the integration of pre-trained embeddings. Our
                    approach introduces two distinct methodologies for uncovering hidden
                    connections within the knowledge graph: a cluster-based approach and a
                    node-based approach. Through rigorous testing involving 100 frequently
                    occurring medical concepts in Electronic Health Records (EHRs), our M-KGA
                    framework demonstrates promising results, indicating its potential to address
                    the limitations of existing knowledge graph automation techniques.
                </p>
            </div>
        </dd>
        <dt><a name="item24">[24]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02323"
                    title="Abstract">arXiv:2405.02323</a> [<a href="/pdf/2405.02323" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02323" title="Download PostScript">ps</a>, <a href="/format/2405.02323"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CNN-Based Equalization for Communications: Achieving Gigabit
                    Throughput with a Flexible FPGA Hardware Architecture
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ney%2C+J">Jonas Ney</a>,
                    <a href="/search/cs?searchtype=author&amp;query=F%C3%BCllner%2C+C">Christoph Füllner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lauinger%2C+V">Vincent Lauinger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schmalen%2C+L">Laurent Schmalen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Randel%2C+S">Sebastian Randel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wehn%2C+N">Norbert Wehn</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> The article was submitted to the International Journal of
                    Parallel Programming (IJPP) and is currently under review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture
                        (cs.AR)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

                </div>
                <p class="mathjax">To satisfy the growing throughput demand of data-intensive applications, the
                    performance of optical communication systems increased dramatically in recent
                    years. With higher throughput, more advanced equalizers are crucial, to
                    compensate for impairments caused by inter-symbol interference (ISI). The
                    latest research shows that artificial neural network (ANN)-based equalizers are
                    promising candidates to replace traditional algorithms for high-throughput
                    communications. On the other hand, not only throughput but also flexibility is
                    a main objective of beyond-5G and 6G communication systems. A platform that is
                    able to satisfy the strict throughput and flexibility requirements of modern
                    communication systems are field programmable gate arrays (FPGAs). Thus, in this
                    work, we present a high-performance FPGA implementation of an ANN-based
                    equalizer, which meets the throughput requirements of modern optical
                    communication systems. Further, our architecture is highly flexible since it
                    includes a variable degree of parallelism (DOP) and therefore can also be
                    applied to low-cost or low-power applications which is demonstrated for a
                    magnetic recording channel. The implementation is based on a cross-layer design
                    approach featuring optimizations from the algorithm down to the hardware
                    architecture, including a detailed quantization analysis. Moreover, we present
                    a framework to reduce the latency of the ANN-based equalizer under given
                    throughput constraints. As a result, the bit error ratio (BER) of our equalizer
                    for the optical fiber channel is around four times lower than that of a
                    conventional one, while the corresponding FPGA implementation achieves a
                    throughput of more than 40 GBd, outperforming a high-performance graphics
                    processing unit (GPU) by three orders of magnitude for a similar batch size.
                </p>
            </div>
        </dd>
        <dt><a name="item25">[25]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02324"
                    title="Abstract">arXiv:2405.02324</a> [<a href="/pdf/2405.02324" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02324" title="Download PostScript">ps</a>, <a href="/format/2405.02324"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Combined Compromise for Ideal Solution (CoCoFISo): a
                    multi-criteria decision-making based on the CoCoSo method algorithm
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Rasoanaivo%2C+R+G">Rôlin Gabriel Rasoanaivo</a>
                    (IRIT, UT Capitole, IRIT-ADRIA),
                    <a href="/search/cs?searchtype=author&amp;query=Yazdani%2C+M">Morteza Yazdani</a> (UIV),
                    <a href="/search/cs?searchtype=author&amp;query=Zarat%C3%A9%2C+P">Pascale Zaraté</a> (IRIT, UT
                    Capitole, IRIT-ADRIA),
                    <a href="/search/cs?searchtype=author&amp;query=Fateh%2C+A">Amirhossein Fateh</a> (UPV)
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Expert Systems with Applications, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">Each decision-making tool should be tested and validated in real case studies
                    to be practical and fit to global problems. The application of multi-criteria
                    decision-making methods (MCDM) is currently a trend to rank alternatives. In
                    the literature, there are several multi-criteria decision-making methods
                    according to their classification. During our experimentation on the Combined
                    Compromise Solution (CoCoSo) method, we encountered its limits for real cases.
                    The authors examined the applicability of the CoCoFISo method (improved version
                    of combined compromise solution), by a real case study in a university campus
                    and compared the obtained results to other MCDMs such as Preference Ranking
                    Organisation Method for Enrichment Evaluations (PROMETHEE), Weighted Sum Method
                    (WSM) and Technique for Order Preference by Similarity to the Ideal Solution
                    (TOPSIS). Our research finding indicates that CoCoSo is an applied method that
                    has been developed to solve complex multi variable assessment problems, while
                    CoCoFISo can improve the shortages observed in CoCoSo and deliver stable
                    outcomes compared to other developed tools. The findings imply that application
                    of CoCoFISo is suggested to decision makers, experts and researchers while they
                    are facing practical challenges and sensitive questions regarding the
                    utilization of a reliable decision-making method. Unlike many prior studies,
                    the current version of CoCoSo is unique, original and is presented for the
                    first time. Its performance was approved using several strategies and
                    examinations.
                </p>
            </div>
        </dd>
        <dt><a name="item26">[26]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02325"
                    title="Abstract">arXiv:2405.02325</a> [<a href="/pdf/2405.02325" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02325" title="Download PostScript">ps</a>, <a href="/format/2405.02325"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Meat Meets Machine! Multiscale Competency Enables Causal
                    Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bennett%2C+M+T">Michael Timothy Bennett</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Definitions shared with <a
                        href="/abs/2404.07227">arXiv:2404.07227</a>, <a href="/abs/2302.00843">arXiv:2302.00843</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">Biological intelligence uses a "multiscale competency architecture" (MCA). It
                    exhibits adaptive, goal directed behaviour at all scales, from cells to organs
                    to organisms. In contrast, machine intelligence is only adaptive and goal
                    directed at a high level. Learned policies are passively interpreted using
                    abstractions (e.g. arithmetic) embodied in static interpreters (e.g. x86).
                    Biological intelligence excels at causal learning. Machine intelligence does
                    not. Previous work showed causal learning follows from weak policy
                    optimisation, which is hindered by presupposed abstractions in silico. Here we
                    formalise MCAs as nested "agentic abstraction layers", to understand how they
                    might learn causes. We show that weak policy optimisation at low levels enables
                    weak policy optimisation at high. This facilitates what we call "multiscale
                    causal learning" and high level goal directed behaviour. We argue that by
                    engineering human abstractions in silico we disconnect high level goal directed
                    behaviour from the low level goal directed behaviour that gave rise to it. This
                    inhibits causal learning, and we speculate this is one reason why human recall
                    would be accompanied by feeling, and in silico recall not.
                </p>
            </div>
        </dd>
        <dt><a name="item27">[27]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02326"
                    title="Abstract">arXiv:2405.02326</a> [<a href="/pdf/2405.02326" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02326" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Evaluating LLMs for Hardware Design and Test
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Blocklove%2C+J">Jason Blocklove</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Garg%2C+S">Siddharth Garg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Karri%2C+R">Ramesh Karri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pearce%2C+H">Hammond Pearce</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture
                        (cs.AR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine
                    Learning (cs.LG); Programming Languages (cs.PL)

                </div>
                <p class="mathjax">Large Language Models (LLMs) have demonstrated capabilities for producing
                    code in Hardware Description Languages (HDLs). However, most of the focus
                    remains on their abilities to write functional code, not test code. The
                    hardware design process consists of both design and test, and so eschewing
                    validation and verification leaves considerable potential benefit unexplored,
                    given that a design and test framework may allow for progress towards full
                    automation of the digital design pipeline. In this work, we perform one of the
                    first studies exploring how a LLM can both design and test hardware modules
                    from provided specifications. Using a suite of 8 representative benchmarks, we
                    examined the capabilities and limitations of the state-of-the-art
                    conversational LLMs when producing Verilog for functional and verification
                    purposes. We taped out the benchmarks on a Skywater 130nm shuttle and received
                    the functional chip.
                </p>
            </div>
        </dd>
        <dt><a name="item28">[28]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02327"
                    title="Abstract">arXiv:2405.02327</a> [<a href="/pdf/2405.02327" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02327" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CausalDisco: Causal discovery using knowledge graph link
                    prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jaimini%2C+U">Utkarshani Jaimini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Henson%2C+C">Cory Henson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sheth%2C+A+P">Amit P. Sheth</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 8 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">Causal discovery is a process of discovering new causal relations from
                    observational data. Traditional causal discovery methods often suffer from
                    issues related to missing data To address these issues, this paper presents a
                    novel approach called CausalDisco that formulates causal discovery as a
                    knowledge graph completion problem. More specifically, the task of discovering
                    causal relations is mapped to the task of knowledge graph link prediction.
                    CausalDisco supports two types of discovery: causal explanation and causal
                    prediction. The causal relations have weights representing the strength of the
                    causal association between entities in the knowledge graph. An evaluation of
                    this approach uses a benchmark dataset of simulated videos for causal
                    reasoning, CLEVRER-Humans, and compares the performance of multiple knowledge
                    graph embedding algorithms. In addition, two distinct dataset splitting
                    approaches are utilized within the evaluation: (1) random-based split, which is
                    the method typically used to evaluate link prediction algorithms, and (2)
                    Markov-based split, a novel data split technique for evaluating link prediction
                    that utilizes the Markovian property of the causal relation. Results show that
                    using weighted causal relations improves causal discovery over the baseline
                    without weighted relations.
                </p>
            </div>
        </dd>
        <dt><a name="item29">[29]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02329"
                    title="Abstract">arXiv:2405.02329</a> [<a href="/pdf/2405.02329" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02329" title="Download PostScript">ps</a>, <a href="/format/2405.02329"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Digital ASIC Design with Ongoing LLMs: Strategies and
                    Prospects
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xiang%2C+M">Maoyang Xiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goh%2C+E">Emil Goh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Teo%2C+T+H">T. Hui Teo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 2 figures, 1 table
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture
                        (cs.AR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">The escalating complexity of modern digital systems has imposed significant
                    challenges on integrated circuit (IC) design, necessitating tools that can
                    simplify the IC design flow. The advent of Large Language Models (LLMs) has
                    been seen as a promising development, with the potential to automate the
                    generation of Hardware Description Language (HDL) code, thereby streamlining
                    digital IC design. However, the practical application of LLMs in this area
                    faces substantial hurdles. Notably, current LLMs often generate HDL code with
                    small but critical syntax errors and struggle to accurately convey the
                    high-level semantics of circuit designs. These issues significantly undermine
                    the utility of LLMs for IC design, leading to misinterpretations and
                    inefficiencies.
                    <br>In response to these challenges, this paper presents targeted strategies to
                    harness the capabilities of LLMs for digital ASIC design. We outline approaches
                    that improve the reliability and accuracy of HDL code generation by LLMs. As a
                    practical demonstration of these strategies, we detail the development of a
                    simple three-phase Pulse Width Modulation (PWM) generator. This project, part
                    of the "Efabless AI-Generated Open-Source Chip Design Challenge," successfully
                    passed the Design Rule Check (DRC) and was fabricated, showcasing the potential
                    of LLMs to enhance digital ASIC design. This work underscores the feasibility
                    and benefits of integrating LLMs into the IC design process, offering a novel
                    approach to overcoming the complexities of modern digital systems.
                </p>
            </div>
        </dd>
        <dt><a name="item30">[30]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02330"
                    title="Abstract">arXiv:2405.02330</a> [<a href="/pdf/2405.02330" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02330" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adaptive Semantic Token Selection for AI-native Goal-oriented
                    Communications
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Devoto%2C+A">Alessio Devoto</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Petruzzi%2C+S">Simone Petruzzi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pomponi%2C+J">Jary Pomponi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Di+Lorenzo%2C+P">Paolo Di Lorenzo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Scardapane%2C+S">Simone Scardapane</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In this paper, we propose a novel design for AI-native goal-oriented
                    communications, exploiting transformer neural networks under dynamic inference
                    constraints on bandwidth and computation. Transformers have become the standard
                    architecture for pretraining large-scale vision and text models, and
                    preliminary results have shown promising performance also in deep joint
                    source-channel coding (JSCC). Here, we consider a dynamic model where
                    communication happens over a channel with variable latency and bandwidth
                    constraints. Leveraging recent works on conditional computation, we exploit the
                    structure of the transformer blocks and the multihead attention operator to
                    design a trainable semantic token selection mechanism that learns to select
                    relevant tokens (e.g., image patches) from the input signal. This is done
                    dynamically, on a per-input basis, with a rate that can be chosen as an
                    additional input by the user. We show that our model improves over
                    state-of-the-art token selection mechanisms, exhibiting high accuracy for a
                    wide range of latency and bandwidth constraints, without the need for deploying
                    multiple architectures tailored to each constraint. Last, but not least, the
                    proposed token selection mechanism helps extract powerful semantics that are
                    easy to understand and explain, paving the way for interpretable-by-design
                    models for the next generation of AI-native communication systems.
                </p>
            </div>
        </dd>
        <dt><a name="item31">[31]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02332"
                    title="Abstract">arXiv:2405.02332</a> [<a href="/pdf/2405.02332" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02332" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient Exploration of Image Classifier Failures with
                    Bayesian Optimization and Text-to-Image Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Coz%2C+A+L">Adrien Le Coz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ouertatani%2C+H">Houssem Ouertatani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Herbin%2C+S">Stéphane Herbin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Adjed%2C+F">Faouzi Adjed</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Generative Models for Computer Vision - CVPR 2024
                    Workshop, Jun
                    2024, Seattle, United States
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Image classifiers should be used with caution in the real world. Performance
                    evaluated on a validation set may not reflect performance in the real world. In
                    particular, classifiers may perform well for conditions that are frequently
                    encountered during training, but poorly for other infrequent conditions. In
                    this study, we hypothesize that recent advances in text-to-image generative
                    models make them valuable for benchmarking computer vision models such as image
                    classifiers: they can generate images conditioned by textual prompts that cause
                    classifier failures, allowing failure conditions to be described with textual
                    attributes. However, their generation cost becomes an issue when a large number
                    of synthetic images need to be generated, which is the case when many different
                    attribute combinations need to be tested. We propose an image classifier
                    benchmarking method as an iterative process that alternates image generation,
                    classifier evaluation, and attribute selection. This method efficiently
                    explores the attributes that ultimately lead to poor behavior detection.
                </p>
            </div>
        </dd>
        <dt><a name="item32">[32]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02333"
                    title="Abstract">arXiv:2405.02333</a> [<a href="/pdf/2405.02333" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02333" title="Download PostScript">ps</a>, <a href="/format/2405.02333"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Speech Technology Services for Oral History Research
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Draxler%2C+C">Christoph Draxler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=van+den+Heuvel%2C+H">Henk van den Heuvel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=van+Hessen%2C+A">Arjan van Hessen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ircing%2C+P">Pavel Ircing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lehe%C4%8Dka%2C+J">Jan Lehečka</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages plus references, 3 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">Oral history is about oral sources of witnesses and commentors on historical
                    events. Speech technology is an important instrument to process such recordings
                    in order to obtain transcription and further enhancements to structure the oral
                    account In this contribution we address the transcription portal and the
                    webservices associated with speech processing at BAS, speech solutions
                    developed at LINDAT, how to do it yourself with Whisper, remaining challenges,
                    and future developments.
                </p>
            </div>
        </dd>
        <dt><a name="item33">[33]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02334"
                    title="Abstract">arXiv:2405.02334</a> [<a href="/pdf/2405.02334" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02334" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Rad4XCNN: a new agnostic method for post-hoc global
                    explanation of CNN-derived features by means of radiomics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Prinzi%2C+F">Francesco Prinzi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Militello%2C+C">Carmelo Militello</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zarcaro%2C+C">Calogero Zarcaro</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bartolotta%2C+T+V">Tommaso Vincenzo Bartolotta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gaglio%2C+S">Salvatore Gaglio</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vitabile%2C+S">Salvatore Vitabile</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In the last years, artificial intelligence (AI) in clinical decision support
                    systems (CDSS) played a key role in harnessing machine learning and deep
                    learning architectures. Despite their promising capabilities, the lack of
                    transparency and explainability of AI models poses significant challenges,
                    particularly in medical contexts where reliability is a mandatory aspect.
                    Achieving transparency without compromising predictive accuracy remains a key
                    challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
                    predictive power of CNN-derived features with the interpretability inherent in
                    radiomic features. Rad4XCNN diverges from conventional methods based on
                    saliency map, by associating intelligible meaning to CNN-derived features by
                    means of Radiomics, offering new perspectives on explanation methods beyond
                    visualization maps. Using a breast cancer classification task as a case study,
                    we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
                    dataset and two in-house datasets for internal and external validation. Some
                    key results are: i) CNN-derived features guarantee more robust accuracy when
                    compared against ViT-derived and radiomic features; ii) conventional
                    visualization map methods for explanation present several pitfalls; iii)
                    Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
                    Rad4XCNN provides global explanation insights enabling the physician to analyze
                    the model outputs and findings. In addition, we highlight the importance of
                    integrating interpretability into AI models for enhanced trust and adoption in
                    clinical practice, emphasizing how our method can mitigate some concerns
                    related to explainable AI methods.
                </p>
            </div>
        </dd>
        <dt><a name="item34">[34]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02335"
                    title="Abstract">arXiv:2405.02335</a> [<a href="/pdf/2405.02335" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02335" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> sDAC -- Semantic Digital Analog Converter for Semantic
                    Communications
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bao%2C+Z">Zhicheng Bao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+C">Chen Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiaodong Xu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In this paper, we propose a novel semantic digital analog converter (sDAC)
                    for the compatibility of semantic communications and digital communications.
                    Most of the current semantic communication systems are based on the analog
                    modulations, ignoring their incorporation with digital communication systems,
                    which are more common in practice. In fact, quantization methods in traditional
                    communication systems are not appropriate for use in the era of semantic
                    communication as these methods do not consider the semantic information inside
                    symbols. In this case, any bit flip caused by channel noise can lead to a great
                    performance drop. To address this challenge, sDAC is proposed. It is a simple
                    yet efficient and generative module used to realize digital and analog
                    bi-directional conversion. On the transmitter side, continuous values from the
                    encoder are converted to binary bits and then can be modulated by any existing
                    methods. After transmitting through the noisy channel, these bits get
                    demodulated by paired methods and converted back to continuous values for
                    further semantic decoding. The whole progress does not depend on any specific
                    semantic model, modulation methods, or channel conditions. In the experiment
                    section, the performance of sDAC is tested across different semantic models,
                    semantic tasks, modulation methods, channel conditions and quantization orders.
                    Test results show that the proposed sDAC has great generative properties and
                    channel robustness.
                </p>
            </div>
        </dd>
        <dt><a name="item35">[35]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02336"
                    title="Abstract">arXiv:2405.02336</a> [<a href="/pdf/2405.02336" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02336" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Artificial General Intelligence (AGI)-Native Wireless
                    Systems: A Journey Beyond 6G
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Saad%2C+W">Walid Saad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hashash%2C+O">Omar Hashash</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chaccour%2C+C">Christina Chaccour</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Debbah%2C+M">Merouane Debbah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mandayam%2C+N">Narayan Mandayam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+Z">Zhu Han</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Building future wireless systems that support services like digital twins
                    (DTs) is challenging to achieve through advances to conventional technologies
                    like meta-surfaces. While artificial intelligence (AI)-native networks promise
                    to overcome some limitations of wireless technologies, developments still rely
                    on AI tools like neural networks. Such tools struggle to cope with the
                    non-trivial challenges of the network environment and the growing demands of
                    emerging use cases. In this paper, we revisit the concept of AI-native wireless
                    systems, equipping them with the common sense necessary to transform them into
                    artificial general intelligence (AGI)-native systems. These systems acquire
                    common sense by exploiting different cognitive abilities such as perception,
                    analogy, and reasoning, that enable them to generalize and deal with unforeseen
                    scenarios. Towards developing the components of such a system, we start by
                    showing how the perception module can be built through abstracting real-world
                    elements into generalizable representations. These representations are then
                    used to create a world model, founded on principles of causality and
                    hyper-dimensional (HD) computing, that aligns with intuitive physics and
                    enables analogical reasoning, that define common sense. Then, we explain how
                    methods such as integrated information theory play a role in the proposed
                    intent-driven and objective-driven planning methods that maneuver the
                    AGI-native network to take actions. Next, we discuss how an AGI-native network
                    can enable use cases related to human and autonomous agents: a) analogical
                    reasoning for next-generation DTs, b) synchronized and resilient experiences
                    for cognitive avatars, and c) brain-level metaverse experiences like
                    holographic teleportation. Finally, we conclude with a set of recommendations
                    to build AGI-native systems. Ultimately, we envision this paper as a roadmap
                    for the beyond 6G era.
                </p>
            </div>
        </dd>
        <dt><a name="item36">[36]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02337"
                    title="Abstract">arXiv:2405.02337</a> [<a href="/pdf/2405.02337" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02337" title="Download PostScript">ps</a>, <a href="/format/2405.02337"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Design Fiction as Breaching Experiment: An Interdisciplinary
                    Methodology for Understanding the Acceptability and Adoption of Future Technologies
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Crabtree%2C+A">Andy Crabtree</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lodge%2C+T">Tom Lodge</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chamberlain%2C+A">Alan Chamberlain</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sailaja%2C+N">Neelima Sailaja</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Coulton%2C+P">Paul Coulton</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pilling%2C+M">Matthew Pilling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Forrester%2C+I">Ian Forrester</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 22 pages plus references
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">HCI is fundamentally occupied with the problem of the future and
                    understanding the acceptability and adoption challenges that future and
                    emerging technologies face from the viewpoint of their being situated in
                    everyday life. This paper explicates an interdisciplinary approach towards
                    addressing the problem and understanding acceptability and adoption challenges
                    that leverages design fiction as breaching experiment. Design fiction is an
                    arts based approach to exploring the future, breaching experiments a social
                    science method for explicating common sense reasoning and surfacing the taken
                    for granted expectations societys members have and hold about situated action
                    and how it should work. Both approaches have previously been employed in HCI,
                    but this the first time they have been combined to enable HCI researchers to
                    provoke through design the acceptability and adoption challenges that confront
                    future and emerging technologies.
                </p>
            </div>
        </dd>
        <dt><a name="item37">[37]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02338"
                    title="Abstract">arXiv:2405.02338</a> [<a href="/pdf/2405.02338" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02338" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mixed or Misperceived Reality?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+A+L">Aven Le Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xi%2C+L">Lei Xi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kang Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">"Surrealism Me" delves into Vil\'em Flusser's critique of media as mediators
                    that often distort human perception of reality through an interactive
                    virtual-embodying MR experience. It examines the obfuscating nature of media
                    and reveals the constructed nature of media-projected realities, prompting a
                    reevaluation of media's role and influence on our perception.
                </p>
            </div>
        </dd>
        <dt><a name="item38">[38]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02341"
                    title="Abstract">arXiv:2405.02341</a> [<a href="/pdf/2405.02341" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02341" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improved Communication-Privacy Trade-offs in <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-7-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-50"
                                style="width: 1.345em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.113em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.188em, 1001.11em, 1.299em, -999.998em); top: -1.016em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-51"><span class="msubsup"
                                                id="MathJax-Span-52"><span
                                                    style="display: inline-block; position: relative; width: 1.113em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.15em, 1000.65em, 4.123em, -999.998em); top: -3.979em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-53"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span
                                                        style="position: absolute; top: -3.84em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-54"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.021em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.219em; border-left: 0px solid; width: 0px; height: 1.114em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-7">L_2</script> Mean Estimation under Streaming
                    Differential Privacy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei-Ning Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Isik%2C+B">Berivan Isik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kairouz%2C+P">Peter Kairouz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=No%2C+A">Albert No</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Oh%2C+S">Sewoong Oh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zheng Xu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">We study <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-55"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.1em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-56"><span class="msubsup"
                                                id="MathJax-Span-57"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-58"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-59"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-8">L_2</script> mean estimation under central
                    differential privacy and
                    communication constraints, and address two key challenges: firstly, existing
                    mean estimation schemes that simultaneously handle both constraints are usually
                    optimized for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-9-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-60"
                                style="width: 1.739em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.45em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-61"><span class="msubsup"
                                                id="MathJax-Span-62"><span
                                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-63"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mi" id="MathJax-Span-64"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">∞</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-9">L_\infty</script> geometry and rely on random
                    rotation or Kashin's
                    representation to adapt to <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-65"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.1em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-66"><span class="msubsup"
                                                id="MathJax-Span-67"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-68"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-69"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-10">L_2</script> geometry, resulting in suboptimal
                    leading
                    constants in mean square errors (MSEs); secondly, schemes achieving
                    order-optimal communication-privacy trade-offs do not extend seamlessly to
                    streaming differential privacy (DP) settings (e.g., tree aggregation or matrix
                    factorization), rendering them incompatible with DP-FTRL type optimizers.
                    <br>In this work, we tackle these issues by introducing a novel privacy
                    accounting method for the sparsified Gaussian mechanism that incorporates the
                    randomness inherent in sparsification into the DP noise. Unlike previous
                    approaches, our accounting algorithm directly operates in <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-70"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.1em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-71"><span class="msubsup"
                                                id="MathJax-Span-72"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-73"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-74"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-11">L_2</script> geometry,
                    yielding MSEs that fast converge to those of the uncompressed Gaussian
                    mechanism. Additionally, we extend the sparsification scheme to the matrix
                    factorization framework under streaming DP and provide a precise accountant
                    tailored for DP-FTRL type optimizers. Empirically, our method demonstrates at
                    least a 100x improvement of compression for DP-SGD across various FL tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item39">[39]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02342"
                    title="Abstract">arXiv:2405.02342</a> [<a href="/pdf/2405.02342" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02342" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Birkhoff completion of finite lattices
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Abdulla%2C+M">Mohammad Abdulla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hirth%2C+J">Johannes Hirth</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stumme%2C+G">Gerd Stumme</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics
                        (cs.DM)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

                </div>
                <p class="mathjax">We introduce the Birkhoff completion as the smallest distributive lattice in
                    which a given finite lattice can be embedded as semi-lattice. We discuss its
                    relationship to implicational theories, in particular to R. Wille's
                    simply-implicational theories. By an example, we show how the Birkhoff
                    completion can be used as a tool for ordinal data science.
                </p>
            </div>
        </dd>
        <dt><a name="item40">[40]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02344"
                    title="Abstract">arXiv:2405.02344</a> [<a href="/pdf/2405.02344" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02344" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Backdoor-based Explainable AI Benchmark for High Fidelity
                    Evaluation of Attribution Methods
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+P">Peiyu Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Akhtar%2C+N">Naveed Akhtar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+J">Jiantong Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mian%2C+A">Ajmal Mian</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Attribution methods compute importance scores for input features to explain
                    the output predictions of deep models. However, accurate assessment of
                    attribution methods is challenged by the lack of benchmark fidelity for
                    attributing model predictions. Moreover, other confounding factors in
                    attribution estimation, including the setup choices of post-processing
                    techniques and explained model predictions, further compromise the reliability
                    of the evaluation. In this work, we first identify a set of fidelity criteria
                    that reliable benchmarks for attribution methods are expected to fulfill,
                    thereby facilitating a systematic assessment of attribution benchmarks. Next,
                    we introduce a Backdoor-based eXplainable AI benchmark (BackX) that adheres to
                    the desired fidelity criteria. We theoretically establish the superiority of
                    our approach over the existing benchmarks for well-founded attribution
                    evaluation. With extensive analysis, we also identify a setup for a consistent
                    and fair benchmarking of attribution methods across different underlying
                    methodologies. This setup is ultimately employed for a comprehensive comparison
                    of existing methods using our BackX benchmark. Finally, our analysis also
                    provides guidance for defending against backdoor attacks with the help of
                    attribution methods.
                </p>
            </div>
        </dd>
        <dt><a name="item41">[41]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02345"
                    title="Abstract">arXiv:2405.02345</a> [<a href="/pdf/2405.02345" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02345" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring the Capabilities of Large Language Models for
                    Generating Diverse Design Solutions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+K">Kevin Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Grandi%2C+D">Daniele Grandi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McComb%2C+C">Christopher McComb</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goucher-Lambert%2C+K">Kosa Goucher-Lambert</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> preprint of journal paper
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Access to large amounts of diverse design solutions can support designers
                    during the early stage of the design process. In this paper, we explore the
                    efficacy of large language models (LLM) in producing diverse design solutions,
                    investigating the level of impact that parameter tuning and various prompt
                    engineering techniques can have on the diversity of LLM-generated design
                    solutions. Specifically, LLMs are used to generate a total of 4,000 design
                    solutions across five distinct design topics, eight combinations of parameters,
                    and eight different types of prompt engineering techniques, comparing each
                    combination of parameter and prompt engineering method across four different
                    diversity metrics. LLM-generated solutions are compared against 100
                    human-crowdsourced solutions in each design topic using the same set of
                    diversity metrics. Results indicate that human-generated solutions consistently
                    have greater diversity scores across all design topics. Using a post hoc
                    logistic regression analysis we investigate whether these differences primarily
                    exist at the semantic level. Results show that there is a divide in some design
                    topics between humans and LLM-generated solutions, while others have no clear
                    divide. Taken together, these results contribute to the understanding of LLMs'
                    capabilities in generating a large volume of diverse design solutions and offer
                    insights for future research that leverages LLMs to generate diverse design
                    solutions for a broad range of design tasks (e.g., inspirational stimuli).
                </p>
            </div>
        </dd>
        <dt><a name="item42">[42]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02346"
                    title="Abstract">arXiv:2405.02346</a> [<a href="/pdf/2405.02346" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02346" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Temporal assessment of malicious behaviors: application to
                    turnout field data monitoring
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Abdellaoui%2C+S">Sara Abdellaoui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dumitrescu%2C+E">Emil Dumitrescu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Escudero%2C+C">Cédric Escudero</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zama%C3%AF%2C+E">Eric Zamaï</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To be published in the International Conference on
                    Control, Automation and Diagnosis (ICCAD24)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

                </div>
                <p class="mathjax">Monitored data collected from railway turnouts are vulnerable to
                    cyberattacks: attackers may either conceal failures or trigger unnecessary
                    maintenance actions. To address this issue, a cyberattack investigation method
                    is proposed based on predictions made from the temporal evolution of the
                    turnout behavior. These predictions are then compared to the field acquired
                    data to detect any discrepancy. This method is illustrated on a collection of
                    real-life data.
                </p>
            </div>
        </dd>
        <dt><a name="item43">[43]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02347"
                    title="Abstract">arXiv:2405.02347</a> [<a href="/pdf/2405.02347" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02347" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> COPAL: Continual Pruning in Large Language Generative Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Malla%2C+S">Srikanth Malla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+J+H">Joon Hee Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+C">Chiho Choi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to ICML2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">Adapting pre-trained large language models to different domains in natural
                    language processing requires two key considerations: high computational demands
                    and model's inability to continual adaptation. To simultaneously address both
                    issues, this paper presents COPAL (COntinual Pruning in Adaptive Language
                    settings), an algorithm developed for pruning large language generative models
                    under a continual model adaptation setting. While avoiding resource-heavy
                    finetuning or retraining, our pruning process is guided by the proposed
                    sensitivity analysis. The sensitivity effectively measures model's ability to
                    withstand perturbations introduced by the new dataset and finds model's weights
                    that are relevant for all encountered datasets. As a result, COPAL allows
                    seamless model adaptation to new domains while enhancing the resource
                    efficiency. Our empirical evaluation on a various size of LLMs show that COPAL
                    outperforms baseline models, demonstrating its efficacy in efficiency and
                    adaptability.
                </p>
            </div>
        </dd>
        <dt><a name="item44">[44]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02349"
                    title="Abstract">arXiv:2405.02349</a> [<a href="/pdf/2405.02349" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02349" title="Download PostScript">ps</a>, <a href="/format/2405.02349"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Explainable Muti-Label Classification of MBTI Types
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kong%2C+S">Siana Kong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sokolova%2C+M">Marina Sokolova</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 22 pages, 12 tables, 2 figure
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">In this study, we aim to identify the most effective machine learning model
                    for accurately classifying Myers-Briggs Type Indicator (MBTI) types from Reddit
                    posts and a Kaggle data set. We apply multi-label classification using the
                    Binary Relevance method. We use Explainable Artificial Intelligence (XAI)
                    approach to highlight the transparency and understandability of the process and
                    result. To achieve this, we experiment with glass-box learning models, i.e.
                    models designed for simplicity, transparency, and interpretability. We selected
                    k-Nearest Neighbour, Multinomial Naive Bayes, and Logistic Regression for the
                    glass-box models. We show that Multinomial Naive Bayes and k-Nearest Neighbour
                    perform better if classes with Observer (S) traits are excluded, whereas
                    Logistic Regression obtains its best results when all classes have &gt; 550
                    entries.
                </p>
            </div>
        </dd>
        <dt><a name="item45">[45]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02350"
                    title="Abstract">arXiv:2405.02350</a> [<a href="/pdf/2405.02350" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02350" title="Download PostScript">ps</a>, <a href="/format/2405.02350"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> What makes Models Compositional? A Theoretical View: With
                    Supplement
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ram%2C+P">Parikshit Ram</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Klinger%2C+T">Tim Klinger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gray%2C+A+G">Alexander G. Gray</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Extended version of the original IJCAI 2024 paper with
                    detailed supplementary materials (27 pages, 7 figures)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Compositionality is thought to be a key component of language, and various
                    compositional benchmarks have been developed to empirically probe the
                    compositional generalization of existing sequence processing models. These
                    benchmarks often highlight failures of existing models, but it is not clear why
                    these models fail in this way. In this paper, we seek to theoretically
                    understand the role the compositional structure of the models plays in these
                    failures and how this structure relates to their expressivity and sample
                    complexity. We propose a general neuro-symbolic definition of compositional
                    functions and their compositional complexity. We then show how various existing
                    general and special purpose sequence processing models (such as recurrent,
                    convolution and attention-based ones) fit this definition and use it to analyze
                    their compositional complexity. Finally, we provide theoretical guarantees for
                    the expressivity and systematic generalization of compositional models that
                    explicitly depend on our proposed definition and highlighting factors which
                    drive poor empirical performance.
                </p>
            </div>
        </dd>
        <dt><a name="item46">[46]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02351"
                    title="Abstract">arXiv:2405.02351</a> [<a href="/pdf/2405.02351" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02351" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards General Neural Surrogate Solvers with Specialized
                    Neural Accelerators
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mao%2C+C">Chenkai Mao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lupoiu%2C+R">Robert Lupoiu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+T">Tianxiang Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Mingkun Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+J+A">Jonathan A. Fan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 7 Figures, to be published in ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing
                    (cs.DC); Optics (physics.optics)

                </div>
                <p class="mathjax">Surrogate neural network-based partial differential equation (PDE) solvers
                    have the potential to solve PDEs in an accelerated manner, but they are largely
                    limited to systems featuring fixed domain sizes, geometric layouts, and
                    boundary conditions. We propose Specialized Neural Accelerator-Powered Domain
                    Decomposition Methods (SNAP-DDM), a DDM-based approach to PDE solving in which
                    subdomain problems containing arbitrary boundary conditions and geometric
                    parameters are accurately solved using an ensemble of specialized neural
                    operators. We tailor SNAP-DDM to 2D electromagnetics and fluidic flow problems
                    and show how innovations in network architecture and loss function engineering
                    can produce specialized surrogate subdomain solvers with near unity accuracy.
                    We utilize these solvers with standard DDM algorithms to accurately solve
                    freeform electromagnetics and fluids problems featuring a wide range of domain
                    sizes.
                </p>
            </div>
        </dd>
        <dt><a name="item47">[47]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02353"
                    title="Abstract">arXiv:2405.02353</a> [<a href="/pdf/2405.02353" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02353" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Early Transformers: A study on Efficient Training of
                    Transformer Models through Early-Bird Lottery Tickets
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cheekati%2C+S">Shravan Cheekati</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">The training of Transformer models has revolutionized natural language
                    processing and computer vision, but it remains a resource-intensive and
                    time-consuming process. This paper investigates the applicability of the
                    early-bird ticket hypothesis to optimize the training efficiency of Transformer
                    models. We propose a methodology that combines iterative pruning, masked
                    distance calculation, and selective retraining to identify early-bird tickets
                    in various Transformer architectures, including ViT, Swin-T, GPT-2, and
                    RoBERTa. Our experimental results demonstrate that early-bird tickets can be
                    consistently found within the first few epochs of training or fine-tuning,
                    enabling significant resource optimization without compromising performance.
                    The pruned models obtained from early-bird tickets achieve comparable or even
                    superior accuracy to their unpruned counterparts while substantially reducing
                    memory usage. Furthermore, our comparative analysis highlights the
                    generalizability of the early-bird ticket phenomenon across different
                    Transformer models and tasks. This research contributes to the development of
                    efficient training strategies for Transformer models, making them more
                    accessible and resource-friendly. By leveraging early-bird tickets,
                    practitioners can accelerate the progress of natural language processing and
                    computer vision applications while reducing the computational burden associated
                    with training Transformer models.
                </p>
            </div>
        </dd>
        <dt><a name="item48">[48]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02354"
                    title="Abstract">arXiv:2405.02354</a> [<a href="/pdf/2405.02354" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02354" title="Download PostScript">ps</a>, <a href="/format/2405.02354"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Heterogeneous network and graph attention auto-encoder for
                    LncRNA-disease association prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jin-Xing Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xi%2C+W">Wen-Yu Xi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+L">Ling-Yun Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+C">Chun-Hou Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Ying-Lian Gao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 8 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

                </div>
                <p class="mathjax">The emerging research shows that lncRNAs are associated with a series of
                    complex human diseases. However, most of the existing methods have limitations
                    in identifying nonlinear lncRNA-disease associations (LDAs), and it remains a
                    huge challenge to predict new LDAs. Therefore, the accurate identification of
                    LDAs is very important for the warning and treatment of diseases. In this work,
                    multiple sources of biomedical data are fully utilized to construct
                    characteristics of lncRNAs and diseases, and linear and nonlinear
                    characteristics are effectively integrated. Furthermore, a novel deep learning
                    model based on graph attention automatic encoder is proposed, called HGATELDA.
                    To begin with, the linear characteristics of lncRNAs and diseases are created
                    by the miRNA-lncRNA interaction matrix and miRNA-disease interaction matrix.
                    Following this, the nonlinear features of diseases and lncRNAs are extracted
                    using a graph attention auto-encoder, which largely retains the critical
                    information and effectively aggregates the neighborhood information of nodes.
                    In the end, LDAs can be predicted by fusing the linear and nonlinear
                    characteristics of diseases and lncRNA. The HGATELDA model achieves an
                    impressive AUC value of 0.9692 when evaluated using a 5-fold cross-validation
                    indicating its superior performance in comparison to several recent prediction
                    models. Meanwhile, the effectiveness of HGATELDA in identifying novel LDAs is
                    further demonstrated by case studies. the HGATELDA model appears to be a viable
                    computational model for predicting LDAs.
                </p>
            </div>
        </dd>
        <dt><a name="item49">[49]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02355"
                    title="Abstract">arXiv:2405.02355</a> [<a href="/pdf/2405.02355" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02355" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CodeGRAG: Extracting Composed Syntax Graphs for Retrieval
                    Augmented Cross-Lingual Code Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Du%2C+K">Kounianhua Du</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rui%2C+R">Renting Rui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chai%2C+H">Huacan Chai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+L">Lingyue Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+W">Wei Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yasheng Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+R">Ruiming Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yong Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weinan Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Utilizing large language models to generate codes has shown promising meaning
                    in software development revolution. Despite the intelligence shown by the
                    general large language models, their specificity in code generation can still
                    be improved due to the syntactic gap and mismatched vocabulary existing among
                    natural language and different programming languages. In addition, programming
                    languages are inherently logical and complex, making them hard to be correctly
                    generated. Existing methods rely on multiple prompts to the large language
                    model to explore better solutions, which is expensive. In this paper, we
                    propose Syntax Graph Retrieval Augmented Code Generation (CodeGRAG) to enhance
                    the performance of LLMs in single-round code generation tasks. CodeGRAG
                    extracts and summarizes the control flow and data flow of code blocks to fill
                    the gap between programming languages and natural language. The extracted
                    external structural knowledge models the inherent flows of code blocks, which
                    can facilitate LLMs for better understanding of code syntax and serve as a
                    bridge among different programming languages. CodeGRAG significantly improves
                    the code generation ability of LLMs and can even offer performance gain for
                    cross-lingual code generation, e.g., C++ for Python.
                </p>
            </div>
        </dd>
        <dt><a name="item50">[50]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02356"
                    title="Abstract">arXiv:2405.02356</a> [<a href="/pdf/2405.02356" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02356" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Stochastic Multivariate Universal-Radix Finite-State Machine:
                    a Theoretically and Practically Elegant Nonlinear Function Approximator
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+X">Xincheng Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+G">Guodong Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Jianhao Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Meng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wong%2C+N">Ngai Wong</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Nonlinearities are crucial for capturing complex input-output relationships
                    especially in deep neural networks. However, nonlinear functions often incur
                    various hardware and compute overheads. Meanwhile, stochastic computing (SC)
                    has emerged as a promising approach to tackle this challenge by trading output
                    precision for hardware simplicity. To this end, this paper proposes a
                    first-of-its-kind stochastic multivariate universal-radix finite-state machine
                    (SMURF) that harnesses SC for hardware-simplistic multivariate nonlinear
                    function generation at high accuracy. We present the finite-state machine (FSM)
                    architecture for SMURF, as well as analytical derivations of sampling gate
                    coefficients for accurately approximating generic nonlinear functions.
                    Experiments demonstrate the superiority of SMURF, requiring only 16.07% area
                    and 14.45% power consumption of Taylor-series approximation, and merely 2.22%
                    area of look-up table (LUT) schemes.
                </p>
            </div>
        </dd>
        <dt><a name="item51">[51]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02357"
                    title="Abstract">arXiv:2405.02357</a> [<a href="/pdf/2405.02357" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02357" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Large Language Models for Mobility in Transportation Systems:
                    A Survey on Forecasting Tasks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zijian Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yujie Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zepu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nie%2C+Y">Yuqi Nie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiaobo Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+P">Peng Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Ruolin Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Mobility analysis is a crucial element in the research area of transportation
                    systems. Forecasting traffic information offers a viable solution to address
                    the conflict between increasing transportation demands and the limitations of
                    transportation infrastructure. Predicting human travel is significant in aiding
                    various transportation and urban management tasks, such as taxi dispatch and
                    urban planning. Machine learning and deep learning methods are favored for
                    their flexibility and accuracy. Nowadays, with the advent of large language
                    models (LLMs), many researchers have combined these models with previous
                    techniques or applied LLMs to directly predict future traffic information and
                    human travel behaviors. However, there is a lack of comprehensive studies on
                    how LLMs can contribute to this field. This survey explores existing approaches
                    using LLMs for mobility forecasting problems. We provide a literature review
                    concerning the forecasting applications within transportation systems,
                    elucidating how researchers utilize LLMs, showcasing recent state-of-the-art
                    advancements, and identifying the challenges that must be overcome to fully
                    leverage LLMs in this domain.
                </p>
            </div>
        </dd>
        <dt><a name="item52">[52]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02358"
                    title="Abstract">arXiv:2405.02358</a> [<a href="/pdf/2405.02358" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02358" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Survey of Time Series Foundation Models: Generalizing Time
                    Series Representation with Large Language Mode
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+J">Jiexia Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weiqi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yi%2C+K">Ke Yi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yongzi Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Ziyue Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jia Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tsung%2C+F">Fugee Tsung</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 figures, 6 tables, 41 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Time series data are ubiquitous across various domains, making time series
                    analysis critically important. Traditional time series models are
                    task-specific, featuring singular functionality and limited generalization
                    capacity. Recently, large language foundation models have unveiled their
                    remarkable capabilities for cross-task transferability, zero-shot/few-shot
                    learning, and decision-making explainability. This success has sparked interest
                    in the exploration of foundation models to solve multiple time series
                    challenges simultaneously. There are two main research lines, namely
                    \textbf{pre-training foundation models from scratch for time series} and
                    \textbf{adapting large language foundation models for time series}. They both
                    contribute to the development of a unified model that is highly generalizable,
                    versatile, and comprehensible for time series analysis. This survey offers a 3E
                    analytical framework for comprehensive examination of related research.
                    Specifically, we examine existing works from three dimensions, namely
                    \textbf{Effectiveness}, \textbf{Efficiency} and \textbf{Explainability}. In
                    each dimension, we focus on discussing how related works devise tailored
                    solution by considering unique challenges in the realm of time
                    series.Furthermore, we provide a domain taxonomy to help followers keep up with
                    the domain-specific advancements. In addition, we introduce extensive resources
                    to facilitate the field's development, including datasets, open-source, time
                    series libraries. A GitHub repository is also maintained for resource updates
                    (https://github.com/start2020/Awesome-TimeSeries-LLM-FM).
                </p>
            </div>
        </dd>
        <dt><a name="item53">[53]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02359"
                    title="Abstract">arXiv:2405.02359</a> [<a href="/pdf/2405.02359" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02359" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CVTGAD: Simplified Transformer with Cross-View Attention for
                    Unsupervised Graph-level Anomaly Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jindong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xing%2C+Q">Qianli Xing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qi Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+Y">Yi Chang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Unsupervised graph-level anomaly detection (UGAD) has received remarkable
                    performance in various critical disciplines, such as chemistry analysis and
                    bioinformatics. Existing UGAD paradigms often adopt data augmentation
                    techniques to construct multiple views, and then employ different strategies to
                    obtain representations from different views for jointly conducting UGAD.
                    However, most previous works only considered the relationship between
                    nodes/graphs from a limited receptive field, resulting in some key structure
                    patterns and feature information being neglected. In addition, most existing
                    methods consider different views separately in a parallel manner, which is not
                    able to explore the inter-relationship across different views directly. Thus, a
                    method with a larger receptive field that can explore the inter-relationship
                    across different views directly is in need. In this paper, we propose a novel
                    Simplified Transformer with Cross-View Attention for Unsupervised Graph-level
                    Anomaly Detection, namely, CVTGAD. To increase the receptive field, we
                    construct a simplified transformer-based module, exploiting the relationship
                    between nodes/graphs from both intra-graph and inter-graph perspectives.
                    Furthermore, we design a cross-view attention mechanism to directly exploit the
                    view co-occurrence between different views, bridging the inter-view gap at node
                    level and graph level. To the best of our knowledge, this is the first work to
                    apply transformer and cross attention to UGAD, which realizes graph neural
                    network and transformer working collaboratively. Extensive experiments on 15
                    real-world datasets of 3 fields demonstrate the superiority of CVTGAD on the
                    UGAD task. The code is available at
                    \url{https://github.com/jindongli-Ai/CVTGAD}.
                </p>
            </div>
        </dd>
        <dt><a name="item54">[54]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02360"
                    title="Abstract">arXiv:2405.02360</a> [<a href="/pdf/2405.02360" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02360" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Holistic Evaluation Metrics: Use Case Sensitive Evaluation
                    Metrics for Federated Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yanli Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ibrahim%2C+J">Jehad Ibrahim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Huaming Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+D">Dong Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choo%2C+K+R">Kim-Kwang Raymond Choo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">A large number of federated learning (FL) algorithms have been proposed for
                    different applications and from varying perspectives. However, the evaluation
                    of such approaches often relies on a single metric (e.g., accuracy). Such a
                    practice fails to account for the unique demands and diverse requirements of
                    different use cases. Thus, how to comprehensively evaluate an FL algorithm and
                    determine the most suitable candidate for a designated use case remains an open
                    question. To mitigate this research gap, we introduce the Holistic Evaluation
                    Metrics (HEM) for FL in this work. Specifically, we collectively focus on three
                    primary use cases, which are Internet of Things (IoT), smart devices, and
                    institutions. The evaluation metric encompasses various aspects including
                    accuracy, convergence, computational efficiency, fairness, and personalization.
                    We then assign a respective importance vector for each use case, reflecting
                    their distinct performance requirements and priorities. The HEM index is
                    finally generated by integrating these metric components with their respective
                    importance vectors. Through evaluating different FL algorithms in these three
                    prevalent use cases, our experimental results demonstrate that HEM can
                    effectively assess and identify the FL algorithms best suited to particular
                    scenarios. We anticipate this work sheds light on the evaluation process for
                    pragmatic FL algorithms in real-world applications.
                </p>
            </div>
        </dd>
        <dt><a name="item55">[55]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02363"
                    title="Abstract">arXiv:2405.02363</a> [<a href="/pdf/2405.02363" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02363" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LLM as Dataset Analyst: Subpopulation Structure Discovery
                    with Large Language Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yulin Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=An%2C+R">Ruichuan An</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zou%2C+B">Bocheng Zou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yiming Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiaming Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shanghang Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL)

                </div>
                <p class="mathjax">The distribution of subpopulations is an important property hidden within a
                    dataset. Uncovering and analyzing the subpopulation distribution within
                    datasets provides a comprehensive understanding of the datasets, standing as a
                    powerful tool beneficial to various downstream tasks, including Dataset
                    Subpopulation Organization, Subpopulation Shift, and Slice Discovery. Despite
                    its importance, there has been no work that systematically explores the
                    subpopulation distribution of datasets to our knowledge. To address the
                    limitation and solve all the mentioned tasks in a unified way, we introduce a
                    novel concept of subpopulation structures to represent, analyze, and utilize
                    subpopulation distributions within datasets. To characterize the structures in
                    an interpretable manner, we propose the Subpopulation Structure Discovery with
                    Large Language Models (SSD-LLM) framework, which employs world knowledge and
                    instruction-following capabilities of Large Language Models (LLMs) to
                    linguistically analyze informative image captions and summarize the structures.
                    Furthermore, we propose complete workflows to address downstream tasks, named
                    Task-specific Tuning, showcasing the application of the discovered structure to
                    a spectrum of subpopulation-related tasks, including dataset subpopulation
                    organization, subpopulation shift, and slice discovery. Furthermore, we propose
                    complete workflows to address downstream tasks, named Task-specific Tuning,
                    showcasing the application of the discovered structure to a spectrum of
                    subpopulation-related tasks, including dataset subpopulation organization,
                    subpopulation shift, and slice discovery.
                </p>
            </div>
        </dd>
        <dt><a name="item56">[56]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02364"
                    title="Abstract">arXiv:2405.02364</a> [<a href="/pdf/2405.02364" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02364" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Survey on Contribution Evaluation in Vertical Federated
                    Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cui%2C+Y">Yue Cui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+C">Chung-ju Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuzhu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Leye Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+L">Lixin Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xiaofang Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Q">Qiang Yang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">Vertical Federated Learning (VFL) has emerged as a critical approach in
                    machine learning to address privacy concerns associated with centralized data
                    storage and processing. VFL facilitates collaboration among multiple entities
                    with distinct feature sets on the same user population, enabling the joint
                    training of predictive models without direct data sharing. A key aspect of VFL
                    is the fair and accurate evaluation of each entity's contribution to the
                    learning process. This is crucial for maintaining trust among participating
                    entities, ensuring equitable resource sharing, and fostering a sustainable
                    collaboration framework. This paper provides a thorough review of contribution
                    evaluation in VFL. We categorize the vast array of contribution evaluation
                    techniques along the VFL lifecycle, granularity of evaluation, privacy
                    considerations, and core computational methods. We also explore various tasks
                    in VFL that involving contribution evaluation and analyze their required
                    evaluation properties and relation to the VFL lifecycle phases. Finally, we
                    present a vision for the future challenges of contribution evaluation in VFL.
                    By providing a structured analysis of the current landscape and potential
                    advancements, this paper aims to guide researchers and practitioners in the
                    design and implementation of more effective, efficient, and privacy-centric VFL
                    solutions. Relevant literature and open-source resources have been compiled and
                    are being continuously updated at the GitHub repository:
                    \url{https://github.com/cuiyuebing/VFL_CE}.
                </p>
            </div>
        </dd>
        <dt><a name="item57">[57]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02365"
                    title="Abstract">arXiv:2405.02365</a> [<a href="/pdf/2405.02365" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02365" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adaptive and robust watermark against model extraction attack
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pang%2C+K">Kaiyi Pang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qi%2C+T">Tao Qi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Chuhan Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bai%2C+M">Minhao Bai</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Large language models have boosted Large Models as a Service (LMaaS) into a
                    thriving business sector. But even model owners offering only API access while
                    keeping model parameters and internal workings private, their Intellectual
                    Property (IP) are still at risk of theft through model extraction attacks. To
                    safeguard the IP of these models and mitigate unfair competition in the
                    language model market, watermarking technology serves as an efficient post-hoc
                    solution for identifying IP infringements. However, existing IP protection
                    watermarking methods either explicitly alter the original output of the
                    language model or implant watermark signals in the model logits. These methods
                    forcefully distort the original distribution of the language model and impact
                    the sampling process, leading to a decline in the quality of the generated
                    text. The existing method also fails to achieve end-to-end adaptive watermark
                    embedding and lack robustness verification in complex scenarios where watermark
                    detection is subject to interference. To overcome these challenges, we propose
                    PromptShield, a plug-and-play IP protection watermarking method to resist model
                    extraction attacks without training additional modules. Leveraging the
                    self-reminding properties inherent in large language models, we encapsulate the
                    user's query with a watermark self-generated instruction, nudging the LLMs to
                    automatically generate watermark words in its output without compromising
                    generation quality. Our method does not require access to the model's internal
                    logits and minimizes alterations to the model's distribution using
                    prompt-guided cues. Comprehensive experimental results consistently demonstrate
                    the effectiveness, harmlessness, and robustness of our watermark. Moreover, Our
                    watermark detection method remains robust and high detection sensitivity even
                    when subjected to interference.
                </p>
            </div>
        </dd>
        <dt><a name="item58">[58]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02367"
                    title="Abstract">arXiv:2405.02367</a> [<a href="/pdf/2405.02367" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02367" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing Social Media Post Popularity Prediction with Visual
                    Content
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jeong%2C+D">Dahyun Jeong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Son%2C+H">Hyelim Son</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+Y">Yunjin Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+K">Keunwoo Kim</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Our study presents a framework for predicting image-based social media
                    content popularity that focuses on addressing complex image information and a
                    hierarchical data structure. We utilize the Google Cloud Vision API to
                    effectively extract key image and color information from users' postings,
                    achieving 6.8\% higher accuracy compared to using non-image covariates alone.
                    For prediction, we explore a wide range of prediction models, including Linear
                    Mixed Model, Support Vector Regression, Multi-layer Perceptron, Random Forest,
                    and XGBoost, with linear regression as the benchmark. Our comparative study
                    demonstrates that models that are capable of capturing the underlying nonlinear
                    interactions between covariates outperform other methods.
                </p>
            </div>
        </dd>
        <dt><a name="item59">[59]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02369"
                    title="Abstract">arXiv:2405.02369</a> [<a href="/pdf/2405.02369" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02369" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> No One-Size-Fits-All Neurons: Task-based Neurons for
                    Artificial Neural Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+F">Feng-Lei Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Meng Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+H">Hang-Cheng Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+J">Jianwei Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+T">Tieyong Zeng</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Biologically, the brain does not rely on a single type of neuron that
                    universally functions in all aspects. Instead, it acts as a sophisticated
                    designer of task-based neurons. In this study, we address the following
                    question: since the human brain is a task-based neuron user, can the artificial
                    network design go from the task-based architecture design to the task-based
                    neuron design? Since methodologically there are no one-size-fits-all neurons,
                    given the same structure, task-based neurons can enhance the feature
                    representation ability relative to the existing universal neurons due to the
                    intrinsic inductive bias for the task. Specifically, we propose a two-step
                    framework for prototyping task-based neurons. First, symbolic regression is
                    used to identify optimal formulas that fit input data by utilizing base
                    functions such as logarithmic, trigonometric, and exponential functions. We
                    introduce vectorized symbolic regression that stacks all variables in a vector
                    and regularizes each input variable to perform the same computation, which can
                    expedite the regression speed, facilitate parallel computation, and avoid
                    overfitting. Second, we parameterize the acquired elementary formula to make
                    parameters learnable, which serves as the aggregation function of the neuron.
                    The activation functions such as ReLU and the sigmoidal functions remain the
                    same because they have proven to be good. Empirically, experimental results on
                    synthetic data, classic benchmarks, and real-world applications show that the
                    proposed task-based neuron design is not only feasible but also delivers
                    competitive performance over other state-of-the-art models.
                </p>
            </div>
        </dd>
        <dt><a name="item60">[60]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02370"
                    title="Abstract">arXiv:2405.02370</a> [<a href="/pdf/2405.02370" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02370" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Neuromorphic Correlates of Artificial Consciousness
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ulhaq%2C+A">Anwaar Ulhaq</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 Pages, 8 Figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">The concept of neural correlates of consciousness (NCC), which suggests that
                    specific neural activities are linked to conscious experiences, has gained
                    widespread acceptance. This acceptance is based on a wealth of evidence from
                    experimental studies, brain imaging techniques such as fMRI and EEG, and
                    theoretical frameworks like integrated information theory (IIT) within
                    neuroscience and the philosophy of mind. This paper explores the potential for
                    artificial consciousness by merging neuromorphic design and architecture with
                    brain simulations. It proposes the Neuromorphic Correlates of Artificial
                    Consciousness (NCAC) as a theoretical framework. While the debate on artificial
                    consciousness remains contentious due to our incomplete grasp of consciousness,
                    this work may raise eyebrows and invite criticism. Nevertheless, this
                    optimistic and forward-thinking approach is fueled by insights from the Human
                    Brain Project, advancements in brain imaging like EEG and fMRI, and recent
                    strides in AI and computing, including quantum and neuromorphic designs.
                    Additionally, this paper outlines how machine learning can play a role in
                    crafting artificial consciousness, aiming to realise machine consciousness and
                    awareness in the future.
                </p>
            </div>
        </dd>
        <dt><a name="item61">[61]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02371"
                    title="Abstract">arXiv:2405.02371</a> [<a href="/pdf/2405.02371" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02371" title="Download PostScript">ps</a>, <a href="/format/2405.02371"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Architecture of a Cortex Inspired Hierarchical Event Recaller
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Varona%2C+V+P">Valentin Puente Varona</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR);
                    Machine Learning (cs.LG)

                </div>
                <p class="mathjax">This paper proposes a new approach to Machine Learning (ML) that focuses on
                    unsupervised continuous context-dependent learning of complex patterns.
                    Although the proposal is partly inspired by some of the current knowledge about
                    the structural and functional properties of the mammalian brain, we do not
                    claim that biological systems work in an analogous way (nor the opposite).
                    Based on some properties of the cerebellar cortex and adjacent structures, a
                    proposal suitable for practical problems is presented. A synthetic structure
                    capable of identifying and predicting complex temporal series will be defined
                    and experimentally tested. The system relies heavily on prediction to help
                    identify and learn patterns based on previously acquired contextual knowledge.
                    As a proof of concept, the proposed system is shown to be able to learn,
                    identify and predict a remarkably complex temporal series such as human speech,
                    with no prior knowledge. From raw data, without any adaptation in the core
                    algorithm, the system is able to identify certain speech structures from a set
                    of Spanish sentences. Unlike conventional ML, the proposal can learn with a
                    reduced training set. Although the idea can be applied to a constrained
                    problem, such as the detection of unknown vocabulary in a speech, it could be
                    used in more applications, such as vision, or (by incorporating the missing
                    biological periphery) fit into other ML techniques. Given the trivial
                    computational primitives used, a potential hardware implementation will be
                    remarkably frugal. Coincidentally, the proposed model not only conforms to a
                    plausible functional framework for biological systems but may also explain many
                    elusive cognitive phenomena.
                </p>
            </div>
        </dd>
        <dt><a name="item62">[62]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02375"
                    title="Abstract">arXiv:2405.02375</a> [<a href="/pdf/2405.02375" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02375" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Sparse Tsetlin Machine: Sparse Representation with Active
                    Literals
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=%C3%98stby%2C+S">Sebastian Østby</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brambo%2C+T+M">Tobias M. Brambo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Glimsdal%2C+S">Sondre Glimsdal</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL)

                </div>
                <p class="mathjax">This paper introduces the Sparse Tsetlin Machine (STM), a novel Tsetlin
                    Machine (TM) that processes sparse data efficiently. Traditionally, the TM does
                    not consider data characteristics such as sparsity, commonly seen in NLP
                    applications and other bag-of-word-based representations. Consequently, a TM
                    must initialize, store, and process a significant number of zero values,
                    resulting in excessive memory usage and computational time. Previous attempts
                    at creating a sparse TM have predominantly been unsuccessful, primarily due to
                    their inability to identify which literals are sufficient for TM training. By
                    introducing Active Literals (AL), the STM can focus exclusively on literals
                    that actively contribute to the current data representation, significantly
                    decreasing memory footprint and computational time while demonstrating
                    competitive classification performance.
                </p>
            </div>
        </dd>
        <dt><a name="item63">[63]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02377"
                    title="Abstract">arXiv:2405.02377</a> [<a href="/pdf/2405.02377" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02377" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Robustness of Decentralised Learning to Nodes and Data
                    Disruption
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Palmieri%2C+L">Luigi Palmieri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boldrini%2C+C">Chiara Boldrini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Valerio%2C+L">Lorenzo Valerio</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Passarella%2C+A">Andrea Passarella</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Conti%2C+M">Marco Conti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kert%C3%A9sz%2C+J">János Kertész</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Supported by the H2020 HumaneAI Net (952026),
                    CHIST-ERA-19-XAI010 SAI, PNRR - M4C2 - Investimento 1.3, Partenariato Esteso PE00000013 FAIR, PNRR -
                    M4C2 - Investimento 1.3, Partenariato Esteso PE00000001 RESTART
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">In the vibrant landscape of AI research, decentralised learning is gaining
                    momentum. Decentralised learning allows individual nodes to keep data locally
                    where they are generated and to share knowledge extracted from local data among
                    themselves through an interactive process of collaborative refinement. This
                    paradigm supports scenarios where data cannot leave local nodes due to privacy
                    or sovereignty reasons or real-time constraints imposing proximity of models to
                    locations where inference has to be carried out. The distributed nature of
                    decentralised learning implies significant new research challenges with respect
                    to centralised learning. Among them, in this paper, we focus on robustness
                    issues. Specifically, we study the effect of nodes' disruption on the
                    collective learning process. Assuming a given percentage of "central" nodes
                    disappear from the network, we focus on different cases, characterised by (i)
                    different distributions of data across nodes and (ii) different times when
                    disruption occurs with respect to the start of the collaborative learning task.
                    Through these configurations, we are able to show the non-trivial interplay
                    between the properties of the network connecting nodes, the persistence of
                    knowledge acquired collectively before disruption or lack thereof, and the
                    effect of data availability pre- and post-disruption. Our results show that
                    decentralised learning processes are remarkably robust to network disruption.
                    As long as even minimum amounts of data remain available somewhere in the
                    network, the learning process is able to recover from disruptions and achieve
                    significant classification accuracy. This clearly varies depending on the
                    remaining connectivity after disruption, but we show that even nodes that
                    remain completely isolated can retain significant knowledge acquired before the
                    disruption.
                </p>
            </div>
        </dd>
        <dt><a name="item64">[64]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02378"
                    title="Abstract">arXiv:2405.02378</a> [<a href="/pdf/2405.02378" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02378" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Combining Crown Structures for Vulnerability Measures
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Casel%2C+K">Katrin Casel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Friedrich%2C+T">Tobias Friedrich</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Niklanovits%2C+A">Aikaterini Niklanovits</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Simonov%2C+K">Kirill Simonov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zeif%2C+Z">Ziena Zeif</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>

                </div>
                <p class="mathjax">Over the past decades, various metrics have emerged in graph theory to grasp
                    the complex nature of network vulnerability. In this paper, we study two
                    specific measures: (weighted) vertex integrity (wVI) and (weighted) component
                    order connectivity (wCOC). These measures not only evaluate the number of
                    vertices required to decompose a graph into fragments, but also take into
                    account the size of the largest remaining component. The main focus of our
                    paper is on kernelization algorithms tailored to both measures. We capitalize
                    on the structural attributes inherent in different crown decompositions,
                    strategically combining them to introduce novel kernelization algorithms that
                    advance the current state of the field. In particular, we extend the scope of
                    the balanced crown decomposition provided by Casel et al.~[7] and expand the
                    applicability of crown decomposition techniques.
                    <br>In summary, we improve the vertex kernel of VI from <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-75"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.93em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-76"><span class="msubsup"
                                                id="MathJax-Span-77"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.52em, 4.343em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-78"
                                                            style="font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-79"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-12">p^3</script> to <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-80"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.93em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-81"><span class="msubsup"
                                                id="MathJax-Span-82"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.52em, 4.343em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-83"
                                                            style="font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-84"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-13">p^2</script>, and of
                    wVI from <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-14-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-85"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.93em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-86"><span class="msubsup"
                                                id="MathJax-Span-87"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.52em, 4.343em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-88"
                                                            style="font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-89"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-14">p^3</script> to <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-90"
                                style="width: 7.063em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.848em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1005.73em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-91"><span class="mn" id="MathJax-Span-92"
                                                style="font-family: MathJax_Main;">3</span><span class="mo"
                                                id="MathJax-Span-93" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-94"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.52em, 4.343em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-95"
                                                            style="font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-96"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-97"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="msubsup" id="MathJax-Span-98"
                                                style="padding-left: 0.234em;"><span
                                                    style="display: inline-block; position: relative; width: 1.508em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.52em, 4.343em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-99"
                                                            style="font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="texatom" id="MathJax-Span-100"><span class="mrow"
                                                                id="MathJax-Span-101"><span class="mn"
                                                                    id="MathJax-Span-102"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1.5</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-103"><span
                                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.52em, 4.343em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-104"
                                                            style="font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.524em;"><span
                                                            class="texatom" id="MathJax-Span-105"><span class="mrow"
                                                                id="MathJax-Span-106"><span class="mi"
                                                                    id="MathJax-Span-107"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">ℓ</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-108"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-15">3(p^2 + p^{1.5} p_{\ell})</script>, where <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-16-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-109"
                                style="width: 3.302em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.723em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.45em, 1002.72em, 2.491em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-110"><span class="msubsup"
                                                id="MathJax-Span-111"><span
                                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.52em, 4.343em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-112"
                                                            style="font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.524em;"><span
                                                            class="texatom" id="MathJax-Span-113"><span class="mrow"
                                                                id="MathJax-Span-114"><span class="mi"
                                                                    id="MathJax-Span-115"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">ℓ</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-116"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">&lt;</span><span
                                                class="mi" id="MathJax-Span-117"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">p</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-16">p_{\ell} < p</script> represents
                    the weight of the heaviest component after removing a solution. For wCOC we
                    improve the vertex kernel from <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-118"
                                style="width: 8.278em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.889em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1006.77em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-119"><span class="texatom"
                                                id="MathJax-Span-120"><span class="mrow" id="MathJax-Span-121"><span
                                                        class="mi" id="MathJax-Span-122"
                                                        style="font-family: MathJax_Caligraphic;">O</span></span></span><span
                                                class="mo" id="MathJax-Span-123"
                                                style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                id="MathJax-Span-124"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.52em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-125"
                                                            style="font-family: MathJax_Math-italic;">k</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-126"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mi" id="MathJax-Span-127"
                                                style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-128"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mi" id="MathJax-Span-129"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">k</span><span
                                                class="msubsup" id="MathJax-Span-130"><span
                                                    style="display: inline-block; position: relative; width: 1.565em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.04em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-131"
                                                            style="font-family: MathJax_Math-italic;">W<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 1.16em;"><span
                                                            class="mn" id="MathJax-Span-132"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-133"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-17">\mathcal{O}(k^2W + kW^2)</script> to <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-18-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-134"
                                style="width: 7.41em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.137em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1006.02em, 2.781em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-135"><span class="mn" id="MathJax-Span-136"
                                                style="font-family: MathJax_Main;">3</span><span class="mi"
                                                id="MathJax-Span-137"
                                                style="font-family: MathJax_Math-italic;">μ</span><span class="mo"
                                                id="MathJax-Span-138" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-139"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mo"
                                                id="MathJax-Span-140"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="msqrt" id="MathJax-Span-141" style="padding-left: 0.234em;"><span
                                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.401em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                            class="mrow" id="MathJax-Span-142"><span class="mi"
                                                                id="MathJax-Span-143"
                                                                style="font-family: MathJax_Math-italic;">μ</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1000.64em, 3.938em, -999.997em); top: -4.337em; left: 0.813em;"><span
                                                            style="display: inline-block; position: relative; width: 0.639em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -3.817em; left: 0em;"><span
                                                            style="font-family: MathJax_Main;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mi" id="MathJax-Span-144"
                                                style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-145"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.552em; border-left: 0px solid; width: 0px; height: 1.531em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-18">3\mu(k +
    \sqrt{\mu}W)</script>, where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-19-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-146"
                                style="width: 7.989em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.658em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1006.54em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-147"><span class="mi" id="MathJax-Span-148"
                                                style="font-family: MathJax_Math-italic;">μ</span><span class="mo"
                                                id="MathJax-Span-149"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mo" id="MathJax-Span-150"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">max</span><span
                                                class="mo" id="MathJax-Span-151"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-152"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mo"
                                                id="MathJax-Span-153" style="font-family: MathJax_Main;">,</span><span
                                                class="mi" id="MathJax-Span-154"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-155"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-19">\mu = \max(k,W)</script>. We also give a
                    combinatorial algorithm
                    that provides a <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-20-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-156"
                                style="width: 2.549em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.09em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-157"><span class="mn" id="MathJax-Span-158"
                                                style="font-family: MathJax_Main;">2</span><span class="mi"
                                                id="MathJax-Span-159"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mi"
                                                id="MathJax-Span-160" style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-20">2kW</script> vertex kernel in FPT-runtime when
                    parameterized by <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-21-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-161"
                                style="width: 0.582em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.466em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-162"><span class="mi" id="MathJax-Span-163"
                                                style="font-family: MathJax_Math-italic;">r</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-21">r</script>,
                    where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-22-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-164"
                                style="width: 2.781em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.32em, 2.433em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-165"><span class="mi" id="MathJax-Span-166"
                                                style="font-family: MathJax_Math-italic;">r</span><span class="mo"
                                                id="MathJax-Span-167"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≤</span><span
                                                class="mi" id="MathJax-Span-168"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-22">r \leq k</script> is the size of a maximum <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-23-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-169"
                                style="width: 4.343em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.591em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1003.48em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-170"><span class="mo" id="MathJax-Span-171"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-172" style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-173"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mn" id="MathJax-Span-174"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">1</span><span
                                                class="mo" id="MathJax-Span-175"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-23">(W+1)</script>-packing. We further show that
                    the algorithm computing the <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-24-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-176"
                                style="width: 2.549em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.09em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-177"><span class="mn" id="MathJax-Span-178"
                                                style="font-family: MathJax_Main;">2</span><span class="mi"
                                                id="MathJax-Span-179"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mi"
                                                id="MathJax-Span-180" style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-24">2kW</script> vertex kernel for COC can be
                    transformed into
                    a polynomial algorithm for two special cases, namely when <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-25-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-181"
                                style="width: 3.591em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.954em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.9em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-182"><span class="mi" id="MathJax-Span-183"
                                                style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-184"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mn" id="MathJax-Span-185"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-25">W=1</script>, which
                    corresponds to the well-known vertex cover problem, and for claw-free graphs.
                    In particular, we show a new way to obtain a <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-26-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-186"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.04em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-187"><span class="mn" id="MathJax-Span-188"
                                                style="font-family: MathJax_Main;">2</span><span class="mi"
                                                id="MathJax-Span-189"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-26">2k</script> vertex kernel (or to obtain a
                    2-approximation) for the vertex cover problem by only using crown structures.
                </p>
            </div>
        </dd>
        <dt><a name="item65">[65]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02384"
                    title="Abstract">arXiv:2405.02384</a> [<a href="/pdf/2405.02384" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02384" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CogDPM: Diffusion Probabilistic Models via Cognitive
                    Predictive Coding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K">Kaiyuan Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+X">Xingzhuo Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianmin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Long%2C+M">Mingsheng Long</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Predictive Coding (PC) is a theoretical framework in cognitive science
                    suggesting that the human brain processes cognition through spatiotemporal
                    prediction of the visual world. Existing studies have developed spatiotemporal
                    prediction neural networks based on the PC theory, emulating its two core
                    mechanisms: Correcting predictions from residuals and hierarchical learning.
                    However, these models do not show the enhancement of prediction skills on
                    real-world forecasting tasks and ignore the Precision Weighting mechanism of PC
                    theory. The precision weighting mechanism posits that the brain allocates more
                    attention to signals with lower precision, contributing to the cognitive
                    ability of human brains. This work introduces the Cognitive Diffusion
                    Probabilistic Models (CogDPM), which demonstrate the connection between
                    diffusion probabilistic models and PC theory. CogDPM features a precision
                    estimation method based on the hierarchical sampling capabilities of diffusion
                    models and weight the guidance with precision weights estimated by the inherent
                    property of diffusion models. We experimentally show that the precision weights
                    effectively estimate the data predictability. We apply CogDPM to real-world
                    prediction tasks using the United Kindom precipitation and ERA surface wind
                    datasets. Our results demonstrate that CogDPM outperforms both existing
                    domain-specific operational models and general deep prediction models by
                    providing more proficient forecasting.
                </p>
            </div>
        </dd>
        <dt><a name="item66">[66]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02385"
                    title="Abstract">arXiv:2405.02385</a> [<a href="/pdf/2405.02385" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02385" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient Deep Learning with Decorrelated Backpropagation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dalm%2C+S">Sander Dalm</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Offergeld%2C+J">Joshua Offergeld</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ahmad%2C+N">Nasir Ahmad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=van+Gerven%2C+M">Marcel van Gerven</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">The backpropagation algorithm remains the dominant and most successful method
                    for training deep neural networks (DNNs). At the same time, training DNNs at
                    scale comes at a significant computational cost and therefore a high carbon
                    footprint. Converging evidence suggests that input decorrelation may speed up
                    deep learning. However, to date, this has not yet translated into substantial
                    improvements in training efficiency in large-scale DNNs. This is mainly caused
                    by the challenge of enforcing fast and stable network-wide decorrelation. Here,
                    we show for the first time that much more efficient training of very deep
                    neural networks using decorrelated backpropagation is feasible. To achieve this
                    goal we made use of a novel algorithm which induces network-wide input
                    decorrelation using minimal computational overhead. By combining this algorithm
                    with careful optimizations, we obtain a more than two-fold speed-up and higher
                    test accuracy compared to backpropagation when training a 18-layer deep
                    residual network. This demonstrates that decorrelation provides exciting
                    prospects for efficient deep learning at scale.
                </p>
            </div>
        </dd>
        <dt><a name="item67">[67]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02386"
                    title="Abstract">arXiv:2405.02386</a> [<a href="/pdf/2405.02386" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02386" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Rip-NeRF: Anti-aliasing Radiance Fields with Ripmap-Encoded
                    Platonic Solids
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Junchen Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+W">Wenbo Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhuo Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jianteng Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+G">Guoliang Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaoxue Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yantong Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+H">Huan-ang Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hao Zhao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> SIGGRAPH 2024, Project page: <a
                        href="https://junchenliu77.github.io/Rip-NeRF">this https URL</a> , Code: <a
                        href="https://github.com/JunchenLiu77/Rip-NeRF">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
                <p class="mathjax">Despite significant advancements in Neural Radiance Fields (NeRFs), the
                    renderings may still suffer from aliasing and blurring artifacts, since it
                    remains a fundamental challenge to effectively and efficiently characterize
                    anisotropic areas induced by the cone-casting procedure. This paper introduces
                    a Ripmap-Encoded Platonic Solid representation to precisely and efficiently
                    featurize 3D anisotropic areas, achieving high-fidelity anti-aliasing
                    renderings. Central to our approach are two key components: Platonic Solid
                    Projection and Ripmap encoding. The Platonic Solid Projection factorizes the 3D
                    space onto the unparalleled faces of a certain Platonic solid, such that the
                    anisotropic 3D areas can be projected onto planes with distinguishable
                    characterization. Meanwhile, each face of the Platonic solid is encoded by the
                    Ripmap encoding, which is constructed by anisotropically pre-filtering a
                    learnable feature grid, to enable featurzing the projected anisotropic areas
                    both precisely and efficiently by the anisotropic area-sampling. Extensive
                    experiments on both well-established synthetic datasets and a newly captured
                    real-world dataset demonstrate that our Rip-NeRF attains state-of-the-art
                    rendering quality, particularly excelling in the fine details of repetitive
                    structures and textures, while maintaining relatively swift training times.
                </p>
            </div>
        </dd>
        <dt><a name="item68">[68]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02411"
                    title="Abstract">arXiv:2405.02411</a> [<a href="/pdf/2405.02411" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02411" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Call for Socially Aware Language Technologies
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+D">Diyi Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hovy%2C+D">Dirk Hovy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jurgens%2C+D">David Jurgens</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Plank%2C+B">Barbara Plank</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Language technologies have made enormous progress, especially with the
                    introduction of large language models (LLMs). On traditional tasks such as
                    machine translation and sentiment analysis, these models perform at near-human
                    level. These advances can, however, exacerbate a variety of issues that models
                    have traditionally struggled with, such as bias, evaluation, and risks. In this
                    position paper, we argue that many of these issues share a common core: a lack
                    of awareness of the factors, context, and implications of the social
                    environment in which NLP operates, which we call social awareness. While NLP is
                    getting better at solving the formal linguistic aspects, limited progress has
                    been made in adding the social awareness required for language applications to
                    work in all situations for all users. Integrating social awareness into NLP
                    models will make applications more natural, helpful, and safe, and will open up
                    new possibilities. Thus we argue that substantial challenges remain for NLP to
                    develop social awareness and that we are just at the beginning of a new era for
                    the field.
                </p>
            </div>
        </dd>
        <dt><a name="item69">[69]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02412"
                    title="Abstract">arXiv:2405.02412</a> [<a href="/pdf/2405.02412" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02412" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Learning and Transfer Learning Architectures for English
                    Premier League Player Performance Forecasting
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Frees%2C+D">Daniel Frees</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ravella%2C+P">Pranav Ravella</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Charlie Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">This paper presents a groundbreaking model for forecasting English Premier
                    League (EPL) player performance using convolutional neural networks (CNNs). We
                    evaluate Ridge regression, LightGBM and CNNs on the task of predicting upcoming
                    player FPL score based on historical FPL data over the previous weeks. Our
                    baseline models, Ridge regression and LightGBM, achieve solid performance and
                    emphasize the importance of recent FPL points, influence, creativity, threat,
                    and playtime in predicting EPL player performances. Our optimal CNN
                    architecture achieves better performance with fewer input features and even
                    outperforms the best previous EPL player performance forecasting models in the
                    literature. The optimal CNN architecture also achieves very strong Spearman
                    correlation with player rankings, indicating its strong implications for
                    supporting the development of FPL artificial intelligence (AI) Agents and
                    providing analysis for FPL managers. We additionally perform transfer learning
                    experiments on soccer news data collected from The Guardian, for the same task
                    of predicting upcoming player score, but do not identify a strong predictive
                    signal in natural language news texts, achieving worse performance compared to
                    both the CNN and baseline models. Overall, our CNN-based approach marks a
                    significant advancement in EPL player performance forecasting and lays the
                    foundation for transfer learning to other EPL prediction tasks such as win-loss
                    odds for sports betting and the development of cutting-edge FPL AI Agents.
                </p>
            </div>
        </dd>
        <dt><a name="item70">[70]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02413"
                    title="Abstract">arXiv:2405.02413</a> [<a href="/pdf/2405.02413" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02413" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Unified Framework for Human-Allied Learning of
                    Probabilistic Circuits
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Karanam%2C+A">Athresh Karanam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mathur%2C+S">Saurabh Mathur</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sidheekh%2C+S">Sahil Sidheekh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Probabilistic Circuits (PCs) have emerged as an efficient framework for
                    representing and learning complex probability distributions. Nevertheless, the
                    existing body of research on PCs predominantly concentrates on data-driven
                    parameter learning, often neglecting the potential of knowledge-intensive
                    learning, a particular issue in data-scarce/knowledge-rich domains such as
                    healthcare. To bridge this gap, we propose a novel unified framework that can
                    systematically integrate diverse domain knowledge into the parameter learning
                    process of PCs. Experiments on several benchmarks as well as real world
                    datasets show that our proposed framework can both effectively and efficiently
                    leverage domain knowledge to achieve superior performance compared to purely
                    data-driven learning approaches.
                </p>
            </div>
        </dd>
        <dt><a name="item71">[71]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02417"
                    title="Abstract">arXiv:2405.02417</a> [<a href="/pdf/2405.02417" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02417" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Hierarchies define the scalability of robot swarms
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Varadharajan%2C+V+S">Vivek Shankar Varadharajan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Soma%2C+K">Karthik Soma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dyanatkar%2C+S">Sepand Dyanatkar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lajoie%2C+P">Pierre-Yves Lajoie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Beltrame%2C+G">Giovanni Beltrame</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 31 Pages, 7 Figures. Supplementary material attached to
                    the paper
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">The emerging behaviors of swarms have fascinated scientists and gathered
                    significant interest in the field of robotics. Traditionally, swarms are viewed
                    as egalitarian, with robots sharing identical roles and capabilities. However,
                    recent findings highlight the importance of hierarchy for deploying robot
                    swarms more effectively in diverse scenarios. Despite nature's preference for
                    hierarchies, the robotics field has clung to the egalitarian model, partly due
                    to a lack of empirical evidence for the conditions favoring hierarchies. Our
                    research demonstrates that while egalitarian swarms excel in environments
                    proportionate to their collective sensing abilities, they struggle in larger or
                    more complex settings. Hierarchical swarms, conversely, extend their sensing
                    reach efficiently, proving successful in larger, more unstructured environments
                    with fewer resources. We validated these concepts through simulations and
                    physical robot experiments, using a complex radiation cleanup task. This study
                    paves the way for developing adaptable, hierarchical swarm systems applicable
                    in areas like planetary exploration and autonomous vehicles. Moreover, these
                    insights could deepen our understanding of hierarchical structures in
                    biological organisms.
                </p>
            </div>
        </dd>
        <dt><a name="item72">[72]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02420"
                    title="Abstract">arXiv:2405.02420</a> [<a href="/pdf/2405.02420" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02420" title="Download PostScript">ps</a>, <a href="/format/2405.02420"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Inductive Reasoning with Equality Predicates, Contextual
                    Rewriting and Variant-Based Simplification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Meseguer%2C+J">Jose Meseguer</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted for publication
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>

                </div>
                <p class="mathjax">An inductive inference system for proving validity of formulas in the initial
                    algebra <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-27-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-190"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.04em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-191"><span class="msubsup"
                                                id="MathJax-Span-192"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.7em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-193"
                                                            style="font-family: MathJax_Math-italic;">T<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.582em;"><span
                                                            class="texatom" id="MathJax-Span-194"><span class="mrow"
                                                                id="MathJax-Span-195"><span class="texatom"
                                                                    id="MathJax-Span-196"><span class="mrow"
                                                                        id="MathJax-Span-197"><span class="mi"
                                                                            id="MathJax-Span-198"
                                                                            style="font-size: 70.7%; font-family: MathJax_Caligraphic;">E<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-27">T_{\mathcal{E}}</script> of an order-sorted
                    equational theory <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-28-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-199"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1000.58em, 2.202em, -999.997em); top: -2.023em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-200"><span class="texatom"
                                                id="MathJax-Span-201"><span class="mrow" id="MathJax-Span-202"><span
                                                        class="mi" id="MathJax-Span-203"
                                                        style="font-family: MathJax_Caligraphic;">E<span
                                                            style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.028em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-28">\mathcal{E}</script> is
                    presented. It has 20 inference rules, but only 9 of them require user
                    interaction; the remaining 11 can be automated as simplification rules. In this
                    way, a substantial fraction of the proof effort can be automated. The inference
                    rules are based on advanced equational reasoning techniques, including:
                    equationally defined equality predicates, narrowing, constructor variant
                    unification, variant satisfiability, order-sorted congruence closure,
                    contextual rewriting, ordered rewriting, and recursive path orderings. All
                    these techniques work modulo axioms <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-29-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-204"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.75em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-205"><span class="mi" id="MathJax-Span-206"
                                                style="font-family: MathJax_Math-italic;">B</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-29">B</script>, for <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-30-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-207"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.75em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-208"><span class="mi" id="MathJax-Span-209"
                                                style="font-family: MathJax_Math-italic;">B</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-30">B</script> any combination of
                    associativity and/or commutativity and/or identity axioms. Most of these
                    inference rules have already been implemented in Maude's NuITP inductive
                    theorem prover.
                </p>
            </div>
        </dd>
        <dt><a name="item73">[73]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02421"
                    title="Abstract">arXiv:2405.02421</a> [<a href="/pdf/2405.02421" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02421" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> What does the Knowledge Neuron Thesis Have to do with
                    Knowledge?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Niu%2C+J">Jingcheng Niu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+A">Andrew Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zining Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Penn%2C+G">Gerald Penn</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024 (Spotlight)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">We reassess the Knowledge Neuron (KN) Thesis: an interpretation of the
                    mechanism underlying the ability of large language models to recall facts from
                    a training corpus. This nascent thesis proposes that facts are recalled from
                    the training corpus through the MLP weights in a manner resembling key-value
                    memory, implying in effect that "knowledge" is stored in the network.
                    Furthermore, by modifying the MLP modules, one can control the language model's
                    generation of factual information. The plausibility of the KN thesis has been
                    demonstrated by the success of KN-inspired model editing methods (Dai et al.,
                    2022; Meng et al., 2022).
                    <br>We find that this thesis is, at best, an oversimplification. Not only have we
                    found that we can edit the expression of certain linguistic phenomena using the
                    same model editing methods but, through a more comprehensive evaluation, we
                    have found that the KN thesis does not adequately explain the process of
                    factual expression. While it is possible to argue that the MLP weights store
                    complex patterns that are interpretable both syntactically and semantically,
                    these patterns do not constitute "knowledge." To gain a more comprehensive
                    understanding of the knowledge representation process, we must look beyond the
                    MLP weights and explore recent models' complex layer structures and attention
                    mechanisms.
                </p>
            </div>
        </dd>
        <dt><a name="item74">[74]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02425"
                    title="Abstract">arXiv:2405.02425</a> [<a href="/pdf/2405.02425" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02425" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Learning Robot Soccer from Egocentric Vision with Deep
                    Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tirumala%2C+D">Dhruva Tirumala</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wulfmeier%2C+M">Markus Wulfmeier</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Moran%2C+B">Ben Moran</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+S">Sandy Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Humplik%2C+J">Jan Humplik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lever%2C+G">Guy Lever</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Haarnoja%2C+T">Tuomas Haarnoja</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hasenclever%2C+L">Leonard Hasenclever</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Byravan%2C+A">Arunkumar Byravan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Batchelor%2C+N">Nathan Batchelor</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sreendra%2C+N">Neil Sreendra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Patel%2C+K">Kushal Patel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gwira%2C+M">Marlon Gwira</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nori%2C+F">Francesco Nori</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Riedmiller%2C+M">Martin Riedmiller</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Heess%2C+N">Nicolas Heess</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">We apply multi-agent deep reinforcement learning (RL) to train end-to-end
                    robot soccer policies with fully onboard computation and sensing via egocentric
                    RGB vision. This setting reflects many challenges of real-world robotics,
                    including active perception, agile full-body control, and long-horizon planning
                    in a dynamic, partially-observable, multi-agent domain. We rely on large-scale,
                    simulation-based data generation to obtain complex behaviors from egocentric
                    vision which can be successfully transferred to physical robots using low-cost
                    sensors. To achieve adequate visual realism, our simulation combines rigid-body
                    physics with learned, realistic rendering via multiple Neural Radiance Fields
                    (NeRFs). We combine teacher-based multi-agent RL and cross-experiment data
                    reuse to enable the discovery of sophisticated soccer strategies. We analyze
                    active-perception behaviors including object tracking and ball seeking that
                    emerge when simply optimizing perception-agnostic soccer play. The agents
                    display equivalent levels of performance and agility as policies with access to
                    privileged, ground-truth state. To our knowledge, this paper constitutes a
                    first demonstration of end-to-end training for multi-agent robot soccer,
                    mapping raw pixel observations to joint-level actions, that can be deployed in
                    the real world. Videos of the game-play and analyses can be seen on our website
                    https://sites.google.com/view/vision-soccer .
                </p>
            </div>
        </dd>
        <dt><a name="item75">[75]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02429"
                    title="Abstract">arXiv:2405.02429</a> [<a href="/pdf/2405.02429" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02429" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CALRec: Contrastive Alignment of Generative LLMs For
                    Sequential Recommendation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yaoyiran Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+X">Xiang Zhai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alzantot%2C+M">Moustafa Alzantot</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+K">Keyi Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vuli%C4%87%2C+I">Ivan Vulić</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Korhonen%2C+A">Anna Korhonen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hammad%2C+M">Mohamed Hammad</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine
                    Learning (cs.LG)

                </div>
                <p class="mathjax">Traditional recommender systems such as matrix factorization methods rely on
                    learning a shared dense embedding space to represent both items and user
                    preferences. Sequence models such as RNN, GRUs, and, recently, Transformers
                    have also excelled in the task of sequential recommendation. This task requires
                    understanding the sequential structure present in users' historical
                    interactions to predict the next item they may like. Building upon the success
                    of Large Language Models (LLMs) in a variety of tasks, researchers have
                    recently explored using LLMs that are pretrained on vast corpora of text for
                    sequential recommendation. To use LLMs in sequential recommendations, both the
                    history of user interactions and the model's prediction of the next item are
                    expressed in text form. We propose CALRec, a two-stage LLM finetuning framework
                    that finetunes a pretrained LLM in a two-tower fashion using a mixture of two
                    contrastive losses and a language modeling loss: the LLM is first finetuned on
                    a data mixture from multiple domains followed by another round of target domain
                    finetuning. Our model significantly outperforms many state-of-the-art baselines
                    (+37% in Recall@1 and +24% in NDCG@10) and systematic ablation studies reveal
                    that (i) both stages of finetuning are crucial, and, when combined, we achieve
                    improved performance, and (ii) contrastive alignment is effective among the
                    target domains explored in our experiments.
                </p>
            </div>
        </dd>
        <dt><a name="item76">[76]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02430"
                    title="Abstract">arXiv:2405.02430</a> [<a href="/pdf/2405.02430" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02430" title="Download PostScript">ps</a>, <a href="/format/2405.02430"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> How to generate all possible rational Wilf-Zeilberger forms?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Shaoshi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Koutschan%2C+C">Christoph Koutschan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yisen Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation
                        (cs.SC)</span>

                </div>
                <p class="mathjax">Wilf-Zeilberger pairs are fundamental in the algorithmic theory of Wilf and
                    Zeilberger for computer-generated proofs of combinatorial identities.
                    Wilf-Zeilberger forms are their high-dimensional generalizations, which can be
                    used for proving and discovering convergence acceleration formulas. This paper
                    presents a structural description of all possible rational such forms, which
                    can be viewed as an additive analog of the classical Ore-Sato theorem. Based on
                    this analog, we show a structural decomposition of so-called multivariate
                    hyperarithmetic terms, which extend multivariate hypergeometric terms to the
                    additive setting.
                </p>
            </div>
        </dd>
        <dt><a name="item77">[77]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02431"
                    title="Abstract">arXiv:2405.02431</a> [<a href="/pdf/2405.02431" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02431" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Delphi: Efficient Asynchronous Approximate Agreement for
                    Distributed Oracles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bandarupalli%2C+A">Akhil Bandarupalli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bhat%2C+A">Adithya Bhat</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bagchi%2C+S">Saurabh Bagchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kate%2C+A">Aniket Kate</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu-Zhang%2C+C">Chen-Da Liu-Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reiter%2C+M+K">Michael K. Reiter</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 8 figures, Accepted to DSN 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

                </div>
                <p class="mathjax">Agreement protocols are crucial in various emerging applications, spanning
                    from distributed (blockchains) oracles to fault-tolerant cyber-physical
                    systems. In scenarios where sensor/oracle nodes measure a common source,
                    maintaining output within the convex range of correct inputs, known as convex
                    validity, is imperative. Present asynchronous convex agreement protocols employ
                    either randomization, incurring substantial computation overhead, or
                    approximate agreement techniques, leading to high <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-31-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-210"
                                style="width: 3.244em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.665em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1002.55em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-211"><span class="texatom"
                                                id="MathJax-Span-212"><span class="mrow" id="MathJax-Span-213"><span
                                                        class="texatom" id="MathJax-Span-214"><span class="mrow"
                                                            id="MathJax-Span-215"><span class="munderover"
                                                                id="MathJax-Span-216"><span
                                                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-217"
                                                                            style="font-family: MathJax_Caligraphic;">O</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(3.533em, 1000.41em, 3.938em, -999.997em); top: -4.627em; left: 0.234em;"><span
                                                                            class="mo" id="MathJax-Span-218"
                                                                            style="font-family: MathJax_Main;">~</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span></span></span></span><span
                                                class="mo" id="MathJax-Span-219"
                                                style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                id="MathJax-Span-220"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-221"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-222"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-223"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.601em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-31">\mathcal{\tilde{O}}(n^3)</script>
                    communication for an <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-32-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-224"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-225"><span class="mi" id="MathJax-Span-226"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-32">n</script>-node system.
                    <br>This paper introduces Delphi, a deterministic protocol with
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-33-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-227"
                                style="width: 3.244em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.665em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1002.55em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-228"><span class="texatom"
                                                id="MathJax-Span-229"><span class="mrow" id="MathJax-Span-230"><span
                                                        class="texatom" id="MathJax-Span-231"><span class="mrow"
                                                            id="MathJax-Span-232"><span class="munderover"
                                                                id="MathJax-Span-233"><span
                                                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-234"
                                                                            style="font-family: MathJax_Caligraphic;">O</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(3.533em, 1000.41em, 3.938em, -999.997em); top: -4.627em; left: 0.234em;"><span
                                                                            class="mo" id="MathJax-Span-235"
                                                                            style="font-family: MathJax_Main;">~</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span></span></span></span><span
                                                class="mo" id="MathJax-Span-236"
                                                style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                id="MathJax-Span-237"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-238"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-239"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-240"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.601em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-33">\mathcal{\tilde{O}}(n^2)</script> communication and
                    minimal computation overhead.
                    Delphi assumes that honest inputs are bounded, except with negligible
                    probability, and integrates agreement primitives from literature with a novel
                    weighted averaging technique. Experimental results highlight Delphi's superior
                    performance, showcasing a significantly lower latency compared to
                    state-of-the-art protocols. Specifically, for an <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-34-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-241"
                                style="width: 4.17em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.475em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1003.42em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-242"><span class="mi" id="MathJax-Span-243"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-244"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mn" id="MathJax-Span-245"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">160</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-34">n=160</script>-node system, Delphi
                    achieves an 8x and 3x improvement in latency within CPS and AWS environments,
                    respectively.
                </p>
            </div>
        </dd>
        <dt><a name="item78">[78]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02435"
                    title="Abstract">arXiv:2405.02435</a> [<a href="/pdf/2405.02435" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02435" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bridging the Gap: A Study of AI-based Vulnerability
                    Management between Industry and Academia
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wan%2C+S">Shengye Wan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saxe%2C+J">Joshua Saxe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gomes%2C+C">Craig Gomes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chennabasappa%2C+S">Sahana Chennabasappa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rath%2C+A">Avilash Rath</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+K">Kun Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinda Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IEEE/IFIP International Conference on
                    Dependable Systems and Networks, Industry Track, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Software Engineering (cs.SE)

                </div>
                <p class="mathjax">Recent research advances in Artificial Intelligence (AI) have yielded
                    promising results for automated software vulnerability management. AI-based
                    models are reported to greatly outperform traditional static analysis tools,
                    indicating a substantial workload relief for security engineers. However, the
                    industry remains very cautious and selective about integrating AI-based
                    techniques into their security vulnerability management workflow. To understand
                    the reasons, we conducted a discussion-based study, anchored in the authors'
                    extensive industrial experience and keen observations, to uncover the gap
                    between research and practice in this field. We empirically identified three
                    main barriers preventing the industry from adopting academic models, namely,
                    complicated requirements of scalability and prioritization, limited
                    customization flexibility, and unclear financial implications. Meanwhile,
                    research works are significantly impacted by the lack of extensive real-world
                    security data and expertise. We proposed a set of future directions to help
                    better understand industry expectations, improve the practical usability of
                    AI-based security vulnerability research, and drive a synergistic relationship
                    between industry and academia.
                </p>
            </div>
        </dd>
        <dt><a name="item79">[79]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02437"
                    title="Abstract">arXiv:2405.02437</a> [<a href="/pdf/2405.02437" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02437" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FastLloyd: Federated, Accurate, Secure, and Tunable <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-35-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-246"
                                style="width: 0.604em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.512em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.113em, 1000.51em, 2.086em, -999.998em); top: -1.942em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-247"><span class="mi" id="MathJax-Span-248"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.947em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.947em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-35">k</script>-Means Clustering with Differential
                    Privacy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Diaa%2C+A">Abdulrahman Diaa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Humphries%2C+T">Thomas Humphries</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kerschbaum%2C+F">Florian Kerschbaum</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">We study the problem of privacy-preserving <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-36-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-249"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-250"><span class="mi" id="MathJax-Span-251"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-36">k</script>-means clustering in the
                    horizontally federated setting. Existing federated approaches using secure
                    computation, suffer from substantial overheads and do not offer output privacy.
                    At the same time, differentially private (DP) <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-37-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-252"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-253"><span class="mi" id="MathJax-Span-254"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-37">k</script>-means algorithms assume a
                    trusted central curator and do not extend to federated settings. Naively
                    combining the secure and DP solutions results in a protocol with impractical
                    overhead. Instead, our work provides enhancements to both the DP and secure
                    computation components, resulting in a design that is faster, more private, and
                    more accurate than previous work. By utilizing the computational DP model, we
                    design a lightweight, secure aggregation-based approach that achieves four
                    orders of magnitude speed-up over state-of-the-art related work. Furthermore,
                    we not only maintain the utility of the state-of-the-art in the central model
                    of DP, but we improve the utility further by taking advantage of constrained
                    clustering techniques.
                </p>
            </div>
        </dd>
        <dt><a name="item80">[80]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02438"
                    title="Abstract">arXiv:2405.02438</a> [<a href="/pdf/2405.02438" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02438" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ROS2swarm - A ROS 2 Package for Swarm Robot Behaviors
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kaiser%2C+T+K">Tanja Katharina Kaiser</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Begemann%2C+M+J">Marian Johannes Begemann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Plattenteich%2C+T">Tavia Plattenteich</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schilling%2C+L">Lars Schilling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schildbach%2C+G">Georg Schildbach</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hamann%2C+H">Heiko Hamann</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> published in 2022 International Conference on Robotics and
                    Automation (ICRA)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Multiagent Systems (cs.MA)

                </div>
                <p class="mathjax">Developing reusable software for mobile robots is still challenging. Even
                    more so for swarm robots, despite the desired simplicity of the robot
                    controllers. Prototyping and experimenting are difficult due to the multi-robot
                    setting and often require robot-robot communication. Also, the diversity of
                    swarm robot hardware platforms increases the need for hardware-independent
                    software concepts. The main advantages of the commonly used robot software
                    architecture ROS 2 are modularity and platform independence. We propose a new
                    ROS 2 package, ROS2swarm, for applications of swarm robotics that provides a
                    library of ready-to-use swarm behavioral primitives. We show the successful
                    application of our approach on three different platforms, the TurtleBot3
                    Burger, the TurtleBot3 Waffle Pi, and the Jackal UGV, and with a set of
                    different behavioral primitives, such as aggregation, dispersion, and
                    collective decision-making. The proposed approach is easy to maintain,
                    extendable, and has good potential for simplifying swarm robotics experiments
                    in future applications.
                </p>
            </div>
        </dd>
        <dt><a name="item81">[81]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02441"
                    title="Abstract">arXiv:2405.02441</a> [<a href="/pdf/2405.02441" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02441" title="Download PostScript">ps</a>, <a href="/format/2405.02441"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Learning minimal volume uncertainty ellipsoids
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Alon%2C+I">Itai Alon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Arnon%2C+D">David Arnon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wiesel%2C+A">Ami Wiesel</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
                <p class="mathjax">We consider the problem of learning uncertainty regions for parameter
                    estimation problems. The regions are ellipsoids that minimize the average
                    volumes subject to a prescribed coverage probability. As expected, under the
                    assumption of jointly Gaussian data, we prove that the optimal ellipsoid is
                    centered around the conditional mean and shaped as the conditional covariance
                    matrix. In more practical cases, we propose a differentiable optimization
                    approach for approximately computing the optimal ellipsoids using a neural
                    network with proper calibration. Compared to existing methods, our network
                    requires less storage and less computations in inference time, leading to
                    accurate yet smaller ellipsoids. We demonstrate these advantages on four
                    real-world localization datasets.
                </p>
            </div>
        </dd>
        <dt><a name="item82">[82]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02447"
                    title="Abstract">arXiv:2405.02447</a> [<a href="/pdf/2405.02447" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02447" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Active flux methods for hyperbolic conservation laws -- flux
                    vector splitting and bound-preservation: One-dimensional case
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Duan%2C+J">Junming Duan</a>,
                    <a href="/search/math?searchtype=author&amp;query=Barsukow%2C+W">Wasilij Barsukow</a>,
                    <a href="/search/math?searchtype=author&amp;query=Klingenberg%2C+C">Christian Klingenberg</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 27 pages, 12 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">The active flux (AF) method is a compact high-order finite volume method that
                    evolves cell averages and point values at cell interfaces independently. Within
                    the method of lines framework, the point value can be updated based on Jacobian
                    splitting (JS), incorporating the upwind idea. However, such JS-based AF
                    methods encounter transonic issues for nonlinear problems due to inaccurate
                    upwind direction estimation. This paper proposes to use flux vector splitting
                    for the point value update, offering a natural and uniform remedy to the
                    transonic issue. To improve robustness, this paper also develops
                    bound-preserving (BP) AF methods for one-dimensional hyperbolic conservation
                    laws. Two cases are considered: preservation of the maximum principle for the
                    scalar case, and preservation of positive density and pressure for the
                    compressible Euler equations. The update of the cell average in high-order AF
                    methods is rewritten as a convex combination of using the original high-order
                    fluxes and robust low-order (local Lax-Friedrichs or Rusanov) fluxes, and the
                    desired bounds are enforced by choosing the right amount of low-order fluxes. A
                    similar blending strategy is used for the point value update. Several
                    challenging benchmark tests are conducted to verify the accuracy, BP
                    properties, and shock-capturing ability of the methods.
                </p>
            </div>
        </dd>
        <dt><a name="item83">[83]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02454"
                    title="Abstract">arXiv:2405.02454</a> [<a href="/pdf/2405.02454" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02454" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> What is Sentiment Meant to Mean to Language Models?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Burnham%2C+M">Michael Burnham</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Sentiment analysis is one of the most widely used techniques in text
                    analysis. Recent advancements with Large Language Models have made it more
                    accurate and accessible than ever, allowing researchers to classify text with
                    only a plain English prompt. However, "sentiment" entails a wide variety of
                    concepts depending on the domain and tools used. It has been used to mean
                    emotion, opinions, market movements, or simply a general ``good-bad''
                    dimension. This raises a question: What exactly are language models doing when
                    prompted to label documents by sentiment? This paper first overviews how
                    sentiment is defined across different contexts, highlighting that it is a
                    confounded measurement construct in that it entails multiple variables, such as
                    emotional valence and opinion, without disentangling them. I then test three
                    language models across two data sets with prompts requesting sentiment,
                    valence, and stance classification. I find that sentiment labels most strongly
                    correlate with valence labels. I further find that classification improves when
                    researchers more precisely specify their dimension of interest rather than
                    using the less well-defined concept of sentiment. I conclude by encouraging
                    researchers to move beyond "sentiment" when feasible and use a more precise
                    measurement construct.
                </p>
            </div>
        </dd>
        <dt><a name="item84">[84]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02458"
                    title="Abstract">arXiv:2405.02458</a> [<a href="/pdf/2405.02458" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02458" title="Download PostScript">ps</a>, <a href="/format/2405.02458"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Controlled Query Evaluation through Epistemic Dependencies
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cima%2C+G">Gianluca Cima</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lembo%2C+D">Domenico Lembo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Marconi%2C+L">Lorenzo Marconi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rosati%2C+R">Riccardo Rosati</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Savo%2C+D+F">Domenico Fabio Savo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">In this paper, we propose the use of epistemic dependencies to express data
                    protection policies in Controlled Query Evaluation (CQE), which is a form of
                    confidentiality-preserving query answering over ontologies and databases. The
                    resulting policy language goes significantly beyond those proposed in the
                    literature on CQE so far, allowing for very rich and practically interesting
                    forms of data protection rules. We show the expressive abilities of our
                    framework and study the data complexity of CQE for (unions of) conjunctive
                    queries when ontologies are specified in the Description Logic DL-Lite_R.
                    Interestingly, while we show that the problem is in general intractable, we
                    prove tractability for the case of acyclic epistemic dependencies by providing
                    a suitable query rewriting algorithm. The latter result paves the way towards
                    the implementation and practical application of this new approach to CQE.
                </p>
            </div>
        </dd>
        <dt><a name="item85">[85]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02463"
                    title="Abstract">arXiv:2405.02463</a> [<a href="/pdf/2405.02463" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02463" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Knowledge Graph Extension by Entity Type Recognition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+D">Daqian Shi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> PhD thesis
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">Knowledge graphs have emerged as a sophisticated advancement and refinement
                    of semantic networks, and their deployment is one of the critical methodologies
                    in contemporary artificial intelligence. The construction of knowledge graphs
                    is a multifaceted process involving various techniques, where researchers aim
                    to extract the knowledge from existing resources for the construction since
                    building from scratch entails significant labor and time costs. However, due to
                    the pervasive issue of heterogeneity, the description diversity across
                    different knowledge graphs can lead to mismatches between concepts, thereby
                    impacting the efficacy of knowledge extraction. This Ph.D. study focuses on
                    automatic knowledge graph extension, i.e., properly extending the reference
                    knowledge graph by extracting and integrating concepts from one or more
                    candidate knowledge graphs. We propose a novel knowledge graph extension
                    framework based on entity type recognition. The framework aims to achieve
                    high-quality knowledge extraction by aligning the schemas and entities across
                    different knowledge graphs, thereby enhancing the performance of the extension.
                    This paper elucidates three major contributions: (i) we propose an entity type
                    recognition method exploiting machine learning and property-based similarities
                    to enhance knowledge extraction; (ii) we introduce a set of assessment metrics
                    to validate the quality of the extended knowledge graphs; (iii) we develop a
                    platform for knowledge graph acquisition, management, and extension to benefit
                    knowledge engineers practically. Our evaluation comprehensively demonstrated
                    the feasibility and effectiveness of the proposed extension framework and its
                    functionalities through quantitative experiments and case studies.
                </p>
            </div>
        </dd>
        <dt><a name="item86">[86]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02466"
                    title="Abstract">arXiv:2405.02466</a> [<a href="/pdf/2405.02466" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02466" title="Download PostScript">ps</a>, <a href="/format/2405.02466"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ProFLingo: A Fingerprinting-based Copyright Protection Scheme
                    for Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+H">Heng Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chaoyu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+S">Shanghao Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lou%2C+W">Wenjing Lou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hou%2C+Y+T">Y. Thomas Hou</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This is the author's pre-print version of the work. It is
                    posted here for your personal use. Not for redistribution
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Large language models (LLMs) have attracted significant attention in recent
                    years. Due to their "Large" nature, training LLMs from scratch consumes immense
                    computational resources. Since several major players in the artificial
                    intelligence (AI) field have open-sourced their original LLMs, an increasing
                    number of individual researchers and smaller companies are able to build
                    derivative LLMs based on these open-sourced models at much lower costs.
                    However, this practice opens up possibilities for unauthorized use or
                    reproduction that may not comply with licensing agreements, and deriving models
                    can change the model's behavior, thus complicating the determination of model
                    ownership. Current copyright protection schemes for LLMs are either designed
                    for white-box settings or require additional modifications to the original
                    model, which restricts their use in real-world settings.
                    <br>In this paper, we propose ProFLingo, a black-box fingerprinting-based
                    copyright protection scheme for LLMs. ProFLingo generates adversarial examples
                    (AEs) that can represent the unique decision boundary characteristics of an
                    original model, thereby establishing unique fingerprints. Our scheme checks the
                    effectiveness of these adversarial examples on a suspect model to determine
                    whether it has been derived from the original model. ProFLingo offers a
                    non-invasive approach, which neither requires knowledge of the suspect model
                    nor modifications to the base model or its training process. To the best of our
                    knowledge, our method represents the first black-box fingerprinting technique
                    for copyright protection for LLMs. Our source code and generated AEs are
                    available at: https://github.com/hengvt/ProFLingo_arXiv.
                </p>
            </div>
        </dd>
        <dt><a name="item87">[87]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02472"
                    title="Abstract">arXiv:2405.02472</a> [<a href="/pdf/2405.02472" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02472" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Semantic Scaling: Bayesian Ideal Point Estimates with Large
                    Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Burnham%2C+M">Michael Burnham</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">This paper introduces "Semantic Scaling," a novel method for ideal point
                    estimation from text. I leverage large language models to classify documents
                    based on their expressed stances and extract survey-like data. I then use item
                    response theory to scale subjects from these data. Semantic Scaling
                    significantly improves on existing text-based scaling methods, and allows
                    researchers to explicitly define the ideological dimensions they measure. This
                    represents the first scaling approach that allows such flexibility outside of
                    survey instruments and opens new avenues of inquiry for populations difficult
                    to survey. Additionally, it works with documents of varying length, and
                    produces valid estimates of both mass and elite ideology. I demonstrate that
                    the method can differentiate between policy preferences and in-group/out-group
                    affect. Among the public, Semantic Scaling out-preforms Tweetscores according
                    to human judgement; in Congress, it recaptures the first dimension DW-NOMINATE
                    while allowing for greater flexibility in resolving construct validity
                    challenges.
                </p>
            </div>
        </dd>
        <dt><a name="item88">[88]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02475"
                    title="Abstract">arXiv:2405.02475</a> [<a href="/pdf/2405.02475" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02475" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Generalizing Orthogonalization for Models with
                    Non-linearities
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=R%C3%BCgamer%2C+D">David Rügamer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kolb%2C+C">Chris Kolb</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Weber%2C+T">Tobias Weber</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kook%2C+L">Lucas Kook</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nagler%2C+T">Thomas Nagler</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation (stat.CO); Methodology (stat.ME)

                </div>
                <p class="mathjax">The complexity of black-box algorithms can lead to various challenges,
                    including the introduction of biases. These biases present immediate risks in
                    the algorithms' application. It was, for instance, shown that neural networks
                    can deduce racial information solely from a patient's X-ray scan, a task beyond
                    the capability of medical experts. If this fact is not known to the medical
                    expert, automatic decision-making based on this algorithm could lead to
                    prescribing a treatment (purely) based on racial information. While current
                    methodologies allow for the "orthogonalization" or "normalization" of neural
                    networks with respect to such information, existing approaches are grounded in
                    linear models. Our paper advances the discourse by introducing corrections for
                    non-linearities such as ReLU activations. Our approach also encompasses scalar
                    and tensor-valued predictions, facilitating its integration into neural network
                    architectures. Through extensive experiments, we validate our method's
                    effectiveness in safeguarding sensitive data in generalized linear models,
                    normalizing convolutional neural networks for metadata, and rectifying
                    pre-existing embeddings for undesired attributes.
                </p>
            </div>
        </dd>
        <dt><a name="item89">[89]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02476"
                    title="Abstract">arXiv:2405.02476</a> [<a href="/pdf/2405.02476" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02476" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SSI4IoT: Unlocking the Potential of IoT Tailored
                    Self-Sovereign Identity
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dayaratne%2C+T">Thusitha Dayaratne</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+X">Xinxin Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuhong Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rudolph%2C+C">Carsten Rudolph</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies
                        (cs.ET)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing
                    (cs.DC)

                </div>
                <p class="mathjax">The emerging Self-Sovereign Identity (SSI) techniques, such as Decentralized
                    Identifiers (DIDs) and Verifiable Credentials (VCs), move control of digital
                    identity from conventional identity providers to individuals and lay down the
                    foundation for people, organizations, and things establishing rich digital
                    relationship. The existing applications of SSI mainly focus on creating
                    person-to-person and person-to-service relationships, whereas person-to-device
                    and device-to-device interactions have been largely overlooked. In this paper,
                    we close this gap by identifying a number of key challenges of applying SSI to
                    the Internet of Things (IoT) and providing a comprehensive taxonomy and usage
                    of VCs in the IoT context with respect to their validity period, trust and
                    interoperability level, and scope of usage. The life-cycle management of VCs as
                    well as various optimization techniques for realizing SSI in IoT environments
                    are also addressed in great detail. This work is a noteworthy step towards
                    massive adoption of SSI for securing existing and future IoT applications in
                    practice.
                </p>
            </div>
        </dd>
        <dt><a name="item90">[90]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02478"
                    title="Abstract">arXiv:2405.02478</a> [<a href="/pdf/2405.02478" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02478" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Continuous Learned Primal Dual
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Runkel%2C+C">Christina Runkel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Biguri%2C+A">Ander Biguri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Schönlieb</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Image and Video Processing (eess.IV)

                </div>
                <p class="mathjax">Neural ordinary differential equations (Neural ODEs) propose the idea that a
                    sequence of layers in a neural network is just a discretisation of an ODE, and
                    thus can instead be directly modelled by a parameterised ODE. This idea has had
                    resounding success in the deep learning literature, with direct or indirect
                    influence in many state of the art ideas, such as diffusion models or time
                    dependant models. Recently, a continuous version of the U-net architecture has
                    been proposed, showing increased performance over its discrete counterpart in
                    many imaging applications and wrapped with theoretical guarantees around its
                    performance and robustness. In this work, we explore the use of Neural ODEs for
                    learned inverse problems, in particular with the well-known Learned Primal Dual
                    algorithm, and apply it to computed tomography (CT) reconstruction.
                </p>
            </div>
        </dd>
        <dt><a name="item91">[91]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02479"
                    title="Abstract">arXiv:2405.02479</a> [<a href="/pdf/2405.02479" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02479" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deterministic Sub-exponential Algorithm for Discounted-sum
                    Games with Unary Weights
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Asadi%2C+A">Ali Asadi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chatterjee%2C+K">Krishnendu Chatterjee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saona%2C+R">Raimundo Saona</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Svoboda%2C+J">Jakub Svoboda</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>

                </div>
                <p class="mathjax">Turn-based discounted-sum games are two-player zero-sum games played on
                    finite directed graphs. The vertices of the graph are partitioned between
                    player 1 and player 2. Plays are infinite walks on the graph where the next
                    vertex is decided by a player that owns the current vertex. Each edge is
                    assigned an integer weight and the payoff of a play is the discounted-sum of
                    the weights of the play. The goal of player 1 is to maximize the discounted-sum
                    payoff against the adversarial player 2. These games lie in NP and coNP and are
                    among the rare combinatorial problems that belong to this complexity class and
                    the existence of a polynomial-time algorithm is a major open question. Since
                    breaking the general exponential barrier has been a challenging problem, faster
                    parameterized algorithms have been considered. If the discount factor is
                    expressed in unary, then discounted-sum games can be solved in polynomial time.
                    However, if the discount factor is arbitrary (or expressed in binary), but the
                    weights are in unary, none of the existing approaches yield a sub-exponential
                    bound. Our main result is a new analysis technique for a classical algorithm
                    (namely, the strategy iteration algorithm) that present a new runtime bound
                    which is <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-38-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-255"
                                style="width: 5.327em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.401em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.229em, 1004.4em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-256"><span class="msubsup"
                                                id="MathJax-Span-257"><span
                                                    style="display: inline-block; position: relative; width: 4.401em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-258"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="texatom" id="MathJax-Span-259"><span class="mrow"
                                                                id="MathJax-Span-260"><span class="mi"
                                                                    id="MathJax-Span-261"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">O</span><span
                                                                    class="mo" id="MathJax-Span-262"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span
                                                                    class="msubsup" id="MathJax-Span-263"><span
                                                                        style="display: inline-block; position: relative; width: 1.623em; height: 0px;"><span
                                                                            style="position: absolute; clip: rect(3.359em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                                class="mi" id="MathJax-Span-264"
                                                                                style="font-size: 70.7%; font-family: MathJax_Math-italic;">W<span
                                                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                            style="position: absolute; top: -4.28em; left: 0.813em;"><span
                                                                                class="texatom"
                                                                                id="MathJax-Span-265"><span class="mrow"
                                                                                    id="MathJax-Span-266"><span
                                                                                        class="mn" id="MathJax-Span-267"
                                                                                        style="font-size: 50%; font-family: MathJax_Main;">1</span><span
                                                                                        class="texatom"
                                                                                        id="MathJax-Span-268"><span
                                                                                            class="mrow"
                                                                                            id="MathJax-Span-269"><span
                                                                                                class="mo"
                                                                                                id="MathJax-Span-270"
                                                                                                style="font-size: 50%; font-family: MathJax_Main;">/</span></span></span><span
                                                                                        class="mn" id="MathJax-Span-271"
                                                                                        style="font-size: 50%; font-family: MathJax_Main;">4</span></span></span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                    class="msqrt" id="MathJax-Span-272"><span
                                                                        style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                                            style="position: absolute; clip: rect(3.533em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0.582em;"><span
                                                                                class="mrow" id="MathJax-Span-273"><span
                                                                                    class="mi" id="MathJax-Span-274"
                                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span></span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                            style="position: absolute; clip: rect(0.987em, 1000.41em, 1.334em, -999.997em); top: -1.617em; left: 0.582em;"><span
                                                                                style="display: inline-block; overflow: hidden; vertical-align: -0.055em; border-top: 1.3px solid; width: 0.408em; height: 0px;"></span><span
                                                                                style="display: inline-block; width: 0px; height: 1.102em;"></span></span><span
                                                                            style="position: absolute; clip: rect(3.244em, 1000.58em, 4.285em, -999.997em); top: -3.932em; left: 0em;"><span><span
                                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">√</span></span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                    class="mo" id="MathJax-Span-275"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-38">n^{O ( W^{1/4} \sqrt{n} )}</script>, for game graphs
                    with <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-39-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-276"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-277"><span class="mi" id="MathJax-Span-278"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-39">n</script> vertices and
                    maximum absolute weight of at most <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-40-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-279"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1001.04em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-280"><span class="mi" id="MathJax-Span-281"
                                                style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-40">W</script>. In particular, our result yields a
                    deterministic sub-exponential bound for games with weights that are constant or
                    represented in unary.
                </p>
            </div>
        </dd>
        <dt><a name="item92">[92]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02481"
                    title="Abstract">arXiv:2405.02481</a> [<a href="/pdf/2405.02481" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02481" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Proximal Curriculum with Task Correlations for Deep
                    Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tzannetos%2C+G">Georgios Tzannetos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kamalaruban%2C+P">Parameswaran Kamalaruban</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singla%2C+A">Adish Singla</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> IJCAI'24 paper (longer version)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Curriculum design for reinforcement learning (RL) can speed up an agent's
                    learning process and help it learn to perform well on complex tasks. However,
                    existing techniques typically require domain-specific hyperparameter tuning,
                    involve expensive optimization procedures for task selection, or are suitable
                    only for specific learning objectives. In this work, we consider curriculum
                    design in contextual multi-task settings where the agent's final performance is
                    measured w.r.t. a target distribution over complex tasks. We base our
                    curriculum design on the Zone of Proximal Development concept, which has proven
                    to be effective in accelerating the learning process of RL agents for uniform
                    distribution over all tasks. We propose a novel curriculum, ProCuRL-Target,
                    that effectively balances the need for selecting tasks that are not too
                    difficult for the agent while progressing the agent's learning toward the
                    target distribution via leveraging task correlations. We theoretically justify
                    the task selection strategy of ProCuRL-Target by analyzing a simple learning
                    setting with REINFORCE learner model. Our experimental results across various
                    domains with challenging target task distributions affirm the effectiveness of
                    our curriculum strategy over state-of-the-art baselines in accelerating the
                    training process of deep RL agents.
                </p>
            </div>
        </dd>
        <dt><a name="item93">[93]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02484"
                    title="Abstract">arXiv:2405.02484</a> [<a href="/pdf/2405.02484" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02484" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Hierarchically Decentralized Heterogeneous Multi-Robot Task
                    Allocation System
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kashid%2C+S">Sujeet Kashid</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kumat%2C+A+D">Ashwin D. Kumat</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">With plans to send humans to the Moon and further, the supply of resources
                    like oxygen, water, fuel, etc., can be satiated by performing In-Situ Resource
                    Utilization (ISRU), where resources from the extra-terrestrial body are
                    extracted to be utilized. These ISRU missions can be carried out by a
                    Multi-Robot System (MRS). In this research, a high-level auction- based
                    Multi-Robot Task Allocation (MRTA) system is developed for coordinating tasks
                    amongst multiple robots with distinct capabilities. A hierarchical
                    decentralized coordination architecture is implemented in this research to
                    allocate the tasks amongst the robots for achieving intentional cooperation in
                    the Multi-Robot System (MRS). 3 different policies are formulated that govern
                    how robots should act in the multiple auction situations of the auction-based
                    task allocation system proposed in this research, and their performance is
                    evaluated in a 2D simulation called pyrobosim using ROS2. The decentralized
                    coordination architecture and the auction-based MRTA make the MRS highly
                    scalable, reliable, flexible, and robust.
                </p>
            </div>
        </dd>
        <dt><a name="item94">[94]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02485"
                    title="Abstract">arXiv:2405.02485</a> [<a href="/pdf/2405.02485" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02485" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Survey of Few-Shot Learning for Biomedical Time Series
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chenqi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Denison%2C+T">Timothy Denison</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+T">Tingting Zhu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible
                    publication. Copyright may be transferred without notice, after which this version may no longer be
                    accessible
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Advancements in wearable sensor technologies and the digitization of medical
                    records have contributed to the unprecedented ubiquity of biomedical time
                    series data. Data-driven models have tremendous potential to assist clinical
                    diagnosis and improve patient care by improving long-term monitoring
                    capabilities, facilitating early disease detection and intervention, as well as
                    promoting personalized healthcare delivery. However, accessing extensively
                    labeled datasets to train data-hungry deep learning models encounters many
                    barriers, such as long-tail distribution of rare diseases, cost of annotation,
                    privacy and security concerns, data-sharing regulations, and ethical
                    considerations. An emerging approach to overcome the scarcity of labeled data
                    is to augment AI methods with human-like capabilities to leverage past
                    experiences to learn new tasks with limited examples, called few-shot learning.
                    This survey provides a comprehensive review and comparison of few-shot learning
                    methods for biomedical time series applications. The clinical benefits and
                    limitations of such methods are discussed in relation to traditional
                    data-driven approaches. This paper aims to provide insights into the current
                    landscape of few-shot learning for biomedical time series and its implications
                    for future research and applications.
                </p>
            </div>
        </dd>
        <dt><a name="item95">[95]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02486"
                    title="Abstract">arXiv:2405.02486</a> [<a href="/pdf/2405.02486" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02486" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Concurrent Stochastic Games with Stateful-discounted and
                    Parity Objectives: Complexity and Algorithms
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Asadi%2C+A">Ali Asadi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chatterjee%2C+K">Krishnendu Chatterjee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saona%2C+R">Raimundo Saona</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Svoboda%2C+J">Jakub Svoboda</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>

                </div>
                <p class="mathjax">We study two-player zero-sum concurrent stochastic games with finite state
                    and action space played for an infinite number of steps. In every step, the two
                    players simultaneously and independently choose an action. Given the current
                    state and the chosen actions, the next state is obtained according to a
                    stochastic transition function. An objective is a measurable function on plays
                    (or infinite trajectories) of the game, and the value for an objective is the
                    maximal expectation that the player can guarantee against the adversarial
                    player. We consider: (a) stateful-discounted objectives, which are similar to
                    the classical discounted-sum objectives, but states are associated with
                    different discount factors rather than a single discount factor; and (b) parity
                    objectives, which are a canonical representation for <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-41-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-282"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.64em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-283"><span class="mi" id="MathJax-Span-284"
                                                style="font-family: MathJax_Math-italic;">ω</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-41">\omega</script>-regular
                    objectives. For stateful-discounted objectives, given an ordering of the
                    discount factors, the limit value is the limit of the value of the
                    stateful-discounted objectives, as the discount factors approach zero according
                    to the given order.
                    <br>The computational problem we consider is the approximation of the value
                    within an arbitrary additive error. The above problem is known to be in
                    EXPSPACE for the limit value of stateful-discounted objectives and in PSPACE
                    for parity objectives. The best-known algorithms for both the above problems
                    are at least exponential time, with an exponential dependence on the number of
                    states and actions. Our main results for the value approximation problem for
                    the limit value of stateful-discounted objectives and parity objectives are as
                    follows: (a) we establish TFNP[NP] complexity; and (b) we present algorithms
                    that improve the dependency on the number of actions in the exponent from
                    linear to logarithmic. In particular, if the number of states is constant, our
                    algorithms run in polynomial time.
                </p>
            </div>
        </dd>
        <dt><a name="item96">[96]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02487"
                    title="Abstract">arXiv:2405.02487</a> [<a href="/pdf/2405.02487" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02487" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Stable Distributed Online Feedback Optimization for
                    Distribution System Voltage Regulation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Zhan%2C+S">Sen Zhan</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Paterakis%2C+N+G">Nikolaos G. Paterakis</a>,
                    <a href="/search/eess?searchtype=author&amp;query=van+den+Akker%2C+W">Wouter van den Akker</a>,
                    <a href="/search/eess?searchtype=author&amp;query=van+der+Molen%2C+A">Anne van der Molen</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Morren%2C+J">Johan Morren</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Slootweg%2C+J+G">J. G. Slootweg</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">We investigate the distributed voltage regulation problem in distribution
                    systems employing online feedback optimization and short-range communication
                    between physical neighbours. We show that a two-metric approach can be
                    unstable. As a remedy, we propose a nested feedback optimization strategy.
                    Simulation results reveal that while the two-metric approach fails to regulate
                    voltages, the proposed approach achieves even less voltage limit violations
                    than its centralized counterpart.
                </p>
            </div>
        </dd>
        <dt><a name="item97">[97]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02490"
                    title="Abstract">arXiv:2405.02490</a> [<a href="/pdf/2405.02490" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02490" title="Download PostScript">ps</a>, <a href="/format/2405.02490"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Software Fairness Debt
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=de+Souza+Santos%2C+R">Ronnie de Souza Santos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fronchetti%2C+F">Felipe Fronchetti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Freire%2C+S">Savio Freire</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Spinola%2C+R">Rodrigo Spinola</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">As software systems continue to play a significant role in modern society,
                    ensuring their fairness has become a critical concern in software engineering.
                    Motivated by this scenario, this paper focused on exploring the multifaceted
                    nature of bias in software systems, aiming to provide a comprehensive
                    understanding of its origins, manifestations, and impacts. Through a scoping
                    study, we identified the primary causes of fairness deficiency in software
                    development and highlighted their adverse effects on individuals and
                    communities, including instances of discrimination and the perpetuation of
                    inequalities. Our investigation culminated in the introduction of the concept
                    of software fairness debt, which complements the notions of technical and
                    social debt, encapsulating the accumulation of biases in software engineering
                    practices while emphasizing the societal ramifications of bias embedded within
                    software systems. Our study contributes to a deeper understanding of fairness
                    in software engineering and paves the way for the development of more equitable
                    and socially responsible software systems.
                </p>
            </div>
        </dd>
        <dt><a name="item98">[98]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02492"
                    title="Abstract">arXiv:2405.02492</a> [<a href="/pdf/2405.02492" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02492" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Investigating the Generalizability of Assistive Robots Models
                    over Various Tasks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Osooli%2C+H">Hamid Osooli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Coco%2C+C">Christopher Coco</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Spanos%2C+J">Johnathan Spanos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Majdi%2C+A">Amin Majdi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Azadeh%2C+R">Reza Azadeh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to 2024 21st International Conference on
                    Ubiquitous Robots (UR)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">In the domain of assistive robotics, the significance of effective modeling
                    is well acknowledged. Prior research has primarily focused on enhancing model
                    accuracy or involved the collection of extensive, often impractical amounts of
                    data. While improving individual model accuracy is beneficial, it necessitates
                    constant remodeling for each new task and user interaction. In this paper, we
                    investigate the generalizability of different modeling methods. We focus on
                    constructing the dynamic model of an assistive exoskeleton using six
                    data-driven regression algorithms. Six tasks are considered in our experiments,
                    including horizontal, vertical, diagonal from left leg to the right eye and the
                    opposite, as well as eating and pushing. We constructed thirty-six unique
                    models applying different regression methods to data gathered from each task.
                    Each trained model's performance was evaluated in a cross-validation scenario,
                    utilizing five folds for each dataset. These trained models are then tested on
                    the other tasks that the model is not trained with. Finally the models in our
                    study are assessed in terms of generalizability. Results show the superior
                    generalizability of the task model performed along the horizontal plane, and
                    decision tree based algorithms.
                </p>
            </div>
        </dd>
        <dt><a name="item99">[99]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02495"
                    title="Abstract">arXiv:2405.02495</a> [<a href="/pdf/2405.02495" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02495" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Design of Fuzzy Logic Parameter Tuners for Upper-Limb
                    Assistive Robots
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Coco%2C+C">Christopher Coco Jr.</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Spanos%2C+J">Jonathan Spanos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Osooli%2C+H">Hamid Osooli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Azadeh%2C+R">Reza Azadeh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 4 pages, 5 figures, Accepted to 2024 21st International
                    Conference on Ubiquitous Robots (UR)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Assistive Exoskeleton Robots are helping restore functions to people
                    suffering from underlying medical conditions. These robots require precise
                    tuning of hyper-parameters to feel natural to the user. The device
                    hyper-parameters often need to be re-tuned from task to task, which can be
                    tedious and require expert knowledge. To address this issue, we develop a set
                    of fuzzy logic controllers that can dynamically tune robot gain parameters to
                    adapt its sensitivity to the user's intention determined from muscle
                    activation. The designed fuzzy controllers benefit from a set of expert-defined
                    rules and do not rely on extensive amounts of training data. We evaluate the
                    designed controllers with three different tasks and compare our results against
                    the manually tuned system. Our preliminary results show that our controllers
                    reduce the amount of fighting between the device and the human, measured using
                    a set of pressure sensors.
                </p>
            </div>
        </dd>
        <dt><a name="item100">[100]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02499"
                    title="Abstract">arXiv:2405.02499</a> [<a href="/pdf/2405.02499" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02499" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DRAMScope: Uncovering DRAM Microarchitecture and
                    Characteristics by Issuing Memory Commands
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nam%2C+H">Hwayong Nam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baek%2C+S">Seungmin Baek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wi%2C+M">Minbok Wi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+M+J">Michael Jaemin Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+J">Jaehyun Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+C">Chihun Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+N+S">Nam Sung Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ahn%2C+J+H">Jung Ho Ahn</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To appear at the 51st IEEE/ACM International Symposium on
                    Computer Architecture (ISCA)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Hardware Architecture (cs.AR)

                </div>
                <p class="mathjax">The demand for precise information on DRAM microarchitectures and error
                    characteristics has surged, driven by the need to explore processing in memory,
                    enhance reliability, and mitigate security vulnerability. Nonetheless, DRAM
                    manufacturers have disclosed only a limited amount of information, making it
                    difficult to find specific information on their DRAM microarchitectures. This
                    paper addresses this gap by presenting more rigorous findings on the
                    microarchitectures of commodity DRAM chips and their impacts on the
                    characteristics of activate-induced bitflips (AIBs), such as RowHammer and
                    RowPress. The previous studies have also attempted to understand the DRAM
                    microarchitectures and associated behaviors, but we have found some of their
                    results to be misled by inaccurate address mapping and internal data swizzling,
                    or lack of a deeper understanding of the modern DRAM cell structure. For
                    accurate and efficient reverse-engineering, we use three tools: AIBs, retention
                    time test, and RowCopy, which can be cross-validated. With these three tools,
                    we first take a macroscopic view of modern DRAM chips to uncover the size,
                    structure, and operation of their subarrays, memory array tiles (MATs), and
                    rows. Then, we analyze AIB characteristics based on the microscopic view of the
                    DRAM microarchitecture, such as 6F^2 cell layout, through which we rectify
                    misunderstandings regarding AIBs and discover a new data pattern that
                    accelerates AIBs. Lastly, based on our findings at both macroscopic and
                    microscopic levels, we identify previously unknown AIB vulnerabilities and
                    propose a simple yet effective protection solution.
                </p>
            </div>
        </dd>
        <dt><a name="item101">[101]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02501"
                    title="Abstract">arXiv:2405.02501</a> [<a href="/pdf/2405.02501" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02501" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Beyond Helpfulness and Harmlessness: Eliciting Diverse
                    Behaviors from Large Language Models with Persona In-Context Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+H+K">Hyeong Kyu Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yixuan Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Paper accepted at ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Large Language Models (LLMs) are trained on massive text corpora, which are
                    encoded with diverse personality traits. This triggers an interesting goal of
                    eliciting a desired personality trait from the LLM, and probing its behavioral
                    preferences. Accordingly, we formalize the persona elicitation task, aiming to
                    customize LLM behaviors to align with a target persona. We present Persona
                    In-Context Learning (PICLe), a novel persona elicitation framework grounded in
                    Bayesian inference. At the core, PICLe introduces a new ICL example selection
                    criterion based on likelihood ratio, which is designed to optimally guide the
                    model in eliciting a specific target persona. We demonstrate the effectiveness
                    of PICLe through extensive comparisons against baseline methods across three
                    contemporary LLMs. Code is available at
                    https://github.com/deeplearning-wisc/picle.
                </p>
            </div>
        </dd>
        <dt><a name="item102">[102]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02503"
                    title="Abstract">arXiv:2405.02503</a> [<a href="/pdf/2405.02503" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02503" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Axiomatic Causal Interventions for Reverse Engineering
                    Relevance Computation in Neural Retrieval Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Catherine Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Merullo%2C+J">Jack Merullo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eickhoff%2C+C">Carsten Eickhoff</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 10 figures, accepted at SIGIR 2024 as
                    perspective paper
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">Neural models have demonstrated remarkable performance across diverse ranking
                    tasks. However, the processes and internal mechanisms along which they
                    determine relevance are still largely unknown. Existing approaches for
                    analyzing neural ranker behavior with respect to IR properties rely either on
                    assessing overall model behavior or employing probing methods that may offer an
                    incomplete understanding of causal mechanisms. To provide a more granular
                    understanding of internal model decision-making processes, we propose the use
                    of causal interventions to reverse engineer neural rankers, and demonstrate how
                    mechanistic interpretability methods can be used to isolate components
                    satisfying term-frequency axioms within a ranking model. We identify a group of
                    attention heads that detect duplicate tokens in earlier layers of the model,
                    then communicate with downstream heads to compute overall document relevance.
                    More generally, we propose that this style of mechanistic analysis opens up
                    avenues for reverse engineering the processes neural retrieval models use to
                    compute relevance. This work aims to initiate granular interpretability efforts
                    that will not only benefit retrieval model development and training, but
                    ultimately ensure safer deployment of these models.
                </p>
            </div>
        </dd>
        <dt><a name="item103">[103]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02506"
                    title="Abstract">arXiv:2405.02506</a> [<a href="/pdf/2405.02506" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02506" title="Download PostScript">ps</a>, <a href="/format/2405.02506"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Big Data, Big Decisions Choosing the Right Database
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hassan%2C+F">Fahmy Hassan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

                </div>
                <p class="mathjax">In the burgeoning era of big data, selecting the optimal database solution
                    has become a critical decision for organizations across every industry. Big
                    data demands a powerful database solution. Traditionally, SQL Database,
                    Database ruled, offering a structured approach familiar to many organizations.
                    However, big data's complexity and unstructured nature challenge SQL Database's
                    limitations. Enter NoSQL Database: flexible and scalable, making them ideal for
                    big data's ever-changing nature. We'll explore the key differences between SQL
                    and NoSQL Database. Performance-wise, SQL Database shines for structured
                    queries. Its standardized language (SQL) ensures data consistency and complex
                    analysis. But for big data's unstructured formats, this rigidity becomes a
                    hurdle. NoSQL offers a welcome contrast. Its flexible schema allows for diverse
                    data formats and evolving structures, perfect for undefined or frequently
                    changing data models. Additionally, NoSQL boasts superior horizontal
                    scalability, distributing data across multiple servers for cost-effective
                    growth. Understanding these key differentiators empowers organizations to
                    choose the optimal database for their big data needs.
                </p>
            </div>
        </dd>
        <dt><a name="item104">[104]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02508"
                    title="Abstract">arXiv:2405.02508</a> [<a href="/pdf/2405.02508" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02508" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Rasterized Edge Gradients: Handling Discontinuities
                    Differentiably
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pidhorskyi%2C+S">Stanislav Pidhorskyi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Simon%2C+T">Tomas Simon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schwartz%2C+G">Gabriel Schwartz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wen%2C+H">He Wen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sheikh%2C+Y">Yaser Sheikh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saragih%2C+J">Jason Saragih</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
                <p class="mathjax">Computing the gradients of a rendering process is paramount for diverse
                    applications in computer vision and graphics. However, accurate computation of
                    these gradients is challenging due to discontinuities and rendering
                    approximations, particularly for surface-based representations and
                    rasterization-based rendering. We present a novel method for computing
                    gradients at visibility discontinuities for rasterization-based differentiable
                    renderers. Our method elegantly simplifies the traditionally complex problem
                    through a carefully designed approximation strategy, allowing for a
                    straightforward, effective, and performant solution. We introduce a novel
                    concept of micro-edges, which allows us to treat the rasterized images as
                    outcomes of a differentiable, continuous process aligned with the inherently
                    non-differentiable, discrete-pixel rasterization. This technique eliminates the
                    necessity for rendering approximations or other modifications to the forward
                    pass, preserving the integrity of the rendered image, which makes it applicable
                    to rasterized masks, depth, and normals images where filtering is prohibitive.
                    Utilizing micro-edges simplifies gradient interpretation at discontinuities and
                    enables handling of geometry intersections, offering an advantage over the
                    prior art. We showcase our method in dynamic human head scene reconstruction,
                    demonstrating effective handling of camera images and segmentation masks.
                </p>
            </div>
        </dd>
        <dt><a name="item105">[105]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02509"
                    title="Abstract">arXiv:2405.02509</a> [<a href="/pdf/2405.02509" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02509" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Implicit Neural Representations for Robust Joint Sparse-View
                    CT Reconstruction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+J">Jiayang Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+J">Junyi Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pelt%2C+D+M">Daniel M. Pelt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Batenburg%2C+K+J">K. Joost Batenburg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Blaschko%2C+M+B">Matthew B. Blaschko</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Computed Tomography (CT) is pivotal in industrial quality control and medical
                    diagnostics. Sparse-view CT, offering reduced ionizing radiation, faces
                    challenges due to its under-sampled nature, leading to ill-posed reconstruction
                    problems. Recent advancements in Implicit Neural Representations (INRs) have
                    shown promise in addressing sparse-view CT reconstruction. Recognizing that CT
                    often involves scanning similar subjects, we propose a novel approach to
                    improve reconstruction quality through joint reconstruction of multiple objects
                    using INRs. This approach can potentially leverage both the strengths of INRs
                    and the statistical regularities across multiple objects. While current INR
                    joint reconstruction techniques primarily focus on accelerating convergence via
                    meta-initialization, they are not specifically tailored to enhance
                    reconstruction quality. To address this gap, we introduce a novel INR-based
                    Bayesian framework integrating latent variables to capture the inter-object
                    relationships. These variables serve as a dynamic reference throughout the
                    optimization, thereby enhancing individual reconstruction fidelity. Our
                    extensive experiments, which assess various key factors such as reconstruction
                    quality, resistance to overfitting, and generalizability, demonstrate
                    significant improvements over baselines in common numerical metrics. This
                    underscores a notable advancement in CT reconstruction methods.
                </p>
            </div>
        </dd>
        <dt><a name="item106">[106]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02510"
                    title="Abstract">arXiv:2405.02510</a> [<a href="/pdf/2405.02510" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02510" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Low-cost sensors and circuits for plasma education:
                    characterizing power and illuminance
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Vargas%2C+A+N">Alessandro N. Vargas</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Miller%2C+V">Victor Miller</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Mesbah%2C+A">Ali Mesbah</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Neretti%2C+G">Gabriele Neretti</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>; Plasma Physics (physics.plasm-ph)

                </div>
                <p class="mathjax">Industrial applications of plasma have significantly increased beyond
                    semiconductor manufacturing in recent years. This necessitates training a
                    skilled workforce in plasma science and technology. However, an essential
                    challenge to this end stems from the high cost of plasma devices and
                    diagnostics. The limited access to plasma devices has hindered plasma
                    education, particularly in the least developed countries. To this end, this
                    paper demonstrates how low-cost sensors and circuits can be developed to enable
                    inexpensive plasma experiments in laboratory environments. In particular, we
                    show how to measure high voltage, current, and power from a cold-atmospheric
                    plasma discharge. Additionally, we develop a low-cost illuminance sensor and
                    demonstrate how it can be used to estimate the corresponding plasma power. The
                    low-cost sensors and electronics presented in this paper can aid educators in
                    characterizing plasma power versus plasma illuminance.
                </p>
            </div>
        </dd>
        <dt><a name="item107">[107]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02511"
                    title="Abstract">arXiv:2405.02511</a> [<a href="/pdf/2405.02511" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02511" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Incremental Volt/Var Control for Distribution Networks via
                    Chance-Constrained Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Colot%2C+A">Antonin Colot</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Perotti%2C+E">Elisabetta Perotti</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Glavic%2C+M">Mevludin Glavic</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Dall%27Anese%2C+E">Emiliano Dall'Anese</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">This paper considers an incremental Volt/Var control scheme for distribution
                    systems with high integration of inverter-interfaced distributed generation
                    (such as photovoltaic systems). The incremental Volt/Var controller is
                    implemented with the objective of minimizing reactive power usage while
                    maintaining voltages within safe limits sufficiently often. To this end, the
                    parameters of the incremental Volt/Var controller are obtained by solving a
                    chance-constrained optimization problem, where constraints are designed to
                    ensure that voltage violations do not occur more often than a pre-specified
                    probability. This approach leads to cost savings in a controlled, predictable
                    way, while still avoiding significant over- or under-voltage issues. The
                    proposed chance-constrained problem is solved using a successive convex
                    approximation method. Once the gains are broadcast to the inverters, no
                    additional communication is required since the controller is implemented
                    locally at the inverters. The proposed method is successfully tested on a
                    low-voltage 42-nodes network.
                </p>
            </div>
        </dd>
        <dt><a name="item108">[108]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02512"
                    title="Abstract">arXiv:2405.02512</a> [<a href="/pdf/2405.02512" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02512" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spatio-Temporal SwinMAE: A Swin Transformer based Multiscale
                    Representation Learner for Temporal Satellite Imagery
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nakayama%2C+Y">Yohei Nakayama</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+J">Jiawei Su</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Currently, the foundation models represented by large language models have
                    made dramatic progress and are used in a very wide range of domains including
                    2D and 3D vision. As one of the important application domains of foundation
                    models, earth observation has attracted attention and various approaches have
                    been developed. When considering earth observation as a single image capture,
                    earth observation imagery can be processed as an image with three or more
                    channels, and when it comes with multiple image captures of different
                    timestamps at one location, the temporal observation can be considered as a set
                    of continuous image resembling video frames or medical SCAN slices. This paper
                    presents Spatio-Temporal SwinMAE (ST-SwinMAE), an architecture which
                    particularly focuses on representation learning for spatio-temporal image
                    processing. Specifically, it uses a hierarchical Masked Auto-encoder (MAE) with
                    Video Swin Transformer blocks. With the architecture, we present a pretrained
                    model named Degas 100M as a geospatial foundation model. Also, we propose an
                    approach for transfer learning with Degas 100M, which both pretrained encoder
                    and decoder of MAE are utilized with skip connections added between them to
                    achieve multi-scale information communication, forms an architecture named
                    Spatio-Temporal SwinUNet (ST-SwinUNet). Our approach shows significant
                    improvements of performance over existing state-of-the-art of foundation
                    models. Specifically, for transfer learning of the land cover downstream task
                    on the PhilEO Bench dataset, it shows 10.4\% higher accuracy compared with
                    other geospatial foundation models on average.
                </p>
            </div>
        </dd>
        <dt><a name="item109">[109]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02515"
                    title="Abstract">arXiv:2405.02515</a> [<a href="/pdf/2405.02515" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02515" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SR4ZCT: Self-supervised Through-plane Resolution Enhancement
                    for CT Images with Arbitrary Resolution and Overlap
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+J">Jiayang Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pelt%2C+D+M">Daniel M. Pelt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Batenburg%2C+K+J">K. Joost Batenburg</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> MLMI2023
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Computed tomography (CT) is a widely used non-invasive medical imaging
                    technique for disease diagnosis. The diagnostic accuracy is often affected by
                    image resolution, which can be insufficient in practice. For medical CT images,
                    the through-plane resolution is often worse than the in-plane resolution and
                    there can be overlap between slices, causing difficulties in diagnoses.
                    Self-supervised methods for through-plane resolution enhancement, which train
                    on in-plane images and infer on through-plane images, have shown promise for
                    both CT and MRI imaging. However, existing self-supervised methods either
                    neglect overlap or can only handle specific cases with fixed combinations of
                    resolution and overlap. To address these limitations, we propose a
                    self-supervised method called SR4ZCT. It employs the same off-axis training
                    approach while being capable of handling arbitrary combinations of resolution
                    and overlap. Our method explicitly models the relationship between resolutions
                    and voxel spacings of different planes to accurately simulate training images
                    that match the original through-plane images. We highlight the significance of
                    accurate modeling in self-supervised off-axis training and demonstrate the
                    effectiveness of SR4ZCT using a real-world dataset.
                </p>
            </div>
        </dd>
        <dt><a name="item110">[110]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02517"
                    title="Abstract">arXiv:2405.02517</a> [<a href="/pdf/2405.02517" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02517" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mothman at SemEval-2024 Task 9: An Iterative System for
                    Chain-of-Thought Prompt Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+A+P">Alvin Po-Chun Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Groshan%2C+R">Ray Groshan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=von+Bayern%2C+S">Sean von Bayern</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages, 2 figures, to be published in Proceedings of the
                    18th International Workshop on Semantic Evaluation (SemEval-2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Extensive research exists on the performance of large language models on
                    logic-based tasks, whereas relatively little has been done on their ability to
                    generate creative solutions on lateral thinking tasks. The BrainTeaser shared
                    task tests lateral thinking and uses adversarial datasets to prevent
                    memorization, resulting in poor performance for out-of-the-box models. We
                    propose a system for iterative, chain-of-thought prompt engineering which
                    optimizes prompts using human evaluation. Using this shared task, we
                    demonstrate our system's ability to significantly improve model performance by
                    optimizing prompts and evaluate the input dataset.
                </p>
            </div>
        </dd>
        <dt><a name="item111">[111]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02520"
                    title="Abstract">arXiv:2405.02520</a> [<a href="/pdf/2405.02520" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02520" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TurboFFT: A High-Performance Fast Fourier Transform with
                    Fault Tolerance on GPU
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S">Shixun Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+Y">Yujia Zhai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jinyang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiajun Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jian%2C+Z">Zizhe Jian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+H">Huangliang Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Di%2C+S">Sheng Di</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zizhong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cappello%2C+F">Franck Cappello</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>

                </div>
                <p class="mathjax">The Fast Fourier Transform (FFT), as a core computation in a wide range of
                    scientific applications, is increasingly threatened by reliability issues. In
                    this paper, we introduce TurboFFT, a high-performance FFT implementation
                    equipped with a two-sided checksum scheme that detects and corrects silent data
                    corruptions at computing units efficiently. The proposed two-sided checksum
                    addresses the error propagation issue by encoding a batch of input signals with
                    different linear combinations, which not only allows fast batched error
                    detection but also enables error correction on-the-fly instead of recomputing.
                    We explore two-sided checksum designs at the kernel, thread, and threadblock
                    levels, and provide a baseline FFT implementation competitive to the
                    state-of-the-art, closed-source cuFFT. We demonstrate a kernel fusion strategy
                    to mitigate and overlap the computation/memory overhead introduced by fault
                    tolerance with underlying FFT computation. We present a template-based code
                    generation strategy to reduce development costs and support a wide range of
                    input sizes and data types. Experimental results on an NVIDIA A100 server GPU
                    and a Tesla Turing T4 GPU demonstrate TurboFFT offers a competitive or superior
                    performance compared to the closed-source library cuFFT. TurboFFT only incurs a
                    minimum overhead (7\% to 15\% on average) compared to cuFFT, even under
                    hundreds of error injections per minute for both single and double precision.
                    TurboFFT achieves a 23\% improvement compared to existing fault tolerance FFT
                    schemes.
                </p>
            </div>
        </dd>
        <dt><a name="item112">[112]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02522"
                    title="Abstract">arXiv:2405.02522</a> [<a href="/pdf/2405.02522" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02522" title="Download PostScript">ps</a>, <a href="/format/2405.02522"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> New contexts, old heuristics: How young people in India and
                    the US trust online content in the age of generative AI
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Rachel Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Le%2C+N">Nhu Le</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+R">Rebekah Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Murray%2C+L">Laura Murray</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Das%2C+V">Vishnupriya Das</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+D">Devika Kumar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goldberg%2C+B">Beth Goldberg</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Social and
                    Information Networks (cs.SI)

                </div>
                <p class="mathjax">We conducted an in-person ethnography in India and the US to investigate how
                    young people (18-24) trusted online content, with a focus on generative AI
                    (GenAI). We had four key findings about how young people use GenAI and
                    determine what to trust online. First, when online, we found participants
                    fluidly shifted between mindsets and emotional states, which we term
                    "information modes." Second, these information modes shaped how and why
                    participants trust GenAI and how they applied literacy skills. In the modes
                    where they spent most of their time, they eschewed literacy skills. Third, with
                    the advent of GenAI, participants imported existing trust heuristics from
                    familiar online contexts into their interactions with GenAI. Fourth, although
                    study participants had reservations about GenAI, they saw it as a requisite
                    tool to adopt to keep up with the times. Participants valued efficiency above
                    all else, and used GenAI to further their goals quickly at the expense of
                    accuracy. Our findings suggest that young people spend the majority of their
                    time online not concerned with truth because they are seeking only to pass the
                    time. As a result, literacy interventions should be designed to intervene at
                    the right time, to match users' distinct information modes, and to work with
                    their existing fact-checking practices.
                </p>
            </div>
        </dd>
        <dt><a name="item113">[113]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02525"
                    title="Abstract">arXiv:2405.02525</a> [<a href="/pdf/2405.02525" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02525" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> RLStop: A Reinforcement Learning Stopping Method for TAR
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bin-Hezam%2C+R">Reem Bin-Hezam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stevenson%2C+M">Mark Stevenson</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at SIGIR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">We present RLStop, a novel Technology Assisted Review (TAR) stopping rule
                    based on reinforcement learning that helps minimise the number of documents
                    that need to be manually reviewed within TAR applications. RLStop is trained on
                    example rankings using a reward function to identify the optimal point to stop
                    examining documents. Experiments at a range of target recall levels on multiple
                    benchmark datasets (CLEF e-Health, TREC Total Recall, and Reuters RCV1)
                    demonstrated that RLStop substantially reduces the workload required to screen
                    a document collection for relevance. RLStop outperforms a wide range of
                    alternative approaches, achieving performance close to the maximum possible for
                    the task under some circumstances.
                </p>
            </div>
        </dd>
        <dt><a name="item114">[114]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02528"
                    title="Abstract">arXiv:2405.02528</a> [<a href="/pdf/2405.02528" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02528" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GigSense: An LLM-Infused Tool forWorkers' Collective
                    Intelligence
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Imteyaz%2C+K">Kashif Imteyaz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Flores-Saviaga%2C+C">Claudia Flores-Saviaga</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Savage%2C+S">Saiph Savage</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> CI: ACM Collective Intelligence Conference 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">Collective intelligence among gig workers yields considerable advantages,
                    including improved information exchange, deeper social bonds, and stronger
                    advocacy for better labor conditions. Especially as it enables workers to
                    collaboratively pinpoint shared challenges and devise optimal strategies for
                    addressing these issues. However, enabling collective intelligence remains
                    challenging, as existing tools often overestimate gig workers' available time
                    and uniformity in analytical reasoning. To overcome this, we introduce
                    GigSense, a tool that leverages large language models alongside theories of
                    collective intelligence and sensemaking. GigSense enables gig workers to
                    rapidly understand and address shared challenges effectively, irrespective of
                    their diverse backgrounds. Our user study showed that GigSense users
                    outperformed those using a control interface in problem identification and
                    generated solutions more quickly and of higher quality, with better usability
                    experiences reported. GigSense not only empowers gig workers but also opens up
                    new possibilities for supporting workers more broadly, demonstrating the
                    potential of large language model interfaces to enhance collective intelligence
                    efforts in the evolving workplace.
                </p>
            </div>
        </dd>
        <dt><a name="item115">[115]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02534"
                    title="Abstract">arXiv:2405.02534</a> [<a href="/pdf/2405.02534" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02534" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Multi-Domain Multi-Task Approach for Feature Selection from
                    Bulk RNA Datasets
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Salta%2C+K">Karim Salta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghosh%2C+T">Tomojit Ghosh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kirby%2C+M">Michael Kirby</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Genomics (q-bio.GN)

                </div>
                <p class="mathjax">In this paper a multi-domain multi-task algorithm for feature selection in
                    bulk RNAseq data is proposed. Two datasets are investigated arising from mouse
                    host immune response to Salmonella infection. Data is collected from several
                    strains of collaborative cross mice. Samples from the spleen and liver serve as
                    the two domains. Several machine learning experiments are conducted and the
                    small subset of discriminative across domains features have been extracted in
                    each case. The algorithm proves viable and underlines the benefits of across
                    domain feature selection by extracting new subset of discriminative features
                    which couldn't be extracted only by one-domain approach.
                </p>
            </div>
        </dd>
        <dt><a name="item116">[116]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02537"
                    title="Abstract">arXiv:2405.02537</a> [<a href="/pdf/2405.02537" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02537" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Robust Data-Driven Iterative Control Method for Linear
                    Systems with Bounded Disturbances
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Hu%2C+K">Kaijian Hu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Liu%2C+T">Tao Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">This paper proposes a new robust data-driven control method for linear
                    systems with bounded disturbances, where the system model and disturbances are
                    unknown. Due to disturbances, accurately determining the true system becomes
                    challenging using the collected dataset. Therefore, instead of designing
                    controllers directly for the unknown true system, an available approach is to
                    design controllers for all systems compatible with the dataset. To overcome the
                    limitations of using a single dataset and benefit from collecting more data,
                    multiple datasets are employed in this paper. Furthermore, a new iterative
                    method is developed to address the challenges of using multiple datasets. Based
                    on this method, this paper develops an offline and online robust data-driven
                    iterative control method, respectively. Compared to the existing robust
                    data-driven controller method, both proposed control methods iteratively
                    utilize multiple datasets in the controller design process. This allows for the
                    incorporation of numerous datasets, potentially reducing the conservativeness
                    of the designed controller. Particularly, the online controller is iteratively
                    designed by continuously incorporating online collected data into the
                    historical data to construct new datasets. Lastly, the effectiveness of the
                    proposed methods is demonstrated using a batch reactor.
                </p>
            </div>
        </dd>
        <dt><a name="item117">[117]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02538"
                    title="Abstract">arXiv:2405.02538</a> [<a href="/pdf/2405.02538" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02538" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AdaFPP: Adapt-Focused Bi-Propagating Prototype Learning for
                    Panoramic Activity Recognition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+M">Meiqi Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+R">Rui Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shu%2C+X">Xiangbo Shu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+G">Guangzhao Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yazhou Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+G">Guo-Sen Xie</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Panoramic Activity Recognition (PAR) aims to identify multi-granularity
                    behaviors performed by multiple persons in panoramic scenes, including
                    individual activities, group activities, and global activities. Previous
                    methods 1) heavily rely on manually annotated detection boxes in training and
                    inference, hindering further practical deployment; or 2) directly employ normal
                    detectors to detect multiple persons with varying size and spatial occlusion in
                    panoramic scenes, blocking the performance gain of PAR. To this end, we
                    consider learning a detector adapting varying-size occluded persons, which is
                    optimized along with the recognition module in the all-in-one framework.
                    Therefore, we propose a novel Adapt-Focused bi-Propagating Prototype learning
                    (AdaFPP) framework to jointly recognize individual, group, and global
                    activities in panoramic activity scenes by learning an adapt-focused detector
                    and multi-granularity prototypes as the pretext tasks in an end-to-end way.
                    Specifically, to accommodate the varying sizes and spatial occlusion of
                    multiple persons in crowed panoramic scenes, we introduce a panoramic
                    adapt-focuser, achieving the size-adapting detection of individuals by
                    comprehensively selecting and performing fine-grained detections on
                    object-dense sub-regions identified through original detections. In addition,
                    to mitigate information loss due to inaccurate individual localizations, we
                    introduce a bi-propagation prototyper that promotes closed-loop interaction and
                    informative consistency across different granularities by facilitating
                    bidirectional information propagation among the individual, group, and global
                    levels. Extensive experiments demonstrate the significant performance of AdaFPP
                    and emphasize its powerful applicability for PAR.
                </p>
            </div>
        </dd>
        <dt><a name="item118">[118]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02543"
                    title="Abstract">arXiv:2405.02543</a> [<a href="/pdf/2405.02543" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02543" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring Extreme Quantization in Spiking Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bal%2C+M">Malyaban Bal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yi Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sengupta%2C+A">Abhronil Sengupta</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>

                </div>
                <p class="mathjax">Despite the growing prevalence of large language model (LLM) architectures, a
                    crucial concern persists regarding their energy and power consumption, which
                    still lags far behind the remarkable energy efficiency of the human brain.
                    Recent strides in spiking language models (LM) and transformer architectures
                    aim to address this concern by harnessing the spiking activity of biological
                    neurons to enhance energy/power efficiency. Doubling down on the principles of
                    model quantization and energy efficiency, this paper proposes the development
                    of a novel binary/ternary (1/1.58-bit) spiking LM architecture. Achieving
                    scalability comparable to a deep spiking LM architecture is facilitated by an
                    efficient knowledge distillation technique, wherein knowledge from a
                    non-spiking full-precision "teacher" model is transferred to an extremely
                    weight quantized spiking "student" LM. Our proposed model represents a
                    significant advancement as the first-of-its-kind 1/1.58-bit spiking LM, and its
                    performance is rigorously evaluated on multiple text classification tasks of
                    the GLUE benchmark.
                </p>
            </div>
        </dd>
        <dt><a name="item119">[119]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02544"
                    title="Abstract">arXiv:2405.02544</a> [<a href="/pdf/2405.02544" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02544" title="Download PostScript">ps</a>, <a href="/format/2405.02544"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Novel Endorsement Protocol to Secure BFT-Based Consensus in
                    Permissionless Blockchain
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Ziqiang Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shahraki%2C+A+S">Ahmad Salehi Shahraki</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chilamkurti%2C+N">Naveen Chilamkurti</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at IEEE Wireless Communications and Networking
                    Conference (WCNC), 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Permissionless blockchain technology offers numerous potential benefits for
                    decentralised applications, such as security, transparency, and openness.
                    BFT-based consensus mechanisms are widely adopted in the permissioned
                    blockchain to meet the high scalability requirements of the network. Sybil
                    attacks are one of the most potential threats when applying BFT-based consensus
                    mechanisms in permissionless blockchain due to the lack of effective
                    verification mechanisms for participants' identities. This paper presents a
                    novel endorsement-based bootstrapping protocol with a signature algorithm that
                    offers a streamlined, scalable identity endorsement and verification process.
                    This approach effectively safeguards the BFT-based consensus mechanism against
                    Sybil attacks. Using our proposed method, we have conducted thorough security
                    analyses and simulation experiments to assess security, robustness, and
                    scalability advantages in large-scale networks. Our results demonstrate that
                    the scheme can effectively address the identity verification challenges when
                    applying BFT-based consensus in a permissionless blockchain.
                </p>
            </div>
        </dd>
        <dt><a name="item120">[120]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02546"
                    title="Abstract">arXiv:2405.02546</a> [<a href="/pdf/2405.02546" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02546" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Scaling SNNs Trained Using Equilibrium Propagation to
                    Convolutional Architectures
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jiaqi Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bal%2C+M">Malyaban Bal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sengupta%2C+A">Abhronil Sengupta</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>

                </div>
                <p class="mathjax">Equilibrium Propagation (EP) is a biologically plausible local learning
                    algorithm initially developed for convergent recurrent neural networks (RNNs),
                    where weight updates rely solely on the connecting neuron states across two
                    phases. The gradient calculations in EP have been shown to approximate the
                    gradients computed by Backpropagation Through Time (BPTT) when an
                    infinitesimally small nudge factor is used. This property makes EP a powerful
                    candidate for training Spiking Neural Networks (SNNs), which are commonly
                    trained by BPTT. However, in the spiking domain, previous studies on EP have
                    been limited to architectures involving few linear layers. In this work, for
                    the first time we provide a formulation for training convolutional spiking
                    convergent RNNs using EP, bridging the gap between spiking and non-spiking
                    convergent RNNs. We demonstrate that for spiking convergent RNNs, there is a
                    mismatch in the maximum pooling and its inverse operation, leading to
                    inaccurate gradient estimation in EP. Substituting this with average pooling
                    resolves this issue and enables accurate gradient estimation for spiking
                    convergent RNNs. We also highlight the memory efficiency of EP compared to
                    BPTT. In the regime of SNNs trained by EP, our experimental results indicate
                    state-of-the-art performance on the MNIST and FashionMNIST datasets, with test
                    errors of 0.97% and 8.89%, respectively. These results are comparable to those
                    of convergent RNNs and SNNs trained by BPTT. These findings underscore EP as an
                    optimal choice for on-chip training and a biologically-plausible method for
                    computing error gradients.
                </p>
            </div>
        </dd>
        <dt><a name="item121">[121]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02548"
                    title="Abstract">arXiv:2405.02548</a> [<a href="/pdf/2405.02548" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02548" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CNN-LSTM and Transfer Learning Models for Malware
                    Classification based on Opcodes and API Calls
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bensaoud%2C+A">Ahmed Bensaoud</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kalita%2C+J">Jugal Kalita</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Bensaoud, A., &amp; Kalita, J. (2024). CNN-LSTM and
                    transfer learning
                    models for malware classification based on opcodes and API calls.
                    Knowledge-Based Systems, 111543
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In this paper, we propose a novel model for a malware classification system
                    based on Application Programming Interface (API) calls and opcodes, to improve
                    classification accuracy. This system uses a novel design of combined
                    Convolutional Neural Network and Long Short-Term Memory. We extract opcode
                    sequences and API Calls from Windows malware samples for classification. We
                    transform these features into N-grams (N = 2, 3, and 10)-gram sequences. Our
                    experiments on a dataset of 9,749,57 samples produce high accuracy of 99.91%
                    using the 8-gram sequences. Our method significantly improves the malware
                    classification performance when using a wide range of recent deep learning
                    architectures, leading to state-of-the-art performance. In particular, we
                    experiment with ConvNeXt-T, ConvNeXt-S, RegNetY-4GF, RegNetY-8GF, RegNetY-12GF,
                    EfficientNetV2, Sequencer2D-L, Swin-T, ViT-G/14, ViT-Ti, ViT-S, VIT-B, VIT-L,
                    and MaxViT-B. Among these architectures, Swin-T and Sequencer2D-L architectures
                    achieved high accuracies of 99.82% and 99.70%, respectively, comparable to our
                    CNN-LSTM architecture although not surpassing it.
                </p>
            </div>
        </dd>
        <dt><a name="item122">[122]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02556"
                    title="Abstract">arXiv:2405.02556</a> [<a href="/pdf/2405.02556" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02556" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Few-Shot Fruit Segmentation via Transfer Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=James%2C+J+A">Jordan A. James</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Manching%2C+H+K">Heather K. Manching</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hulse-Kemp%2C+A+M">Amanda M. Hulse-Kemp</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Beksi%2C+W+J">William J. Beksi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To be published in the 2024 IEEE International Conference
                    on Robotics and Automation (ICRA)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Robotics (cs.RO)

                </div>
                <p class="mathjax">Advancements in machine learning, computer vision, and robotics have paved
                    the way for transformative solutions in various domains, particularly in
                    agriculture. For example, accurate identification and segmentation of fruits
                    from field images plays a crucial role in automating jobs such as harvesting,
                    disease detection, and yield estimation. However, achieving robust and precise
                    infield fruit segmentation remains a challenging task since large amounts of
                    labeled data are required to handle variations in fruit size, shape, color, and
                    occlusion. In this paper, we develop a few-shot semantic segmentation framework
                    for infield fruits using transfer learning. Concretely, our work is aimed at
                    addressing agricultural domains that lack publicly available labeled data.
                    Motivated by similar success in urban scene parsing, we propose specialized
                    pre-training using a public benchmark dataset for fruit transfer learning. By
                    leveraging pre-trained neural networks, accurate semantic segmentation of fruit
                    in the field is achieved with only a few labeled images. Furthermore, we show
                    that models with pre-training learn to distinguish between fruit still on the
                    trees and fruit that have fallen on the ground, and they can effectively
                    transfer the knowledge to the target fruit dataset.
                </p>
            </div>
        </dd>
        <dt><a name="item123">[123]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02559"
                    title="Abstract">arXiv:2405.02559</a> [<a href="/pdf/2405.02559" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02559" title="Download PostScript">ps</a>, <a href="/format/2405.02559"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Literature Review and Framework for Human Evaluation of
                    Generative Large Language Models in Healthcare
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tam%2C+T+Y+C">Thomas Yu Chow Tam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sivarajkumar%2C+S">Sonish Sivarajkumar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kapoor%2C+S">Sumit Kapoor</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stolyar%2C+A+V">Alisa V Stolyar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Polanska%2C+K">Katelyn Polanska</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McCarthy%2C+K+R">Karleigh R McCarthy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Osterhoudt%2C+H">Hunter Osterhoudt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xizhi Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Visweswaran%2C+S">Shyam Visweswaran</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+S">Sunyang Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mathur%2C+P">Piyush Mathur</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cacciamani%2C+G+E">Giovanni E. Cacciamani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+C">Cong Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yifan Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanshan Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">As generative artificial intelligence (AI), particularly Large Language
                    Models (LLMs), continues to permeate healthcare, it remains crucial to
                    supplement traditional automated evaluations with human expert evaluation.
                    Understanding and evaluating the generated texts is vital for ensuring safety,
                    reliability, and effectiveness. However, the cumbersome, time-consuming, and
                    non-standardized nature of human evaluation presents significant obstacles to
                    the widespread adoption of LLMs in practice. This study reviews existing
                    literature on human evaluation methodologies for LLMs within healthcare. We
                    highlight a notable need for a standardized and consistent human evaluation
                    approach. Our extensive literature search, adhering to the Preferred Reporting
                    Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, spans
                    publications from January 2018 to February 2024. This review provides a
                    comprehensive overview of the human evaluation approaches used in diverse
                    healthcare applications.This analysis examines the human evaluation of LLMs
                    across various medical specialties, addressing factors such as evaluation
                    dimensions, sample types, and sizes, the selection and recruitment of
                    evaluators, frameworks and metrics, the evaluation process, and statistical
                    analysis of the results. Drawing from diverse evaluation strategies highlighted
                    in these studies, we propose a comprehensive and practical framework for human
                    evaluation of generative LLMs, named QUEST: Quality of Information,
                    Understanding and Reasoning, Expression Style and Persona, Safety and Harm, and
                    Trust and Confidence. This framework aims to improve the reliability,
                    generalizability, and applicability of human evaluation of generative LLMs in
                    different healthcare applications by defining clear evaluation dimensions and
                    offering detailed guidelines.
                </p>
            </div>
        </dd>
        <dt><a name="item124">[124]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02560"
                    title="Abstract">arXiv:2405.02560</a> [<a href="/pdf/2405.02560" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02560" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Pilot Study on the Comparison of Prefrontal Cortex
                    Activities of Robotic Therapies on Elderly with Mild Cognitive Impairment
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Au-Yeung%2C+K+T+H">King Tai Henry Au-Yeung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+W+W+L">William Wai Lam Chan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+K+Y+B">Kwan Yin Brian Chan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+H">Hongjie Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+J">Junpei Zhong</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> submitted to IEEE on affective computing
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Demographic shifts have led to an increase in mild cognitive impairment
                    (MCI), and this study investigates the effects of cognitive training (CT) and
                    reminiscence therapy (RT) conducted by humans or socially assistive robots
                    (SARs) on prefrontal cortex activation in elderly individuals with MCI, aiming
                    to determine the most effective therapy-modality combination for promoting
                    cognitive function. This pilot study employs a randomized control trial (RCT)
                    design. Additionally, the study explores the efficacy of Reminiscence Therapy
                    (RT) in comparison to Cognitive Training (CT). Eight MCI subjects, with a mean
                    age of 70.125 years, were randomly assigned to ``human-led'' or ``SAR-led''
                    groups. Utilizing Functional Near-infrared Spectroscopy (fNIRS) to measure
                    oxy-hemoglobin concentration changes in the dorsolateral prefrontal cortex
                    (DLPFC), the study found no significant differences in the effects of human-led
                    and SAR-led cognitive training on DLPFC activation. However, distinct patterns
                    emerged in memory encoding and retrieval phases between RT and CT, shedding
                    light on the impacts of these interventions on brain activation in the context
                    of MCI.
                </p>
            </div>
        </dd>
        <dt><a name="item125">[125]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02561"
                    title="Abstract">arXiv:2405.02561</a> [<a href="/pdf/2405.02561" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02561" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Understanding the Difficulty of Solving Cauchy Problems with
                    PINNs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+B">Bo Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+S">Sicun Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+R">Rose Yu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages and 18 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">Physics-Informed Neural Networks (PINNs) have gained popularity in scientific
                    computing in recent years. However, they often fail to achieve the same level
                    of accuracy as classical methods in solving differential equations. In this
                    paper, we identify two sources of this issue in the case of Cauchy problems:
                    the use of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-42-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-285"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1001.1em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-286"><span class="msubsup"
                                                id="MathJax-Span-287"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-288"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-289"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-42">L^2</script> residuals as objective functions and
                    the approximation gap of
                    neural networks. We show that minimizing the sum of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-43-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-290"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1001.1em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-291"><span class="msubsup"
                                                id="MathJax-Span-292"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-293"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-294"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-43">L^2</script> residual and initial
                    condition error is not sufficient to guarantee the true solution, as this loss
                    function does not capture the underlying dynamics. Additionally, neural
                    networks are not capable of capturing singularities in the solutions due to the
                    non-compactness of their image sets. This, in turn, influences the existence of
                    global minima and the regularity of the network. We demonstrate that when the
                    global minimum does not exist, machine precision becomes the predominant source
                    of achievable error in practice. We also present numerical experiments in
                    support of our theoretical claims.
                </p>
            </div>
        </dd>
        <dt><a name="item126">[126]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02564"
                    title="Abstract">arXiv:2405.02564</a> [<a href="/pdf/2405.02564" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02564" title="Download PostScript">ps</a>, <a href="/format/2405.02564"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Leveraging the Human Ventral Visual Stream to Improve Neural
                    Network Robustness
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shao%2C+Z">Zhenan Shao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+L">Linjian Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Beck%2C+D+M">Diane M. Beck</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

                </div>
                <p class="mathjax">Human object recognition exhibits remarkable resilience in cluttered and
                    dynamic visual environments. In contrast, despite their unparalleled
                    performance across numerous visual tasks, Deep Neural Networks (DNNs) remain
                    far less robust than humans, showing, for example, a surprising susceptibility
                    to adversarial attacks involving image perturbations that are (almost)
                    imperceptible to humans. Human object recognition likely owes its robustness,
                    in part, to the increasingly resilient representations that emerge along the
                    hierarchy of the ventral visual cortex. Here we show that DNNs, when guided by
                    neural representations from a hierarchical sequence of regions in the human
                    ventral visual stream, display increasing robustness to adversarial attacks.
                    These neural-guided models also exhibit a gradual shift towards more human-like
                    decision-making patterns and develop hierarchically smoother decision surfaces.
                    Importantly, the resulting representational spaces differ in important ways
                    from those produced by conventional smoothing methods, suggesting that such
                    neural-guidance may provide previously unexplored robustness solutions. Our
                    findings support the gradual emergence of human robustness along the ventral
                    visual hierarchy and suggest that the key to DNN robustness may lie in
                    increasing emulation of the human brain.
                </p>
            </div>
        </dd>
        <dt><a name="item127">[127]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02568"
                    title="Abstract">arXiv:2405.02568</a> [<a href="/pdf/2405.02568" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02568" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ActiveNeuS: Active 3D Reconstruction using Neural Implicit
                    Surface Uncertainty
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+H">Hyunseo Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H">Hyeonseo Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+T">Taekyung Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+Y">YoonSung Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jin-Hwa Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+B">Byoung-Tak Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Active learning in 3D scene reconstruction has been widely studied, as
                    selecting informative training views is critical for the reconstruction.
                    Recently, Neural Radiance Fields (NeRF) variants have shown performance
                    increases in active 3D reconstruction using image rendering or geometric
                    uncertainty. However, the simultaneous consideration of both uncertainties in
                    selecting informative views remains unexplored, while utilizing different types
                    of uncertainty can reduce the bias that arises in the early training stage with
                    sparse inputs. In this paper, we propose ActiveNeuS, which evaluates candidate
                    views considering both uncertainties. ActiveNeuS provides a way to accumulate
                    image rendering uncertainty while avoiding the bias that the estimated
                    densities can introduce. ActiveNeuS computes the neural implicit surface
                    uncertainty, providing the color uncertainty along with the surface
                    information. It efficiently handles the bias by using the surface information
                    and a grid, enabling the fast selection of diverse viewpoints. Our method
                    outperforms previous works on popular datasets, Blender and DTU, showing that
                    the views selected by ActiveNeuS significantly improve performance.
                </p>
            </div>
        </dd>
        <dt><a name="item128">[128]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02569"
                    title="Abstract">arXiv:2405.02569</a> [<a href="/pdf/2405.02569" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02569" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Decoupling Exploration and Exploitation for Unsupervised
                    Pre-training with Successor Features
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">JaeYoon Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xuan%2C+J">Junyu Xuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liang%2C+C">Christy Liang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hussain%2C+F">Farookh Hussain</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> IJCNN 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Unsupervised pre-training has been on the lookout for the virtue of a value
                    function representation referred to as successor features (SFs), which
                    decouples the dynamics of the environment from the rewards. It has a
                    significant impact on the process of task-specific fine-tuning due to the
                    decomposition. However, existing approaches struggle with local optima due to
                    the unified intrinsic reward of exploration and exploitation without
                    considering the linear regression problem and the discriminator supporting a
                    small skill sapce. We propose a novel unsupervised pre-training model with SFs
                    based on a non-monolithic exploration methodology. Our approach pursues the
                    decomposition of exploitation and exploration of an agent built on SFs, which
                    requires separate agents for the respective purpose. The idea will leverage not
                    only the inherent characteristics of SFs such as a quick adaptation to new
                    tasks but also the exploratory and task-agnostic capabilities. Our suggested
                    model is termed Non-Monolithic unsupervised Pre-training with Successor
                    features (NMPS), which improves the performance of the original monolithic
                    exploration method of pre-training with SFs. NMPS outperforms Active
                    Pre-training with Successor Features (APS) in a comparative experiment.
                </p>
            </div>
        </dd>
        <dt><a name="item129">[129]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02571"
                    title="Abstract">arXiv:2405.02571</a> [<a href="/pdf/2405.02571" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02571" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ViTALS: Vision Transformer for Action Localization in
                    Surgical Nephrectomy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chandra%2C+S">Soumyadeep Chandra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chowdhury%2C+S+S">Sayeed Shafayet Chowdhury</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yong%2C+C">Courtney Yong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sundaram%2C+C+P">Chandru P. Sundaram</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roy%2C+K">Kaushik Roy</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Nephrectomy surgery, Surgical Phase Recognition, Surgical
                    Workflow Segmentation, 11 pages, 2 figures, 2 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Surgical action localization is a challenging computer vision problem. While
                    it has promising applications including automated training of surgery
                    procedures, surgical workflow optimization, etc., appropriate model design is
                    pivotal to accomplishing this task. Moreover, the lack of suitable medical
                    datasets adds an additional layer of complexity. To that effect, we introduce a
                    new complex dataset of nephrectomy surgeries called UroSlice. To perform the
                    action localization from these videos, we propose a novel model termed as
                    `ViTALS' (Vision Transformer for Action Localization in Surgical Nephrectomy).
                    Our model incorporates hierarchical dilated temporal convolution layers and
                    inter-layer residual connections to capture the temporal correlations at finer
                    as well as coarser granularities. The proposed approach achieves
                    state-of-the-art performance on Cholec80 and UroSlice datasets (89.8% and 66.1%
                    accuracy, respectively), validating its effectiveness.
                </p>
            </div>
        </dd>
        <dt><a name="item130">[130]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02572"
                    title="Abstract">arXiv:2405.02572</a> [<a href="/pdf/2405.02572" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02572" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Off-OAB: Off-Policy Policy Gradient Method with Optimal
                    Action-Dependent Baseline
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Meng%2C+W">Wenjia Meng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+Q">Qian Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L">Long Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yin%2C+Y">Yilong Yin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pan%2C+G">Gang Pan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 3 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Policy-based methods have achieved remarkable success in solving challenging
                    reinforcement learning problems. Among these methods, off-policy policy
                    gradient methods are particularly important due to that they can benefit from
                    off-policy data. However, these methods suffer from the high variance of the
                    off-policy policy gradient (OPPG) estimator, which results in poor sample
                    efficiency during training. In this paper, we propose an off-policy policy
                    gradient method with the optimal action-dependent baseline (Off-OAB) to
                    mitigate this variance issue. Specifically, this baseline maintains the OPPG
                    estimator's unbiasedness while theoretically minimizing its variance. To
                    enhance practical computational efficiency, we design an approximated version
                    of this optimal baseline. Utilizing this approximation, our method (Off-OAB)
                    aims to decrease the OPPG estimator's variance during policy optimization. We
                    evaluate the proposed Off-OAB method on six representative tasks from OpenAI
                    Gym and MuJoCo, where it demonstrably surpasses state-of-the-art methods on the
                    majority of these tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item131">[131]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02573"
                    title="Abstract">arXiv:2405.02573</a> [<a href="/pdf/2405.02573" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02573" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Combination of BERT and Transformer for Vietnamese Spelling
                    Correction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Trung%2C+H+N">Hieu Ngo Trung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ham%2C+D+T">Duong Tran Ham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huynh%2C+T">Tin Huynh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hoang%2C+K">Kiem Hoang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> ACIIDS 2022, LNCS, vol 13757, Springer, Cham
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Recently, many studies have shown the efficiency of using Bidirectional
                    Encoder Representations from Transformers (BERT) in various Natural Language
                    Processing (NLP) tasks. Specifically, English spelling correction task that
                    uses Encoder-Decoder architecture and takes advantage of BERT has achieved
                    state-of-the-art result. However, to our knowledge, there is no implementation
                    in Vietnamese yet. Therefore, in this study, a combination of Transformer
                    architecture (state-of-the-art for Encoder-Decoder model) and BERT was proposed
                    to deal with Vietnamese spelling correction. The experiment results have shown
                    that our model outperforms other approaches as well as the Google Docs Spell
                    Checking tool, achieves an 86.24 BLEU score on this task.
                </p>
            </div>
        </dd>
        <dt><a name="item132">[132]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02574"
                    title="Abstract">arXiv:2405.02574</a> [<a href="/pdf/2405.02574" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02574" title="Download PostScript">ps</a>, <a href="/format/2405.02574"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Data Mining-Based Dynamical Anomaly Detection Method for
                    Integrating with an Advance Metering System
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Maitra%2C+S">Sarit Maitra</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Building operations consume 30% of total power consumption and contribute 26%
                    of global power-related emissions. Therefore, monitoring, and early detection
                    of anomalies at the meter level are essential for residential and commercial
                    buildings. This work investigates both supervised and unsupervised approaches
                    and introduces a dynamic anomaly detection system. The system introduces a
                    supervised Light Gradient Boosting machine and an unsupervised autoencoder with
                    a dynamic threshold. This system is designed to provide real-time detection of
                    anomalies at the meter level. The proposed dynamical system comes with a
                    dynamic threshold based on the Mahalanobis distance and moving averages. This
                    approach allows the system to adapt to changes in the data distribution over
                    time. The effectiveness of the proposed system is evaluated using real-life
                    power consumption data collected from smart metering systems. This empirical
                    testing ensures that the system's performance is validated under real-world
                    conditions. By detecting unusual data movements and providing early warnings,
                    the proposed system contributes significantly to visual analytics and decision
                    science. Early detection of anomalies enables timely troubleshooting,
                    preventing financial losses and potential disasters such as fire incidents.
                </p>
            </div>
        </dd>
        <dt><a name="item133">[133]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02576"
                    title="Abstract">arXiv:2405.02576</a> [<a href="/pdf/2405.02576" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02576" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CTD4 - A Deep Continuous Distributional Actor-Critic Agent
                    with a Kalman Fusion of Multiple Critics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Valencia%2C+D">David Valencia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Williams%2C+H">Henry Williams</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gee%2C+T">Trevor Gee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=MacDonaland%2C+B+A">Bruce A MacDonaland</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liarokapis%2C+M">Minas Liarokapis</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Categorical Distributional Reinforcement Learning (CDRL) has demonstrated
                    superior sample efficiency in learning complex tasks compared to conventional
                    Reinforcement Learning (RL) approaches. However, the practical application of
                    CDRL is encumbered by challenging projection steps, detailed parameter tuning,
                    and domain knowledge. This paper addresses these challenges by introducing a
                    pioneering Continuous Distributional Model-Free RL algorithm tailored for
                    continuous action spaces. The proposed algorithm simplifies the implementation
                    of distributional RL, adopting an actor-critic architecture wherein the critic
                    outputs a continuous probability distribution. Additionally, we propose an
                    ensemble of multiple critics fused through a Kalman fusion mechanism to
                    mitigate overestimation bias. Through a series of experiments, we validate that
                    our proposed method is easy to train and serves as a sample-efficient solution
                    for executing complex continuous-control tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item134">[134]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02578"
                    title="Abstract">arXiv:2405.02578</a> [<a href="/pdf/2405.02578" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02578" title="Download PostScript">ps</a>, <a href="/format/2405.02578"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mixat: A Data Set of Bilingual Emirati-English Speech
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ali%2C+M+A">Maryam Al Ali</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Aldarmaki%2C+H">Hanan Aldarmaki</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> SIGUL 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">This paper introduces Mixat: a dataset of Emirati speech code-mixed with
                    English. Mixat was developed to address the shortcomings of current speech
                    recognition resources when applied to Emirati speech, and in particular, to
                    bilignual Emirati speakers who often mix and switch between their local dialect
                    and English. The data set consists of 15 hours of speech derived from two
                    public podcasts featuring native Emirati speakers, one of which is in the form
                    of conversations between the host and a guest. Therefore, the collection
                    contains examples of Emirati-English code-switching in both formal and natural
                    conversational contexts. In this paper, we describe the process of data
                    collection and annotation, and describe some of the features and statistics of
                    the resulting data set. In addition, we evaluate the performance of pre-trained
                    Arabic and multi-lingual ASR systems on our dataset, demonstrating the
                    shortcomings of existing models on this low-resource dialectal Arabic, and the
                    additional challenge of recognizing code-switching in ASR. The dataset will be
                    made publicly available for research use.
                </p>
            </div>
        </dd>
        <dt><a name="item135">[135]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02579"
                    title="Abstract">arXiv:2405.02579</a> [<a href="/pdf/2405.02579" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02579" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Innate Motivation for Robot Swarms by Minimizing Surprise:
                    From Simple Simulations to Real-World Experiments
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kaiser%2C+T+K">Tanja Katharina Kaiser</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hamann%2C+H">Heiko Hamann</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published in IEEE Transactions on Robotics
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Multiagent Systems (cs.MA); Neural and Evolutionary Computing (cs.NE)

                </div>
                <p class="mathjax">Applications of large-scale mobile multi-robot systems can be beneficial over
                    monolithic robots because of higher potential for robustness and scalability.
                    Developing controllers for multi-robot systems is challenging because the
                    multitude of interactions is hard to anticipate and difficult to model.
                    Automatic design using machine learning or evolutionary robotics seem to be
                    options to avoid that challenge, but bring the challenge of designing reward or
                    fitness functions. Generic reward and fitness functions seem unlikely to exist
                    and task-specific rewards often have undesired side effects. Approaches of
                    so-called innate motivation try to avoid the specific formulation of rewards
                    and work instead with different drivers, such as curiosity. Our approach to
                    innate motivation is to minimize surprise, which we implement by maximizing the
                    accuracy of the swarm robot's sensor predictions using neuroevolution. A unique
                    advantage of the swarm robot case is that swarm members populate the robot's
                    environment and can trigger more active behaviors in a self-referential loop.
                    We summarize our previous simulation-based results concerning behavioral
                    diversity, robustness, scalability, and engineered self-organization, and put
                    them into context. In several new studies, we analyze the influence of the
                    optimizer's hyperparameters, the scalability of evolved behaviors, and the
                    impact of realistic robot simulations. Finally, we present results using real
                    robots that show how the reality gap can be bridged.
                </p>
            </div>
        </dd>
        <dt><a name="item136">[136]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02580"
                    title="Abstract">arXiv:2405.02580</a> [<a href="/pdf/2405.02580" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02580" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PropertyGPT: LLM-driven Formal Verification of Smart
                    Contracts through Retrieval-Augmented Property Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Ye Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+Y">Yue Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+D">Daoyuan Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuqiang Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+M">Miaolei Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">With recent advances in large language models (LLMs), this paper explores the
                    potential of leveraging state-of-the-art LLMs, such as GPT-4, to transfer
                    existing human-written properties (e.g., those from Certora auditing reports)
                    and automatically generate customized properties for unknown code. To this end,
                    we embed existing properties into a vector database and retrieve a reference
                    property for LLM-based in-context learning to generate a new prop- erty for a
                    given code. While this basic process is relatively straight- forward, ensuring
                    that the generated properties are (i) compilable, (ii) appropriate, and (iii)
                    runtime-verifiable presents challenges. To address (i), we use the compilation
                    and static analysis feedback as an external oracle to guide LLMs in iteratively
                    revising the generated properties. For (ii), we consider multiple dimensions of
                    similarity to rank the properties and employ a weighted algorithm to identify
                    the top-K properties as the final result. For (iii), we design a dedicated
                    prover to formally verify the correctness of the generated prop- erties. We
                    have implemented these strategies into a novel system called PropertyGPT, with
                    623 human-written properties collected from 23 Certora projects. Our
                    experiments show that PropertyGPT can generate comprehensive and high-quality
                    properties, achieving an 80% recall compared to the ground truth. It
                    successfully detected 26 CVEs/attack incidents out of 37 tested and also
                    uncovered 12 zero-day vulnerabilities, resulting in $8,256 bug bounty rewards.
                </p>
            </div>
        </dd>
        <dt><a name="item137">[137]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02581"
                    title="Abstract">arXiv:2405.02581</a> [<a href="/pdf/2405.02581" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02581" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Stationary Representations: Optimally Approximating
                    Compatibility and Implications for Improved Model Replacements
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Biondi%2C+N">Niccolò Biondi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pernici%2C+F">Federico Pernici</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ricci%2C+S">Simone Ricci</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Del+Bimbo%2C+A">Alberto Del Bimbo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at CVPR24 as Poster Highlight
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Learning compatible representations enables the interchangeable use of
                    semantic features as models are updated over time. This is particularly
                    relevant in search and retrieval systems where it is crucial to avoid
                    reprocessing of the gallery images with the updated model. While recent
                    research has shown promising empirical evidence, there is still a lack of
                    comprehensive theoretical understanding about learning compatible
                    representations. In this paper, we demonstrate that the stationary
                    representations learned by the <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-44-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-295"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-296"><span class="mi" id="MathJax-Span-297"
                                                style="font-family: MathJax_Math-italic;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-44">d</script>-Simplex fixed classifier optimally
                    approximate compatibility representation according to the two inequality
                    constraints of its formal definition. This not only establishes a solid
                    foundation for future works in this line of research but also presents
                    implications that can be exploited in practical learning scenarios. An
                    exemplary application is the now-standard practice of downloading and
                    fine-tuning new pre-trained models. Specifically, we show the strengths and
                    critical issues of stationary representations in the case in which a model
                    undergoing sequential fine-tuning is asynchronously replaced by downloading a
                    better-performing model pre-trained elsewhere. Such a representation enables
                    seamless delivery of retrieval service (i.e., no reprocessing of gallery
                    images) and offers improved performance without operational disruptions during
                    model replacement. Code available at: https://github.com/miccunifi/iamcl2r.
                </p>
            </div>
        </dd>
        <dt><a name="item138">[138]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02583"
                    title="Abstract">arXiv:2405.02583</a> [<a href="/pdf/2405.02583" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02583" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Explainable Interface for Human-Autonomy Teaming: A Survey
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kong%2C+X">Xiangqi Kong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xing%2C+Y">Yang Xing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tsourdos%2C+A">Antonios Tsourdos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziyue Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+W">Weisi Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Perrusquia%2C+A">Adolfo Perrusquia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wikander%2C+A">Andreas Wikander</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 45 pages, 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">Nowadays, large-scale foundation models are being increasingly integrated
                    into numerous safety-critical applications, including human-autonomy teaming
                    (HAT) within transportation, medical, and defence domains. Consequently, the
                    inherent 'black-box' nature of these sophisticated deep neural networks
                    heightens the significance of fostering mutual understanding and trust between
                    humans and autonomous systems. To tackle the transparency challenges in HAT,
                    this paper conducts a thoughtful study on the underexplored domain of
                    Explainable Interface (EI) in HAT systems from a human-centric perspective,
                    thereby enriching the existing body of research in Explainable Artificial
                    Intelligence (XAI). We explore the design, development, and evaluation of EI
                    within XAI-enhanced HAT systems. To do so, we first clarify the distinctions
                    between these concepts: EI, explanations and model explainability, aiming to
                    provide researchers and practitioners with a structured understanding. Second,
                    we contribute to a novel framework for EI, addressing the unique challenges in
                    HAT. Last, our summarized evaluation framework for ongoing EI offers a holistic
                    perspective, encompassing model performance, human-centered factors, and group
                    task objectives. Based on extensive surveys across XAI, HAT, psychology, and
                    Human-Computer Interaction (HCI), this review offers multiple novel insights
                    into incorporating XAI into HAT systems and outlines future directions.
                </p>
            </div>
        </dd>
        <dt><a name="item139">[139]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02585"
                    title="Abstract">arXiv:2405.02585</a> [<a href="/pdf/2405.02585" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02585" title="Download PostScript">ps</a>, <a href="/format/2405.02585"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Maximal Guesswork Leakage
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kurri%2C+G+R">Gowtham R. Kurri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Managoli%2C+M">Malhar Managoli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Prabhakaran%2C+V+M">Vinod M. Prabhakaran</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages. Extended version of a paper accepted to ISIT 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">We introduce the study of information leakage through \emph{guesswork}, the
                    minimum expected number of guesses required to guess a random variable. In
                    particular, we define \emph{maximal guesswork leakage} as the multiplicative
                    decrease, upon observing <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-45-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-298"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.75em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-299"><span class="mi" id="MathJax-Span-300"
                                                style="font-family: MathJax_Math-italic;">Y<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.177em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-45">Y</script>, of the guesswork of a randomized
                    function of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-46-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-301"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.81em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-302"><span class="mi" id="MathJax-Span-303"
                                                style="font-family: MathJax_Math-italic;">X<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-46">X</script>,
                    maximized over all such randomized functions. We also study a pointwise form of
                    the leakage which captures the leakage due to the release of a single
                    realization of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-47-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-304"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.75em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-305"><span class="mi" id="MathJax-Span-306"
                                                style="font-family: MathJax_Math-italic;">Y<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.177em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-47">Y</script>. We also study these two notions of
                    leakage with oblivious
                    (or memoryless) guessing. We obtain closed-form expressions for all these
                    leakage measures, with the exception of one. Specifically, we are able to
                    obtain closed-form expression for maximal guesswork leakage for the binary
                    erasure source only; deriving expressions for arbitrary sources appears
                    challenging. Some of the consequences of our results are -- a connection
                    between guesswork and differential privacy and a new operational interpretation
                    to maximal <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-48-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-307"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-308"><span class="mi" id="MathJax-Span-309"
                                                style="font-family: MathJax_Math-italic;">α</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-48">\alpha</script>-leakage in terms of guesswork.
                </p>
            </div>
        </dd>
        <dt><a name="item140">[140]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02586"
                    title="Abstract">arXiv:2405.02586</a> [<a href="/pdf/2405.02586" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02586" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Generalizing CLIP to Unseen Domain via Text-Guided Diverse
                    Novel Feature Synthesis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+S">Siyuan Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+C">Cheng Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhen Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ge%2C+Z">Zongyuan Ge</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 24 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Vision-language foundation models like CLIP have shown impressive zero-shot
                    generalization, but finetuning on downstream datasets can cause overfitting and
                    loss of its generalization ability on unseen domains. Although collecting
                    additional data from new domains of interest is possible, this method is often
                    impractical due to the challenges in obtaining annotated data. To address this,
                    we propose a plug-and-play feature augmentation method called LDFS
                    (Language-Guided Diverse Feature Synthesis) to synthesize new domain features
                    and improve existing CLIP fine-tuning strategies. LDFS has three main
                    contributions: 1) To synthesize novel domain features and promote diversity, we
                    propose an instance-conditional feature augmentation strategy based on a
                    textguided feature augmentation loss. 2) To maintain feature quality after
                    augmenting, we introduce a pairwise regularizer to preserve augmented feature
                    coherence within the CLIP feature space. 3) We propose to use stochastic text
                    feature augmentation to reduce the modality gap and further facilitate the
                    process of text-guided feature synthesis. Extensive experiments show LDFS
                    superiority in improving CLIP generalization ability on unseen domains without
                    collecting data from those domains. The code will be made publicly available.
                </p>
            </div>
        </dd>
        <dt><a name="item141">[141]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02590"
                    title="Abstract">arXiv:2405.02590</a> [<a href="/pdf/2405.02590" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02590" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Performance Evaluation of PAC Decoding with Deep Neural
                    Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+J">Jingxin Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yin%2C+H">Hang Yin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lv%2C+Y">Yansong Lv</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuhuan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lv%2C+R">Rui Lv</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">By concatenating a polar transform with a convolutional transform,
                    polarization-adjusted convolutional (PAC) codes can reach the dispersion
                    approximation bound in certain rate cases. However, the sequential decoding
                    nature of traditional PAC decoding algorithms results in high decoding latency.
                    Due to the parallel computing capability, deep neural network (DNN) decoders
                    have emerged as a promising solution. In this paper, we propose three types of
                    DNN decoders for PAC codes: multi-layer perceptron (MLP), convolutional neural
                    network (CNN), and recurrent neural network (RNN). The performance of these DNN
                    decoders is evaluated through extensive simulation. Numerical results show that
                    the MLP decoder has the best error-correction performance under a similar model
                    parameter number.
                </p>
            </div>
        </dd>
        <dt><a name="item142">[142]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02591"
                    title="Abstract">arXiv:2405.02591</a> [<a href="/pdf/2405.02591" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02591" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Better YOLO with Attention-Augmented Network and Enhanced
                    Generalization Performance for Safety Helmet Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+S">Shuqi Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Junjie Yang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Safety helmets play a crucial role in protecting workers from head injuries
                    in construction sites, where potential hazards are prevalent. However,
                    currently, there is no approach that can simultaneously achieve both model
                    accuracy and performance in complex environments. In this study, we utilized a
                    Yolo-based model for safety helmet detection, achieved a 2% improvement in mAP
                    (mean Average Precision) performance while reducing parameters and Flops count
                    by over 25%. YOLO(You Only Look Once) is a widely used, high-performance,
                    lightweight model architecture that is well suited for complex environments. We
                    presents a novel approach by incorporating a lightweight feature extraction
                    network backbone based on GhostNetv2, integrating attention modules such as
                    Spatial Channel-wise Attention Net(SCNet) and Coordination Attention
                    Net(CANet), and adopting the Gradient Norm Aware optimizer (GAM) for improved
                    generalization ability. In safety-critical environments, the accurate detection
                    and speed of safety helmets plays a pivotal role in preventing occupational
                    hazards and ensuring compliance with safety protocols. This work addresses the
                    pressing need for robust and efficient helmet detection methods, offering a
                    comprehensive framework that not only enhances accuracy but also improves the
                    adaptability of detection models to real-world conditions. Our experimental
                    results underscore the synergistic effects of GhostNetv2, attention modules,
                    and the GAM optimizer, presenting a compelling solution for safety helmet
                    detection that achieves superior performance in terms of accuracy,
                    generalization, and efficiency.
                </p>
            </div>
        </dd>
        <dt><a name="item143">[143]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02594"
                    title="Abstract">arXiv:2405.02594</a> [<a href="/pdf/2405.02594" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02594" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Leveraging (Biased) Information: Multi-armed Bandits with
                    Offline Data
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cheung%2C+W+C">Wang Chi Cheung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+L">Lixing Lyu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 24 pages, 5 figures. Accepted to ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
                <p class="mathjax">We leverage offline data to facilitate online learning in stochastic
                    multi-armed bandits. The probability distributions that govern the offline data
                    and the online rewards can be different. Without any non-trivial upper bound on
                    their difference, we show that no non-anticipatory policy can outperform the
                    UCB policy by (Auer et al. 2002), even in the presence of offline data. In
                    complement, we propose an online policy MIN-UCB, which outperforms UCB when a
                    non-trivial upper bound is given. MIN-UCB adaptively chooses to utilize the
                    offline data when they are deemed informative, and to ignore them otherwise.
                    MIN-UCB is shown to be tight in terms of both instance independent and
                    dependent regret bounds. Finally, we corroborate the theoretical results with
                    numerical experiments.
                </p>
            </div>
        </dd>
        <dt><a name="item144">[144]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02595"
                    title="Abstract">arXiv:2405.02595</a> [<a href="/pdf/2405.02595" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02595" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Vision-based 3D occupancy prediction in autonomous driving: a
                    review and outlook
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jinqing Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zengran Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Junhao Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+D">Di Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 20 pages, 20 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">In recent years, autonomous driving has garnered escalating attention for its
                    potential to relieve drivers' burdens and improve driving safety. Vision-based
                    3D occupancy prediction, which predicts the spatial occupancy status and
                    semantics of 3D voxel grids around the autonomous vehicle from image inputs, is
                    an emerging perception task suitable for cost-effective perception system of
                    autonomous driving. Although numerous studies have demonstrated the greater
                    advantages of 3D occupancy prediction over object-centric perception tasks,
                    there is still a lack of a dedicated review focusing on this rapidly developing
                    field. In this paper, we first introduce the background of vision-based 3D
                    occupancy prediction and discuss the challenges in this task. Secondly, we
                    conduct a comprehensive survey of the progress in vision-based 3D occupancy
                    prediction from three aspects: feature enhancement, deployment friendliness and
                    label efficiency, and provide an in-depth analysis of the potentials and
                    challenges of each category of methods. Finally, we present a summary of
                    prevailing research trends and propose some inspiring future outlooks. To
                    provide a valuable reference for researchers, a regularly updated collection of
                    related papers, datasets, and codes is organized at
                    https://github.com/zya3d/Awesome-3D-Occupancy-Prediction.
                </p>
            </div>
        </dd>
        <dt><a name="item145">[145]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02596"
                    title="Abstract">arXiv:2405.02596</a> [<a href="/pdf/2405.02596" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02596" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Random Masking Finds Winning Tickets for Parameter Efficient
                    Fine-tuning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jing Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jingzhao Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">Fine-tuning large language models (LLM) can be costly. Parameter-efficient
                    fine-tuning (PEFT) addresses the problems by training a fraction of the
                    parameters, whose success reveals the expressiveness and flexibility of
                    pretrained models. This paper studies the limit of PEFT, by further simplifying
                    its design and reducing the number of trainable parameters beyond standard
                    setups. To this end, we use Random Masking to fine-tune the pretrained model.
                    Despite its simplicity, we show that Random Masking is surprisingly effective:
                    with a larger-than-expected learning rate, Random Masking can match the
                    performance of standard PEFT algorithms such as LoRA on various tasks, using
                    fewer trainable parameters. We provide both empirical and theoretical
                    explorations into the success of Random Masking. We show that masking induces a
                    flatter loss landscape and more distant solutions, which allows for and
                    necessitates large learning rates.
                </p>
            </div>
        </dd>
        <dt><a name="item146">[146]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02598"
                    title="Abstract">arXiv:2405.02598</a> [<a href="/pdf/2405.02598" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02598" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> UDUC: An Uncertainty-driven Approach for Learning-based
                    Robust Control
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hoffmann%2C+J">Jasper Hoffmann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boedecker%2C+J">Joschka Boedecker</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Learning-based techniques have become popular in both model predictive
                    control (MPC) and reinforcement learning (RL). Probabilistic ensemble (PE)
                    models offer a promising approach for modelling system dynamics, showcasing the
                    ability to capture uncertainty and scalability in high-dimensional control
                    scenarios. However, PE models are susceptible to mode collapse, resulting in
                    non-robust control when faced with environments slightly different from the
                    training set. In this paper, we introduce the
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-49-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-310"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.623em, 1000.64em, 2.433em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-311"><span class="texatom"
                                                id="MathJax-Span-312"><span class="mrow" id="MathJax-Span-313"><span
                                                        class="mtext" id="MathJax-Span-314"
                                                        style="font-family: MathJax_Main-bold;">u</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-49">\textbf{u}</script>ncertainty-<span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-50-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-315"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.392em, 1000.58em, 2.433em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-316"><span class="texatom"
                                                id="MathJax-Span-317"><span class="mrow" id="MathJax-Span-318"><span
                                                        class="mtext" id="MathJax-Span-319"
                                                        style="font-family: MathJax_Main-bold;">d</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-50">\textbf{d}</script>riven rob<span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-51-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-320"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.623em, 1000.64em, 2.433em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-321"><span class="texatom"
                                                id="MathJax-Span-322"><span class="mrow" id="MathJax-Span-323"><span
                                                        class="mtext" id="MathJax-Span-324"
                                                        style="font-family: MathJax_Main-bold;">u</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-51">\textbf{u}</script>st <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-52-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-325"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.623em, 1000.47em, 2.433em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-326"><span class="texatom"
                                                id="MathJax-Span-327"><span class="mrow" id="MathJax-Span-328"><span
                                                        class="mtext" id="MathJax-Span-329"
                                                        style="font-family: MathJax_Main-bold;">c</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-52">\textbf{c}</script>ontrol
                    (UDUC) loss as an alternative objective for training PE models, drawing
                    inspiration from contrastive learning. We analyze the robustness of UDUC loss
                    through the lens of robust optimization and evaluate its performance on the
                    challenging Real-world Reinforcement Learning (RWRL) benchmark, which involves
                    significant environmental mismatches between the training and testing
                    environments.
                </p>
            </div>
        </dd>
        <dt><a name="item147">[147]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02599"
                    title="Abstract">arXiv:2405.02599</a> [<a href="/pdf/2405.02599" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02599" title="Download PostScript">ps</a>, <a href="/format/2405.02599"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Assembling ensembling: An adventure in approaches across
                    disciplines
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bleichrodt%2C+A">Amanda Bleichrodt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bourouiba%2C+L">Lydia Bourouiba</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chowell%2C+G">Gerardo Chowell</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lofgren%2C+E+T">Eric T. Lofgren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reed%2C+J+M">J. Michael Reed</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ryan%2C+S+J">Sadie J. Ryan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fefferman%2C+N+H">Nina H. Fefferman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 33 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries
                        (cs.DL)</span>

                </div>
                <p class="mathjax">When we think of model ensembling or ensemble modeling, there are many
                    possibilities that come to mind in different disciplines. For example, one
                    might think of a set of descriptions of a phenomenon in the world, perhaps a
                    time series or a snapshot of multivariate space, and perhaps that set is
                    comprised of data-independent descriptions, or perhaps it is quite
                    intentionally fit *to* data, or even a suite of data sets with a common theme
                    or intention. The very meaning of 'ensemble' - a collection together - conjures
                    different ideas across and even within disciplines approaching phenomena. In
                    this paper, we present a typology of the scope of these potential perspectives.
                    It is not our goal to present a review of terms and concepts, nor is it to
                    convince all disciplines to adopt a common suite of terms, which we view as
                    futile. Rather, our goal is to disambiguate terms, concepts, and processes
                    associated with 'ensembles' and 'ensembling' in order to facilitate
                    communication, awareness, and possible adoption of tools across disciplines.
                </p>
            </div>
        </dd>
        <dt><a name="item148">[148]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02602"
                    title="Abstract">arXiv:2405.02602</a> [<a href="/pdf/2405.02602" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02602" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Astro-NER -- Astronomy Named Entity Recognition: Is GPT a
                    Good Domain Expert Annotator?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Evans%2C+J">Julia Evans</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sadruddin%2C+S">Sameer Sadruddin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=D%27Souza%2C+J">Jennifer D'Souza</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

                </div>
                <p class="mathjax">In this study, we address one of the challenges of developing NER models for
                    scholarly domains, namely the scarcity of suitable labeled data. We experiment
                    with an approach using predictions from a fine-tuned LLM model to aid
                    non-domain experts in annotating scientific entities within astronomy
                    literature, with the goal of uncovering whether such a collaborative process
                    can approximate domain expertise. Our results reveal moderate agreement between
                    a domain expert and the LLM-assisted non-experts, as well as fair agreement
                    between the domain expert and the LLM model's predictions. In an additional
                    experiment, we compare the performance of finetuned and default LLMs on this
                    task. We have also introduced a specialized scientific entity annotation scheme
                    for astronomy, validated by a domain expert. Our approach adopts a scholarly
                    research contribution-centric perspective, focusing exclusively on scientific
                    entities relevant to the research theme. The resultant dataset, containing
                    5,000 annotated astronomy article titles, is made publicly available.
                </p>
            </div>
        </dd>
        <dt><a name="item149">[149]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02604"
                    title="Abstract">arXiv:2405.02604</a> [<a href="/pdf/2405.02604" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02604" title="Download PostScript">ps</a>, <a href="/format/2405.02604"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Interleave Frequency Division Multiplexing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chi%2C+Y">Yuhao Chi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+L">Lei Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ge%2C+Y">Yao Ge</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xuehui Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Ying Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoyang Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IEEE Wireless Communications Letters
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">In this letter, we study interleave frequency division multiplexing (IFDM)
                    for multicarrier modulation in static multipath and mobile time-varying
                    channels, which outperforms orthogonal frequency division multiplexing (OFDM),
                    orthogonal time frequency space (OTFS), and affine frequency division
                    multiplexing (AFDM) by considering practical advanced detectors. The
                    fundamental principle underlying existing modulation techniques is to establish
                    sparse equivalent channel matrices in order to facilitate the design of
                    low-complexity detection algorithms for signal recovery, making a trade-off
                    between performance and implementation complexity. In contrast, the proposed
                    IFDM establishes an equivalent fully dense and right-unitarily invariant
                    channel matrix with the goal of achieving channel capacity, ensuring that the
                    signals undergo sufficient statistical channel fading. Meanwhile, a
                    low-complexity and replica maximum a posteriori (MAP)-optimal cross-domain
                    memory approximate message passing (CD-MAMP) detector is proposed for IFDM by
                    exploiting the sparsity of the time-domain channel and the unitary invariance
                    in interleave-frequency-domain channel. Numerical results show that IFDM with
                    extremely low-complexity CD-MAMP outperforms OFDM, OTFS, and AFDM with
                    state-of-the-art orthogonal approximate message passing detectors, particularly
                    at low velocities.
                </p>
            </div>
        </dd>
        <dt><a name="item150">[150]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02605"
                    title="Abstract">arXiv:2405.02605</a> [<a href="/pdf/2405.02605" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02605" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MEXGEN: An Effective and Efficient Information Gain
                    Approximation for Information Gathering Path Planning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chesser%2C+J">Joshua Chesser</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sathyan%2C+T">Thuraiappah Sathyan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ranasinghe%2C+D+C">Damith C. Ranasinghe</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to IEEE Robotics and Automation Letters
                    (RA-L)(Demo Video: <a href="https://www.youtube.com/watch?v=XrsCC6MkaB4">this https URL</a>)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Autonomous robots for gathering information on objects of interest has
                    numerous real-world applications because of they improve efficiency,
                    performance and safety. Realizing autonomy demands online planning algorithms
                    to solve sequential decision making problems under uncertainty; because,
                    objects of interest are often dynamic, object state, such as location is not
                    directly observable and are obtained from noisy measurements. Such planning
                    problems are notoriously difficult due to the combinatorial nature of
                    predicting the future to make optimal decisions. For information theoretic
                    planning algorithms, we develop a computationally efficient and effective
                    approximation for the difficult problem of predicting the likely sensor
                    measurements from uncertain belief states}. The approach more accurately
                    predicts information gain from information gathering actions. Our theoretical
                    analysis proves the proposed formulation achieves a lower prediction error than
                    the current efficient-method. We demonstrate improved performance gains in
                    radio-source tracking and localization problems using extensive simulated and
                    field experiments with a multirotor aerial robot.
                </p>
            </div>
        </dd>
        <dt><a name="item151">[151]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02606"
                    title="Abstract">arXiv:2405.02606</a> [<a href="/pdf/2405.02606" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02606" title="Download PostScript">ps</a>, <a href="/format/2405.02606"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Communication Modalities
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kuznets%2C+R">Roman Kuznets</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Logic in Computer Science (cs.LO); Multiagent Systems (cs.MA)

                </div>
                <p class="mathjax">Epistemic analysis of distributed systems is one of the biggest successes
                    among applications of logic in computer science. The reason for that is that
                    agents' actions are necessarily guided by their knowledge. Thus, epistemic
                    modal logic, with its knowledge and belief modalities (and group versions
                    thereof), has played a vital role in establishing both impossibility results
                    and necessary conditions for solvable distributed tasks. In distributed
                    systems, knowledge is largely attained via communication. It has been standard
                    in both distributed systems and dynamic epistemic logic to treat incoming
                    messages as trustworthy, thus, creating difficulties in the epistemic analysis
                    of byzantine distributed systems where faulty agents may lie. In this paper, we
                    argue that handling such communication scenarios calls for additional
                    modalities representing the informational content of messages that should not
                    be taken at face value. We present two such modalities: hope for the case of
                    fully byzantine agents and creed for non-uniform communication protocols in
                    general.
                </p>
            </div>
        </dd>
        <dt><a name="item152">[152]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02608"
                    title="Abstract">arXiv:2405.02608</a> [<a href="/pdf/2405.02608" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02608" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> UnSAMFlow: Unsupervised Optical Flow Guided by Segment
                    Anything Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+S">Shuai Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+L">Lei Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hui%2C+Z">Zhuo Hui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pu%2C+C">Can Pu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiang%2C+X">Xiaoyu Xiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ranjan%2C+R">Rakesh Ranjan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Demandolx%2C+D">Denis Demandolx</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by CVPR 2024. Code is available at <a
                        href="https://github.com/facebookresearch/UnSAMFlow">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

                </div>
                <p class="mathjax">Traditional unsupervised optical flow methods are vulnerable to occlusions
                    and motion boundaries due to lack of object-level information. Therefore, we
                    propose UnSAMFlow, an unsupervised flow network that also leverages object
                    information from the latest foundation model Segment Anything Model (SAM). We
                    first include a self-supervised semantic augmentation module tailored to SAM
                    masks. We also analyze the poor gradient landscapes of traditional smoothness
                    losses and propose a new smoothness definition based on homography instead. A
                    simple yet effective mask feature module has also been added to further
                    aggregate features on the object level. With all these adaptations, our method
                    produces clear optical flow estimation with sharp boundaries around objects,
                    which outperforms state-of-the-art methods on both KITTI and Sintel datasets.
                    Our method also generalizes well across domains and runs very efficiently.
                </p>
            </div>
        </dd>
        <dt><a name="item153">[153]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02609"
                    title="Abstract">arXiv:2405.02609</a> [<a href="/pdf/2405.02609" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02609" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Advanced Equalization in 112 Gb/s Upstream PON Using a Novel
                    Fourier Convolution-based Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shao%2C+C">Chen Shao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Giacoumidis%2C+E">Elias Giacoumidis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matalla%2C+P">Patrick Matalla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jialei Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Randel%2C+S">Sebastian Randel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Richter%2C+A">Andre Richter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Faerber%2C+M">Michael Faerber</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kaefer%2C+T">Tobias Kaefer</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 4 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">We experimentally demonstrate a novel, low-complexity Fourier
                    Convolution-based Network (FConvNet) based equalizer for 112 Gb/s upstream
                    PAM4-PON. At a BER of 0.005, FConvNet enhances the receiver sensitivity by 2
                    and 1 dB compared to a 51-tap Sato equalizer and benchmark machine learning
                    algorithms respectively.
                </p>
            </div>
        </dd>
        <dt><a name="item154">[154]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02611"
                    title="Abstract">arXiv:2405.02611</a> [<a href="/pdf/2405.02611" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02611" title="Download PostScript">ps</a>, <a href="/format/2405.02611"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Predicting the impact of water transport on
                    carbonation-induced corrosion in variably saturated reinforced concrete
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Korec%2C+E">E. Korec</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mingazzi%2C+L">L. Mingazzi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Freddi%2C+F">F. Freddi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mart%C3%ADnez-Pa%C3%B1eda%2C+E">E.
                        Martínez-Pañeda</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Materials Science (cond-mat.mtrl-sci); Applied Physics
                    (physics.app-ph); Chemical Physics (physics.chem-ph)

                </div>
                <p class="mathjax">A modelling framework for predicting carbonation-induced corrosion in
                    reinforced concrete is presented. The framework constituents include a new
                    model for water transport in cracked concrete, a link between corrosion current
                    density and water saturation, and a theory for characterising concrete
                    carbonation. The theoretical framework is numerically implemented using the
                    finite element method and model predictions are extensively benchmarked against
                    experimental data. The results show that the model is capable of accurately
                    predicting carbonation progress, as well as wetting and drying of cracked and
                    uncracked concrete, revealing a very good agreement with independent
                    experiments from a set of consistent parameters. In addition, insight is gained
                    into the evolution of carbonation penetration and corrosion current density
                    under periodic wetting and drying conditions. Among others, we find that cyclic
                    wetting periods significantly speed up the carbonation progress and that the
                    induced corrosion current density is very sensitive to concrete saturation.
                </p>
            </div>
        </dd>
        <dt><a name="item155">[155]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02612"
                    title="Abstract">arXiv:2405.02612</a> [<a href="/pdf/2405.02612" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02612" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Learning Linear Utility Functions From Pairwise Comparison
                    Queries
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ge%2C+L">Luise Ge</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Juba%2C+B">Brendan Juba</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to ECAI for review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning
                    (stat.ML)

                </div>
                <p class="mathjax">We study learnability of linear utility functions from pairwise comparison
                    queries. In particular, we consider two learning objectives. The first
                    objective is to predict out-of-sample responses to pairwise comparisons,
                    whereas the second is to approximately recover the true parameters of the
                    utility function. We show that in the passive learning setting, linear
                    utilities are efficiently learnable with respect to the first objective, both
                    when query responses are uncorrupted by noise, and under Tsybakov noise when
                    the distributions are sufficiently "nice". In contrast, we show that utility
                    parameters are not learnable for a large set of data distributions without
                    strong modeling assumptions, even when query responses are noise-free. Next, we
                    proceed to analyze the learning problem in an active learning setting. In this
                    case, we show that even the second objective is efficiently learnable, and
                    present algorithms for both the noise-free and noisy query response settings.
                    Our results thus exhibit a qualitative learnability gap between passive and
                    active learning from pairwise preference queries, demonstrating the value of
                    the ability to select pairwise queries for utility learning.
                </p>
            </div>
        </dd>
        <dt><a name="item156">[156]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02615"
                    title="Abstract">arXiv:2405.02615</a> [<a href="/pdf/2405.02615" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02615" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TetraBFT: Reducing Latency of Unauthenticated, Responsive BFT
                    Consensus
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Q">Qianyu Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Losa%2C+G">Giuliano Losa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xuechao Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> The full version of the PODC 2024 paper
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">This paper presents TetraBFT, a novel unauthenticated Byzantine fault
                    tolerant protocol for solving consensus in partial synchrony, eliminating the
                    need for public key cryptography and ensuring resilience against
                    computationally unbounded adversaries. TetraBFT has several compelling
                    features: it necessitates only constant local storage, has optimal
                    communication complexity, satisfies optimistic responsiveness -- allowing the
                    protocol to operate at actual network speeds under ideal conditions -- and can
                    achieve consensus in just 5 message delays, which outperforms all known
                    unauthenticated protocols achieving the other properties listed. We validate
                    the correctness of TetraBFT through rigorous security analysis and formal
                    verification. Furthermore, we extend TetraBFT into a multi-shot, chained
                    consensus protocol, making a pioneering effort in applying pipelining
                    techniques to unauthenticated protocols. This positions TetraBFT as a practical
                    and deployable solution for blockchain systems aiming for high efficiency.
                </p>
            </div>
        </dd>
        <dt><a name="item157">[157]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02616"
                    title="Abstract">arXiv:2405.02616</a> [<a href="/pdf/2405.02616" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02616" title="Download PostScript">ps</a>, <a href="/format/2405.02616"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Convergence analysis of a second order numerical scheme for
                    the Flory-Huggins-Cahn-Hilliard-Navier-Stokes system
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Chen%2C+W">Wenbin Chen</a>,
                    <a href="/search/math?searchtype=author&amp;query=Jing%2C+J">Jianyu Jing</a>,
                    <a href="/search/math?searchtype=author&amp;query=Liu%2C+Q">Qianqian Liu</a>,
                    <a href="/search/math?searchtype=author&amp;query=Wang%2C+C">Cheng Wang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Wang%2C+X">Xiaoming Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">We present an optimal rate convergence analysis for a second order accurate
                    in time, fully discrete finite difference scheme for the
                    Cahn-Hilliard-Navier-Stokes (CHNS) system, combined with logarithmic
                    Flory-Huggins energy potential. The numerical scheme has been recently
                    proposed, and the positivity-preserving property of the logarithmic arguments,
                    as well as the total energy stability, have been theoretically justified. In
                    this paper, we rigorously prove second order convergence of the proposed
                    numerical scheme, in both time and space. Since the CHNS is a coupled system,
                    the standard <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-53-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-330"
                                style="width: 13.545em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 11.288em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1011.17em, 2.723em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-331"><span class="msubsup"
                                                id="MathJax-Span-332"><span
                                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-333"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mi" id="MathJax-Span-334"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">∞</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-335"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-336" style="font-family: MathJax_Main;">0</span><span
                                                class="mo" id="MathJax-Span-337"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-338"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-339"
                                                style="font-family: MathJax_Main;">;</span><span class="msubsup"
                                                id="MathJax-Span-340" style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-341"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mn" id="MathJax-Span-342"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-343"
                                                style="font-family: MathJax_Main;">)</span><span class="mo"
                                                id="MathJax-Span-344"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">∩</span><span
                                                class="msubsup" id="MathJax-Span-345"
                                                style="padding-left: 0.234em;"><span
                                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-346"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mn" id="MathJax-Span-347"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-348"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-349" style="font-family: MathJax_Main;">0</span><span
                                                class="mo" id="MathJax-Span-350"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-351"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-352"
                                                style="font-family: MathJax_Main;">;</span><span class="msubsup"
                                                id="MathJax-Span-353" style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-354"
                                                            style="font-family: MathJax_Math-italic;">H<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -4.337em; left: 0.987em;"><span
                                                            class="mn" id="MathJax-Span-355"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-356"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-357"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.531em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex"
                        id="MathJax-Element-53">\ell^\infty (0, T; \ell^2) \cap \ell^2 (0, T; H_h^2)</script> error
                    estimate could not be easily derived, due to the lack of regularity to control
                    the numerical error associated with the coupled terms. Instead, the
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-54-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-358"
                                style="width: 14.181em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 11.808em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1011.69em, 2.723em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-359"><span class="msubsup"
                                                id="MathJax-Span-360"><span
                                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-361"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mi" id="MathJax-Span-362"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">∞</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-363"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-364" style="font-family: MathJax_Main;">0</span><span
                                                class="mo" id="MathJax-Span-365"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-366"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-367"
                                                style="font-family: MathJax_Main;">;</span><span class="msubsup"
                                                id="MathJax-Span-368" style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-369"
                                                            style="font-family: MathJax_Math-italic;">H<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -4.337em; left: 0.987em;"><span
                                                            class="mn" id="MathJax-Span-370"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-371"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-372"
                                                style="font-family: MathJax_Main;">)</span><span class="mo"
                                                id="MathJax-Span-373"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">∩</span><span
                                                class="msubsup" id="MathJax-Span-374"
                                                style="padding-left: 0.234em;"><span
                                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-375"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mn" id="MathJax-Span-376"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-377"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-378" style="font-family: MathJax_Main;">0</span><span
                                                class="mo" id="MathJax-Span-379"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-380"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-381"
                                                style="font-family: MathJax_Main;">;</span><span class="msubsup"
                                                id="MathJax-Span-382" style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-383"
                                                            style="font-family: MathJax_Math-italic;">H<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -4.337em; left: 0.987em;"><span
                                                            class="mn" id="MathJax-Span-384"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-385"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-386"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.531em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex"
                        id="MathJax-Element-54">\ell^\infty (0, T; H_h^1) \cap \ell^2 (0, T; H_h^3)</script> error
                    analysis for the
                    phase variable and the <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-55-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-387"
                                style="width: 6.021em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.98em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.86em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-388"><span class="msubsup"
                                                id="MathJax-Span-389"><span
                                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-390"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mi" id="MathJax-Span-391"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">∞</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-392"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-393" style="font-family: MathJax_Main;">0</span><span
                                                class="mo" id="MathJax-Span-394"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-395"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-396"
                                                style="font-family: MathJax_Main;">;</span><span class="msubsup"
                                                id="MathJax-Span-397" style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-398"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mn" id="MathJax-Span-399"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-400"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-55">\ell^\infty (0, T; \ell^2)</script> analysis for the
                    velocity
                    vector, which shares the same regularity as the energy estimate, is more
                    suitable to pass through the nonlinear analysis for the error terms associated
                    with the coupled physical process. Furthermore, the highly nonlinear and
                    singular nature of the logarithmic error terms makes the convergence analysis
                    even more challenging, since a uniform distance between the numerical solution
                    and the singular limit values of is needed for the associated error estimate.
                    Many highly non-standard estimates, such as a higher order asymptotic expansion
                    of the numerical solution (up to the third order accuracy in time and fourth
                    order in space), combined with a rough error estimate (to establish the maximum
                    norm bound for the phase variable), as well as a refined error estimate, have
                    to be carried out to conclude the desired convergence result.
                </p>
            </div>
        </dd>
        <dt><a name="item158">[158]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02620"
                    title="Abstract">arXiv:2405.02620</a> [<a href="/pdf/2405.02620" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02620" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Accelerating Autonomy: Insights from Pro Racers in the Era of
                    Autonomous Racing - An Expert Interview Study
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Werner%2C+F">Frederik Werner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Oberhuber%2C+R">René Oberhuber</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Betz%2C+J">Johannes Betz</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">This research aims to investigate professional racing drivers' expertise to
                    develop an understanding of their cognitive and adaptive skills to create new
                    autonomy algorithms. An expert interview study was conducted with 11
                    professional race drivers, data analysts, and racing instructors from across
                    prominent racing leagues. The interviews were conducted using an exploratory,
                    non-standardized expert interview format guided by a set of prepared questions.
                    The study investigates drivers' exploration strategies to reach their vehicle
                    limits and contrasts them with the capabilities of state-of-the-art autonomous
                    racing software stacks. Participants were questioned about the techniques and
                    skills they have developed to quickly approach and maneuver at the vehicle
                    limit, ultimately minimizing lap times. The analysis of the interviews was
                    grounded in Mayring's qualitative content analysis framework, which facilitated
                    the organization of the data into multiple categories and subcategories. Our
                    findings create insights into human behavior regarding reaching a vehicle's
                    limit and minimizing lap times. We conclude from the findings the development
                    of new autonomy software modules that allow for more adaptive vehicle behavior.
                    By emphasizing the distinct nuances between manual and autonomous driving
                    techniques, the paper encourages further investigation into human drivers'
                    strategies to maximize their vehicles' capabilities.
                </p>
            </div>
        </dd>
        <dt><a name="item159">[159]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02628"
                    title="Abstract">arXiv:2405.02628</a> [<a href="/pdf/2405.02628" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02628" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Contrastive Dual-Interaction Graph Neural Network for
                    Molecular Property Prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zexing Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+G">Guangsi Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiaopeng Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+R">Ruohua Ren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+X">Xiaojun Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+F">Fuyi Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Molecular property prediction is a key component of AI-driven drug discovery
                    and molecular characterization learning. Despite recent advances, existing
                    methods still face challenges such as limited ability to generalize, and
                    inadequate representation of learning from unlabeled data, especially for tasks
                    specific to molecular structures. To address these limitations, we introduce
                    DIG-Mol, a novel self-supervised graph neural network framework for molecular
                    property prediction. This architecture leverages the power of contrast learning
                    with dual interaction mechanisms and unique molecular graph enhancement
                    strategies. DIG-Mol integrates a momentum distillation network with two
                    interconnected networks to efficiently improve molecular characterization. The
                    framework's ability to extract key information about molecular structure and
                    higher-order semantics is supported by minimizing loss of contrast. We have
                    established DIG-Mol's state-of-the-art performance through extensive
                    experimental evaluation in a variety of molecular property prediction tasks. In
                    addition to demonstrating superior transferability in a small number of
                    learning scenarios, our visualizations highlight DIG-Mol's enhanced
                    interpretability and representation capabilities. These findings confirm the
                    effectiveness of our approach in overcoming challenges faced by traditional
                    methods and mark a significant advance in molecular property prediction.
                </p>
            </div>
        </dd>
        <dt><a name="item160">[160]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02629"
                    title="Abstract">arXiv:2405.02629</a> [<a href="/pdf/2405.02629" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02629" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SPARSE: Semantic Tracking and Path Analysis for Attack
                    Investigation in Real-time
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ying%2C+J">Jie Ying</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+T">Tiantian Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+W">Wenrui Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Q">Qixuan Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+M">Mingjun Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+C">Chunlin Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tieming Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lv%2C+M">Mingqi Lv</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yan Chen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">As the complexity and destructiveness of Advanced Persistent Threat (APT)
                    increase, there is a growing tendency to identify a series of actions
                    undertaken to achieve the attacker's target, called attack investigation.
                    Currently, analysts construct the provenance graph to perform causality
                    analysis on Point-Of-Interest (POI) event for capturing critical events
                    (related to the attack). However, due to the vast size of the provenance graph
                    and the rarity of critical events, existing attack investigation methods suffer
                    from problems of high false positives, high overhead, and high latency. To this
                    end, we propose SPARSE, an efficient and real-time system for constructing
                    critical component graphs (i.e., consisting of critical events) from streaming
                    logs. Our key observation is 1) Critical events exist in a suspicious semantic
                    graph (SSG) composed of interaction flows between suspicious entities, and 2)
                    Information flows that accomplish attacker's goal exist in the form of paths.
                    Therefore, SPARSE uses a two-stage framework to implement attack investigation
                    (i.e., constructing the SSG and performing path-level contextual analysis).
                    First, SPARSE operates in a state-based mode where events are consumed as
                    streams, allowing easy access to the SSG related to the POI event through
                    semantic transfer rule and storage strategy. Then, SPARSE identifies all
                    suspicious flow paths (SFPs) related to the POI event from the SSG, quantifies
                    the influence of each path to filter irrelevant events. Our evaluation on a
                    real large-scale attack dataset shows that SPARSE can generate a critical
                    component graph (~ 113 edges) in 1.6 seconds, which is 2014 X smaller than the
                    backtracking graph (~ 227,589 edges). SPARSE is 25 X more effective than other
                    state-of-the-art techniques in filtering irrelevant edges.
                </p>
            </div>
        </dd>
        <dt><a name="item161">[161]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02631"
                    title="Abstract">arXiv:2405.02631</a> [<a href="/pdf/2405.02631" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02631" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unsupervised machine learning for data-driven classification
                    of rock mass using drilling data: How can a data-driven system handle limitations in existing rock
                    mass classification systems?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hansen%2C+T+F">T. F. Hansen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Aarset%2C+A">A. Aarset</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 38 pages, 11 figures. Includes ancillary interactive
                    versions of some figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Emerging Technologies (cs.ET); Systems and Control (eess.SY)

                </div>
                <p class="mathjax">Rock mass classification systems are crucial for assessing stability and risk
                    in underground construction globally and guiding support and excavation design.
                    However, systems developed primarily in the 1970s lack access to modern
                    high-resolution data and advanced statistical techniques, limiting their
                    effectiveness as decision-support systems. Initially, we outline the
                    limitations observed in this context and later describe how a data-driven
                    system, based on drilling data as detailed in this study, can overcome these
                    limitations. Using extracted statistical information from thousands of MWD-data
                    values in one-meter sections of a full tunnel profile, thus working as a
                    signature of the rock mass, we have demonstrated that it is possible to form
                    well-defined clusters that can act as a foundational basis for various rock
                    mass classification systems. We reduced the dimensionality of 48-value vectors
                    using nonlinear manifold learning techniques (UMAP) and linear principal
                    component analysis (PCA) to enhance clustering. Unsupervised machine learning
                    methods (HDBSCAN, Agglomerative Clustering, K-means) were employed to cluster
                    the data, with hyperparameters optimised through multi-objective Bayesian
                    optimisation for effective clustering. Using domain knowledge, we experienced
                    improved clustering and system tuning opportunities in adding extra features to
                    core clusters of MWD-data. We structured and correlated these clusters with
                    physical rock mass properties, including labels of rock type and rock quality,
                    and analysed cumulative distributions of key MWD-parameters for rock mass
                    assessment to determine if clusters meaningfully differentiate rock masses. The
                    ability of MWD data to form distinct rock mass clusters suggests substantial
                    potential for future classification systems grounded in this objective,
                    data-driven methodology, free from human bias.
                </p>
            </div>
        </dd>
        <dt><a name="item162">[162]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02633"
                    title="Abstract">arXiv:2405.02633</a> [<a href="/pdf/2405.02633" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02633" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Risk Assessment for Nonlinear Cyber-Physical Systems under
                    Stealth Attacks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Chen%2C+G">Guang Chen</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Sun%2C+Z">Zhicong Sun</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Ding%2C+Y">Yulong Ding</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yang%2C+S">Shuang-hua Yang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages and 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">Stealth attacks pose potential risks to cyber-physical systems because they
                    are difficult to detect. Assessing the risk of systems under stealth attacks
                    remains an open challenge, especially in nonlinear systems. To comprehensively
                    quantify these risks, we propose a framework that considers both the
                    reachability of a system and the risk distribution of a scenario. We propose an
                    algorithm to approximate the reachability of a nonlinear system under stealth
                    attacks with a union of standard sets. Meanwhile, we present a method to
                    construct a risk field to formally describe the risk distribution in a given
                    scenario. The intersection relationships of system reachability and risk
                    regions in the risk field indicate that attackers can cause corresponding risks
                    without being detected. Based on this, we introduce a metric to dynamically
                    quantify the risk. Compared to traditional methods, our framework predicts the
                    risk value in an explainable way and provides early warnings for safety
                    control. We demonstrate the effectiveness of our framework through a case study
                    of an automated warehouse.
                </p>
            </div>
        </dd>
        <dt><a name="item163">[163]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02634"
                    title="Abstract">arXiv:2405.02634</a> [<a href="/pdf/2405.02634" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02634" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Onboard Out-of-Calibration Detection of Deep Learning Models
                    using Conformal Prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bhattacharjee%2C+P">Protim Bhattacharjee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jung%2C+P">Peter Jung</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">The black box nature of deep learning models complicate their usage in
                    critical applications such as remote sensing. Conformal prediction is a method
                    to ensure trust in such scenarios. Subject to data exchangeability, conformal
                    prediction provides finite sample coverage guarantees in the form of a
                    prediction set that is guaranteed to contain the true class within a user
                    defined error rate. In this letter we show that conformal prediction algorithms
                    are related to the uncertainty of the deep learning model and that this
                    relation can be used to detect if the deep learning model is
                    out-of-calibration. Popular classification models like Resnet50, Densenet161,
                    InceptionV3, and MobileNetV2 are applied on remote sensing datasets such as the
                    EuroSAT to demonstrate how under noisy scenarios the model outputs become
                    untrustworthy. Furthermore an out-of-calibration detection procedure relating
                    the model uncertainty and the average size of the conformal prediction set is
                    presented.
                </p>
            </div>
        </dd>
        <dt><a name="item164">[164]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02637"
                    title="Abstract">arXiv:2405.02637</a> [<a href="/pdf/2405.02637" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02637" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TREC iKAT 2023: A Test Collection for Evaluating
                    Conversational and Interactive Knowledge Assistants
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Aliannejadi%2C+M">Mohammad Aliannejadi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abbasiantaeb%2C+Z">Zahra Abbasiantaeb</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chatterjee%2C+S">Shubham Chatterjee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dalton%2C+J">Jeffery Dalton</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Azzopardi%2C+L">Leif Azzopardi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To appear in SIGIR 2024. arXiv admin note: substantial
                    text overlap with <a href="/abs/2401.01330">arXiv:2401.01330</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">Conversational information seeking has evolved rapidly in the last few years
                    with the development of Large Language Models (LLMs), providing the basis for
                    interpreting and responding in a naturalistic manner to user requests. The
                    extended TREC Interactive Knowledge Assistance Track (iKAT) collection aims to
                    enable researchers to test and evaluate their Conversational Search Agents
                    (CSA). The collection contains a set of 36 personalized dialogues over 20
                    different topics each coupled with a Personal Text Knowledge Base (PTKB) that
                    defines the bespoke user personas. A total of 344 turns with approximately
                    26,000 passages are provided as assessments on relevance, as well as additional
                    assessments on generated responses over four key dimensions: relevance,
                    completeness, groundedness, and naturalness. The collection challenges CSA to
                    efficiently navigate diverse personal contexts, elicit pertinent persona
                    information, and employ context for relevant conversations. The integration of
                    a PTKB and the emphasis on decisional search tasks contribute to the uniqueness
                    of this test collection, making it an essential benchmark for advancing
                    research in conversational and interactive knowledge assistants.
                </p>
            </div>
        </dd>
        <dt><a name="item165">[165]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02638"
                    title="Abstract">arXiv:2405.02638</a> [<a href="/pdf/2405.02638" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02638" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PrivSGP-VR: Differentially Private Variance-Reduced
                    Stochastic Gradient Push with Tight Utility Bounds
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zehan Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yan Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jinming Xu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper has been accepted by the 33rd International
                    Joint Conference on Artificial Intelligence(IJCAI 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">In this paper, we propose a differentially private decentralized learning
                    method (termed PrivSGP-VR) which employs stochastic gradient push with variance
                    reduction and guarantees <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-56-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-401"
                                style="width: 2.549em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.97em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-402"><span class="mo" id="MathJax-Span-403"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-404"
                                                style="font-family: MathJax_Math-italic;">ϵ</span><span class="mo"
                                                id="MathJax-Span-405" style="font-family: MathJax_Main;">,</span><span
                                                class="mi" id="MathJax-Span-406"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">δ<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-407"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-56">(\epsilon, \delta)</script>-differential privacy
                    (DP) for
                    each node. Our theoretical analysis shows that, under DP Gaussian noise with
                    constant variance, PrivSGP-VR achieves a sub-linear convergence rate of
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-57-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-408"
                                style="width: 5.906em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.922em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1004.81em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-409"><span class="texatom"
                                                id="MathJax-Span-410"><span class="mrow" id="MathJax-Span-411"><span
                                                        class="mi" id="MathJax-Span-412"
                                                        style="font-family: MathJax_Caligraphic;">O</span></span></span><span
                                                class="mo" id="MathJax-Span-413"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-414" style="font-family: MathJax_Main;">1</span><span
                                                class="texatom" id="MathJax-Span-415"><span class="mrow"
                                                    id="MathJax-Span-416"><span class="mo" id="MathJax-Span-417"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="msqrt" id="MathJax-Span-418"><span
                                                    style="display: inline-block; position: relative; width: 2.318em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.51em, 4.17em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                            class="mrow" id="MathJax-Span-419"><span class="mi"
                                                                id="MathJax-Span-420"
                                                                style="font-family: MathJax_Math-italic;">n</span><span
                                                                class="mi" id="MathJax-Span-421"
                                                                style="font-family: MathJax_Math-italic;">K<span
                                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1001.45em, 3.938em, -999.997em); top: -4.569em; left: 0.813em;"><span
                                                            style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: 0.755em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 0.35em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -4.048em; left: 0em;"><span
                                                            style="font-family: MathJax_Main;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-422"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-57">\mathcal{O}(1/\sqrt{nK})</script>, where <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-58-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-423"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-424"><span class="mi" id="MathJax-Span-425"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-58">n</script> and <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-59-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-426"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-427"><span class="mi" id="MathJax-Span-428"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-59">K</script> are the number of nodes and
                    iterations, respectively, which is independent of stochastic gradient variance,
                    and achieves a linear speedup with respect to <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-60-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-429"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-430"><span class="mi" id="MathJax-Span-431"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-60">n</script>. Leveraging the moments
                    accountant method, we further derive an optimal <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-61-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-432"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-433"><span class="mi" id="MathJax-Span-434"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-61">K</script> to maximize the model
                    utility under certain privacy budget in decentralized settings. With this
                    optimized <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-62-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-435"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-436"><span class="mi" id="MathJax-Span-437"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-62">K</script>, PrivSGP-VR achieves a tight utility
                    bound of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-63-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-438"
                                style="width: 13.313em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 11.056em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.797em, 1010.83em, 4.517em, -999.997em); top: -3.411em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-439"><span class="texatom"
                                                id="MathJax-Span-440"><span class="mrow" id="MathJax-Span-441"><span
                                                        class="mi" id="MathJax-Span-442"
                                                        style="font-family: MathJax_Caligraphic;">O</span></span></span><span
                                                class="mrow" id="MathJax-Span-443" style="padding-left: 0.177em;"><span
                                                    class="mo" id="MathJax-Span-444" style="vertical-align: 0em;"><span
                                                        style="font-family: MathJax_Size3;">(</span></span><span
                                                    class="msqrt" id="MathJax-Span-445"><span
                                                        style="display: inline-block; position: relative; width: 4.864em; height: 0px;"><span
                                                            style="position: absolute; clip: rect(2.665em, 1003.71em, 4.806em, -999.997em); top: -3.99em; left: 0.987em;"><span
                                                                class="mrow" id="MathJax-Span-446"><span class="mi"
                                                                    id="MathJax-Span-447"
                                                                    style="font-family: MathJax_Math-italic;">d<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                    class="mi" id="MathJax-Span-448"
                                                                    style="font-family: MathJax_Main; padding-left: 0.177em;">log</span><span
                                                                    class="mo" id="MathJax-Span-449"></span><span
                                                                    class="mrow" id="MathJax-Span-450"><span class="mo"
                                                                        id="MathJax-Span-451"
                                                                        style="vertical-align: 0em;"><span
                                                                            style="font-family: MathJax_Size2;">(</span></span><span
                                                                        class="mfrac" id="MathJax-Span-452"><span
                                                                            style="display: inline-block; position: relative; width: 0.466em; height: 0px; margin-right: 0.119em; margin-left: 0.119em;"><span
                                                                                style="position: absolute; clip: rect(3.359em, 1000.29em, 4.17em, -999.997em); top: -4.395em; left: 50%; margin-left: -0.171em;"><span
                                                                                    class="mn" id="MathJax-Span-453"
                                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                                style="position: absolute; clip: rect(3.302em, 1000.35em, 4.17em, -999.997em); top: -3.585em; left: 50%; margin-left: -0.171em;"><span
                                                                                    class="mi" id="MathJax-Span-454"
                                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">δ<span
                                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                                style="position: absolute; clip: rect(0.871em, 1000.47em, 1.276em, -999.997em); top: -1.328em; left: 0em;"><span
                                                                                    style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.466em; height: 0px;"></span><span
                                                                                    style="display: inline-block; width: 0px; height: 1.102em;"></span></span></span></span><span
                                                                        class="mo" id="MathJax-Span-455"
                                                                        style="vertical-align: 0em;"><span
                                                                            style="font-family: MathJax_Size2;">)</span></span></span></span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                            style="position: absolute; clip: rect(3.533em, 1003.82em, 3.938em, -999.997em); top: -5.148em; left: 0.987em;"><span
                                                                style="display: inline-block; position: relative; width: 3.822em; height: 0px;"><span
                                                                    style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                    style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: 3.128em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                    style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 0.466em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                    style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 0.987em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                    style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 1.565em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                    style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 2.086em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                    style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 2.665em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                            style="position: absolute; clip: rect(2.376em, 1001.04em, 5.095em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                style="font-family: MathJax_Size3;">√</span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                    class="texatom" id="MathJax-Span-456"><span class="mrow"
                                                        id="MathJax-Span-457"><span class="mo" id="MathJax-Span-458"
                                                            style="font-family: MathJax_Main;">/</span></span></span><span
                                                    class="mo" id="MathJax-Span-459"
                                                    style="font-family: MathJax_Main;">(</span><span class="msqrt"
                                                    id="MathJax-Span-460"><span
                                                        style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                            style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                                class="mrow" id="MathJax-Span-461"><span class="mi"
                                                                    id="MathJax-Span-462"
                                                                    style="font-family: MathJax_Math-italic;">n</span></span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                            style="position: absolute; clip: rect(3.533em, 1000.64em, 3.938em, -999.997em); top: -4.395em; left: 0.813em;"><span
                                                                style="display: inline-block; position: relative; width: 0.639em; height: 0px;"><span
                                                                    style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                    style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                        style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                            style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -3.932em; left: 0em;"><span
                                                                style="font-family: MathJax_Main;">√</span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                    class="mi" id="MathJax-Span-463"
                                                    style="font-family: MathJax_Math-italic;">J<span
                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                    class="mi" id="MathJax-Span-464"
                                                    style="font-family: MathJax_Math-italic;">ϵ</span><span class="mo"
                                                    id="MathJax-Span-465"
                                                    style="font-family: MathJax_Main;">)</span><span class="mo"
                                                    id="MathJax-Span-466" style="vertical-align: 0em;"><span
                                                        style="font-family: MathJax_Size3;">)</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 3.417em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -1.177em; border-left: 0px solid; width: 0px; height: 3.059em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-63">\mathcal{O}\left(
    \sqrt{d\log \left( \frac{1}{\delta} \right)}/(\sqrt{n}J\epsilon) \right)</script>,
                    where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-64-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-467"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.64em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-468"><span class="mi" id="MathJax-Span-469"
                                                style="font-family: MathJax_Math-italic;">J<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-64">J</script> and <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-65-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-470"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-471"><span class="mi" id="MathJax-Span-472"
                                                style="font-family: MathJax_Math-italic;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-65">d</script> are the number of local samples and the
                    dimension of decision
                    variable, respectively, which matches that of the server-client distributed
                    counterparts, and exhibits an extra factor of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-66-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-473"
                                style="width: 2.954em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.433em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.43em, 2.607em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-474"><span class="mn" id="MathJax-Span-475"
                                                style="font-family: MathJax_Main;">1</span><span class="texatom"
                                                id="MathJax-Span-476"><span class="mrow" id="MathJax-Span-477"><span
                                                        class="mo" id="MathJax-Span-478"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="msqrt" id="MathJax-Span-479"><span
                                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                            class="mrow" id="MathJax-Span-480"><span class="mi"
                                                                id="MathJax-Span-481"
                                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1000.64em, 3.938em, -999.997em); top: -4.395em; left: 0.813em;"><span
                                                            style="display: inline-block; position: relative; width: 0.639em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -3.932em; left: 0em;"><span
                                                            style="font-family: MathJax_Main;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-66">1/\sqrt{n}</script> improvement compared
                    to that of the existing decentralized counterparts, such as A(DP)<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-67-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-482"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.41em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-483"><span class="msubsup"
                                                id="MathJax-Span-484"><span
                                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.822em, 1000em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-485"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-486"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-67">^2</script>SGD.
                    Extensive experiments corroborate our theoretical findings, especially in terms
                    of the maximized utility with optimized <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-68-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-487"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-488"><span class="mi" id="MathJax-Span-489"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-68">K</script>, in fully decentralized settings.
                </p>
            </div>
        </dd>
        <dt><a name="item166">[166]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02639"
                    title="Abstract">arXiv:2405.02639</a> [<a href="/pdf/2405.02639" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02639" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Wall-Climbing Performance of Gecko-inspired Robot with Soft
                    Feet and Digits enhanced by Gravity Compensation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bingcheng Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Weng%2C+Z">Zhiyuan Weng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haoyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuangjie Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhouyi Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+Z">Zhendong Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jusufi%2C+A">Ardian Jusufi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Gravitational forces can induce deviations in body posture from desired
                    configurations in multi-legged arboreal robot locomotion with low leg
                    stiffness, affecting the contact angle between the swing leg's end-effector and
                    the climbing surface during the gait cycle. The relationship between desired
                    and actual foot positions is investigated here in a leg-stiffness-enhanced
                    model under external forces, focusing on the challenge of unreliable
                    end-effector attachment on climbing surfaces in such robots. Inspired by the
                    difference in ceiling attachment postures of dead and living geckos,
                    feedforward compensation of the stance phase legs is the key to solving this
                    problem. A feedforward gravity compensation (FGC) strategy, complemented by leg
                    coordination, is proposed to correct gravity-influenced body posture and
                    improve adhesion stability by reducing body inclination. The efficacy of this
                    strategy is validated using a quadrupedal climbing robot, EF-I, as the
                    experimental platform. Experimental validation on an inverted surface (ceiling
                    walking) highlight the benefits of the FGC strategy, demonstrating its role in
                    enhancing stability and ensuring reliable end-effector attachment without
                    external assistance. In the experiment, robots without FGC only completed in 3
                    out of 10 trials, while robots with FGC achieved a 100\% success rate in the
                    same trials. The speed was substantially greater with FGC, achieved 9.2 mm/s in
                    the trot gait. This underscores the proposed potential of FGC strategy in
                    overcoming the challenges associated with inconsistent end-effector attachment
                    in robots with low leg stiffness, thereby facilitating stable locomotion even
                    at inverted body attitude.
                </p>
            </div>
        </dd>
        <dt><a name="item167">[167]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02642"
                    title="Abstract">arXiv:2405.02642</a> [<a href="/pdf/2405.02642" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02642" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Machine Learning in Space: Surveying the Robustness of
                    on-board ML models to Radiation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lange%2C+K">Kevin Lange</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fontana%2C+F">Federico Fontana</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rossi%2C+F">Francesco Rossi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Varile%2C+M">Mattia Varile</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Apruzzese%2C+G">Giovanni Apruzzese</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Modern spacecraft are increasingly relying on machine learning (ML). However,
                    physical equipment in space is subject to various natural hazards, such as
                    radiation, which may inhibit the correct operation of computing devices.
                    Despite plenty of evidence showing the damage that naturally-induced faults can
                    cause to ML-related hardware, we observe that the effects of radiation on ML
                    models for space applications are not well-studied. This is a problem: without
                    understanding how ML models are affected by these natural phenomena, it is
                    uncertain "where to start from" to develop radiation-tolerant ML software. As
                    ML researchers, we attempt to tackle this dilemma. By partnering up with
                    space-industry practitioners specialized in ML, we perform a reflective
                    analysis of the state of the art. We provide factual evidence that prior work
                    did not thoroughly examine the impact of natural hazards on ML models meant for
                    spacecraft. Then, through a "negative result", we show that some existing
                    open-source technologies can hardly be used by researchers to study the effects
                    of radiation for some applications of ML in satellites. As a constructive step
                    forward, we perform simple experiments showcasing how to leverage current
                    frameworks to assess the robustness of practical ML models for cloud detection
                    against radiation-induced faults. Our evaluation reveals that not all faults
                    are as devastating as claimed by some prior work. By publicly releasing our
                    resources, we provide a foothold -- usable by researchers without access to
                    spacecraft -- for spearheading development of space-tolerant ML models.
                </p>
            </div>
        </dd>
        <dt><a name="item168">[168]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02644"
                    title="Abstract">arXiv:2405.02644</a> [<a href="/pdf/2405.02644" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02644" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Interpretable Multi-View Clustering
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+M">Mudi Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+L">Lianyu Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+Z">Zengyou He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhikui Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages,6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Multi-view clustering has become a significant area of research, with
                    numerous methods proposed over the past decades to enhance clustering accuracy.
                    However, in many real-world applications, it is crucial to demonstrate a clear
                    decision-making process-specifically, explaining why samples are assigned to
                    particular clusters. Consequently, there remains a notable gap in developing
                    interpretable methods for clustering multi-view data. To fill this crucial gap,
                    we make the first attempt towards this direction by introducing an
                    interpretable multi-view clustering framework. Our method begins by extracting
                    embedded features from each view and generates pseudo-labels to guide the
                    initial construction of the decision tree. Subsequently, it iteratively
                    optimizes the feature representation for each view along with refining the
                    interpretable decision tree. Experimental results on real datasets demonstrate
                    that our method not only provides a transparent clustering process for
                    multi-view data but also delivers performance comparable to state-of-the-art
                    multi-view clustering methods. To the best of our knowledge, this is the first
                    effort to design an interpretable clustering framework specifically for
                    multi-view data, opening a new avenue in this field.
                </p>
            </div>
        </dd>
        <dt><a name="item169">[169]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02646"
                    title="Abstract">arXiv:2405.02646</a> [<a href="/pdf/2405.02646" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02646" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Updating Windows Malware Detectors: Balancing Robustness and
                    Regression against Adversarial EXEmples
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kozak%2C+M">Matous Kozak</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Demetrio%2C+L">Luca Demetrio</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Trizna%2C+D">Dmitrijs Trizna</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roli%2C+F">Fabio Roli</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 3 figures, 7 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Adversarial EXEmples are carefully-perturbed programs tailored to evade
                    machine learning Windows malware detectors, with an on-going effort in
                    developing robust models able to address detection effectiveness. However, even
                    if robust models can prevent the majority of EXEmples, to maintain predictive
                    power over time, models are fine-tuned to newer threats, leading either to
                    partial updates or time-consuming retraining from scratch. Thus, even if the
                    robustness against attacks is higher, the new models might suffer a regression
                    in performance by misclassifying threats that were previously correctly
                    detected. For these reasons, we study the trade-off between accuracy and
                    regression when updating Windows malware detectors, by proposing EXE-scanner, a
                    plugin that can be chained to existing detectors to promptly stop EXEmples
                    without causing regression. We empirically show that previously-proposed
                    hardening techniques suffer a regression of accuracy when updating non-robust
                    models. On the contrary, we show that EXE-scanner exhibits comparable
                    performance to robust models without regression of accuracy, and we show how to
                    properly chain it after the base classifier to obtain the best performance
                    without the need of costly retraining. To foster reproducibility, we openly
                    release source code, along with the dataset of adversarial EXEmples based on
                    state-of-the-art perturbation algorithms.
                </p>
            </div>
        </dd>
        <dt><a name="item170">[170]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02647"
                    title="Abstract">arXiv:2405.02647</a> [<a href="/pdf/2405.02647" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02647" title="Download PostScript">ps</a>, <a href="/format/2405.02647"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SubwayMeshDTN: Exploring Opportunistic Delay Tolerant Routing
                    Protocols when Disseminating Emergency Alerts on a Smart City Subway Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Estivil%2C+B">Bruce Estivil</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Radenkovic%2C+M">Milena Radenkovic</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>

                </div>
                <p class="mathjax">This paper seeks to understand the effectiveness of using multi-dimensional
                    opportunistic delay-tolerant network (DTN) routing protocols, specifically
                    Epidemic and MaxProp, in the context of New York City (NYC) metropolitan subway
                    network. We examine how efficiently emergency messages spread through mobile,
                    self-configuring, edge-based movement patterns on the train network to
                    understand and propose solutions for improving communication in subterranean
                    environments. Since DTNs are able to store, carry and forward messages through
                    intermediate edges, this paper benchmarks both Wi-Fi and Bluetooth topologies
                    to compare and critically evaluate movement patterns, latency, overheads and
                    delivery rates on pseudo-realistic underground traces. We also show that the
                    accordion effect is predominant in these networks, and therefore, the most
                    effective protocol configurations vary.
                </p>
            </div>
        </dd>
        <dt><a name="item171">[171]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02648"
                    title="Abstract">arXiv:2405.02648</a> [<a href="/pdf/2405.02648" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02648" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Conformal Prediction Score that is Robust to Label Noise
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Penso%2C+C">Coby Penso</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goldberger%2C+J">Jacob Goldberger</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Conformal Prediction (CP) quantifies network uncertainty by building a small
                    prediction set with a pre-defined probability that the correct class is within
                    this set. In this study we tackle the problem of CP calibration based on a
                    validation set with noisy labels. We introduce a conformal score that is robust
                    to label noise. The noise-free conformal score is estimated using the noisy
                    labeled data and the noise level. In the test phase the noise-free score is
                    used to form the prediction set. We applied the proposed algorithm to several
                    standard medical imaging classification datasets. We show that our method
                    outperforms current methods by a large margin, in terms of the average size of
                    the prediction set, while maintaining the required coverage.
                </p>
            </div>
        </dd>
        <dt><a name="item172">[172]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02649"
                    title="Abstract">arXiv:2405.02649</a> [<a href="/pdf/2405.02649" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02649" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Generic Multi-modal Representation Learning for Network
                    Traffic Analysis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gioacchini%2C+L">Luca Gioacchini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Drago%2C+I">Idilio Drago</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mellia%2C+M">Marco Mellia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Houidi%2C+Z+B">Zied Ben Houidi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rossi%2C+D">Dario Rossi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Network traffic analysis is fundamental for network management,
                    troubleshooting, and security. Tasks such as traffic classification, anomaly
                    detection, and novelty discovery are fundamental for extracting operational
                    information from network data and measurements. We witness the shift from deep
                    packet inspection and basic machine learning to Deep Learning (DL) approaches
                    where researchers define and test a custom DL architecture designed for each
                    specific problem. We here advocate the need for a general DL architecture
                    flexible enough to solve different traffic analysis tasks. We test this idea by
                    proposing a DL architecture based on generic data adaptation modules, followed
                    by an integration module that summarises the extracted information into a
                    compact and rich intermediate representation (i.e. embeddings). The result is a
                    flexible Multi-modal Autoencoder (MAE) pipeline that can solve different use
                    cases. We demonstrate the architecture with traffic classification (TC) tasks
                    since they allow us to quantitatively compare results with state-of-the-art
                    solutions. However, we argue that the MAE architecture is generic and can be
                    used to learn representations useful in multiple scenarios. On TC, the MAE
                    performs on par or better than alternatives while avoiding cumbersome feature
                    engineering, thus streamlining the adoption of DL solutions for traffic
                    analysis.
                </p>
            </div>
        </dd>
        <dt><a name="item173">[173]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02650"
                    title="Abstract">arXiv:2405.02650</a> [<a href="/pdf/2405.02650" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02650" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Identifying Narrative Patterns and Outliers in Holocaust
                    Testimonies Using Topic Modeling
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ifergan%2C+M">Maxim Ifergan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Keydar%2C+R">Renana Keydar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abend%2C+O">Omri Abend</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pinchevski%2C+A">Amit Pinchevski</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 7 figures, LREC-COLING 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">The vast collection of Holocaust survivor testimonies presents invaluable
                    historical insights but poses challenges for manual analysis. This paper
                    leverages advanced Natural Language Processing (NLP) techniques to explore the
                    USC Shoah Foundation Holocaust testimony corpus. By treating testimonies as
                    structured question-and-answer sections, we apply topic modeling to identify
                    key themes. We experiment with BERTopic, which leverages recent advances in
                    language modeling technology. We align testimony sections into fixed parts,
                    revealing the evolution of topics across the corpus of testimonies. This
                    highlights both a common narrative schema and divergences between subgroups
                    based on age and gender. We introduce a novel method to identify testimonies
                    within groups that exhibit atypical topic distributions resembling those of
                    other groups. This study offers unique insights into the complex narratives of
                    Holocaust survivors, demonstrating the power of NLP to illuminate historical
                    discourse and identify potential deviations in survivor experiences.
                </p>
            </div>
        </dd>
        <dt><a name="item174">[174]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02652"
                    title="Abstract">arXiv:2405.02652</a> [<a href="/pdf/2405.02652" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02652" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Pulse-Signal Magnification for remote Heart Rate
                    Estimation in Compressed Videos
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Comas%2C+J">Joaquim Comas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ruiz%2C+A">Adria Ruiz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sukno%2C+F">Federico Sukno</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Recent advancements in remote heart rate measurement (rPPG), motivated by
                    data-driven approaches, have significantly improved accuracy. However, certain
                    challenges, such as video compression, still remain: recovering the rPPG signal
                    from highly compressed videos is particularly complex. Although several studies
                    have highlighted the difficulties and impact of video compression for this,
                    effective solutions remain limited. In this paper, we present a novel approach
                    to address the impact of video compression on rPPG estimation, which leverages
                    a pulse-signal magnification transformation to adapt compressed videos to an
                    uncompressed data domain in which the rPPG signal is magnified. We validate the
                    effectiveness of our model by exhaustive evaluations on two publicly available
                    datasets, UCLA-rPPG and UBFC-rPPG, employing both intra- and cross-database
                    performance at several compression rates. Additionally, we assess the
                    robustness of our approach on two additional highly compressed and widely-used
                    datasets, MAHNOB-HCI and COHFACE, which reveal outstanding heart rate
                    estimation results.
                </p>
            </div>
        </dd>
        <dt><a name="item175">[175]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02653"
                    title="Abstract">arXiv:2405.02653</a> [<a href="/pdf/2405.02653" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02653" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Isopignistic Canonical Decomposition via Belief Evolution
                    Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Q">Qianli Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhan%2C+T">Tianxiang Zhan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yong Deng</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">Developing a general information processing model in uncertain environments
                    is fundamental for the advancement of explainable artificial intelligence.
                    Dempster-Shafer theory of evidence is a well-known and effective reasoning
                    method for representing epistemic uncertainty, which is closely related to
                    subjective probability theory and possibility theory. Although they can be
                    transformed to each other under some particular belief structures, there
                    remains a lack of a clear and interpretable transformation process, as well as
                    a unified approach for information processing. In this paper, we aim to address
                    these issues from the perspectives of isopignistic belief functions and the
                    hyper-cautious transferable belief model. Firstly, we propose an isopignistic
                    transformation based on the belief evolution network. This transformation
                    allows for the adjustment of the information granule while retaining the
                    potential decision outcome. The isopignistic transformation is integrated with
                    a hyper-cautious transferable belief model to establish a new canonical
                    decomposition. This decomposition offers a reverse path between the possibility
                    distribution and its isopignistic mass functions. The result of the canonical
                    decomposition, called isopignistic function, is an identical information
                    content distribution to reflect the propensity and relative commitment degree
                    of the BPA. Furthermore, this paper introduces a method to reconstruct the
                    basic belief assignment by adjusting the isopignistic function. It explores the
                    advantages of this approach in modeling and handling uncertainty within the
                    hyper-cautious transferable belief model. More general, this paper establishes
                    a theoretical basis for building general models of artificial intelligence
                    based on probability theory, Dempster-Shafer theory, and possibility theory.
                </p>
            </div>
        </dd>
        <dt><a name="item176">[176]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02654"
                    title="Abstract">arXiv:2405.02654</a> [<a href="/pdf/2405.02654" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02654" title="Download PostScript">ps</a>, <a href="/format/2405.02654"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing Cooperation through Selective Interaction and
                    Long-term Experiences in Multi-Agent Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+T">Tianyu Ren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+X">Xiao-Jun Zeng</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at IJCAI 2024 (33nd International Joint
                    Conference on Artificial Intelligence - Jeju)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems
                        (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

                </div>
                <p class="mathjax">The significance of network structures in promoting group cooperation within
                    social dilemmas has been widely recognized. Prior studies attribute this
                    facilitation to the assortment of strategies driven by spatial interactions.
                    Although reinforcement learning has been employed to investigate the impact of
                    dynamic interaction on the evolution of cooperation, there remains a lack of
                    understanding about how agents develop neighbour selection behaviours and the
                    formation of strategic assortment within an explicit interaction structure. To
                    address this, our study introduces a computational framework based on
                    multi-agent reinforcement learning in the spatial Prisoner's Dilemma game. This
                    framework allows agents to select dilemma strategies and interacting neighbours
                    based on their long-term experiences, differing from existing research that
                    relies on preset social norms or external incentives. By modelling each agent
                    using two distinct Q-networks, we disentangle the coevolutionary dynamics
                    between cooperation and interaction. The results indicate that long-term
                    experience enables agents to develop the ability to identify non-cooperative
                    neighbours and exhibit a preference for interaction with cooperative ones. This
                    emergent self-organizing behaviour leads to the clustering of agents with
                    similar strategies, thereby increasing network reciprocity and enhancing group
                    cooperation.
                </p>
            </div>
        </dd>
        <dt><a name="item177">[177]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02655"
                    title="Abstract">arXiv:2405.02655</a> [<a href="/pdf/2405.02655" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02655" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fast Online Movement Optimization of Aerial Base Stations
                    Based on Global Connectivity Map
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yiling Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+J">Jiangbin Lyu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+L">Liqun Fu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages, 6 figures. Investigate site-specific movement
                    optimization of UAV-mounted aerial base stations to cover a group of moving ground users, based on
                    site-specific Global Connectivity Map. arXiv admin note: text overlap with <a
                        href="/abs/2312.10490">arXiv:2312.10490</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">Unmanned aerial vehicles (UAVs) can serve as aerial base stations (ABSs) to
                    provide wireless connectivity for ground users (GUs) in diverse scenarios.
                    However, it is an NP-hard problem with exponential complexity in <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-69-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-490"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1001.04em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-491"><span class="mi" id="MathJax-Span-492"
                                                style="font-family: MathJax_Math-italic;">M<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-69">M</script> and <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-70-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-493"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-494"><span class="mi" id="MathJax-Span-495"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-70">N</script>,
                    in order to maximize the coverage rate (CR) of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-71-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-496"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1001.04em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-497"><span class="mi" id="MathJax-Span-498"
                                                style="font-family: MathJax_Math-italic;">M<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-71">M</script> GUs by jointly placing <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-72-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-499"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-500"><span class="mi" id="MathJax-Span-501"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-72">N</script>
                    ABSs with limited coverage range. This problem becomes even more intricate when
                    the coverage range becomes irregular due to site-specific obstructions (e.g.,
                    buildings) on the air-ground channel, and/or when the GUs are in motion. To
                    address the above challenges, we study a multi-ABS movement optimization
                    problem to maximize the average coverage rate of mobile GUs within a
                    site-specific environment. We tackle this challenging problem by 1)
                    constructing the global connectivity map (GCM) which contains the connectivity
                    information between given pairs of ABS/GU locations; 2) partitioning the ABS
                    movement problem into ABS placement sub-problems and formulate each sub-problem
                    into a binary integer linear programing (BILP) problem based on GCM; 3)
                    proposing a fast online algorithm to execute (one-pass) projected stochastic
                    subgradient descent within the dual space to rapidly solve the BILP problem
                    with near-optimal performance. Numerical results demonstrate that our proposed
                    algorithm achieves a high CR performance close to that obtained by the open
                    source solver (SCIP), yet with significantly reduced running time. In addition,
                    the algorithm also notably outperforms one of the state-of-the-art deep
                    reinforcement learning (DRL) methods and the K-means initiated evolutionary
                    algorithm in terms of CR performance and/or time efficiency.
                </p>
            </div>
        </dd>
        <dt><a name="item178">[178]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02659"
                    title="Abstract">arXiv:2405.02659</a> [<a href="/pdf/2405.02659" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02659" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> R4: Reinforced Retriever-Reorder-Responder for
                    Retrieval-Augmented Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Taolin Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dongyang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qizhou Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chengyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+L">Longtao Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+H">Hui Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+X">Xiaofeng He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jun Huang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Retrieval-augmented large language models (LLMs) leverage relevant content
                    retrieved by information retrieval systems to generate correct responses,
                    aiming to alleviate the hallucination problem. However, existing
                    retriever-responder methods typically append relevant documents to the prompt
                    of LLMs to perform text generation tasks without considering the interaction of
                    fine-grained structural semantics between the retrieved documents and the LLMs.
                    This issue is particularly important for accurate response generation as LLMs
                    tend to ``lose in the middle'' when dealing with input prompts augmented with
                    lengthy documents. In this work, we propose a new pipeline named ``Reinforced
                    Retriever-Reorder-Responder'' (R<span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-73-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-502"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1000.41em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-503"><span class="msubsup"
                                                id="MathJax-Span-504"><span
                                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.822em, 1000em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-505"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-506"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">4</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-73">^4</script>) to learn document orderings for
                    retrieval-augmented LLMs, thereby further enhancing their generation abilities
                    while the large numbers of parameters of LLMs remain frozen. The reordering
                    learning process is divided into two steps according to the quality of the
                    generated responses: document order adjustment and document representation
                    enhancement. Specifically, document order adjustment aims to organize retrieved
                    document orderings into beginning, middle, and end positions based on graph
                    attention learning, which maximizes the reinforced reward of response quality.
                    Document representation enhancement further refines the representations of
                    retrieved documents for responses of poor quality via document-level gradient
                    adversarial learning. Extensive experiments demonstrate that our proposed
                    pipeline achieves better factual question-answering performance on
                    knowledge-intensive tasks compared to strong baselines across various public
                    datasets. The source codes and trained models will be released upon paper
                    acceptance.
                </p>
            </div>
        </dd>
        <dt><a name="item179">[179]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02660"
                    title="Abstract">arXiv:2405.02660</a> [<a href="/pdf/2405.02660" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02660" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AFDM Channel Estimation in Multi-Scale Multi-Lag Channels
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+R">Rongyou Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yuheng Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+J">Jiangbin Lyu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+D">Deqing Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+L">Liqun Fu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages, 6 figures. Investigate AFDM under underwater
                    multi-scale multi-lag channels. Derive the new input-output formula with the impact of Doppler time
                    scaling. Propose two new channel estimation methods to tackle different level of Doppler factors.
                    Perform diversity analyis based on CFR overlap probability (COP) and mutual incoherent property
                    (MIP)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">Affine Frequency Division Multiplexing (AFDM) is a brand new chirp-based
                    multi-carrier (MC) waveform for high mobility communications, with promising
                    advantages over Orthogonal Frequency Division Multiplexing (OFDM) and other MC
                    waveforms. Existing AFDM research focuses on wireless communication at high
                    carrier frequency (CF), which typically considers only Doppler frequency shift
                    (DFS) as a result of mobility, while ignoring the accompanied Doppler time
                    scaling (DTS) on waveform. However, for underwater acoustic (UWA) communication
                    at much lower CF and propagating at speed of sound, the DTS effect could not be
                    ignored and poses significant challenges for channel estimation. This paper
                    analyzes the channel frequency response (CFR) of AFDM under multi-scale
                    multi-lag (MSML) channels, where each propagating path could have different
                    delay and DFS/DTS. Based on the newly derived input-output formula and its
                    characteristics, two new channel estimation methods are proposed, i.e., AFDM
                    with iterative multi-index (AFDM-IMI) estimation under low to moderate DTS, and
                    AFDM with orthogonal matching pursuit (AFDM-OMP) estimation under high DTS.
                    Numerical results confirm the effectiveness of the proposed methods against the
                    original AFDM channel estimation method. Moreover, the resulted AFDM system
                    outperforms OFDM as well as Orthogonal Chirp Division Multiplexing (OCDM) in
                    terms of channel estimation accuracy and bit error rate (BER), which is
                    consistent with our theoretical analysis based on CFR overlap probability
                    (COP), mutual incoherent property (MIP) and channel diversity gain under MSML
                    channels.
                </p>
            </div>
        </dd>
        <dt><a name="item180">[180]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02661"
                    title="Abstract">arXiv:2405.02661</a> [<a href="/pdf/2405.02661" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02661" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DDE-Find: Learning Delay Differential Equations from Data
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Stephany%2C+R">Robert Stephany</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 42 pages, 19 tables, 8 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Delay Differential Equations (DDEs) are a class of differential equations
                    that can model diverse scientific phenomena. However, identifying the
                    parameters, especially the time delay, that make a DDE's predictions match
                    experimental results can be challenging. We introduce DDE-Find, a data-driven
                    framework for learning a DDE's parameters, time delay, and initial condition
                    function. DDE-Find uses an adjoint-based approach to efficiently compute the
                    gradient of a loss function with respect to the model parameters. We motivate
                    and rigorously prove an expression for the gradients of the loss using the
                    adjoint. DDE-Find builds upon recent developments in learning DDEs from data
                    and delivers the first complete framework for learning DDEs from data. Through
                    a series of numerical experiments, we demonstrate that DDE-Find can learn DDEs
                    from noisy, limited data.
                </p>
            </div>
        </dd>
        <dt><a name="item181">[181]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02664"
                    title="Abstract">arXiv:2405.02664</a> [<a href="/pdf/2405.02664" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02664" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MedPromptExtract (Medical Data Extraction Tool):
                    Anonymization and Hi-fidelity Automated data extraction using NLP and prompt engineering
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Srivastava%2C+R">Roomani Srivastava</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Prasad%2C+S">Suraj Prasad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bhat%2C+L">Lipika Bhat</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deshpande%2C+S">Sarvesh Deshpande</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Das%2C+B">Barnali Das</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jadhav%2C+K">Kshitij Jadhav</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Information Retrieval (cs.IR)

                </div>
                <p class="mathjax">A major roadblock in the seamless digitization of medical records remains the
                    lack of interoperability of existing records. Extracting relevant medical
                    information required for further treatment planning or even research is a time
                    consuming labour intensive task involving the much valuable time of doctors. In
                    this demo paper we present, MedPromptExtract an automated tool using a
                    combination of semi supervised learning, large language models, natural
                    lanuguage processing and prompt engineering to convert unstructured medical
                    records to structured data which is amenable to further analysis.
                </p>
            </div>
        </dd>
        <dt><a name="item182">[182]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02665"
                    title="Abstract">arXiv:2405.02665</a> [<a href="/pdf/2405.02665" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02665" title="Download PostScript">ps</a>, <a href="/format/2405.02665"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Metric Differential Privacy at the User-Level
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Imola%2C+J">Jacob Imola</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chowdhury%2C+A+R">Amrita Roy Chowdhury</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chaudhuri%2C+K">Kamalika Chaudhuri</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Metric differential privacy (DP) provides heterogeneous privacy guarantees
                    based on a distance between the pair of inputs. It is a widely popular notion
                    of privacy since it captures the natural privacy semantics for many
                    applications (such as, for location data) and results in better utility than
                    standard DP. However, prior work in metric DP has primarily focused on the
                    \textit{item-level} setting where every user only reports a single data item. A
                    more realistic setting is that of user-level DP where each user contributes
                    multiple items and privacy is then desired at the granularity of the user's
                    \textit{entire} contribution. In this paper, we initiate the study of metric DP
                    at the user-level. Specifically, we use the earth-mover's distance
                    (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-74-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-507"
                                style="width: 1.97em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.62em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-508"><span class="msubsup"
                                                id="MathJax-Span-509"><span
                                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.52em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-510"
                                                            style="font-family: MathJax_Math-italic;">d<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.524em;"><span
                                                            class="texatom" id="MathJax-Span-511"><span class="mrow"
                                                                id="MathJax-Span-512"><span class="mtext"
                                                                    id="MathJax-Span-513"
                                                                    style="font-size: 70.7%; font-family: MathJax_SansSerif;">EM</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-74">d_\textsf{EM}</script>) as our metric to obtain a
                    notion of privacy as it captures
                    both the magnitude and spatial aspects of changes in a user's data.
                    <br>We make three main technical contributions. First, we design two novel
                    mechanisms under <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-75-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-514"
                                style="width: 1.97em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.62em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-515"><span class="msubsup"
                                                id="MathJax-Span-516"><span
                                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.52em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-517"
                                                            style="font-family: MathJax_Math-italic;">d<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.524em;"><span
                                                            class="texatom" id="MathJax-Span-518"><span class="mrow"
                                                                id="MathJax-Span-519"><span class="mtext"
                                                                    id="MathJax-Span-520"
                                                                    style="font-size: 70.7%; font-family: MathJax_SansSerif;">EM</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-75">d_\textsf{EM}</script>-DP to answer linear queries
                    and item-wise
                    queries. Specifically, our analysis for the latter involves a generalization of
                    the privacy amplification by shuffling result which may be of independent
                    interest. Second, we provide a black-box reduction from the general unbounded
                    to bounded <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-76-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-521"
                                style="width: 1.97em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.62em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-522"><span class="msubsup"
                                                id="MathJax-Span-523"><span
                                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.52em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-524"
                                                            style="font-family: MathJax_Math-italic;">d<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.524em;"><span
                                                            class="texatom" id="MathJax-Span-525"><span class="mrow"
                                                                id="MathJax-Span-526"><span class="mtext"
                                                                    id="MathJax-Span-527"
                                                                    style="font-size: 70.7%; font-family: MathJax_SansSerif;">EM</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-76">d_\textsf{EM}</script>-DP (size of the dataset is
                    fixed and public) with a
                    novel sampling based mechanism. Third, we show that our proposed mechanisms can
                    provably provide improved utility over user-level DP, for certain types of
                    linear queries and frequency estimation.
                </p>
            </div>
        </dd>
        <dt><a name="item183">[183]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02670"
                    title="Abstract">arXiv:2405.02670</a> [<a href="/pdf/2405.02670" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02670" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> From Generalization Analysis to Optimization Designs for
                    State Space Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+F">Fusheng Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qianxiao Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">A State Space Model (SSM) is a foundation model in time series analysis,
                    which has recently been shown as an alternative to transformers in sequence
                    modeling. In this paper, we theoretically study the generalization of SSMs and
                    propose improvements to training algorithms based on the generalization
                    results. Specifically, we give a \textit{data-dependent} generalization bound
                    for SSMs, showing an interplay between the SSM parameters and the temporal
                    dependencies of the training sequences. Leveraging the generalization bound, we
                    (1) set up a scaling rule for model initialization based on the proposed
                    generalization measure, which significantly improves the robustness of the
                    output value scales on SSMs to different temporal patterns in the sequence
                    data; (2) introduce a new regularization method for training SSMs to enhance
                    the generalization performance. Numerical results are conducted to validate our
                    results.
                </p>
            </div>
        </dd>
        <dt><a name="item184">[184]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02672"
                    title="Abstract">arXiv:2405.02672</a> [<a href="/pdf/2405.02672" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02672" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Effects of Realism and Representation on Self-Embodied
                    Avatars in Immersive Virtual Environments
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Anjos%2C+R+K+d">Rafael Kuffner dos Anjos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pereira%2C+J+M">João Madeiras Pereira</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Graphics (cs.GR)

                </div>
                <p class="mathjax">Virtual Reality (VR) has recently gained traction with many new and ever more
                    affordable devices being released. The increase in popularity of this paradigm
                    of interaction has given birth to new applications and has attracted casual
                    consumers to experience VR. Providing a self-embodied representation (avatar)
                    of users' full bodies inside shared virtual spaces can improve the VR
                    experience and make it more engaging to both new and experienced users . This
                    is especially important in fully immersive systems, where the equipment
                    completely occludes the real world making self awareness problematic. Indeed,
                    the feeling of presence of the user is highly influenced by their virtual
                    representations, even though small flaws could lead to uncanny valley
                    side-effects. Following previous research, we would like to assess whether
                    using a third-person perspective could also benefit the VR experience, via an
                    improved spatial awareness of the user's virtual surroundings. In this paper we
                    investigate realism and perspective of self-embodied representation in VR
                    setups in natural tasks, such as walking and avoiding obstacles. We compare
                    both First and Third-Person perspectives with three different levels of realism
                    in avatar representation. These range from a stylized abstract avatar, to a
                    "realistic" mesh-based humanoid representation and a point-cloud rendering. The
                    latter uses data captured via depth-sensors and mapped into a virtual self
                    inside the Virtual Environment. We present a throughout evaluation and
                    comparison of these different representations, describing a series of
                    guidelines for self-embodied VR applications. The effects of the uncanny valley
                    are also discussed in the context of navigation and reflex-based tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item185">[185]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02673"
                    title="Abstract">arXiv:2405.02673</a> [<a href="/pdf/2405.02673" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02673" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the Information Redundancy in Non-Autoregressive
                    Translation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhihao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Longyue Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+J">Jinsong Su</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+J">Junfeng Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tu%2C+Z">Zhaopeng Tu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 10 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Token repetition is a typical form of multi-modal problem in fully
                    non-autoregressive translation (NAT). In this work, we revisit the multi-modal
                    problem in recently proposed NAT models. Our study reveals that these advanced
                    models have introduced other types of information redundancy errors, which
                    cannot be measured by the conventional metric - the continuous repetition
                    ratio. By manually annotating the NAT outputs, we identify two types of
                    information redundancy errors that correspond well to lexical and reordering
                    multi-modality problems. Since human annotation is time-consuming and
                    labor-intensive, we propose automatic metrics to evaluate the two types of
                    redundant errors. Our metrics allow future studies to evaluate new methods and
                    gain a more comprehensive understanding of their effectiveness.
                </p>
            </div>
        </dd>
        <dt><a name="item186">[186]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02675"
                    title="Abstract">arXiv:2405.02675</a> [<a href="/pdf/2405.02675" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02675" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Quranic Audio Dataset: Crowdsourced and Labeled Recitation
                    from Non-Arabic Speakers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Salameh%2C+R">Raghad Salameh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mdfaa%2C+M+A">Mohamad Al Mdfaa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Askarbekuly%2C+N">Nursultan Askarbekuly</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mazzara%2C+M">Manuel Mazzara</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">This paper addresses the challenge of learning to recite the Quran for
                    non-Arabic speakers. We explore the possibility of crowdsourcing a carefully
                    annotated Quranic dataset, on top of which AI models can be built to simplify
                    the learning process. In particular, we use the volunteer-based crowdsourcing
                    genre and implement a crowdsourcing API to gather audio assets. We integrated
                    the API into an existing mobile application called NamazApp to collect audio
                    recitations. We developed a crowdsourcing platform called Quran Voice for
                    annotating the gathered audio assets. As a result, we have collected around
                    7000 Quranic recitations from a pool of 1287 participants across more than 11
                    non-Arabic countries, and we have annotated 1166 recitations from the dataset
                    in six categories. We have achieved a crowd accuracy of 0.77, an inter-rater
                    agreement of 0.63 between the annotators, and 0.89 between the labels assigned
                    by the algorithm and the expert judgments.
                </p>
            </div>
        </dd>
        <dt><a name="item187">[187]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02676"
                    title="Abstract">arXiv:2405.02676</a> [<a href="/pdf/2405.02676" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02676" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Hand-Object Interaction Controller (HOIC): Deep Reinforcement
                    Learning for Reconstructing Interactions with Physics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Haoyu Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yi%2C+X">Xinyu Yi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+Z">Zhe Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yong%2C+J">Jun-Hai Yong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+F">Feng Xu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> SIGGRAPH 2024 Conference Track
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
                <p class="mathjax">Hand manipulating objects is an important interaction motion in our daily
                    activities. We faithfully reconstruct this motion with a single RGBD camera by
                    a novel deep reinforcement learning method to leverage physics. Firstly, we
                    propose object compensation control which establishes direct object control to
                    make the network training more stable. Meanwhile, by leveraging the
                    compensation force and torque, we seamlessly upgrade the simple point contact
                    model to a more physical-plausible surface contact model, further improving the
                    reconstruction accuracy and physical correctness. Experiments indicate that
                    without involving any heuristic physical rules, this work still successfully
                    involves physics in the reconstruction of hand-object interactions which are
                    complex motions hard to imitate with deep reinforcement learning. Our code and
                    data are available at https://github.com/hu-hy17/HOIC.
                </p>
            </div>
        </dd>
        <dt><a name="item188">[188]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02677"
                    title="Abstract">arXiv:2405.02677</a> [<a href="/pdf/2405.02677" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02677" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Evaluating the Ability of Computationally Extracted Narrative
                    Maps to Encode Media Framing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mac%C3%ADas%2C+S+C">Sebastián Concha Macías</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Norambuena%2C+B+K">Brian Keith Norambuena</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Text2Story Workshop 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Information Retrieval (cs.IR)

                </div>
                <p class="mathjax">Narratives serve as fundamental frameworks in our understanding of the world
                    and play a crucial role in collaborative sensemaking, providing a versatile
                    foundation for sensemaking. Framing is a subtle yet potent mechanism that
                    influences public perception through specific word choices, shaping
                    interpretations of reported news events. Despite the recognized importance of
                    narratives and framing, a significant gap exists in the literature with regard
                    to the explicit consideration of framing within the context of computational
                    extraction and representation. This article explores the capabilities of a
                    specific narrative extraction and representation approach -- narrative maps --
                    to capture framing information from news data. The research addresses two key
                    questions: (1) Does the narrative extraction method capture the framing
                    distribution of the data set? (2) Does it produce a representation with
                    consistent framing? Our results indicate that while the algorithm captures
                    framing distributions, achieving consistent framing across various starting and
                    ending events poses challenges. Our results highlight the potential of
                    narrative maps to provide users with insights into the intricate framing
                    dynamics within news narratives. However, we note that directly leveraging
                    framing information in the computational narrative extraction process remains
                    an open challenge.
                </p>
            </div>
        </dd>
        <dt><a name="item189">[189]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02678"
                    title="Abstract">arXiv:2405.02678</a> [<a href="/pdf/2405.02678" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02678" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Position Paper: Quo Vadis, Unsupervised Time Series Anomaly
                    Detection?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sarfraz%2C+M+S">M. Saquib Sarfraz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Mei-Yen Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Layer%2C+L">Lukas Layer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+K">Kunyu Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Koulakis%2C+M">Marios Koulakis</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">The current state of machine learning scholarship in Timeseries Anomaly
                    Detection (TAD) is plagued by the persistent use of flawed evaluation metrics,
                    inconsistent benchmarking practices, and a lack of proper justification for the
                    choices made in novel deep learning-based model designs. Our paper presents a
                    critical analysis of the status quo in TAD, revealing the misleading track of
                    current research and highlighting problematic methods, and evaluation
                    practices. Our position advocates for a shift in focus from pursuing only the
                    novelty in model design to improving benchmarking practices, creating
                    non-trivial datasets, and placing renewed emphasis on studying the utility of
                    model architectures for specific tasks. Our findings demonstrate the need for
                    rigorous evaluation protocols, the creation of simple baselines, and the
                    revelation that state-of-the-art deep anomaly detection models effectively
                    learn linear mappings. These findings suggest the need for more exploration and
                    development of simple and interpretable TAD methods. The increment of model
                    complexity in the state-of-the-art deep-learning based models unfortunately
                    offers very little improvement. We offer insights and suggestions for the field
                    to move forward.
                </p>
            </div>
        </dd>
        <dt><a name="item190">[190]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02681"
                    title="Abstract">arXiv:2405.02681</a> [<a href="/pdf/2405.02681" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02681" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spider RIS: Mobilizing Intelligent Surfaces for Enhanced
                    Wireless Communications
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yildirim%2C+I">Ibrahim Yildirim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mahmood%2C+M">Mobeen Mahmood</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Basar%2C+E">Ertugrul Basar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Le-Ngoc%2C+T">Tho Le-Ngoc</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in 2024 EuCNC and 6G Summit, Antwerp, Belgium,
                    3-6 June 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">In this study, we introduce Spider RIS technology, which offers an innovative
                    solution to the challenges encountered in movable antennas (MAs) and unmanned
                    aerial vehicle (UAV)-enabled communication systems. By combining the dynamic
                    adaptation capability of MAs and the flexible location advantages of UAVs, this
                    technology offers a dynamic and movable RIS, which can flexibly optimize
                    physical locations within the two-dimensional movement platform. Spider RIS
                    aims to enhance the communication efficiency and reliability of wireless
                    networks, particularly in obstructive environments, by elevating the signal
                    quality and achievable rate. The motivation of Spider RIS is based on the
                    ability to fully exploit the spatial variability of wireless channels and
                    maximize channel capacity even with a limited number of reflecting elements by
                    overcoming the limitations of traditional fixed RIS and energy-intensive UAV
                    systems. Considering the geometry-based millimeter wave channel model, we
                    present the design of a three-stage angular-based hybrid beamforming system
                    empowered by Spider RIS: First, analog beamformers are designed using angular
                    information, followed by the generation of digital precoder/combiner based on
                    the effective channel observed from baseband stage. Subsequently, the joint
                    dynamic positioning with phase shift design of the Spider RIS is optimized
                    using particle swarm optimization, maximizing the achievable rate of the
                    systems.
                </p>
            </div>
        </dd>
        <dt><a name="item191">[191]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02682"
                    title="Abstract">arXiv:2405.02682</a> [<a href="/pdf/2405.02682" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02682" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deduplicator: When Computation Reuse Meets Load Balancing at
                    the Network Edge
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Azad%2C+M+W+A">Md Washik Al Azad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mastorakis%2C+S">Spyridon Mastorakis</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for publication by IFIP Networking 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

                </div>
                <p class="mathjax">Load balancing has been a fundamental building block of cloud and, more
                    recently, edge computing environments. At the same time, in edge computing
                    environments, prior research has highlighted that applications operate on
                    similar (correlated) data. Based on this observation, prior research has
                    advocated for the direction of "computation reuse", where the results of
                    previously executed computational tasks are stored at the edge and are reused
                    (if possible) to satisfy incoming tasks with similar input data, instead of
                    executing incoming tasks from scratch. Both load balancing and computation
                    reuse are critical to the deployment of scalable edge computing environments,
                    yet they are contradictory in nature. In this paper, we propose the
                    Deduplicator, a middlebox that aims to facilitate both load balancing and
                    computation reuse at the edge. The Deduplicator features mechanisms to identify
                    and deduplicate similar tasks offloaded by user devices, collect information
                    about the usage of edge servers' resources, manage the addition of new edge
                    servers and the failures of existing edge servers, and ultimately balance the
                    load imposed on edge servers. Our evaluation results demonstrate that the
                    Deduplicator achieves up to 20% higher percentages of computation reuse
                    compared to several other load balancing approaches, while also effectively
                    balancing the distribution of tasks among edge servers at line rate.
                </p>
            </div>
        </dd>
        <dt><a name="item192">[192]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02683"
                    title="Abstract">arXiv:2405.02683</a> [<a href="/pdf/2405.02683" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02683" title="Download PostScript">ps</a>, <a href="/format/2405.02683"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Two-Dimensional Multi-Access Coded Caching with Multiple
                    Transmit Antennas
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Namboodiri%2C+K+K+K">K. K. Krishnan Namboodiri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peter%2C+E">Elizabath Peter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rajan%2C+B+S">B. Sundar Rajan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> A shorter version is accepted for presentation in ISIT
                    2024. 8 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">This work introduces a multi-antenna coded caching problem in a
                    two-dimensional multi-access network, where a server with <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-77-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-528"
                                style="width: 0.871em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.64em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-529"><span class="mi" id="MathJax-Span-530"
                                                style="font-family: MathJax_Math-italic;">L</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-77">L</script> transmit antennas
                    and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-78-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-531"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-532"><span class="mi" id="MathJax-Span-533"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-78">N</script> files communicates to <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-79-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-534"
                                style="width: 3.07em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.549em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1002.55em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-535"><span class="msubsup"
                                                id="MathJax-Span-536"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-537"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-538"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-539"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-540"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-541"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-79">K_1K_2</script> users, each with a single receive
                    antenna, through a wireless broadcast link. The network consists of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-80-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-542"
                                style="width: 3.07em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.549em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1002.55em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-543"><span class="msubsup"
                                                id="MathJax-Span-544"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-545"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-546"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-547"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-548"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-549"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-80">K_1K_2</script>
                    cache nodes and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-81-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-550"
                                style="width: 3.07em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.549em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1002.55em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-551"><span class="msubsup"
                                                id="MathJax-Span-552"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-553"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-554"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-555"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-556"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-557"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-81">K_1K_2</script> users. The cache nodes, each with
                    capacity <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-82-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-558"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1001.04em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-559"><span class="mi" id="MathJax-Span-560"
                                                style="font-family: MathJax_Math-italic;">M<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-82">M</script>, are
                    placed on a rectangular grid with <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-83-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-561"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.28em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-562"><span class="msubsup"
                                                id="MathJax-Span-563"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-564"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-565"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-83">K_1</script> rows and <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-84-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-566"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.28em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-567"><span class="msubsup"
                                                id="MathJax-Span-568"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-569"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-570"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-84">K_2</script> columns, and the users
                    are placed regularly on the square grid such that a user can access <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-85-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-571"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.87em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-572"><span class="msubsup"
                                                id="MathJax-Span-573"><span
                                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-574"
                                                            style="font-family: MathJax_Math-italic;">r</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.466em;"><span
                                                            class="mn" id="MathJax-Span-575"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-85">r^2</script>
                    neighbouring caches in a cyclic wrap-around fashion. For a given cache memory
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-86-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-576"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1001.04em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-577"><span class="mi" id="MathJax-Span-578"
                                                style="font-family: MathJax_Math-italic;">M<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-86">M</script>, the goal of the coded caching problem is
                    to serve the user demands with a
                    minimum delivery time. We propose a solution for the aforementioned coded
                    caching problem by designing two arrays: a caching array and a delivery array.
                    Further, we present two classes of caching and delivery arrays and obtain
                    corresponding multi-access coded caching schemes. The first scheme achieves a
                    normalized delivery time (NDT)
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-87-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-579"
                                style="width: 6.137em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.095em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.634em, 1005.1em, 2.086em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-580"><span class="mfrac"
                                                id="MathJax-Span-581"><span
                                                    style="display: inline-block; position: relative; width: 4.864em; height: 0px; margin-right: 0.119em; margin-left: 0.119em;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1004.69em, 4.517em, -999.997em); top: -4.742em; left: 50%; margin-left: -2.37em;"><span
                                                            class="mrow" id="MathJax-Span-582"><span class="msubsup"
                                                                id="MathJax-Span-583"><span
                                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-584"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">K<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -3.874em; left: 0.582em;"><span
                                                                            class="mn" id="MathJax-Span-585"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">1</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="msubsup" id="MathJax-Span-586"><span
                                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-587"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">K<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -3.874em; left: 0.582em;"><span
                                                                            class="mn" id="MathJax-Span-588"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">2</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="mo" id="MathJax-Span-589"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span
                                                                class="mn" id="MathJax-Span-590"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                class="mo" id="MathJax-Span-591"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                class="msubsup" id="MathJax-Span-592"><span
                                                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.533em, 1000.29em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-593"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">r</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -4.222em; left: 0.35em;"><span
                                                                            class="mn" id="MathJax-Span-594"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">2</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="mfrac" id="MathJax-Span-595"><span
                                                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; margin-right: 0.119em; margin-left: 0.119em;"><span
                                                                        style="position: absolute; clip: rect(3.475em, 1000.52em, 4.17em, -999.997em); top: -4.337em; left: 50%; margin-left: -0.286em;"><span
                                                                            class="mi" id="MathJax-Span-596"
                                                                            style="font-size: 50%; font-family: MathJax_Math-italic;">M<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(3.475em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.229em;"><span
                                                                            class="mi" id="MathJax-Span-597"
                                                                            style="font-size: 50%; font-family: MathJax_Math-italic;">N<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(0.871em, 1000.64em, 1.276em, -999.997em); top: -1.27em; left: 0em;"><span
                                                                            style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.639em; height: 0px;"></span><span
                                                                            style="display: inline-block; width: 0px; height: 1.102em;"></span></span></span></span><span
                                                                class="mo" id="MathJax-Span-598"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.128em, 1003.71em, 4.517em, -999.997em); top: -3.411em; left: 50%; margin-left: -1.849em;"><span
                                                            class="mrow" id="MathJax-Span-599"><span class="mi"
                                                                id="MathJax-Span-600"
                                                                style="font-size: 70.7%; font-family: MathJax_Math-italic;">L</span><span
                                                                class="mo" id="MathJax-Span-601"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span
                                                                class="msubsup" id="MathJax-Span-602"><span
                                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-603"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">K<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -3.874em; left: 0.582em;"><span
                                                                            class="mn" id="MathJax-Span-604"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">1</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="msubsup" id="MathJax-Span-605"><span
                                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-606"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">K<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -3.874em; left: 0.582em;"><span
                                                                            class="mn" id="MathJax-Span-607"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">2</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="mfrac" id="MathJax-Span-608"><span
                                                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; margin-right: 0.119em; margin-left: 0.119em;"><span
                                                                        style="position: absolute; clip: rect(3.475em, 1000.52em, 4.17em, -999.997em); top: -4.337em; left: 50%; margin-left: -0.286em;"><span
                                                                            class="mi" id="MathJax-Span-609"
                                                                            style="font-size: 50%; font-family: MathJax_Math-italic;">M<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(3.475em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.229em;"><span
                                                                            class="mi" id="MathJax-Span-610"
                                                                            style="font-size: 50%; font-family: MathJax_Math-italic;">N<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(0.871em, 1000.64em, 1.276em, -999.997em); top: -1.27em; left: 0em;"><span
                                                                            style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.639em; height: 0px;"></span><span
                                                                            style="display: inline-block; width: 0px; height: 1.102em;"></span></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(0.871em, 1004.86em, 1.276em, -999.997em); top: -1.328em; left: 0em;"><span
                                                            style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 4.864em; height: 0px;"></span><span
                                                            style="display: inline-block; width: 0px; height: 1.102em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -1.177em; border-left: 0px solid; width: 0px; height: 2.99em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex"
                        id="MathJax-Element-87">\frac{K_1K_2(1-r^2\frac{M}{N})}{L+K_1K_2\frac{M}{N}}</script>. The
                    second scheme
                    achieves an NDT <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-88-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-611"
                                style="width: 6.137em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.095em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.634em, 1005.1em, 2.086em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-612"><span class="mfrac"
                                                id="MathJax-Span-613"><span
                                                    style="display: inline-block; position: relative; width: 4.864em; height: 0px; margin-right: 0.119em; margin-left: 0.119em;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1004.69em, 4.517em, -999.997em); top: -4.742em; left: 50%; margin-left: -2.37em;"><span
                                                            class="mrow" id="MathJax-Span-614"><span class="msubsup"
                                                                id="MathJax-Span-615"><span
                                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-616"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">K<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -3.874em; left: 0.582em;"><span
                                                                            class="mn" id="MathJax-Span-617"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">1</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="msubsup" id="MathJax-Span-618"><span
                                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-619"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">K<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -3.874em; left: 0.582em;"><span
                                                                            class="mn" id="MathJax-Span-620"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">2</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="mo" id="MathJax-Span-621"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span
                                                                class="mn" id="MathJax-Span-622"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                class="mo" id="MathJax-Span-623"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                class="msubsup" id="MathJax-Span-624"><span
                                                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.533em, 1000.29em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-625"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">r</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -4.222em; left: 0.35em;"><span
                                                                            class="mn" id="MathJax-Span-626"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">2</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="mfrac" id="MathJax-Span-627"><span
                                                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; margin-right: 0.119em; margin-left: 0.119em;"><span
                                                                        style="position: absolute; clip: rect(3.475em, 1000.52em, 4.17em, -999.997em); top: -4.337em; left: 50%; margin-left: -0.286em;"><span
                                                                            class="mi" id="MathJax-Span-628"
                                                                            style="font-size: 50%; font-family: MathJax_Math-italic;">M<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(3.475em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.229em;"><span
                                                                            class="mi" id="MathJax-Span-629"
                                                                            style="font-size: 50%; font-family: MathJax_Math-italic;">N<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(0.871em, 1000.64em, 1.276em, -999.997em); top: -1.27em; left: 0em;"><span
                                                                            style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.639em; height: 0px;"></span><span
                                                                            style="display: inline-block; width: 0px; height: 1.102em;"></span></span></span></span><span
                                                                class="mo" id="MathJax-Span-630"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.128em, 1004.34em, 4.517em, -999.997em); top: -3.411em; left: 50%; margin-left: -2.196em;"><span
                                                            class="mrow" id="MathJax-Span-631"><span class="mi"
                                                                id="MathJax-Span-632"
                                                                style="font-size: 70.7%; font-family: MathJax_Math-italic;">L</span><span
                                                                class="mo" id="MathJax-Span-633"
                                                                style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span
                                                                class="msubsup" id="MathJax-Span-634"><span
                                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-635"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">K<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -3.874em; left: 0.582em;"><span
                                                                            class="mn" id="MathJax-Span-636"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">1</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="msubsup" id="MathJax-Span-637"><span
                                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-638"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">K<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -3.874em; left: 0.582em;"><span
                                                                            class="mn" id="MathJax-Span-639"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">2</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="msubsup" id="MathJax-Span-640"><span
                                                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px;"><span
                                                                        style="position: absolute; clip: rect(3.533em, 1000.29em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                            class="mi" id="MathJax-Span-641"
                                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">r</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; top: -4.222em; left: 0.35em;"><span
                                                                            class="mn" id="MathJax-Span-642"
                                                                            style="font-size: 50%; font-family: MathJax_Main;">2</span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                class="mfrac" id="MathJax-Span-643"><span
                                                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; margin-right: 0.119em; margin-left: 0.119em;"><span
                                                                        style="position: absolute; clip: rect(3.475em, 1000.52em, 4.17em, -999.997em); top: -4.337em; left: 50%; margin-left: -0.286em;"><span
                                                                            class="mi" id="MathJax-Span-644"
                                                                            style="font-size: 50%; font-family: MathJax_Math-italic;">M<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(3.475em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.229em;"><span
                                                                            class="mi" id="MathJax-Span-645"
                                                                            style="font-size: 50%; font-family: MathJax_Math-italic;">N<span
                                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                        style="position: absolute; clip: rect(0.871em, 1000.64em, 1.276em, -999.997em); top: -1.27em; left: 0em;"><span
                                                                            style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 0.639em; height: 0px;"></span><span
                                                                            style="display: inline-block; width: 0px; height: 1.102em;"></span></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(0.871em, 1004.86em, 1.276em, -999.997em); top: -1.328em; left: 0em;"><span
                                                            style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 4.864em; height: 0px;"></span><span
                                                            style="display: inline-block; width: 0px; height: 1.102em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -1.177em; border-left: 0px solid; width: 0px; height: 2.99em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex"
                        id="MathJax-Element-88">\frac{K_1K_2(1-r^2\frac{M}{N})}{L+K_1K_2r^2\frac{M}{N}}</script> when
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-89-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-646"
                                style="width: 8.799em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 7.295em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1007.29em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-647"><span class="mi" id="MathJax-Span-648"
                                                style="font-family: MathJax_Math-italic;">M<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="texatom" id="MathJax-Span-649"><span class="mrow"
                                                    id="MathJax-Span-650"><span class="mo" id="MathJax-Span-651"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="mi" id="MathJax-Span-652"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="mo" id="MathJax-Span-653"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mn" id="MathJax-Span-654"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">1</span><span
                                                class="texatom" id="MathJax-Span-655"><span class="mrow"
                                                    id="MathJax-Span-656"><span class="mo" id="MathJax-Span-657"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="msubsup" id="MathJax-Span-658"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-659"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-660"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-661"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-662"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-663"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-89">M/N=1/K_1K_2</script> and <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-90-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-664"
                                style="width: 8.105em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.716em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1006.72em, 2.549em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-665"><span class="mi" id="MathJax-Span-666"
                                                style="font-family: MathJax_Math-italic;">L</span><span class="mo"
                                                id="MathJax-Span-667"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="msubsup" id="MathJax-Span-668"
                                                style="padding-left: 0.292em;"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-669"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-670"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-671"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-672"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-673"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-674"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="msubsup" id="MathJax-Span-675"
                                                style="padding-left: 0.234em;"><span
                                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-676"
                                                            style="font-family: MathJax_Math-italic;">r</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.466em;"><span
                                                            class="mn" id="MathJax-Span-677"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-90">L=K_1K_2-r^2</script>, which is optimal under
                    uncoded placement and
                    one-shot delivery.
                </p>
            </div>
        </dd>
        <dt><a name="item193">[193]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02685"
                    title="Abstract">arXiv:2405.02685</a> [<a href="/pdf/2405.02685" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02685" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FedProK: Trustworthy Federated Class-Incremental Learning via
                    Prototypical Feature Knowledge Transfer
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+X">Xin Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xin Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Hao Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kang%2C+Y">Yan Kang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+T">Tianrui Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

                </div>
                <p class="mathjax">Federated Class-Incremental Learning (FCIL) focuses on continually
                    transferring the previous knowledge to learn new classes in dynamic Federated
                    Learning (FL). However, existing methods do not consider the trustworthiness of
                    FCIL, i.e., improving continual utility, privacy, and efficiency
                    simultaneously, which is greatly influenced by catastrophic forgetting and data
                    heterogeneity among clients. To address this issue, we propose FedProK
                    (Federated Prototypical Feature Knowledge Transfer), leveraging prototypical
                    feature as a novel representation of knowledge to perform spatial-temporal
                    knowledge transfer. Specifically, FedProK consists of two components: (1)
                    feature translation procedure on the client side by temporal knowledge transfer
                    from the learned classes and (2) prototypical knowledge fusion on the server
                    side by spatial knowledge transfer among clients. Extensive experiments
                    conducted in both synchronous and asynchronous settings demonstrate that our
                    FedProK outperforms the other state-of-the-art methods in three perspectives of
                    trustworthiness, validating its effectiveness in selectively transferring
                    spatial-temporal knowledge.
                </p>
            </div>
        </dd>
        <dt><a name="item194">[194]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02686"
                    title="Abstract">arXiv:2405.02686</a> [<a href="/pdf/2405.02686" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02686" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Boosting 3D Neuron Segmentation with 2D Vision Transformer
                    Pre-trained on Natural Images
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Y+S">Yik San Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+R">Runkai Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Heng Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+H">Hanchuan Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+W">Weidong Cai</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 3 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Neuron reconstruction, one of the fundamental tasks in neuroscience, rebuilds
                    neuronal morphology from 3D light microscope imaging data. It plays a critical
                    role in analyzing the structure-function relationship of neurons in the nervous
                    system. However, due to the scarcity of neuron datasets and high-quality SWC
                    annotations, it is still challenging to develop robust segmentation methods for
                    single neuron reconstruction. To address this limitation, we aim to distill the
                    consensus knowledge from massive natural image data to aid the segmentation
                    model in learning the complex neuron structures. Specifically, in this work, we
                    propose a novel training paradigm that leverages a 2D Vision Transformer model
                    pre-trained on large-scale natural images to initialize our Transformer-based
                    3D neuron segmentation model with a tailored 2D-to-3D weight transferring
                    strategy. Our method builds a knowledge sharing connection between the abundant
                    natural and the scarce neuron image domains to improve the 3D neuron
                    segmentation ability in a data-efficiency manner. Evaluated on a popular
                    benchmark, BigNeuron, our method enhances neuron segmentation performance by
                    8.71% over the model trained from scratch with the same amount of training
                    samples.
                </p>
            </div>
        </dd>
        <dt><a name="item195">[195]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02687"
                    title="Abstract">arXiv:2405.02687</a> [<a href="/pdf/2405.02687" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02687" title="Download PostScript">ps</a>, <a href="/format/2405.02687"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Placement Delivery Arrays for Coded Caching with Shared and
                    Private Caches
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Namboodiri%2C+K+K+K">K. K. Krishnan Namboodiri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peter%2C+E">Elizabath Peter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rajan%2C+B+S">B. Sundar Rajan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> A shorter version is accepted for presentation in ISIT
                    2024. 11 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">We consider a coded caching network consisting of a server with a library of
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-91-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-678"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-679"><span class="mi" id="MathJax-Span-680"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-91">N</script> files connected to <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-92-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-681"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-682"><span class="mi" id="MathJax-Span-683"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-92">K</script> users, where each user is equipped with a
                    dedicated
                    cache of size <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-93-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-684"
                                style="width: 1.681em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.39em, 1.45em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-685"><span class="msubsup"
                                                id="MathJax-Span-686"><span
                                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.04em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-687"
                                                            style="font-family: MathJax_Math-italic;">M<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.987em;"><span
                                                            class="mi" id="MathJax-Span-688"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-93">M_p</script> units. In addition to that, the network
                    consists of
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-94-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-689"
                                style="width: 3.591em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.954em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.95em, 2.433em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-690"><span class="mi" id="MathJax-Span-691"
                                                style="font-family: MathJax_Main;">Λ</span><span class="mo"
                                                id="MathJax-Span-692"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≤</span><span
                                                class="mi" id="MathJax-Span-693"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-94">\Lambda\leq K</script> helper caches, each with a
                    size <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-95-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-694"
                                style="width: 1.739em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.45em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-695"><span class="msubsup"
                                                id="MathJax-Span-696"><span
                                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.04em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-697"
                                                            style="font-family: MathJax_Math-italic;">M<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.987em;"><span
                                                            class="mi" id="MathJax-Span-698"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-95">M_h</script> units. Each helper cache
                    can serve an arbitrary number of users; however, each user can access only a
                    single helper cache. Also, we assume that the server knows the user-to-helper
                    cache association, defined as the sets of users connected to each helper cache,
                    during the cache placement phase. We propose a solution for the aforementioned
                    coded caching problem by introducing a combinatorial structure called a Shared
                    and Private Placement Delivery Array (SP-PDA). These SP-PDAs describe the
                    helper cache placement, private cache placement, and the server transmissions
                    in a single array. Further, we propose a novel construction of SP-PDAs using
                    two Placement Delivery Arrays (PDAs). Interestingly, we observe that the
                    permutations of the columns of the two chosen PDAs result in SP-PDAs with
                    different performances. Moreover, we characterize the conditions for selecting
                    the best column permutations of the chosen PDAs. Furthermore, the coded caching
                    schemes resulting from SP-PDAs subsume two existing coded caching schemes as
                    special cases. Additionally, SP-PDAs enable the construction of coded caching
                    schemes with much smaller subpacketization numbers -subpacketization number is
                    defined as the number of subfiles to which a file is divided- compared to the
                    existing schemes, without paying much in terms of rate (the size of the
                    transmission in the delivery phase).
                </p>
            </div>
        </dd>
        <dt><a name="item196">[196]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02688"
                    title="Abstract">arXiv:2405.02688</a> [<a href="/pdf/2405.02688" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02688" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Semi-supervised Symmetric Matrix Factorization with Low-Rank
                    Tensor Representation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jia%2C+Y">Yuheng Jia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jia-Nan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+W">Wenhui Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+R">Ran Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Semi-supervised symmetric non-negative matrix factorization (SNMF) utilizes
                    the available supervisory information (usually in the form of pairwise
                    constraints) to improve the clustering ability of SNMF. The previous methods
                    introduce the pairwise constraints from the local perspective, i.e., they
                    either directly refine the similarity matrix element-wisely or restrain the
                    distance of the decomposed vectors in pairs according to the pairwise
                    constraints, which overlook the global perspective, i.e., in the ideal case,
                    the pairwise constraint matrix and the ideal similarity matrix possess the same
                    low-rank structure. To this end, we first propose a novel semi-supervised SNMF
                    model by seeking low-rank representation for the tensor synthesized by the
                    pairwise constraint matrix and a similarity matrix obtained by the product of
                    the embedding matrix and its transpose, which could strengthen those two
                    matrices simultaneously from a global perspective. We then propose an enhanced
                    SNMF model, making the embedding matrix tailored to the above tensor low-rank
                    representation. We finally refine the similarity matrix by the strengthened
                    pairwise constraints. We repeat the above steps to continuously boost the
                    similarity matrix and pairwise constraint matrix, leading to a high-quality
                    embedding matrix. Extensive experiments substantiate the superiority of our
                    method. The code is available at https://github.com/JinaLeejnl/TSNMF.
                </p>
            </div>
        </dd>
        <dt><a name="item197">[197]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02692"
                    title="Abstract">arXiv:2405.02692</a> [<a href="/pdf/2405.02692" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02692" title="Download PostScript">ps</a>, <a href="/format/2405.02692"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Diffeomorphic Transformer-based Abdomen MRI-CT Deformable
                    Image Registration
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lei%2C+Y">Yang Lei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matkovic%2C+L+A">Luke A. Matkovic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roper%2C+J">Justin Roper</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tonghe Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jun Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghavidel%2C+B">Beth Ghavidel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McDonald%2C+M">Mark McDonald</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Patel%2C+P">Pretesh Patel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiaofeng Yang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages and 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Medical Physics (physics.med-ph)

                </div>
                <p class="mathjax">This paper aims to create a deep learning framework that can estimate the
                    deformation vector field (DVF) for directly registering abdominal MRI-CT
                    images. The proposed method assumed a diffeomorphic deformation. By using
                    topology-preserved deformation features extracted from the probabilistic
                    diffeomorphic registration model, abdominal motion can be accurately obtained
                    and utilized for DVF estimation. The model integrated Swin transformers, which
                    have demonstrated superior performance in motion tracking, into the
                    convolutional neural network (CNN) for deformation feature extraction. The
                    model was optimized using a cross-modality image similarity loss and a surface
                    matching loss. To compute the image loss, a modality-independent neighborhood
                    descriptor (MIND) was used between the deformed MRI and CT images. The surface
                    matching loss was determined by measuring the distance between the warped
                    coordinates of the surfaces of contoured structures on the MRI and CT images.
                    The deformed MRI image was assessed against the CT image using the target
                    registration error (TRE), Dice similarity coefficient (DSC), and mean surface
                    distance (MSD) between the deformed contours of the MRI image and manual
                    contours of the CT image. When compared to only rigid registration, DIR with
                    the proposed method resulted in an increase of the mean DSC values of the liver
                    and portal vein from 0.850 and 0.628 to 0.903 and 0.763, a decrease of the mean
                    MSD of the liver from 7.216 mm to 3.232 mm, and a decrease of the TRE from
                    26.238 mm to 8.492 mm. The proposed deformable image registration method based
                    on a diffeomorphic transformer provides an effective and efficient way to
                    generate an accurate DVF from an MRI-CT image pair of the abdomen. It could be
                    utilized in the current treatment planning workflow for liver radiotherapy.
                </p>
            </div>
        </dd>
        <dt><a name="item198">[198]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02693"
                    title="Abstract">arXiv:2405.02693</a> [<a href="/pdf/2405.02693" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02693" title="Download PostScript">ps</a>, <a href="/format/2405.02693"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TV White Space and LTE Network Optimization towards Energy
                    Efficiency in Suburban and Rural Scenarios
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Alonso%2C+R+M">Rodney Martinez Alonso</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Plets%2C+D">David Plets</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deruyck%2C+M">Margot Deruyck</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Martens%2C+L">Luc Martens</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Joseph%2C+W">Wout Joseph</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> IEEE Transactions on Broadcasting, vol. 64, no. 1, pp.
                    164-171,
                    2018
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">The radio spectrum is a limited resource. Demand for wireless communication
                    services is increasing exponentially, stressing the availability of radio
                    spectrum to accommodate new services. TV White Space (TVWS) technologies allow
                    a dynamic usage of the spectrum. These technologies provide wireless
                    connectivity, in the channels of the Very High Frequency (VHF) and Ultra High
                    Frequency (UHF) television broadcasting bands. In this paper, we investigate
                    and compare the coverage range, network capacity, and network energy efficiency
                    for TVWS technologies and LTE. We consider Ghent, Belgium and Boyeros, Havana,
                    Cuba to evaluate a realistic outdoor suburban and rural area, respectively. The
                    comparison shows that TVWS networks have an energy efficiency 9-12 times higher
                    than LTE networks.
                </p>
            </div>
        </dd>
        <dt><a name="item199">[199]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02694"
                    title="Abstract">arXiv:2405.02694</a> [<a href="/pdf/2405.02694" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02694" title="Download PostScript">ps</a>, <a href="/format/2405.02694"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multi-objective Optimization of Cognitive Radio Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Alonso%2C+R+M">Rodney Martinez Alonso</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Plets%2C+D">David Plets</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deruyck%2C+M">Margot Deruyck</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Martens%2C+L">Luc Martens</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nieto%2C+G+G">Glauco Guillen Nieto</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Joseph%2C+W">Wout Joseph</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Computer Networks, Volume 184, 2021
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>

                </div>
                <p class="mathjax">New generation networks, based on Cognitive Radio technology, allow dynamic
                    allocation of the spectrum, alleviating spectrum scarcity. These networks also
                    have a resilient potential for dynamic operation for energy saving. In this
                    paper, we present a novel wireless network optimization algorithm for cognitive
                    radio networks based on a cloud sharing-decision mechanism. Three Key
                    Performance Indicators (KPIs) were optimized: spectrum usage, power
                    consumption, and exposure of human beings. For a realistic suburban scenario in
                    Ghent city, Belgium, we determine the optimality among the KPIs. Compared to a
                    traditional Cognitive Radio network design, our optimization algorithm for the
                    cloud-based architecture reduced the network power consumption by 27.5%, the
                    average global exposure by 34.3%, and spectrum usage by 34.5% at the same time.
                    Even for the worst optimization case, our solution performs better than the
                    traditional architecture by 4.8% in terms of network power consumption, 7.3% in
                    terms of spectrum usage and 4.3% in terms of global exposure.
                </p>
            </div>
        </dd>
        <dt><a name="item200">[200]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02695"
                    title="Abstract">arXiv:2405.02695</a> [<a href="/pdf/2405.02695" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02695" title="Download PostScript">ps</a>, <a href="/format/2405.02695"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improved All-Pairs Approximate Shortest Paths in Congested
                    Clique
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bui%2C+H+D">Hong Duc Bui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chandra%2C+S">Shashwat Chandra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+Y">Yi-Jun Chang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dory%2C+M">Michal Dory</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Leitersdorf%2C+D">Dean Leitersdorf</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">In this paper, we present new algorithms for approximating All-Pairs Shortest
                    Paths (APSP) in the Congested Clique model. We present randomized algorithms
                    for weighted undirected graphs.
                    <br>Our first contribution is an <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-96-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-699"
                                style="width: 2.433em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.028em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.91em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-700"><span class="mi" id="MathJax-Span-701"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-702" style="font-family: MathJax_Main;">(</span><span
                                                class="mn" id="MathJax-Span-703"
                                                style="font-family: MathJax_Main;">1</span><span class="mo"
                                                id="MathJax-Span-704"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-96">O(1)</script>-approximate APSP algorithm taking just
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-97-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-705"
                                style="width: 7.815em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.484em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1006.37em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-706"><span class="mi" id="MathJax-Span-707"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-708" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-709"
                                                style="font-family: MathJax_Main;">log</span><span class="mo"
                                                id="MathJax-Span-710"></span><span class="mi" id="MathJax-Span-711"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">log</span><span
                                                class="mo" id="MathJax-Span-712"></span><span class="mi"
                                                id="MathJax-Span-713"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">log</span><span
                                                class="mo" id="MathJax-Span-714"></span><span class="mi"
                                                id="MathJax-Span-715"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="mo" id="MathJax-Span-716"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-97">O(\log \log \log n)</script> rounds. Prior to our
                    work, the fastest algorithms that
                    give an <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-98-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-717"
                                style="width: 2.433em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.028em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.91em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-718"><span class="mi" id="MathJax-Span-719"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-720" style="font-family: MathJax_Main;">(</span><span
                                                class="mn" id="MathJax-Span-721"
                                                style="font-family: MathJax_Main;">1</span><span class="mo"
                                                id="MathJax-Span-722"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-98">O(1)</script>-approximation for APSP take <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-99-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-723"
                                style="width: 5.674em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.69em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1004.58em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-724"><span class="mi" id="MathJax-Span-725"
                                                style="font-family: MathJax_Main;">poly</span><span class="mo"
                                                id="MathJax-Span-726"></span><span class="mo" id="MathJax-Span-727"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-728" style="font-family: MathJax_Main;">log</span><span
                                                class="mo" id="MathJax-Span-729"></span><span class="texatom"
                                                id="MathJax-Span-730" style="padding-left: 0.177em;"><span class="mrow"
                                                    id="MathJax-Span-731"><span class="mi" id="MathJax-Span-732"
                                                        style="font-family: MathJax_Math-italic;">n</span></span></span><span
                                                class="mo" id="MathJax-Span-733"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-99">\operatorname{poly}(\log{n})</script>
                    rounds in weighted undirected graphs, and <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-100-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-734"
                                style="width: 7.41em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.137em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1006.02em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-735"><span class="mi" id="MathJax-Span-736"
                                                style="font-family: MathJax_Main;">poly</span><span class="mo"
                                                id="MathJax-Span-737"></span><span class="mo" id="MathJax-Span-738"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-739" style="font-family: MathJax_Main;">log</span><span
                                                class="mo" id="MathJax-Span-740"></span><span class="mi"
                                                id="MathJax-Span-741"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">log</span><span
                                                class="mo" id="MathJax-Span-742"></span><span class="mi"
                                                id="MathJax-Span-743"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="mo" id="MathJax-Span-744"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-100">\operatorname{poly}(\log \log n)</script>
                    rounds in unweighted undirected graphs.
                    <br>If we terminate the execution of the algorithm early, we obtain an
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-101-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-745"
                                style="width: 2.318em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.913em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.8em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-746"><span class="mi" id="MathJax-Span-747"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-748" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-749"
                                                style="font-family: MathJax_Math-italic;">t</span><span class="mo"
                                                id="MathJax-Span-750"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-101">O(t)</script>-round algorithm that yields an <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-102-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-751"
                                style="width: 7.063em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.848em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1005.67em, 2.781em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-752"><span class="mi" id="MathJax-Span-753"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="texatom"
                                                id="MathJax-Span-754" style=""><span class="mrow"
                                                    id="MathJax-Span-755"><span class="mo" id="MathJax-Span-756"
                                                        style="vertical-align: 0em;"><span
                                                            style="font-family: MathJax_Size1;">(</span></span></span></span><span
                                                class="mo" id="MathJax-Span-757"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-758" style="font-family: MathJax_Main;">log</span><span
                                                class="mo" id="MathJax-Span-759"></span><span class="mi"
                                                id="MathJax-Span-760"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="msubsup" id="MathJax-Span-761"><span
                                                    style="display: inline-block; position: relative; width: 1.739em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.07em, 1000.29em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mo" id="MathJax-Span-762"
                                                            style="font-family: MathJax_Main;">)</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="texatom" id="MathJax-Span-763"><span class="mrow"
                                                                id="MathJax-Span-764"><span class="mn"
                                                                    id="MathJax-Span-765"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                    class="texatom" id="MathJax-Span-766"><span
                                                                        class="mrow" id="MathJax-Span-767"><span
                                                                            class="mo" id="MathJax-Span-768"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="msubsup" id="MathJax-Span-769"><span
                                                                        style="display: inline-block; position: relative; width: 0.582em; height: 0px;"><span
                                                                            style="position: absolute; clip: rect(3.359em, 1000.29em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                                class="mn" id="MathJax-Span-770"
                                                                                style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                            style="position: absolute; top: -4.28em; left: 0.35em;"><span
                                                                                class="mi" id="MathJax-Span-771"
                                                                                style="font-size: 50%; font-family: MathJax_Math-italic;">t</span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="texatom" id="MathJax-Span-772" style=""><span class="mrow"
                                                    id="MathJax-Span-773"><span class="mo" id="MathJax-Span-774"
                                                        style="vertical-align: 0em;"><span
                                                            style="font-family: MathJax_Size1;">)</span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.74em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-102">O \big( (\log n)^{1/2^t} \big) </script>
                    distance approximation for a parameter <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-103-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-775"
                                style="width: 0.466em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.35em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1000.29em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-776"><span class="mi" id="MathJax-Span-777"
                                                style="font-family: MathJax_Math-italic;">t</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-103">t</script>. The trade-off between <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-104-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-778"
                                style="width: 0.466em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.35em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1000.29em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-779"><span class="mi" id="MathJax-Span-780"
                                                style="font-family: MathJax_Math-italic;">t</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-104">t</script> and the
                    approximation quality provides flexibility for different scenarios, allowing
                    the algorithm to adapt to specific requirements. In particular, we can get an
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-105-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-781"
                                style="width: 7.063em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.848em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1005.67em, 2.781em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-782"><span class="mi" id="MathJax-Span-783"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="texatom"
                                                id="MathJax-Span-784" style=""><span class="mrow"
                                                    id="MathJax-Span-785"><span class="mo" id="MathJax-Span-786"
                                                        style="vertical-align: 0em;"><span
                                                            style="font-family: MathJax_Size1;">(</span></span></span></span><span
                                                class="mo" id="MathJax-Span-787"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-788" style="font-family: MathJax_Main;">log</span><span
                                                class="mo" id="MathJax-Span-789"></span><span class="mi"
                                                id="MathJax-Span-790"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="msubsup" id="MathJax-Span-791"><span
                                                    style="display: inline-block; position: relative; width: 1.739em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.07em, 1000.29em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mo" id="MathJax-Span-792"
                                                            style="font-family: MathJax_Main;">)</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="texatom" id="MathJax-Span-793"><span class="mrow"
                                                                id="MathJax-Span-794"><span class="mn"
                                                                    id="MathJax-Span-795"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                    class="texatom" id="MathJax-Span-796"><span
                                                                        class="mrow" id="MathJax-Span-797"><span
                                                                            class="mo" id="MathJax-Span-798"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="msubsup" id="MathJax-Span-799"><span
                                                                        style="display: inline-block; position: relative; width: 0.582em; height: 0px;"><span
                                                                            style="position: absolute; clip: rect(3.359em, 1000.29em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                                class="mn" id="MathJax-Span-800"
                                                                                style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                            style="position: absolute; top: -4.28em; left: 0.35em;"><span
                                                                                class="mi" id="MathJax-Span-801"
                                                                                style="font-size: 50%; font-family: MathJax_Math-italic;">t</span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="texatom" id="MathJax-Span-802" style=""><span class="mrow"
                                                    id="MathJax-Span-803"><span class="mo" id="MathJax-Span-804"
                                                        style="vertical-align: 0em;"><span
                                                            style="font-family: MathJax_Size1;">)</span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.74em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-105">O \big( (\log n)^{1/2^t} \big) </script>
                    -approximation for any constant <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-106-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-805"
                                style="width: 0.466em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.35em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1000.29em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-806"><span class="mi" id="MathJax-Span-807"
                                                style="font-family: MathJax_Math-italic;">t</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-106">t</script> in
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-107-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-808"
                                style="width: 2.433em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.028em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.91em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-809"><span class="mi" id="MathJax-Span-810"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-811" style="font-family: MathJax_Main;">(</span><span
                                                class="mn" id="MathJax-Span-812"
                                                style="font-family: MathJax_Main;">1</span><span class="mo"
                                                id="MathJax-Span-813"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-107">O(1)</script>-rounds. Such result was previously
                    known only for the special case that
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-108-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-814"
                                style="width: 2.665em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.202em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.14em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-815"><span class="mi" id="MathJax-Span-816"
                                                style="font-family: MathJax_Math-italic;">t</span><span class="mo"
                                                id="MathJax-Span-817"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mn" id="MathJax-Span-818"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">0</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-108">t=0</script>.
                    <br>A key ingredient in our algorithm is a lemma that allows to improve an
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-109-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-819"
                                style="width: 2.549em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.97em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-820"><span class="mi" id="MathJax-Span-821"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-822" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-823"
                                                style="font-family: MathJax_Math-italic;">a</span><span class="mo"
                                                id="MathJax-Span-824"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-109">O(a)</script>-approximation for APSP to an <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-110-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-825"
                                style="width: 3.591em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.954em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.84em, 2.607em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-826"><span class="mi" id="MathJax-Span-827"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-828" style="font-family: MathJax_Main;">(</span><span
                                                class="msqrt" id="MathJax-Span-829"><span
                                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.52em, 4.17em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                            class="mrow" id="MathJax-Span-830"><span class="mi"
                                                                id="MathJax-Span-831"
                                                                style="font-family: MathJax_Math-italic;">a</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1000.58em, 3.938em, -999.997em); top: -4.395em; left: 0.813em;"><span
                                                            style="display: inline-block; position: relative; width: 0.582em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.113em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -3.932em; left: 0em;"><span
                                                            style="font-family: MathJax_Main;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-832"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-110">O(\sqrt{a})</script>-approximation for APSP in
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-111-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-833"
                                style="width: 2.433em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.028em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.91em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-834"><span class="mi" id="MathJax-Span-835"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-836" style="font-family: MathJax_Main;">(</span><span
                                                class="mn" id="MathJax-Span-837"
                                                style="font-family: MathJax_Main;">1</span><span class="mo"
                                                id="MathJax-Span-838"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-111">O(1)</script> rounds. To prove the lemma, we
                    develop several new tools, including
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-112-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-839"
                                style="width: 2.433em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.028em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.91em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-840"><span class="mi" id="MathJax-Span-841"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-842" style="font-family: MathJax_Main;">(</span><span
                                                class="mn" id="MathJax-Span-843"
                                                style="font-family: MathJax_Main;">1</span><span class="mo"
                                                id="MathJax-Span-844"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-112">O(1)</script>-round algorithms for computing the
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-113-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-845"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-846"><span class="mi" id="MathJax-Span-847"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-113">k</script> closest nodes, a certain type of
                    hopset, and skeleton graphs.
                </p>
            </div>
        </dd>
        <dt><a name="item201">[201]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02696"
                    title="Abstract">arXiv:2405.02696</a> [<a href="/pdf/2405.02696" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02696" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DiffuseTrace: A Transparent and Flexible Watermarking Scheme
                    for Latent Diffusion Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lei%2C+L">Liangqi Lei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gai%2C+K">Keke Gai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jing Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+L">Liehuang Zhu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Latent Diffusion Models (LDMs) enable a wide range of applications but raise
                    ethical concerns regarding illegal utilization.Adding watermarks to generative
                    model outputs is a vital technique employed for copyright tracking and
                    mitigating potential risks associated with AI-generated content. However,
                    post-hoc watermarking techniques are susceptible to evasion. Existing
                    watermarking methods for LDMs can only embed fixed messages. Watermark message
                    alteration requires model retraining. The stability of the watermark is
                    influenced by model updates and iterations. Furthermore, the current
                    reconstruction-based watermark removal techniques utilizing variational
                    autoencoders (VAE) and diffusion models have the capability to remove a
                    significant portion of watermarks. Therefore, we propose a novel technique
                    called DiffuseTrace. The goal is to embed invisible watermarks in all generated
                    images for future detection semantically. The method establishes a unified
                    representation of the initial latent variables and the watermark information
                    through training an encoder-decoder model. The watermark information is
                    embedded into the initial latent variables through the encoder and integrated
                    into the sampling process. The watermark information is extracted by reversing
                    the diffusion process and utilizing the decoder. DiffuseTrace does not rely on
                    fine-tuning of the diffusion model components. The watermark is embedded into
                    the image space semantically without compromising image quality. The
                    encoder-decoder can be utilized as a plug-in in arbitrary diffusion models. We
                    validate through experiments the effectiveness and flexibility of DiffuseTrace.
                    DiffuseTrace holds an unprecedented advantage in combating the latest attacks
                    based on variational autoencoders and Diffusion Models.
                </p>
            </div>
        </dd>
        <dt><a name="item202">[202]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02698"
                    title="Abstract">arXiv:2405.02698</a> [<a href="/pdf/2405.02698" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02698" title="Download PostScript">ps</a>, <a href="/format/2405.02698"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Stable Diffusion Dataset Generation for Downstream
                    Classification Tasks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lomurno%2C+E">Eugenio Lomurno</a>,
                    <a href="/search/cs?searchtype=author&amp;query=D%27Oria%2C+M">Matteo D'Oria</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matteucci%2C+M">Matteo Matteucci</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Recent advances in generative artificial intelligence have enabled the
                    creation of high-quality synthetic data that closely mimics real-world data.
                    This paper explores the adaptation of the Stable Diffusion 2.0 model for
                    generating synthetic datasets, using Transfer Learning, Fine-Tuning and
                    generation parameter optimisation techniques to improve the utility of the
                    dataset for downstream classification tasks. We present a class-conditional
                    version of the model that exploits a Class-Encoder and optimisation of key
                    generation parameters. Our methodology led to synthetic datasets that, in a
                    third of cases, produced models that outperformed those trained on real
                    datasets.
                </p>
            </div>
        </dd>
        <dt><a name="item203">[203]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02699"
                    title="Abstract">arXiv:2405.02699</a> [<a href="/pdf/2405.02699" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02699" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Platform Competition in the Autobidding World
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Aggarwal%2C+G">Gagan Aggarwal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Perlroth%2C+A">Andres Perlroth</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schvartzman%2C+A">Ariel Schvartzman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+M">Mingfei Zhao</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>

                </div>
                <p class="mathjax">We study the problem of auction design for advertising platforms that face
                    strategic advertisers who are bidding across platforms. Each advertiser's goal
                    is to maximize their total value or conversions while satisfying some
                    constraint(s) across all the platforms they participates in. In this paper, we
                    focus on advertisers with return-over-investment (henceforth, ROI) constraints,
                    i.e. each advertiser is trying to maximize value while making sure that their
                    ROI across all platforms is no less than some target value. An advertiser
                    interacts with the platforms through autobidders -- for each platform, the
                    advertiser strategically chooses a target ROI to report to the platform's
                    autobidder, which in turn uses a uniform bid multiplier to bid on the
                    advertiser's behalf on the queries owned by the given platform.
                    <br>Our main result is that for a platform trying to maximize revenue,
                    competition with other platforms is a key factor to consider when designing
                    their auction. While first-price auctions are optimal (for both revenue and
                    welfare) in the absence of competition, this no longer holds true in
                    multi-platform settings. We show that there exists a large class of advertiser
                    valuations over queries such that, from the platform's perspective, running a
                    second price auction dominates running a first price auction.
                    <br>Furthermore, our analysis reveals the key factors influencing platform choice
                    of auction format: (i) intensity of competition among advertisers, (ii)
                    sensitivity of bid landscapes to an auction change (driven by advertiser
                    sensitivity to price changes), and (iii) relative inefficiency of second-price
                    auctions compared to first-price auctions.
                </p>
            </div>
        </dd>
        <dt><a name="item204">[204]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02700"
                    title="Abstract">arXiv:2405.02700</a> [<a href="/pdf/2405.02700" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02700" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards a Scalable Identification of Novel Modes in
                    Generative Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jingwei Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jalali%2C+M">Mohammad Jalali</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C+T">Cheuk Ting Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Farnia%2C+F">Farzan Farnia</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">An interpretable comparison of generative models requires the identification
                    of sample types produced more frequently by each of the involved models. While
                    several quantitative scores have been proposed in the literature to rank
                    different generative models, such score-based evaluations do not reveal the
                    nuanced differences between the generative models in capturing various sample
                    types. In this work, we propose a method called Fourier-based Identification of
                    Novel Clusters (FINC) to identify modes produced by a generative model with a
                    higher frequency in comparison to a reference distribution. FINC provides a
                    scalable stochastic algorithm based on random Fourier features to estimate the
                    eigenspace of kernel covariance matrices of two generative models and utilize
                    the principal eigendirections to detect the sample types present more
                    dominantly in each model. We demonstrate the application of the FINC method to
                    standard computer vision datasets and generative model frameworks. Our
                    numerical results suggest the scalability and efficiency of the developed
                    Fourier-based method in highlighting the sample types captured with different
                    frequencies by widely-used generative models.
                </p>
            </div>
        </dd>
        <dt><a name="item205">[205]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02703"
                    title="Abstract">arXiv:2405.02703</a> [<a href="/pdf/2405.02703" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02703" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Machine Learning Data Practices through a Data Curation Lens:
                    An Evaluation Framework
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bhardwaj%2C+E">Eshta Bhardwaj</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gujral%2C+H">Harshit Gujral</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S">Siyi Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zogheib%2C+C">Ciara Zogheib</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Maharaj%2C+T">Tegan Maharaj</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Becker%2C+C">Christoph Becker</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> In ACM Conference on Fairness, Accountability, and
                    Transparency 2024. ACM, Rio de Janeiro, Brazil
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>

                </div>
                <p class="mathjax">Studies of dataset development in machine learning call for greater attention
                    to the data practices that make model development possible and shape its
                    outcomes. Many argue that the adoption of theory and practices from archives
                    and data curation fields can support greater fairness, accountability,
                    transparency, and more ethical machine learning. In response, this paper
                    examines data practices in machine learning dataset development through the
                    lens of data curation. We evaluate data practices in machine learning as data
                    curation practices. To do so, we develop a framework for evaluating machine
                    learning datasets using data curation concepts and principles through a rubric.
                    Through a mixed-methods analysis of evaluation results for 25 ML datasets, we
                    study the feasibility of data curation principles to be adopted for machine
                    learning data work in practice and explore how data curation is currently
                    performed. We find that researchers in machine learning, which often emphasizes
                    model development, struggle to apply standard data curation principles. Our
                    findings illustrate difficulties at the intersection of these fields, such as
                    evaluating dimensions that have shared terms in both fields but non-shared
                    meanings, a high degree of interpretative flexibility in adapting concepts
                    without prescriptive restrictions, obstacles in limiting the depth of data
                    curation expertise needed to apply the rubric, and challenges in scoping the
                    extent of documentation dataset creators are responsible for. We propose ways
                    to address these challenges and develop an overall framework for evaluation
                    that outlines how data curation concepts and methods can inform machine
                    learning data practices.
                </p>
            </div>
        </dd>
        <dt><a name="item206">[206]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02705"
                    title="Abstract">arXiv:2405.02705</a> [<a href="/pdf/2405.02705" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02705" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Peak Age of Information under Tandem of Queues
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sinha%2C+A">Ashirwad Sinha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singhvi%2C+S">Shubhransh Singhvi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mankar%2C+P+D">Praful D. Mankar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dhillon%2C+H+S">Harpreet S. Dhillon</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at IEEE ISIT'24
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">This paper considers a communication system where a source sends
                    time-sensitive information to its destination via queues in tandem. We assume
                    that the arrival process as well as the service process (of each server) are
                    memoryless, and each of the servers has no buffer. For this setup, we develop a
                    recursive framework to characterize the mean peak age of information (PAoI)
                    under preemptive and non-preemptive policies with <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-114-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-848"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-849"><span class="mi" id="MathJax-Span-850"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-114">N</script> servers having different
                    service rates. For the preemptive case, the proposed framework also allows to
                    obtain mean age of information (AoI).
                </p>
            </div>
        </dd>
        <dt><a name="item207">[207]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02710"
                    title="Abstract">arXiv:2405.02710</a> [<a href="/pdf/2405.02710" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02710" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing News Summarization with ELearnFit through Efficient
                    In-Context Learning and Efficient Fine-Tuning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Guan%2C+C">Che Guan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chin%2C+A">Andrew Chin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vahabi%2C+P">Puya Vahabi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 Pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">With the deluge of information delivered by the daily news cycle, there is a
                    growing need to effectively and efficiently summarize news feeds for quick
                    consumption. We leverage large language models (LLMs), with their advanced
                    learning and generative abilities as compared to conventional language models,
                    to generate concise and coherent summaries for news articles from the XSum
                    dataset. Our paper focuses on two key aspects of LLMs: Efficient in-context
                    Learning (ELearn) and Parameter Efficient Fine-tuning (EFit). Under ELearn, we
                    find that increasing the number of shots in prompts and utilizing simple
                    templates generally improve the quality of summaries. We also find that
                    utilizing relevant examples in few-shot learning for ELearn does not improve
                    model performance. In addition, we studied EFit using different methods and
                    demonstrate that fine-tuning the first layer of LLMs produces better outcomes
                    as compared to fine-tuning other layers or utilizing LoRA. We also find that
                    leveraging more relevant training samples using selective layers does not
                    result in better performance. By combining ELearn and EFit, we create a new
                    model (ELearnFit) that leverages the benefits of both few-shot learning and
                    fine-tuning and produces superior performance to either model alone. We also
                    use ELearnFit to highlight the trade-offs between prompting and fine-tuning,
                    especially for situations where only a limited number of annotated samples are
                    available. Ultimately, our research provides practical techniques to optimize
                    news summarization during the prompting and fine-tuning stages and enhances the
                    synthesis of news articles.
                </p>
            </div>
        </dd>
        <dt><a name="item208">[208]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02711"
                    title="Abstract">arXiv:2405.02711</a> [<a href="/pdf/2405.02711" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02711" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Role of AI in Peer Support for Young People: A Study of
                    Preferences for Human- and AI-Generated Responses
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Young%2C+J">Jordyn Young</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jawara%2C+L+M">Laala M Jawara</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+D+N">Diep N Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Daly%2C+B">Brian Daly</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huh-Yoo%2C+J">Jina Huh-Yoo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Razi%2C+A">Afsaneh Razi</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Proceedings of the CHI Conference on Human Factors in
                    Computing
                    Systems 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Generative Artificial Intelligence (AI) is integrated into everyday
                    technology, including news, education, and social media. AI has further
                    pervaded private conversations as conversational partners, auto-completion, and
                    response suggestions. As social media becomes young people's main method of
                    peer support exchange, we need to understand when and how AI can facilitate and
                    assist in such exchanges in a beneficial, safe, and socially appropriate way.
                    We asked 622 young people to complete an online survey and evaluate blinded
                    human- and AI-generated responses to help-seeking messages. We found that
                    participants preferred the AI-generated response to situations about
                    relationships, self-expression, and physical health. However, when addressing a
                    sensitive topic, like suicidal thoughts, young people preferred the human
                    response. We also discuss the role of training in online peer support exchange
                    and its implications for supporting young people's well-being. Disclaimer: This
                    paper includes sensitive topics, including suicide ideation. Reader discretion
                    is advised.
                </p>
            </div>
        </dd>
        <dt><a name="item209">[209]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02712"
                    title="Abstract">arXiv:2405.02712</a> [<a href="/pdf/2405.02712" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02712" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CoE-SQL: In-Context Learning for Multi-Turn Text-to-SQL with
                    Chain-of-Editions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hanchong Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+R">Ruisheng Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hongshen Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Lu Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+K">Kai Yu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Recently, Large Language Models (LLMs) have been demonstrated to possess
                    impressive capabilities in a variety of domains and tasks. We investigate the
                    issue of prompt design in the multi-turn text-to-SQL task and attempt to
                    enhance the LLMs' reasoning capacity when generating SQL queries. In the
                    conversational context, the current SQL query can be modified from the
                    preceding SQL query with only a few operations due to the context dependency.
                    We introduce our method called CoE-SQL which can prompt LLMs to generate the
                    SQL query based on the previously generated SQL query with an edition chain. We
                    also conduct extensive ablation studies to determine the optimal configuration
                    of our approach. Our approach outperforms different in-context learning
                    baselines stably and achieves state-of-the-art performances on two benchmarks
                    SParC and CoSQL using LLMs, which is also competitive to the SOTA fine-tuned
                    models.
                </p>
            </div>
        </dd>
        <dt><a name="item210">[210]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02713"
                    title="Abstract">arXiv:2405.02713</a> [<a href="/pdf/2405.02713" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02713" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Set Transformation: Trade-off Between Repair Bandwidth and
                    Sub-packetization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+H">Hao Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhengyi Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhongyi Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bai%2C+B">Bo Bai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Gong Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hou%2C+H">Hanxu Hou</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">Maximum distance separable (MDS) codes facilitate the achievement of elevated
                    levels of fault tolerance in storage systems while incurring minimal redundancy
                    overhead. Reed-Solomon (RS) codes are typical MDS codes with the
                    sub-packetization level being one, however, they require large repair bandwidth
                    defined as the total amount of symbols downloaded from other surviving nodes
                    during single-node failure/repair. In this paper, we present the {\em set
                    transformation}, which can transform any MDS code into set transformed code
                    such that (i) the sub-packetization level is flexible and ranges from 2 to
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-115-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-851"
                                style="width: 6.195em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.153em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.929em, 1005.15em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-852"><span class="mo" id="MathJax-Span-853"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-854"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-855"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mi" id="MathJax-Span-856"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">k</span><span
                                                class="msubsup" id="MathJax-Span-857"><span
                                                    style="display: inline-block; position: relative; width: 2.376em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.07em, 1000.29em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mo" id="MathJax-Span-858"
                                                            style="font-family: MathJax_Main;">)</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.453em; left: 0.408em;"><span
                                                            class="texatom" id="MathJax-Span-859"><span class="mrow"
                                                                id="MathJax-Span-860"><span class="mo"
                                                                    id="MathJax-Span-861"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">⌊</span><span
                                                                    class="mfrac" id="MathJax-Span-862"><span
                                                                        style="display: inline-block; position: relative; width: 1.045em; height: 0px; margin-right: 0.119em; margin-left: 0.119em;"><span
                                                                            style="position: absolute; clip: rect(3.591em, 1000.29em, 4.17em, -999.997em); top: -4.337em; left: 50%; margin-left: -0.171em;"><span
                                                                                class="mi" id="MathJax-Span-863"
                                                                                style="font-size: 50%; font-family: MathJax_Math-italic;">n</span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                            style="position: absolute; clip: rect(3.475em, 1000.93em, 4.227em, -999.997em); top: -3.643em; left: 50%; margin-left: -0.46em;"><span
                                                                                class="mrow" id="MathJax-Span-864"><span
                                                                                    class="mi" id="MathJax-Span-865"
                                                                                    style="font-size: 50%; font-family: MathJax_Math-italic;">n</span><span
                                                                                    class="mo" id="MathJax-Span-866"
                                                                                    style="font-size: 50%; font-family: MathJax_Main;">−</span><span
                                                                                    class="mi" id="MathJax-Span-867"
                                                                                    style="font-size: 50%; font-family: MathJax_Math-italic;">k</span></span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                            style="position: absolute; clip: rect(0.871em, 1001.04em, 1.276em, -999.997em); top: -1.27em; left: 0em;"><span
                                                                                style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.3px solid; width: 1.045em; height: 0px;"></span><span
                                                                                style="display: inline-block; width: 0px; height: 1.102em;"></span></span></span></span><span
                                                                    class="mo" id="MathJax-Span-868"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">⌋</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.74em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-115">(n-k)^{\lfloor\frac{n}{n-k}\rfloor}</script> in
                    which <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-116-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-869"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-870"><span class="mi" id="MathJax-Span-871"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-116">n</script> is the number of nodes and
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-117-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-872"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-873"><span class="mi" id="MathJax-Span-874"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-117">k</script> is the number of data nodes, (ii) the
                    new code is MDS code, (iii) the new
                    code has lower repair bandwidth for any single-node failure. We show that our
                    set transformed codes have both lower repair bandwidth and lower field size
                    than the existing related MDS array codes, such as elastic transformed codes
                    \cite{10228984}. Specifically, our set transformed codes have <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-118-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-875"
                                style="width: 5.674em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.69em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.63em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-876"><span class="mn" id="MathJax-Span-877"
                                                style="font-family: MathJax_Main;">2</span><span class="mi"
                                                id="MathJax-Span-878" style="font-family: MathJax_Main;">%</span><span
                                                class="mo" id="MathJax-Span-879"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mn" id="MathJax-Span-880"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">6.6</span><span
                                                class="mi" id="MathJax-Span-881"
                                                style="font-family: MathJax_Main;">%</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-118">2\%-6.6\%</script>
                    repair bandwidth reduction compared with elastic transformed codes
                    \cite{10228984} for the evaluated typical parameters.
                </p>
            </div>
        </dd>
        <dt><a name="item211">[211]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02714"
                    title="Abstract">arXiv:2405.02714</a> [<a href="/pdf/2405.02714" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02714" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Beyond Relevance: Evaluate and Improve Retrievers on
                    Perspective Awareness
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xinran Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Sihao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongming Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+T">Tongshuang Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>; Computation and Language (cs.CL)

                </div>
                <p class="mathjax">The task of Information Retrieval (IR) requires a system to identify relevant
                    documents based on users' information needs. In real-world scenarios,
                    retrievers are expected to not only rely on the semantic relevance between the
                    documents and the queries but also recognize the nuanced intents or
                    perspectives behind a user query. For example, when asked to verify a claim, a
                    retrieval system is expected to identify evidence from both supporting vs.
                    contradicting perspectives, for the downstream system to make a fair judgment
                    call. In this work, we study whether retrievers can recognize and respond to
                    different perspectives of the queries -- beyond finding relevant documents for
                    a claim, can retrievers distinguish supporting vs. opposing documents? We
                    reform and extend six existing tasks to create a benchmark for retrieval, where
                    we have diverse perspectives described in free-form text, besides root, neutral
                    queries. We show that current retrievers covered in our experiments have
                    limited awareness of subtly different perspectives in queries and can also be
                    biased toward certain perspectives. Motivated by the observation, we further
                    explore the potential to leverage geometric features of retriever
                    representation space to improve the perspective awareness of retrievers in a
                    zero-shot manner. We demonstrate the efficiency and effectiveness of our
                    projection-based methods on the same set of tasks. Further analysis also shows
                    how perspective awareness improves performance on various downstream tasks,
                    with 4.2% higher accuracy on AmbigQA and 29.9% more correlation with designated
                    viewpoints on essay writing, compared to non-perspective-aware baselines.
                </p>
            </div>
        </dd>
        <dt><a name="item212">[212]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02716"
                    title="Abstract">arXiv:2405.02716</a> [<a href="/pdf/2405.02716" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02716" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Sign-Guided Bipartite Graph Hashing for Hamming Space Search
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xueyi Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">Bipartite graph hashing (BGH) is extensively used for Top-K search in Hamming
                    space at low storage and inference costs. Recent research adopts graph
                    convolutional hashing for BGH and has achieved the state-of-the-art
                    performance. However, the contributions of its various influencing factors to
                    hashing performance have not been explored in-depth, including the
                    same/different sign count between two binary embeddings during Hamming space
                    search (sign property), the contribution of sub-embeddings at each layer (model
                    property), the contribution of different node types in the bipartite graph
                    (node property), and the combination of augmentation methods. In this work, we
                    build a lightweight graph convolutional hashing model named LightGCH by mainly
                    removing the augmentation methods of the state-of-the-art model BGCH. By
                    analyzing the contributions of each layer and node type to performance, as well
                    as analyzing the Hamming similarity statistics at each layer, we find that the
                    actual neighbors in the bipartite graph tend to have low Hamming similarity at
                    the shallow layer, and all nodes tend to have high Hamming similarity at the
                    deep layers in LightGCH. To tackle these problems, we propose a novel
                    sign-guided framework SGBGH to make improvement, which uses sign-guided
                    negative sampling to improve the Hamming similarity of neighbors, and uses
                    sign-aware contrastive learning to help nodes learn more uniform
                    representations. Experimental results show that SGBGH outperforms BGCH and
                    LightGCH significantly in embedding quality.
                </p>
            </div>
        </dd>
        <dt><a name="item213">[213]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02717"
                    title="Abstract">arXiv:2405.02717</a> [<a href="/pdf/2405.02717" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02717" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AFter: Attention-based Fusion Router for RGBT Tracking
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+A">Andong Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wanyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chenglong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+J">Jin Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+B">Bin Luo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Peer review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Multi-modal feature fusion as a core investigative component of RGBT tracking
                    emerges numerous fusion studies in recent years. However, existing RGBT
                    tracking methods widely adopt fixed fusion structures to integrate multi-modal
                    feature, which are hard to handle various challenges in dynamic scenarios. To
                    address this problem, this work presents a novel \emph{A}ttention-based
                    \emph{F}usion rou\emph{ter} called AFter, which optimizes the fusion structure
                    to adapt to the dynamic challenging scenarios, for robust RGBT tracking. In
                    particular, we design a fusion structure space based on the hierarchical
                    attention network, each attention-based fusion unit corresponding to a fusion
                    operation and a combination of these attention units corresponding to a fusion
                    structure. Through optimizing the combination of attention-based fusion units,
                    we can dynamically select the fusion structure to adapt to various challenging
                    scenarios. Unlike complex search of different structures in neural architecture
                    search algorithms, we develop a dynamic routing algorithm, which equips each
                    attention-based fusion unit with a router, to predict the combination weights
                    for efficient optimization of the fusion structure. Extensive experiments on
                    five mainstream RGBT tracking datasets demonstrate the superior performance of
                    the proposed AFter against state-of-the-art RGBT trackers. We release the code
                    in https://github.com/Alexadlu/AFter.
                </p>
            </div>
        </dd>
        <dt><a name="item214">[214]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02719"
                    title="Abstract">arXiv:2405.02719</a> [<a href="/pdf/2405.02719" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02719" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Active Signal Emitter Placement In Complex Environments
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Denniston%2C+C+E">Christopher E. Denniston</a>,
                    <a href="/search/cs?searchtype=author&amp;query=%C5%9Eenba%C5%9Flar%2C+B">Baskın Şenbaşlar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sukhatme%2C+G+S">Gaurav S. Sukhatme</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to RA-L
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Placement of electromagnetic signal emitting devices, such as light sources,
                    has important usage in for signal coverage tasks. Automatic placement of these
                    devices is challenging because of the complex interaction of the signal and
                    environment due to reflection, refraction and scattering. In this work, we
                    iteratively improve the placement of these devices by interleaving device
                    placement and sensing actions, correcting errors in the model of the signal
                    propagation. To this end, we propose a novel factor-graph based belief model
                    which combines the measurements taken by the robot and an analytical light
                    propagation model. This model allows accurately modelling the uncertainty of
                    the light propagation with respect to the obstacles, which greatly improves the
                    informative path planning routine. Additionally, we propose a method for
                    determining when to re-plan the emitter placements to balance a trade-off
                    between information about a specific configuration and frequent updating of the
                    configuration. This method incorporates the uncertainty from belief model to
                    adaptively determine when re-configuration is needed. We find that our system
                    has a 9.8% median error reduction compared to a baseline system in simulations
                    in the most difficult environment. We also run on-robot tests and determine
                    that our system performs favorably compared to the baseline.
                </p>
            </div>
        </dd>
        <dt><a name="item215">[215]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02724"
                    title="Abstract">arXiv:2405.02724</a> [<a href="/pdf/2405.02724" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02724" title="Download PostScript">ps</a>, <a href="/format/2405.02724"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Taming Equilibrium Bias in Risk-Sensitive Multi-Agent
                    Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fei%2C+Y">Yingjie Fei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Ruitu Xu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 29 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

                </div>
                <p class="mathjax">We study risk-sensitive multi-agent reinforcement learning under general-sum
                    Markov games, where agents optimize the entropic risk measure of rewards with
                    possibly diverse risk preferences. We show that using the regret naively
                    adapted from existing literature as a performance metric could induce policies
                    with equilibrium bias that favor the most risk-sensitive agents and overlook
                    the other agents. To address such deficiency of the naive regret, we propose a
                    novel notion of regret, which we call risk-balanced regret, and show through a
                    lower bound that it overcomes the issue of equilibrium bias. Furthermore, we
                    develop a self-play algorithm for learning Nash, correlated, and coarse
                    correlated equilibria in risk-sensitive Markov games. We prove that the
                    proposed algorithm attains near-optimal regret guarantees with respect to the
                    risk-balanced regret.
                </p>
            </div>
        </dd>
        <dt><a name="item216">[216]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02726"
                    title="Abstract">arXiv:2405.02726</a> [<a href="/pdf/2405.02726" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02726" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Mathematical Model of the Hidden Feedback Loop Effect in
                    Machine Learning Systems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Veprikov%2C+A">Andrey Veprikov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Afanasiev%2C+A">Alexander Afanasiev</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khritankov%2C+A">Anton Khritankov</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 21 pages, 15 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">Widespread deployment of societal-scale machine learning systems necessitates
                    a thorough understanding of the resulting long-term effects these systems have
                    on their environment, including loss of trustworthiness, bias amplification,
                    and violation of AI safety requirements. We introduce a repeated learning
                    process to jointly describe several phenomena attributed to unintended hidden
                    feedback loops, such as error amplification, induced concept drift, echo
                    chambers and others. The process comprises the entire cycle of obtaining the
                    data, training the predictive model, and delivering predictions to end-users
                    within a single mathematical model. A distinctive feature of such repeated
                    learning setting is that the state of the environment becomes causally
                    dependent on the learner itself over time, thus violating the usual assumptions
                    about the data distribution. We present a novel dynamical systems model of the
                    repeated learning process and prove the limiting set of probability
                    distributions for positive and negative feedback loop modes of the system
                    operation. We conduct a series of computational experiments using an exemplary
                    supervised learning problem on two synthetic data sets. The results of the
                    experiments correspond to the theoretical predictions derived from the
                    dynamical model. Our results demonstrate the feasibility of the proposed
                    approach for studying the repeated learning processes in machine learning
                    systems and open a range of opportunities for further research in the area.
                </p>
            </div>
        </dd>
        <dt><a name="item217">[217]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02727"
                    title="Abstract">arXiv:2405.02727</a> [<a href="/pdf/2405.02727" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02727" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Using finite automata to compute the base-<span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-119-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-882"
                                style="width: 0.512em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.419em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.113em, 1000.42em, 2.086em, -999.998em); top: -1.942em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-883"><span class="mi" id="MathJax-Span-884"
                                                style="font-family: MathJax_Math-italic;">b</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.947em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.947em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-119">b</script> representation of the golden ratio and
                    other quadratic irrationals
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Barnoff%2C+A">Aaron Barnoff</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bright%2C+C">Curtis Bright</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shallit%2C+J">Jeffrey Shallit</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and
                        Automata Theory (cs.FL)</span>; Discrete Mathematics (cs.DM); Number Theory (math.NT)

                </div>
                <p class="mathjax">We show that the <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-120-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-885"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-886"><span class="mi" id="MathJax-Span-887"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-120">n</script>'th digit of the base-<span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-121-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-888"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.41em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-889"><span class="mi" id="MathJax-Span-890"
                                                style="font-family: MathJax_Math-italic;">b</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-121">b</script> representation of the golden
                    ratio is a finite-state function of the Zeckendorf representation of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-122-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-891"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1000.93em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-892"><span class="msubsup"
                                                id="MathJax-Span-893"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-894"
                                                            style="font-family: MathJax_Math-italic;">b</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mi" id="MathJax-Span-895"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-122">b^n</script>, and
                    hence can be computed by a finite automaton. Similar results can be proven for
                    any quadratic irrational. We use a satisfiability (SAT) solver to prove, in
                    some cases, that the automata we construct are minimal.
                </p>
            </div>
        </dd>
        <dt><a name="item218">[218]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02730"
                    title="Abstract">arXiv:2405.02730</a> [<a href="/pdf/2405.02730" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02730" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yuchuan Tian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tu%2C+Z">Zhijun Tu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hanting Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Jie Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Chao Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yunhe Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Diffusion Transformers (DiTs) introduce the transformer architecture to
                    diffusion tasks for latent-space image generation. With an isotropic
                    architecture that chains a series of transformer blocks, DiTs demonstrate
                    competitive performance and good scalability; but meanwhile, the abandonment of
                    U-Net by DiTs and their following improvements is worth rethinking. To this
                    end, we conduct a simple toy experiment by comparing a U-Net architectured DiT
                    with an isotropic one. It turns out that the U-Net architecture only gain a
                    slight advantage amid the U-Net inductive bias, indicating potential
                    redundancies within the U-Net-style DiT. Inspired by the discovery that U-Net
                    backbone features are low-frequency-dominated, we perform token downsampling on
                    the query-key-value tuple for self-attention and bring further improvements
                    despite a considerable amount of reduction in computation. Based on
                    self-attention with downsampled tokens, we propose a series of U-shaped DiTs
                    (U-DiTs) in the paper and conduct extensive experiments to demonstrate the
                    extraordinary performance of U-DiT models. The proposed U-DiT could outperform
                    DiT-XL/2 with only 1/6 of its computation cost. Codes are available at
                    https://github.com/YuchuanTian/U-DiT.
                </p>
            </div>
        </dd>
        <dt><a name="item219">[219]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02731"
                    title="Abstract">arXiv:2405.02731</a> [<a href="/pdf/2405.02731" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02731" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Systematic Review: Anomaly Detection in Connected and
                    Autonomous Vehicles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Solaas%2C+J+R+V">J. R. V. Solaas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tuptuk%2C+N">N. Tuptuk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mariconti%2C+E">E. Mariconti</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 17 pages, 2 tables, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">This systematic review focuses on anomaly detection for connected and
                    autonomous vehicles. The initial database search identified 2160 articles, of
                    which 203 were included in this review after rigorous screening and assessment.
                    This study revealed that the most commonly used Artificial Intelligence (AI)
                    algorithms employed in anomaly detection are neural networks like LSTM, CNN,
                    and autoencoders, alongside one-class SVM. Most anomaly-based models were
                    trained using real-world operational vehicle data, although anomalies, such as
                    attacks and faults, were often injected artificially into the datasets. These
                    models were evaluated mostly using five key evaluation metrics: recall,
                    accuracy, precision, F1-score, and false positive rate. The most frequently
                    used selection of evaluation metrics used for anomaly detection models were
                    accuracy, precision, recall, and F1-score. This systematic review presents
                    several recommendations. First, there is a need to incorporate multiple
                    evaluation metrics to provide a comprehensive assessment of the anomaly
                    detection models. Second, only a small proportion of the studies have made
                    their models open source, indicating a need to share models publicly to
                    facilitate collaboration within the research community, and to validate and
                    compare findings effectively. Third, there is a need for benchmarking datasets
                    with predefined anomalies or cyberattacks to test and improve the effectiveness
                    of the proposed anomaly-based detection models. Furthermore, there is a need
                    for future research to investigate the deployment of anomaly detection to a
                    vehicle to assess its performance on the road. There is a notable lack of
                    research done on intrusion detection systems using different protocols to CAN,
                    such as Ethernet and FlexRay.
                </p>
            </div>
        </dd>
        <dt><a name="item220">[220]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02732"
                    title="Abstract">arXiv:2405.02732</a> [<a href="/pdf/2405.02732" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02732" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Recall Them All: Retrieval-Augmented Language Models for Long
                    Object List Extraction from Long Documents
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Singhania%2C+S">Sneha Singhania</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Razniewski%2C+S">Simon Razniewski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Weikum%2C+G">Gerhard Weikum</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Information Retrieval (cs.IR)

                </div>
                <p class="mathjax">Methods for relation extraction from text mostly focus on high precision, at
                    the cost of limited recall. High recall is crucial, though, to populate long
                    lists of object entities that stand in a specific relation with a given
                    subject. Cues for relevant objects can be spread across many passages in long
                    texts. This poses the challenge of extracting long lists from long texts. We
                    present the L3X method which tackles the problem in two stages: (1)
                    recall-oriented generation using a large language model (LLM) with judicious
                    techniques for retrieval augmentation, and (2) precision-oriented
                    scrutinization to validate or prune candidates. Our L3X method outperforms
                    LLM-only generations by a substantial margin.
                </p>
            </div>
        </dd>
        <dt><a name="item221">[221]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02734"
                    title="Abstract">arXiv:2405.02734</a> [<a href="/pdf/2405.02734" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02734" title="Download PostScript">ps</a>, <a href="/format/2405.02734"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Diagramming Technique for Teaching Students to Read
                    Software Engineering Research Papers: an experience report
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shaw%2C+M">Mary Shaw</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages, 6 figures, working paper
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">Reading scientific research papers is a skill that many students do not learn
                    before entering PhD programs, but it is critical to their success. This paper
                    describes our diagramming technique for teaching this skill, which helps them
                    identify the structure and the scientific argument of the paper. This has made
                    our students more effective readers.
                </p>
            </div>
        </dd>
        <dt><a name="item222">[222]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02738"
                    title="Abstract">arXiv:2405.02738</a> [<a href="/pdf/2405.02738" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02738" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Relations Prediction for Knowledge Graph Completion using
                    Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Alqaaidi%2C+S+K">Sakher Khalil Alqaaidi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kochut%2C+K">Krzysztof Kochut</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Knowledge Graphs have been widely used to represent facts in a structured
                    format. Due to their large scale applications, knowledge graphs suffer from
                    being incomplete. The relation prediction task obtains knowledge graph
                    completion by assigning one or more possible relations to each pair of nodes.
                    In this work, we make use of the knowledge graph node names to fine-tune a
                    large language model for the relation prediction task. By utilizing the node
                    names only we enable our model to operate sufficiently in the inductive
                    settings. Our experiments show that we accomplish new scores on a widely used
                    knowledge graph benchmark.
                </p>
            </div>
        </dd>
        <dt><a name="item223">[223]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02743"
                    title="Abstract">arXiv:2405.02743</a> [<a href="/pdf/2405.02743" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02743" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Beyond Performance: Quantifying and Mitigating Label Bias in
                    LLMs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Reif%2C+Y">Yuval Reif</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schwartz%2C+R">Roy Schwartz</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> NAACL 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Large language models (LLMs) have shown remarkable adaptability to diverse
                    tasks, by leveraging context prompts containing instructions, or minimal
                    input-output examples. However, recent work revealed they also exhibit label
                    bias -- an undesirable preference toward predicting certain answers over
                    others. Still, detecting and measuring this bias reliably and at scale has
                    remained relatively unexplored. In this study, we evaluate different approaches
                    to quantifying label bias in a model's predictions, conducting a comprehensive
                    investigation across 279 classification tasks and ten LLMs. Our investigation
                    reveals substantial label bias in models both before and after debiasing
                    attempts, as well as highlights the importance of outcomes-based evaluation
                    metrics, which were not previously used in this regard. We further propose a
                    novel label bias calibration method tailored for few-shot prompting, which
                    outperforms recent calibration approaches for both improving performance and
                    mitigating label bias. Our results emphasize that label bias in the predictions
                    of LLMs remains a barrier to their reliability.
                </p>
            </div>
        </dd>
        <dt><a name="item224">[224]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02745"
                    title="Abstract">arXiv:2405.02745</a> [<a href="/pdf/2405.02745" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02745" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Understanding Server-Assisted Federated Learning in the
                    Presence of Incomplete Client Participation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H">Haibo Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+P">Peiwen Qiu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khanduri%2C+P">Prashant Khanduri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+M">Minghong Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jia Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in ICML2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">Existing works in federated learning (FL) often assume an ideal system with
                    either full client or uniformly distributed client participation. However, in
                    practice, it has been observed that some clients may never participate in FL
                    training (aka incomplete client participation) due to a myriad of system
                    heterogeneity factors. A popular approach to mitigate impacts of incomplete
                    client participation is the server-assisted federated learning (SA-FL)
                    framework, where the server is equipped with an auxiliary dataset. However,
                    despite SA-FL has been empirically shown to be effective in addressing the
                    incomplete client participation problem, there remains a lack of theoretical
                    understanding for SA-FL. Meanwhile, the ramifications of incomplete client
                    participation in conventional FL are also poorly understood. These theoretical
                    gaps motivate us to rigorously investigate SA-FL. Toward this end, we first
                    show that conventional FL is {\em not} PAC-learnable under incomplete client
                    participation in the worst case. Then, we show that the PAC-learnability of FL
                    with incomplete client participation can indeed be revived by SA-FL, which
                    theoretically justifies the use of SA-FL for the first time. Lastly, to provide
                    practical guidance for SA-FL training under {\em incomplete client
                    participation}, we propose the <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-123-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-896"
                                style="width: 4.112em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.417em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1003.3em, 2.144em, -999.997em); top: -1.965em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-897"><span class="texatom"
                                                id="MathJax-Span-898"><span class="mrow" id="MathJax-Span-899"><span
                                                        class="mi" id="MathJax-Span-900"
                                                        style="font-family: MathJax_SansSerif;">S</span><span class="mi"
                                                        id="MathJax-Span-901"
                                                        style="font-family: MathJax_SansSerif;">A</span><span class="mi"
                                                        id="MathJax-Span-902"
                                                        style="font-family: MathJax_SansSerif;">F</span><span class="mi"
                                                        id="MathJax-Span-903"
                                                        style="font-family: MathJax_SansSerif;">A</span><span class="mi"
                                                        id="MathJax-Span-904"
                                                        style="font-family: MathJax_SansSerif;">R</span><span class="mi"
                                                        id="MathJax-Span-905"
                                                        style="font-family: MathJax_SansSerif;">I</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.97em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-123">\mathsf{SAFARI}</script> (server-assisted federated
                    averaging) algorithm that enjoys the same linear convergence speedup guarantees
                    as classic FL with ideal client participation assumptions, offering the first
                    SA-FL algorithm with convergence guarantee. Extensive experiments on different
                    datasets show <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-124-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-906"
                                style="width: 4.112em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.417em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1003.3em, 2.144em, -999.997em); top: -1.965em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-907"><span class="texatom"
                                                id="MathJax-Span-908"><span class="mrow" id="MathJax-Span-909"><span
                                                        class="mi" id="MathJax-Span-910"
                                                        style="font-family: MathJax_SansSerif;">S</span><span class="mi"
                                                        id="MathJax-Span-911"
                                                        style="font-family: MathJax_SansSerif;">A</span><span class="mi"
                                                        id="MathJax-Span-912"
                                                        style="font-family: MathJax_SansSerif;">F</span><span class="mi"
                                                        id="MathJax-Span-913"
                                                        style="font-family: MathJax_SansSerif;">A</span><span class="mi"
                                                        id="MathJax-Span-914"
                                                        style="font-family: MathJax_SansSerif;">R</span><span class="mi"
                                                        id="MathJax-Span-915"
                                                        style="font-family: MathJax_SansSerif;">I</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.97em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-124">\mathsf{SAFARI}</script> significantly improves the
                    performance under
                    incomplete client participation.
                </p>
            </div>
        </dd>
        <dt><a name="item225">[225]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02749"
                    title="Abstract">arXiv:2405.02749</a> [<a href="/pdf/2405.02749" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02749" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Sub-goal Distillation: A Method to Improve Small Language
                    Agents
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hashemzadeh%2C+M">Maryam Hashemzadeh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stengel-Eskin%2C+E">Elias Stengel-Eskin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chandar%2C+S">Sarath Chandar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cote%2C+M">Marc-Alexandre Cote</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">While Large Language Models (LLMs) have demonstrated significant promise as
                    agents in interactive tasks, their substantial computational requirements and
                    restricted number of calls constrain their practical utility, especially in
                    long-horizon interactive tasks such as decision-making or in scenarios
                    involving continuous ongoing tasks. To address these constraints, we propose a
                    method for transferring the performance of an LLM with billions of parameters
                    to a much smaller language model (770M parameters). Our approach involves
                    constructing a hierarchical agent comprising a planning module, which learns
                    through Knowledge Distillation from an LLM to generate sub-goals, and an
                    execution module, which learns to accomplish these sub-goals using elementary
                    actions. In detail, we leverage an LLM to annotate an oracle path with a
                    sequence of sub-goals towards completing a goal. Subsequently, we utilize this
                    annotated data to fine-tune both the planning and execution modules.
                    Importantly, neither module relies on real-time access to an LLM during
                    inference, significantly reducing the overall cost associated with LLM
                    interactions to a fixed cost. In ScienceWorld, a challenging and multi-task
                    interactive text environment, our method surpasses standard imitation learning
                    based solely on elementary actions by 16.7% (absolute). Our analysis highlights
                    the efficiency of our approach compared to other LLM-based methods. Our code
                    and annotated data for distillation can be found on GitHub.
                </p>
            </div>
        </dd>
        <dt><a name="item226">[226]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02750"
                    title="Abstract">arXiv:2405.02750</a> [<a href="/pdf/2405.02750" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02750" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing Contextual Understanding in Large Language Models
                    through Contrastive Decoding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zheng Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Monti%2C+E">Emilio Monti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lehmann%2C+J">Jens Lehmann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Assem%2C+H">Haytham Assem</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to NAACL 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Large language models (LLMs) tend to inadequately integrate input context
                    during text generation, relying excessively on encoded prior knowledge in model
                    parameters, potentially resulting in generated text with factual
                    inconsistencies or contextually unfaithful content. LLMs utilize two primary
                    knowledge sources: 1) prior (parametric) knowledge from pretraining, and 2)
                    contextual (non-parametric) knowledge from input prompts. The study addresses
                    the open question of how LLMs effectively balance these knowledge sources
                    during the generation process, specifically in the context of open-domain
                    question answering. To address this issue, we introduce a novel approach
                    integrating contrastive decoding with adversarial irrelevant passages as
                    negative samples to enhance robust context grounding during generation.
                    Notably, our method operates at inference time without requiring further
                    training. We conduct comprehensive experiments to demonstrate its applicability
                    and effectiveness, providing empirical evidence showcasing its superiority over
                    existing methodologies. Our code is publicly available at:
                    https://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.
                </p>
            </div>
        </dd>
        <dt><a name="item227">[227]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02751"
                    title="Abstract">arXiv:2405.02751</a> [<a href="/pdf/2405.02751" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02751" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Image Restoration For Image Anti-Forensics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tahir%2C+E">Eren Tahir</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bal%2C+M">Mert Bal</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">While image forensics is concerned with whether an image has been tampered
                    with, image anti-forensics attempts to prevent image forensics methods from
                    detecting tampered images. The competition between these two fields started
                    long before the advancement of deep learning. JPEG compression, blurring and
                    noising, which are simple methods by today's standards, have long been used for
                    anti-forensics and have been the subject of much research in both forensics and
                    anti-forensics. Although these traditional methods are old, they make it
                    difficult to detect fake images and are used for data augmentation in training
                    deep image forgery detection models. In addition to making the image difficult
                    to detect, these methods leave traces on the image and consequently degrade the
                    image quality. Separate image forensics methods have also been developed to
                    detect these traces. In this study, we go one step further and improve the
                    image quality after these methods with deep image restoration models and make
                    it harder to detect the forged image. We evaluate the impact of these methods
                    on image quality. We then test both our proposed methods with deep learning and
                    methods without deep learning on the two best existing image manipulation
                    detection models. In the obtained results, we show how existing image forgery
                    detection models fail against the proposed methods. Code implementation will be
                    publicly available at https://github.com/99eren99/DIRFIAF .
                </p>
            </div>
        </dd>
        <dt><a name="item228">[228]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02754"
                    title="Abstract">arXiv:2405.02754</a> [<a href="/pdf/2405.02754" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02754" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Implicit Safe Set Algorithm for Provably Safe Reinforcement
                    Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+W">Weiye Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+T">Tairan He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+F">Feihan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Changliu Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> submissions to Journal of Artificial Intelligence
                    Research. arXiv admin note: text overlap with <a href="/abs/2308.13140">arXiv:2308.13140</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Deep reinforcement learning (DRL) has demonstrated remarkable performance in
                    many continuous control tasks. However, a significant obstacle to the
                    real-world application of DRL is the lack of safety guarantees. Although DRL
                    agents can satisfy system safety in expectation through reward shaping,
                    designing agents to consistently meet hard constraints (e.g., safety
                    specifications) at every time step remains a formidable challenge. In contrast,
                    existing work in the field of safe control provides guarantees on persistent
                    satisfaction of hard safety constraints. However, these methods require
                    explicit analytical system dynamics models to synthesize safe control, which
                    are typically inaccessible in DRL settings. In this paper, we present a
                    model-free safe control algorithm, the implicit safe set algorithm, for
                    synthesizing safeguards for DRL agents that ensure provable safety throughout
                    training. The proposed algorithm synthesizes a safety index (barrier
                    certificate) and a subsequent safe control law solely by querying a black-box
                    dynamic function (e.g., a digital twin simulator). Moreover, we theoretically
                    prove that the implicit safe set algorithm guarantees finite time convergence
                    to the safe set and forward invariance for both continuous-time and
                    discrete-time systems. We validate the proposed algorithm on the
                    state-of-the-art Safety Gym benchmark, where it achieves zero safety violations
                    while gaining <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-125-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-916"
                                style="width: 5.327em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.401em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.34em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-917"><span class="mn" id="MathJax-Span-918"
                                                style="font-family: MathJax_Main;">95</span><span class="mi"
                                                id="MathJax-Span-919" style="font-family: MathJax_Main;">%</span><span
                                                class="mo" id="MathJax-Span-920"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">±</span><span
                                                class="mn" id="MathJax-Span-921"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">9</span><span
                                                class="mi" id="MathJax-Span-922"
                                                style="font-family: MathJax_Main;">%</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-125">95\% \pm 9\%</script> cumulative reward compared to
                    state-of-the-art
                    safe DRL methods. Furthermore, the resulting algorithm scales well to
                    high-dimensional systems with parallel computing.
                </p>
            </div>
        </dd>
        <dt><a name="item229">[229]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02756"
                    title="Abstract">arXiv:2405.02756</a> [<a href="/pdf/2405.02756" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02756" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient Open Modification Spectral Library Searching in
                    High-Dimensional Space with Multi-Level-Cell Memory
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+K">Keming Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+W">Wei-Chen Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pinge%2C+S">Sumukh Pinge</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wong%2C+H+-+P">H.-S. Philip Wong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rosing%2C+T">Tajana Rosing</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by DAC'24
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture
                        (cs.AR)</span>

                </div>
                <p class="mathjax">Open Modification Search (OMS) is a promising algorithm for mass spectrometry
                    analysis that enables the discovery of modified peptides. However, OMS
                    encounters challenges as it exponentially extends the search scope. Existing
                    OMS accelerators either have limited parallelism or struggle to scale
                    effectively with growing data volumes. In this work, we introduce an OMS
                    accelerator utilizing multi-level-cell (MLC) RRAM memory to enhance storage
                    capacity by 3x. Through in-memory computing, we achieve up to 77x faster data
                    processing with two to three orders of magnitude better energy efficiency.
                    Testing was done on a fabricated MLC RRAM chip. We leverage hyperdimensional
                    computing to tolerate up to 10% memory errors while delivering massive
                    parallelism in hardware.
                </p>
            </div>
        </dd>
        <dt><a name="item230">[230]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02759"
                    title="Abstract">arXiv:2405.02759</a> [<a href="/pdf/2405.02759" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02759" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Region-Aware Color Smudging
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Ying Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+P">Pengfei Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Congyi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+H">Hongbo Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lau%2C+H">Henry Lau</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenping Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

                </div>
                <p class="mathjax">Color smudge operations from digital painting software enable users to create
                    natural shading effects in high-fidelity paintings by interactively mixing
                    colors. To precisely control results in traditional painting software, users
                    tend to organize flat-filled color regions in multiple layers and smudge them
                    to generate different color gradients. However, the requirement to carefully
                    deal with regions makes the smudging process time-consuming and laborious,
                    especially for non-professional users. This motivates us to investigate how to
                    infer user-desired smudging effects when users smudge over regions in a single
                    layer. To investigate improving color smudge performance, we first conduct a
                    formative study. Following the findings of this study, we design SmartSmudge, a
                    novel smudge tool that offers users dynamical smudge brushes and real-time
                    region selection for easily generating natural and efficient shading effects.
                    We demonstrate the efficiency and effectiveness of the proposed tool via a user
                    study and quantitative analysis
                </p>
            </div>
        </dd>
        <dt><a name="item231">[231]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02760"
                    title="Abstract">arXiv:2405.02760</a> [<a href="/pdf/2405.02760" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02760" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GTFS2STN: Analyzing GTFS Transit Data by Generating
                    Spatiotemporal Transit Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+D">Diyi Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+J">Jing Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+Y">Yangsong Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=King%2C+M">Meredith King</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+L+D">Lee D. Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brakewood%2C+C">Candace Brakewood</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 8 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Social and Information Networks (cs.SI)

                </div>
                <p class="mathjax">GTFS, the General Transit Feed Specialization, is an open standard format to
                    record transit information used by thousands of transit agencies across the
                    world. By converting a static GTFS transit network to a spatiotemporal network
                    connecting bus stops over space and time, a preliminary tool named GTFS2STN is
                    implemented to analyze the accessibility of the transit system. Furthermore, a
                    simple application is built for users to generate spatiotemporal network
                    online. The online tool also supports some basic analysis including generate
                    isochrone maps given origin, generate travel time variability over time given a
                    pair of origin and destination, etc. Results show that the tool has a similar
                    result compared with Mapnificent, another open source endeavour to generate
                    isochrone maps given GTFS inputs. Compared with Mapnificent, the proposed
                    GTFS2STN tool is suited for research and evaluation purposes because the users
                    can upload any historical GTFS dataset by any transit agencies to evaluate the
                    accessibility and travel time variability of transit networks over time.
                </p>
            </div>
        </dd>
        <dt><a name="item232">[232]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02762"
                    title="Abstract">arXiv:2405.02762</a> [<a href="/pdf/2405.02762" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02762" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TK-Planes: Tiered K-Planes with High Dimensional Feature
                    Vectors for Dynamic UAV-based Scenes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Maxey%2C+C">Christopher Maxey</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+J">Jaehoon Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+Y">Yonghan Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+H">Hyungtae Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Manocha%2C+D">Dinesh Manocha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kwon%2C+H">Heesung Kwon</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, submitted to IROS2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

                </div>
                <p class="mathjax">In this paper, we present a new approach to bridge the domain gap between
                    synthetic and real-world data for un- manned aerial vehicle (UAV)-based
                    perception. Our formu- lation is designed for dynamic scenes, consisting of
                    moving objects or human actions, where the goal is to recognize the pose or
                    actions. We propose an extension of K-Planes Neural Radiance Field (NeRF),
                    wherein our algorithm stores a set of tiered feature vectors. The tiered
                    feature vectors are generated to effectively model conceptual information about
                    a scene as well as an image decoder that transforms output feature maps into
                    RGB images. Our technique leverages the information amongst both static and
                    dynamic objects within a scene and is able to capture salient scene attributes
                    of high altitude videos. We evaluate its performance on challenging datasets,
                    including Okutama Action and UG2, and observe considerable improvement in
                    accuracy over state of the art aerial perception algorithms.
                </p>
            </div>
        </dd>
        <dt><a name="item233">[233]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02763"
                    title="Abstract">arXiv:2405.02763</a> [<a href="/pdf/2405.02763" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02763" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Can Nuanced Language Lead to More Actionable Insights?
                    Exploring the Role of Generative AI in Analytical Narrative Structure
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Setlur%2C+V">Vidya Setlur</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Birnbaum%2C+L">Larry Birnbaum</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages, 1 figure
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">Relevant language describing trends in data can be useful for generating
                    summaries to help with readers' takeaways. However, the language employed in
                    these often template-generated summaries tends to be simple, ranging from
                    describing simple statistical information (e.g., extrema and trends) without
                    additional context and richer language to provide actionable insights. Recent
                    advances in Large Language Models (LLMs) have shown promising capabilities in
                    capturing subtle nuances in language when describing information. This workshop
                    paper specifically explores how LLMs can provide more actionable insights when
                    describing trends by focusing on three dimensions of analytical narrative
                    structure: semantic, rhetorical, and pragmatic. Building on prior research that
                    examines visual and linguistic signatures for univariate line charts, we
                    examine how LLMs can further leverage the semantic dimension of analytical
                    narratives using quantified semantics to describe shapes in trends as people
                    intuitively view them. These semantic descriptions help convey insights in a
                    way that leads to a pragmatic outcome, i.e., a call to action, persuasion,
                    warning vs. alert, and situational awareness. Finally, we identify rhetorical
                    implications for how well these generated narratives align with the perceived
                    shape of the data, thereby empowering users to make informed decisions and take
                    meaningful actions based on these data insights.
                </p>
            </div>
        </dd>
        <dt><a name="item234">[234]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02764"
                    title="Abstract">arXiv:2405.02764</a> [<a href="/pdf/2405.02764" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02764" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Assessing Adversarial Robustness of Large Language Models: An
                    Empirical Study
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zeyu Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Meng%2C+Z">Zhao Meng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+X">Xiaochen Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wattenhofer%2C+R">Roger Wattenhofer</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages, 9 figures, 10 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Large Language Models (LLMs) have revolutionized natural language processing,
                    but their robustness against adversarial attacks remains a critical concern. We
                    presents a novel white-box style attack approach that exposes vulnerabilities
                    in leading open-source LLMs, including Llama, OPT, and T5. We assess the impact
                    of model size, structure, and fine-tuning strategies on their resistance to
                    adversarial perturbations. Our comprehensive evaluation across five diverse
                    text classification tasks establishes a new benchmark for LLM robustness. The
                    findings of this study have far-reaching implications for the reliable
                    deployment of LLMs in real-world applications and contribute to the advancement
                    of trustworthy AI systems.
                </p>
            </div>
        </dd>
        <dt><a name="item235">[235]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02765"
                    title="Abstract">arXiv:2405.02765</a> [<a href="/pdf/2405.02765" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02765" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Detecting Edited Knowledge in Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Youssef%2C+P">Paul Youssef</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhixue Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schl%C3%B6tterer%2C+J">Jörg Schlötterer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Seifert%2C+C">Christin Seifert</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Knowledge editing techniques (KEs) can update language models' obsolete or
                    inaccurate knowledge learned from pre-training. However, KE also faces
                    potential malicious applications, e.g. inserting misinformation and toxic
                    content. Moreover, in the context of responsible AI, it is instructive for
                    end-users to know whether a generated output is driven by edited knowledge or
                    first-hand knowledge from pre-training. To this end, we study detecting edited
                    knowledge in language models by introducing a novel task: given an edited model
                    and a specific piece of knowledge the model generates, our objective is to
                    classify the knowledge as either "non-edited" (based on the pre-training), or
                    ``edited'' (based on subsequent editing). We initiate the task with two
                    state-of-the-art KEs, two language models, and two datasets. We further propose
                    a simple classifier, RepReg, a logistic regression model that takes hidden
                    state representations as input features. Our results reveal that RepReg
                    establishes a strong baseline, achieving a peak accuracy of 99.81%, and 97.79%
                    in out-of-domain settings. Second, RepReg achieves near-optimal performance
                    with a limited training set (200 training samples), and it maintains its
                    performance even in out-of-domain settings. Last, we find it more challenging
                    to separate edited and non-edited knowledge when they contain the same subject
                    or object.
                </p>
            </div>
        </dd>
        <dt><a name="item236">[236]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02766"
                    title="Abstract">arXiv:2405.02766</a> [<a href="/pdf/2405.02766" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02766" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Beyond Unimodal Learning: The Importance of Integrating
                    Multiple Modalities for Lifelong Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sarfraz%2C+F">Fahad Sarfraz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zonooz%2C+B">Bahram Zonooz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Arani%2C+E">Elahe Arani</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at 3rd Conference on Lifelong Learning Agents
                    (CoLLAs), 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">While humans excel at continual learning (CL), deep neural networks (DNNs)
                    exhibit catastrophic forgetting. A salient feature of the brain that allows
                    effective CL is that it utilizes multiple modalities for learning and
                    inference, which is underexplored in DNNs. Therefore, we study the role and
                    interactions of multiple modalities in mitigating forgetting and introduce a
                    benchmark for multimodal continual learning. Our findings demonstrate that
                    leveraging multiple views and complementary information from multiple
                    modalities enables the model to learn more accurate and robust representations.
                    This makes the model less vulnerable to modality-specific regularities and
                    considerably mitigates forgetting. Furthermore, we observe that individual
                    modalities exhibit varying degrees of robustness to distribution shift.
                    Finally, we propose a method for integrating and aligning the information from
                    different modalities by utilizing the relational structural similarities
                    between the data points in each modality. Our method sets a strong baseline
                    that enables both single- and multimodal inference. Our study provides a
                    promising case for further exploring the role of multiple modalities in
                    enabling CL and provides a standard benchmark for future research.
                </p>
            </div>
        </dd>
        <dt><a name="item237">[237]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02769"
                    title="Abstract">arXiv:2405.02769</a> [<a href="/pdf/2405.02769" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02769" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Linear Convergence of Independent Natural Policy Gradient in
                    Games with Entropy Regularization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Youbang Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Tao Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+P+R">P. R. Kumar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shahrampour%2C+S">Shahin Shahrampour</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Multiagent Systems (cs.MA); Optimization and Control (math.OC)

                </div>
                <p class="mathjax">This work focuses on the entropy-regularized independent natural policy
                    gradient (NPG) algorithm in multi-agent reinforcement learning. In this work,
                    agents are assumed to have access to an oracle with exact policy evaluation and
                    seek to maximize their respective independent rewards. Each individual's reward
                    is assumed to depend on the actions of all the agents in the multi-agent
                    system, leading to a game between agents. We assume all agents make decisions
                    under a policy with bounded rationality, which is enforced by the introduction
                    of entropy regularization. In practice, a smaller regularization implies the
                    agents are more rational and behave closer to Nash policies. On the other hand,
                    agents with larger regularization acts more randomly, which ensures more
                    exploration. We show that, under sufficient entropy regularization, the
                    dynamics of this system converge at a linear rate to the quantal response
                    equilibrium (QRE). Although regularization assumptions prevent the QRE from
                    approximating a Nash equilibrium, our findings apply to a wide range of games,
                    including cooperative, potential, and two-player matrix games. We also provide
                    extensive empirical results on multiple games (including Markov games) as a
                    verification of our theoretical analysis.
                </p>
            </div>
        </dd>
        <dt><a name="item238">[238]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02770"
                    title="Abstract">arXiv:2405.02770</a> [<a href="/pdf/2405.02770" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02770" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PhilHumans: Benchmarking Machine Learning for Personal Health
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liventsev%2C+V">Vadim Liventsev</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+V">Vivek Kumar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Susaiyah%2C+A+P+S">Allmin Pradhap Singh
                        Susaiyah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zixiu Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rodin%2C+I">Ivan Rodin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yaar%2C+A">Asfand Yaar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baloccu%2C+S">Simone Baloccu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Beraziuk%2C+M">Marharyta Beraziuk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Battiato%2C+S">Sebastiano Battiato</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Farinella%2C+G+M">Giovanni Maria Farinella</a>,
                    <a href="/search/cs?searchtype=author&amp;query=H%C3%A4rm%C3%A4%2C+A">Aki Härmä</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Helaoui%2C+R">Rim Helaoui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Petkovic%2C+M">Milan Petkovic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Recupero%2C+D+R">Diego Reforgiato Recupero</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reiter%2C+E">Ehud Reiter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Riboni%2C+D">Daniele Riboni</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sterling%2C+R">Raymond Sterling</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">The use of machine learning in Healthcare has the potential to improve
                    patient outcomes as well as broaden the reach and affordability of Healthcare.
                    The history of other application areas indicates that strong benchmarks are
                    essential for the development of intelligent systems. We present Personal
                    Health Interfaces Leveraging HUman-MAchine Natural interactions (PhilHumans), a
                    holistic suite of benchmarks for machine learning across different Healthcare
                    settings - talk therapy, diet coaching, emergency care, intensive care,
                    obstetric sonography - as well as different learning settings, such as action
                    anticipation, timeseries modeling, insight mining, language modeling, computer
                    vision, reinforcement learning and program synthesis
                </p>
            </div>
        </dd>
        <dt><a name="item239">[239]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02771"
                    title="Abstract">arXiv:2405.02771</a> [<a href="/pdf/2405.02771" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02771" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MMEarth: Exploring Multi-Modal Pretext Tasks For Geospatial
                    Representation Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nedungadi%2C+V">Vishal Nedungadi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kariryaa%2C+A">Ankit Kariryaa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Oehmcke%2C+S">Stefan Oehmcke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Belongie%2C+S">Serge Belongie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Igel%2C+C">Christian Igel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lang%2C+N">Nico Lang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Data and code is available on the project page: <a
                        href="https://vishalned.github.io/mmearth">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">The volume of unlabelled Earth observation (EO) data is huge, but many
                    important applications lack labelled training data. However, EO data offers the
                    unique opportunity to pair data from different modalities and sensors
                    automatically based on geographic location and time, at virtually no human
                    labor cost. We seize this opportunity to create a diverse multi-modal
                    pretraining dataset at global scale. Using this new corpus of 1.2 million
                    locations, we propose a Multi-Pretext Masked Autoencoder (MP-MAE) approach to
                    learn general-purpose representations for optical satellite images. Our
                    approach builds on the ConvNeXt V2 architecture, a fully convolutional masked
                    autoencoder (MAE). Drawing upon a suite of multi-modal pretext tasks, we
                    demonstrate that our MP-MAE approach outperforms both MAEs pretrained on
                    ImageNet and MAEs pretrained on domain-specific satellite images. This is shown
                    on several downstream tasks including image classification and semantic
                    segmentation. We find that multi-modal pretraining notably improves the linear
                    probing performance, e.g. 4pp on BigEarthNet and 16pp on So2Sat, compared to
                    pretraining on optical satellite images only. We show that this also leads to
                    better label and parameter efficiency which are crucial aspects in global scale
                    applications.
                </p>
            </div>
        </dd>
        <dt><a name="item240">[240]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02772"
                    title="Abstract">arXiv:2405.02772</a> [<a href="/pdf/2405.02772" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02772" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SkinGrip: An Adaptive Soft Robotic Manipulator with
                    Capacitive Sensing for Whole-Limb Bathing Assistance
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+F">Fukang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Puthuveetil%2C+K">Kavya Puthuveetil</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Padmanabha%2C+A">Akhil Padmanabha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khokar%2C+K">Karan Khokar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Temel%2C+Z">Zeynep Temel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Erickson%2C+Z">Zackory Erickson</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Robotics presents a promising opportunity for enhancing bathing assistance,
                    potentially to alleviate labor shortages and reduce care costs, while offering
                    consistent and gentle care for individuals with physical disabilities. However,
                    ensuring flexible and efficient cleaning of the human body poses challenges as
                    it involves direct physical contact between the human and the robot, and
                    necessitates simple, safe, and effective control. In this paper, we introduce a
                    soft, expandable robotic manipulator with embedded capacitive proximity sensing
                    arrays, designed for safe and efficient bathing assistance. We conduct a
                    thorough evaluation of our soft manipulator, comparing it with a baseline rigid
                    end effector in a human study involving 12 participants across <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-126-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-923"
                                style="width: 1.218em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.987em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.93em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-924"><span class="mn" id="MathJax-Span-925"
                                                style="font-family: MathJax_Main;">96</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-126">96</script> bathing
                    trails. Our soft manipulator achieves an an average cleaning effectiveness of
                    88.8% on arms and 81.4% on legs, far exceeding the performance of the baseline.
                    Participant feedback further validates the manipulator's ability to maintain
                    safety, comfort, and thorough cleaning.
                </p>
            </div>
        </dd>
        <dt><a name="item241">[241]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02774"
                    title="Abstract">arXiv:2405.02774</a> [<a href="/pdf/2405.02774" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02774" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Get more for less: Principled Data Selection for Warming Up
                    Fine-Tuning in LLMs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kang%2C+F">Feiyang Kang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Just%2C+H+A">Hoang Anh Just</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yifan Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jahagirdar%2C+H">Himanshu Jahagirdar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuanzhi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Du%2C+R">Rongxing Du</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sahu%2C+A+K">Anit Kumar Sahu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jia%2C+R">Ruoxi Jia</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">This work focuses on leveraging and selecting from vast, unlabeled, open data
                    to pre-fine-tune a pre-trained language model. The goal is to minimize the need
                    for costly domain-specific data for subsequent fine-tuning while achieving
                    desired performance levels. While many data selection algorithms have been
                    designed for small-scale applications, rendering them unsuitable for our
                    context, some emerging methods do cater to language data scales. However, they
                    often prioritize data that aligns with the target distribution. While this
                    strategy may be effective when training a model from scratch, it can yield
                    limited results when the model has already been pre-trained on a different
                    distribution. Differing from prior work, our key idea is to select data that
                    nudges the pre-training distribution closer to the target distribution. We show
                    the optimality of this approach for fine-tuning tasks under certain conditions.
                    We demonstrate the efficacy of our methodology across a diverse array of tasks
                    (NLU, NLG, zero-shot) with models up to 2.7B, showing that it consistently
                    surpasses other selection methods. Moreover, our proposed method is
                    significantly faster than existing techniques, scaling to millions of samples
                    within a single GPU hour. Our code is open-sourced (Code repository:
                    https://anonymous.4open.science/r/DV4LLM-D761/ ). While fine-tuning offers
                    significant potential for enhancing performance across diverse tasks, its
                    associated costs often limit its widespread adoption; with this work, we hope
                    to lay the groundwork for cost-effective fine-tuning, making its benefits more
                    accessible.
                </p>
            </div>
        </dd>
        <dt><a name="item242">[242]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02778"
                    title="Abstract">arXiv:2405.02778</a> [<a href="/pdf/2405.02778" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02778" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improve Temporal Awareness of LLMs for Sequential
                    Recommendation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chu%2C+Z">Zhendong Chu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zichao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruiyi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+Y">Yangfeng Ji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hongning Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+T">Tong Sun</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">Large language models (LLMs) have demonstrated impressive zero-shot abilities
                    in solving a wide range of general-purpose tasks. However, it is empirically
                    found that LLMs fall short in recognizing and utilizing temporal information,
                    rendering poor performance in tasks that require an understanding of sequential
                    data, such as sequential recommendation. In this paper, we aim to improve
                    temporal awareness of LLMs by designing a principled prompting framework
                    inspired by human cognitive processes. Specifically, we propose three prompting
                    strategies to exploit temporal information within historical interactions for
                    LLM-based sequential recommendation. Besides, we emulate divergent thinking by
                    aggregating LLM ranking results derived from these strategies. Evaluations on
                    MovieLens-1M and Amazon Review datasets indicate that our proposed method
                    significantly enhances the zero-shot capabilities of LLMs in sequential
                    recommendation tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item243">[243]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02781"
                    title="Abstract">arXiv:2405.02781</a> [<a href="/pdf/2405.02781" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02781" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Instantaneous Perception of Moving Objects in 3D
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+D">Di Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+B">Bingbing Zhuang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Metaxas%2C+D+N">Dimitris N. Metaxas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chandraker%2C+M">Manmohan Chandraker</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> CVPR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">The perception of 3D motion of surrounding traffic participants is crucial
                    for driving safety. While existing works primarily focus on general large
                    motions, we contend that the instantaneous detection and quantification of
                    subtle motions is equally important as they indicate the nuances in driving
                    behavior that may be safety critical, such as behaviors near a stop sign of
                    parking positions. We delve into this under-explored task, examining its unique
                    challenges and developing our solution, accompanied by a carefully designed
                    benchmark. Specifically, due to the lack of correspondences between consecutive
                    frames of sparse Lidar point clouds, static objects might appear to be moving -
                    the so-called swimming effect. This intertwines with the true object motion,
                    thereby posing ambiguity in accurate estimation, especially for subtle motions.
                    To address this, we propose to leverage local occupancy completion of object
                    point clouds to densify the shape cue, and mitigate the impact of swimming
                    artifacts. The occupancy completion is learned in an end-to-end fashion
                    together with the detection of moving objects and the estimation of their
                    motion, instantaneously as soon as objects start to move. Extensive experiments
                    demonstrate superior performance compared to standard 3D motion estimation
                    approaches, particularly highlighting our method's specialized treatment of
                    subtle motions.
                </p>
            </div>
        </dd>
        <dt><a name="item244">[244]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02782"
                    title="Abstract">arXiv:2405.02782</a> [<a href="/pdf/2405.02782" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02782" title="Download PostScript">ps</a>, <a href="/format/2405.02782"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A self-supervised text-vision framework for automated brain
                    abnormality detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wood%2C+D+A">David A. Wood</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guilhem%2C+E">Emily Guilhem</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kafiabadi%2C+S">Sina Kafiabadi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Busaidi%2C+A+A">Ayisha Al Busaidi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dissanayake%2C+K">Kishan Dissanayake</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hammam%2C+A">Ahmed Hammam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mansoor%2C+N">Nina Mansoor</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Townend%2C+M">Matthew Townend</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+S">Siddharth Agarwal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Y">Yiran Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mazumder%2C+A">Asif Mazumder</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Barker%2C+G+J">Gareth J. Barker</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sasieni%2C+P">Peter Sasieni</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ourselin%2C+S">Sebastien Ourselin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cole%2C+J+H">James H. Cole</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Booth%2C+T+C">Thomas C. Booth</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Under Review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Artificial neural networks trained on large, expert-labelled datasets are
                    considered state-of-the-art for a range of medical image recognition tasks.
                    However, categorically labelled datasets are time-consuming to generate and
                    constrain classification to a pre-defined, fixed set of classes. For
                    neuroradiological applications in particular, this represents a barrier to
                    clinical adoption. To address these challenges, we present a self-supervised
                    text-vision framework that learns to detect clinically relevant abnormalities
                    in brain MRI scans by directly leveraging the rich information contained in
                    accompanying free-text neuroradiology reports. Our training approach consisted
                    of two-steps. First, a dedicated neuroradiological language model - NeuroBERT -
                    was trained to generate fixed-dimensional vector representations of
                    neuroradiology reports (N = 50,523) via domain-specific self-supervised
                    learning tasks. Next, convolutional neural networks (one per MRI sequence)
                    learnt to map individual brain scans to their corresponding text vector
                    representations by optimising a mean square error loss. Once trained, our
                    text-vision framework can be used to detect abnormalities in unreported brain
                    MRI examinations by scoring scans against suitable query sentences (e.g.,
                    'there is an acute stroke', 'there is hydrocephalus' etc.), enabling a range of
                    classification-based applications including automated triage. Potentially, our
                    framework could also serve as a clinical decision support tool, not only by
                    suggesting findings to radiologists and detecting errors in provisional
                    reports, but also by retrieving and displaying examples of pathologies from
                    historical examinations that could be relevant to the current case based on
                    textual descriptors.
                </p>
            </div>
        </dd>
        <dt><a name="item245">[245]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02785"
                    title="Abstract">arXiv:2405.02785</a> [<a href="/pdf/2405.02785" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02785" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fused attention mechanism-based ore sorting network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhen%2C+J">Junjiang Zhen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+B">Bojun Xie</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Deep learning has had a significant impact on the identification and
                    classification of mineral resources, especially playing a key role in
                    efficiently and accurately identifying different minerals, which is important
                    for improving the efficiency and accuracy of mining. However, traditional ore
                    sorting meth- ods often suffer from inefficiency and lack of accuracy,
                    especially in complex mineral environments. To address these challenges, this
                    study proposes a method called OreYOLO, which incorporates an attentional
                    mechanism and a multi-scale feature fusion strategy, based on ore data from
                    gold and sul- fide ores. By introducing the progressive feature pyramid
                    structure into YOLOv5 and embedding the attention mechanism in the feature
                    extraction module, the detection performance and accuracy of the model are
                    greatly improved. In order to adapt to the diverse ore sorting scenarios and
                    the deployment requirements of edge devices, the network structure is designed
                    to be lightweight, which achieves a low number of parameters (3.458M) and
                    computational complexity (6.3GFLOPs) while maintaining high accuracy (99.3% and
                    99.2%, respectively). In the experimental part, a target detection dataset
                    containing 6000 images of gold and sulfuric iron ore is constructed for gold
                    and sulfuric iron ore classification training, and several sets of comparison
                    experiments are set up, including the YOLO series, EfficientDet, Faster-RCNN,
                    and CenterNet, etc., and the experiments prove that OreYOLO outperforms the
                    commonly used high-performance object detection of these architectures
                </p>
            </div>
        </dd>
        <dt><a name="item246">[246]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02787"
                    title="Abstract">arXiv:2405.02787</a> [<a href="/pdf/2405.02787" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02787" title="Download PostScript">ps</a>, <a href="/format/2405.02787"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Light Field Spatial Resolution Enhancement Framework
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shabbir%2C+J">Javeria Shabbir</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alam%2C+M+Z">Muhammad Zeshan.Alam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mukati%2C+M+U">M.Umair Mukati</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages, 6 figures, accepted in IEEE Conference on Signal
                    Processing and Communications Applications
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Light field (LF) imaging captures both angular and spatial light
                    distributions, enabling advanced photographic techniques. However, micro-lens
                    array (MLA)- based cameras face a spatial-angular resolution tradeoff due to a
                    single shared sensor. We propose a novel light field framework for resolution
                    enhancement, employing a modular approach. The first module generates a
                    high-resolution, all-in-focus image. The second module, a texture transformer
                    network, enhances the resolution of each light field perspective independently
                    using the output of the first module as a reference image. The final module
                    leverages light field regularity to jointly improve resolution across all LF
                    image perspectives. Our approach demonstrates superior performance to existing
                    methods in both qualitative and quantitative evaluations.
                </p>
            </div>
        </dd>
        <dt><a name="item247">[247]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02790"
                    title="Abstract">arXiv:2405.02790</a> [<a href="/pdf/2405.02790" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02790" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Confidential and Protected Disease Classifier using Fully
                    Homomorphic Encryption
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Malik%2C+A">Aditya Malik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ratha%2C+N">Nalini Ratha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yalavarthi%2C+B">Bharat Yalavarthi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sharma%2C+T">Tilak Sharma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kaushik%2C+A">Arjun Kaushik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jutla%2C+C">Charanjit Jutla</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">With the rapid surge in the prevalence of Large Language Models (LLMs),
                    individuals are increasingly turning to conversational AI for initial insights
                    across various domains, including health-related inquiries such as disease
                    diagnosis. Many users seek potential causes on platforms like ChatGPT or Bard
                    before consulting a medical professional for their ailment. These platforms
                    offer valuable benefits by streamlining the diagnosis process, alleviating the
                    significant workload of healthcare practitioners, and saving users both time
                    and money by avoiding unnecessary doctor visits. However, Despite the
                    convenience of such platforms, sharing personal medical data online poses
                    risks, including the presence of malicious platforms or potential eavesdropping
                    by attackers. To address privacy concerns, we propose a novel framework
                    combining FHE and Deep Learning for a secure and private diagnosis system.
                    Operating on a question-and-answer-based model akin to an interaction with a
                    medical practitioner, this end-to-end secure system employs Fully Homomorphic
                    Encryption (FHE) to handle encrypted input data. Given FHE's computational
                    constraints, we adapt deep neural networks and activation functions to the
                    encryted domain. Further, we also propose a faster algorithm to compute
                    summation of ciphertext elements. Through rigorous experiments, we demonstrate
                    the efficacy of our approach. The proposed framework achieves strict security
                    and privacy with minimal loss in performance.
                </p>
            </div>
        </dd>
        <dt><a name="item248">[248]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02791"
                    title="Abstract">arXiv:2405.02791</a> [<a href="/pdf/2405.02791" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02791" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient Text-driven Motion Generation via Latent
                    Consistency Training
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+M">Mengxian Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+M">Minghao Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xun Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Q">Qingqing Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shu Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chengju Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qijun Chen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Motion diffusion models have recently proven successful for text-driven human
                    motion generation. Despite their excellent generation performance, they are
                    challenging to infer in real time due to the multi-step sampling mechanism that
                    involves tens or hundreds of repeat function evaluation iterations. To this
                    end, we investigate a motion latent consistency Training (MLCT) for motion
                    generation to alleviate the computation and time consumption during iteration
                    inference. It applies diffusion pipelines to low-dimensional motion latent
                    spaces to mitigate the computational burden of each function evaluation.
                    Explaining the diffusion process with probabilistic flow ordinary differential
                    equation (PF-ODE) theory, the MLCT allows extremely few steps infer between the
                    prior distribution to the motion latent representation distribution via
                    maintaining consistency of the outputs over the trajectory of PF-ODE.
                    Especially, we introduce a quantization constraint to optimize motion latent
                    representations that are bounded, regular, and well-reconstructed compared to
                    traditional variational constraints. Furthermore, we propose a conditional
                    PF-ODE trajectory simulation method, which improves the conditional generation
                    performance with minimal additional training costs. Extensive experiments on
                    two human motion generation benchmarks show that the proposed model achieves
                    state-of-the-art performance with less than 10\% time cost.
                </p>
            </div>
        </dd>
        <dt><a name="item249">[249]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02792"
                    title="Abstract">arXiv:2405.02792</a> [<a href="/pdf/2405.02792" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02792" title="Download PostScript">ps</a>, <a href="/format/2405.02792"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Jointly Learning Spatial, Angular, and Temporal Information
                    for Enhanced Lane Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Alam%2C+M+Z">Muhammad Zeshan Alam</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages, 3 Figures , Accepted IEEE Conference on Signal
                    Processing and Communications Applications
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">This paper introduces a novel approach for enhanced lane detection by
                    integrating spatial, angular, and temporal information through light field
                    imaging and novel deep learning models. Utilizing lenslet-inspired 2D light
                    field representations and LSTM networks, our method significantly improves lane
                    detection in challenging conditions. We demonstrate the efficacy of this
                    approach with modified CNN architectures, showing superior per- formance over
                    traditional methods. Our findings suggest this integrated data approach could
                    advance lane detection technologies and inspire new models that leverage these
                    multidimensional insights for autonomous vehicle percep- tion.
                </p>
            </div>
        </dd>
        <dt><a name="item250">[250]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02793"
                    title="Abstract">arXiv:2405.02793</a> [<a href="/pdf/2405.02793" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02793" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ImageInWords: Unlocking Hyper-Detailed Image Descriptions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Garg%2C+R">Roopal Garg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Burns%2C+A">Andrea Burns</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ayan%2C+B+K">Burcu Karagol Ayan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bitton%2C+Y">Yonatan Bitton</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Montgomery%2C+C">Ceslee Montgomery</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Onoe%2C+Y">Yasumasa Onoe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bunner%2C+A">Andrew Bunner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Krishna%2C+R">Ranjay Krishna</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baldridge%2C+J">Jason Baldridge</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Soricut%2C+R">Radu Soricut</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Webpage (<a
                        href="https://google.github.io/imageinwords">this https URL</a>), GitHub (<a
                        href="https://github.com/google/imageinwords">this https URL</a>), HuggingFace (<a
                        href="https://huggingface.co/datasets/google/imageinwords">this https URL</a>)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL)

                </div>
                <p class="mathjax">Despite the longstanding adage "an image is worth a thousand words," creating
                    accurate and hyper-detailed image descriptions for training Vision-Language
                    models remains challenging. Current datasets typically have web-scraped
                    descriptions that are short, low-granularity, and often contain details
                    unrelated to the visual content. As a result, models trained on such data
                    generate descriptions replete with missing information, visual inconsistencies,
                    and hallucinations. To address these issues, we introduce ImageInWords (IIW), a
                    carefully designed human-in-the-loop annotation framework for curating
                    hyper-detailed image descriptions and a new dataset resulting from this
                    process. We validate the framework through evaluations focused on the quality
                    of the dataset and its utility for fine-tuning with considerations for
                    readability, comprehensiveness, specificity, hallucinations, and
                    human-likeness. Our dataset significantly improves across these dimensions
                    compared to recently released datasets (+66%) and GPT-4V outputs (+48%).
                    Furthermore, models fine-tuned with IIW data excel by +31% against prior work
                    along the same human evaluation dimensions. Given our fine-tuned models, we
                    also evaluate text-to-image generation and vision-language reasoning. Our
                    model's descriptions can generate images closest to the original, as judged by
                    both automated and human metrics. We also find our model produces more
                    compositionally rich descriptions, outperforming the best baseline by up to 6%
                    on ARO, SVO-Probes, and Winoground datasets.
                </p>
            </div>
        </dd>
        <dt><a name="item251">[251]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02794"
                    title="Abstract">arXiv:2405.02794</a> [<a href="/pdf/2405.02794" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02794" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Octopi: Object Property Reasoning with Large Tactile-Language
                    Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+S">Samson Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+K">Kelvin Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+A">Anxing Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Duan%2C+J">Jiafei Duan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Soh%2C+H">Harold Soh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 17 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Physical reasoning is important for effective robot manipulation. Recent work
                    has investigated both vision and language modalities for physical reasoning;
                    vision can reveal information about objects in the environment and language
                    serves as an abstraction and communication medium for additional context.
                    Although these works have demonstrated success on a variety of physical
                    reasoning tasks, they are limited to physical properties that can be inferred
                    from visual or language inputs. In this work, we investigate combining tactile
                    perception with language, which enables embodied systems to obtain physical
                    properties through interaction and apply common-sense reasoning. We contribute
                    a new dataset PhysiCleAR, which comprises both physical/property reasoning
                    tasks and annotated tactile videos obtained using a GelSight tactile sensor. We
                    then introduce Octopi, a system that leverages both tactile representation
                    learning and large vision-language models to predict and reason about tactile
                    inputs with minimal language fine-tuning. Our evaluations on PhysiCleAR show
                    that Octopi is able to effectively use intermediate physical property
                    predictions to improve physical reasoning in both trained tasks and for
                    zero-shot reasoning. PhysiCleAR and Octopi are available on
                    https://github.com/clear-nus/octopi.
                </p>
            </div>
        </dd>
        <dt><a name="item252">[252]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02795"
                    title="Abstract">arXiv:2405.02795</a> [<a href="/pdf/2405.02795" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02795" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Graph as Point Set
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiyuan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+P">Pan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Muhan Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Graph is a fundamental data structure to model interconnections between
                    entities. Set, on the contrary, stores independent elements. To learn graph
                    representations, current Graph Neural Networks (GNNs) primarily use message
                    passing to encode the interconnections. In contrast, this paper introduces a
                    novel graph-to-set conversion method that bijectively transforms interconnected
                    nodes into a set of independent points and then uses a set encoder to learn the
                    graph representation. This conversion method holds dual significance. Firstly,
                    it enables using set encoders to learn from graphs, thereby significantly
                    expanding the design space of GNNs. Secondly, for Transformer, a specific set
                    encoder, we provide a novel and principled approach to inject graph information
                    losslessly, different from all the heuristic structural/positional encoding
                    methods adopted in previous graph transformers. To demonstrate the
                    effectiveness of our approach, we introduce Point Set Transformer (PST), a
                    transformer architecture that accepts a point set converted from a graph as
                    input. Theoretically, PST exhibits superior expressivity for both short-range
                    substructure counting and long-range shortest path distance tasks compared to
                    existing GNNs. Extensive experiments further validate PST's outstanding
                    real-world performance. Besides Transformer, we also devise a Deepset-based set
                    encoder, which achieves performance comparable to representative GNNs,
                    affirming the versatility of our graph-to-set method.
                </p>
            </div>
        </dd>
        <dt><a name="item253">[253]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02797"
                    title="Abstract">arXiv:2405.02797</a> [<a href="/pdf/2405.02797" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02797" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adapting to Distribution Shift by Visual Domain Prompt
                    Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chi%2C+Z">Zhixiang Chi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+L">Li Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+T">Tao Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Huan Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yuanhao Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Plataniotis%2C+K+N">Konstantinos N Plataniotis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yang Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR2024, code: <a
                        href="https://github.com/Guliisgreat/VDPG">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In this paper, we aim to adapt a model at test-time using a few unlabeled
                    data to address distribution shifts. To tackle the challenges of extracting
                    domain knowledge from a limited amount of data, it is crucial to utilize
                    correlated information from pre-trained backbones and source domains. Previous
                    studies fail to utilize recent foundation models with strong
                    out-of-distribution generalization. Additionally, domain-centric designs are
                    not flavored in their works. Furthermore, they employ the process of modelling
                    source domains and the process of learning to adapt independently into disjoint
                    training stages. In this work, we propose an approach on top of the
                    pre-computed features of the foundation model. Specifically, we build a
                    knowledge bank to learn the transferable knowledge from source domains.
                    Conditioned on few-shot target data, we introduce a domain prompt generator to
                    condense the knowledge bank into a domain-specific prompt. The domain prompt
                    then directs the visual features towards a particular domain via a guidance
                    module. Moreover, we propose a domain-aware contrastive loss and employ
                    meta-learning to facilitate domain knowledge extraction. Extensive experiments
                    are conducted to validate the domain knowledge extraction. The proposed method
                    outperforms previous work on 5 large-scale benchmarks including WILDS and
                    DomainNet.
                </p>
            </div>
        </dd>
        <dt><a name="item254">[254]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02798"
                    title="Abstract">arXiv:2405.02798</a> [<a href="/pdf/2405.02798" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02798" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Structural Balance in Real-World Social Networks:
                    Incorporating Direction and Transitivity in Measuring Partial Balance
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Rezapour%2C+R">Rezvaneh Rezapour</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dinh%2C+L">Ly Dinh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+L">Lan Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Diesner%2C+J">Jana Diesner</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a
                        href="/abs/2006.02565">arXiv:2006.02565</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information
                        Networks (cs.SI)</span>

                </div>
                <p class="mathjax">Structural balance theory predicts that triads in networks gravitate towards
                    stable configurations. The theory has been verified for undirected graphs.
                    Since real-world networks are often directed, we introduce a novel method for
                    considering both transitivity and sign consistency for evaluating partial
                    balance in signed digraphs. We test our approach on graphs constructed by using
                    different methods for identifying edge signs: natural language processing to
                    infer signs from underlying text data, and self-reported survey data. Our
                    results show that for various social contexts and edge sign detection methods,
                    partial balance of these digraphs are moderately high, ranging from 61% to 96%.
                    Our approach not only enhances the theoretical framework of structural balance
                    but also provides practical insights into the stability of social networks,
                    enabling a deeper understanding of interpersonal and group dynamics across
                    different communication platforms.
                </p>
            </div>
        </dd>
        <dt><a name="item255">[255]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02800"
                    title="Abstract">arXiv:2405.02800</a> [<a href="/pdf/2405.02800" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02800" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Designing Distinguishable Mid-Air Ultrasound Tactons with
                    Temporal Parameters
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lim%2C+C">Chungman Lim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+G">Gunhyuk Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Seifi%2C+H">Hasti Seifi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">Mid-air ultrasound technology offers new design opportunities for contactless
                    tactile patterns (i.e., Tactons) in user applications. Yet, few guidelines
                    exist for making ultrasound Tactons easy to distinguish for users. In this
                    paper, we investigated the distinguishability of temporal parameters of
                    ultrasound Tactons in five studies (n=72 participants). Study 1 established the
                    discrimination thresholds for amplitude-modulated (AM) frequencies. In Studies
                    2-5, we investigated distinguishable ultrasound Tactons by creating four Tacton
                    sets based on mechanical vibrations in the literature and collected similarity
                    ratings for the ultrasound Tactons. We identified a subset of temporal
                    parameters, such as rhythm and low envelope frequency, that could create
                    distinguishable ultrasound Tactons. Also, a strong correlation (mean Spearman's
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-127-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-926"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.52em, 2.318em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-927"><span class="mi" id="MathJax-Span-928"
                                                style="font-family: MathJax_Math-italic;">ρ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-127">\rho</script>=0.75) existed between similarity
                    ratings for ultrasound Tactons and
                    similarities of mechanical Tactons from the literature, suggesting vibrotactile
                    designers can transfer their knowledge to ultrasound design. We present design
                    guidelines and future directions for creating distinguishable mid-air
                    ultrasound Tactons.
                </p>
            </div>
        </dd>
        <dt><a name="item256">[256]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02801"
                    title="Abstract">arXiv:2405.02801</a> [<a href="/pdf/2405.02801" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02801" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mozart's Touch: A Lightweight Multi-modal Music Generation
                    Framework Based on Pre-Trained Large Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+T">Tianze Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jiajun Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xuesong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yinrui Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shuchang Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 2 figures, submitted to ACM MM 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">In recent years, AI-Generated Content (AIGC) has witnessed rapid
                    advancements, facilitating the generation of music, images, and other forms of
                    artistic expression across various industries. However, researches on general
                    multi-modal music generation model remain scarce. To fill this gap, we propose
                    a multi-modal music generation framework Mozart's Touch. It could generate
                    aligned music with the cross-modality inputs, such as images, videos and text.
                    Mozart's Touch is composed of three main components: Multi-modal Captioning
                    Module, Large Language Model (LLM) Understanding &amp; Bridging Module, and Music
                    Generation Module. Unlike traditional approaches, Mozart's Touch requires no
                    training or fine-tuning pre-trained models, offering efficiency and
                    transparency through clear, interpretable prompts. We also introduce
                    "LLM-Bridge" method to resolve the heterogeneous representation problems
                    between descriptive texts of different modalities. We conduct a series of
                    objective and subjective evaluations on the proposed model, and results
                    indicate that our model surpasses the performance of current state-of-the-art
                    models. Our codes and examples is availble at:
                    https://github.com/WangTooNaive/MozartsTouch
                </p>
            </div>
        </dd>
        <dt><a name="item257">[257]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02803"
                    title="Abstract">arXiv:2405.02803</a> [<a href="/pdf/2405.02803" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02803" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Is Flash Attention Stable?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Golden%2C+A">Alicia Golden</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hsia%2C+S">Samuel Hsia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+F">Fei Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Acun%2C+B">Bilge Acun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hosmer%2C+B">Basil Hosmer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+Y">Yejin Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=DeVito%2C+Z">Zachary DeVito</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Johnson%2C+J">Jeff Johnson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+G">Gu-Yeon Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brooks%2C+D">David Brooks</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Carole-Jean Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">Training large-scale machine learning models poses distinct system
                    challenges, given both the size and complexity of today's workloads. Recently,
                    many organizations training state-of-the-art Generative AI models have reported
                    cases of instability during training, often taking the form of loss spikes.
                    Numeric deviation has emerged as a potential cause of this training
                    instability, although quantifying this is especially challenging given the
                    costly nature of training runs. In this work, we develop a principled approach
                    to understanding the effects of numeric deviation, and construct proxies to put
                    observations into context when downstream effects are difficult to quantify. As
                    a case study, we apply this framework to analyze the widely-adopted Flash
                    Attention optimization. We find that Flash Attention sees roughly an order of
                    magnitude more numeric deviation as compared to Baseline Attention at BF16 when
                    measured during an isolated forward pass. We then use a data-driven analysis
                    based on the Wasserstein Distance to provide upper bounds on how this numeric
                    deviation impacts model weights during training, finding that the numerical
                    deviation present in Flash Attention is 2-5 times less significant than
                    low-precision training.
                </p>
            </div>
        </dd>
        <dt><a name="item258">[258]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02805"
                    title="Abstract">arXiv:2405.02805</a> [<a href="/pdf/2405.02805" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02805" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Verlet Flows: Exact-Likelihood Integrators for Flow-Based
                    Generative Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Erives%2C+E">Ezra Erives</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jing%2C+B">Bowen Jing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jaakkola%2C+T">Tommi Jaakkola</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR AI4DifferentialEqautions In Science workshop 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Approximations in computing model likelihoods with continuous normalizing
                    flows (CNFs) hinder the use of these models for importance sampling of
                    Boltzmann distributions, where exact likelihoods are required. In this work, we
                    present Verlet flows, a class of CNFs on an augmented state-space inspired by
                    symplectic integrators from Hamiltonian dynamics. When used with carefully
                    constructed Taylor-Verlet integrators, Verlet flows provide exact-likelihood
                    generative models which generalize coupled flow architectures from a
                    non-continuous setting while imposing minimal expressivity constraints. On
                    experiments over toy densities, we demonstrate that the variance of the
                    commonly used Hutchinson trace estimator is unsuitable for importance sampling,
                    whereas Verlet flows perform comparably to full autograd trace computations
                    while being significantly faster.
                </p>
            </div>
        </dd>
        <dt><a name="item259">[259]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02807"
                    title="Abstract">arXiv:2405.02807</a> [<a href="/pdf/2405.02807" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02807" title="Download PostScript">ps</a>, <a href="/format/2405.02807"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Kinematic analysis of structural mechanics based on
                    convolutional neural network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Leye Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+X">Xiangxiang Tian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongjun Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 13 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Attempt to use convolutional neural network to achieve kinematic analysis of
                    plane bar structure. Through 3dsMax animation software and OpenCV module,
                    self-build image dataset of geometrically stable system and geometrically
                    unstable system. we construct and train convolutional neural network model
                    based on the TensorFlow and Keras deep learning platform framework. The model
                    achieves 100% accuracy on the training set, validation set, and test set. The
                    accuracy on the additional test set is 93.7%, indicating that convolutional
                    neural network can learn and master the relevant knowledge of kinematic
                    analysis of structural mechanics. In the future, the generalization ability of
                    the model can be improved through the diversity of dataset, which has the
                    potential to surpass human experts for complex structures. Convolutional neural
                    network has certain practical value in the field of kinematic analysis of
                    structural mechanics. Using visualization technology, we reveal how
                    convolutional neural network learns and recognizes structural features. Using
                    pre-trained VGG16 model for feature extraction and fine-tuning, we found that
                    the generalization ability is inferior to the self-built model.
                </p>
            </div>
        </dd>
        <dt><a name="item260">[260]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02808"
                    title="Abstract">arXiv:2405.02808</a> [<a href="/pdf/2405.02808" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02808" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Interactive Tool for Simulating Mid-Air Ultrasound Tactons
                    on the Skin
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lim%2C+C">Chungman Lim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Seifi%2C+H">Hasti Seifi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+G">Gunhyuk Park</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">Mid-air ultrasound haptic technology offers a myriad of temporal and spatial
                    parameters for contactless haptic design. Yet, predicting how these parameters
                    interact to render an ultrasound signal is difficult before testing them on a
                    mid-air ultrasound haptic device. Thus, haptic designers often use a
                    trial-and-error process with different parameter combinations to obtain desired
                    tactile patterns (i.e., Tactons) for user applications. We propose an
                    interactive tool with five temporal and three spatiotemporal design parameters
                    that can simulate the temporal and spectral properties of stimulation at
                    specific skin points. As a preliminary verification, we measured vibrations
                    induced from the ultrasound Tactons varying on one temporal and two
                    spatiotemporal parameters. The measurements and simulation showed similar
                    results for three different ultrasound rendering techniques, suggesting the
                    efficacy of the simulation tool. We present key insights from the simulation
                    and discuss future directions for enhancing the capabilities of simulations.
                </p>
            </div>
        </dd>
        <dt><a name="item261">[261]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02809"
                    title="Abstract">arXiv:2405.02809</a> [<a href="/pdf/2405.02809" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02809" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Does Optimal Control Always Benefit from Better Prediction?
                    An Analysis Framework for Predictive Optimal Control
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Zeng%2C+X">Xiangrui Zeng</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yin%2C+C">Cheng Yin</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yin%2C+Z">Zhouping Yin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">The ``prediction + optimal control'' scheme has shown good performance in
                    many applications of automotive, traffic, robot, and building control. In
                    practice, the prediction results are simply considered correct in the optimal
                    control design process. However, in reality, these predictions may never be
                    perfect. Under a conventional stochastic optimal control formulation, it is
                    difficult to answer questions like ``what if the predictions are wrong''. This
                    paper presents an analysis framework for predictive optimal control where the
                    subjective belief about the future is no longer considered perfect. A novel
                    concept called the hidden prediction state is proposed to establish connections
                    among the predictors, the subjective beliefs, the control policies and the
                    objective control performance. Based on this framework, the predictor
                    evaluation problem is analyzed. Three commonly-used predictor evaluation
                    measures, including the mean squared error, the regret and the log-likelihood,
                    are considered. It is shown that neither using the mean square error nor using
                    the likelihood can guarantee a monotonic relationship between the predictor
                    error and the optimal control cost. To guarantee control cost improvement, it
                    is suggested the predictor should be evaluated with the control performance,
                    e.g., using the optimal control cost or the regret to evaluate predictors.
                    Numerical examples and examples from automotive applications with real-world
                    driving data are provided to illustrate the ideas and the results.
                </p>
            </div>
        </dd>
        <dt><a name="item262">[262]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02810"
                    title="Abstract">arXiv:2405.02810</a> [<a href="/pdf/2405.02810" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02810" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adaptive deep density approximation for stochastic dynamical
                    systems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=He%2C+J">Junjie He</a>,
                    <a href="/search/math?searchtype=author&amp;query=Liao%2C+Q">Qifeng Liao</a>,
                    <a href="/search/math?searchtype=author&amp;query=Wan%2C+X">Xiaoliang Wan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 24 pages, 13 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>; Machine Learning (stat.ML)

                </div>
                <p class="mathjax">In this paper we consider adaptive deep neural network approximation for
                    stochastic dynamical systems. Based on the Liouville equation associated with
                    the stochastic dynamical systems, a new temporal KRnet (tKRnet) is proposed to
                    approximate the probability density functions (PDFs) of the state variables.
                    The tKRnet gives an explicit density model for the solution of the Liouville
                    equation, which alleviates the curse of dimensionality issue that limits the
                    application of traditional grid based numerical methods. To efficiently train
                    the tKRnet, an adaptive procedure is developed to generate collocation points
                    for the corresponding residual loss function, where samples are generated
                    iteratively using the approximate density function at each iteration. A
                    temporal decomposition technique is also employed to improve the long-time
                    integration. Theoretical analysis of our proposed method is provided, and
                    numerical examples are presented to demonstrate its performance.
                </p>
            </div>
        </dd>
        <dt><a name="item263">[263]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02811"
                    title="Abstract">arXiv:2405.02811</a> [<a href="/pdf/2405.02811" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02811" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PVTransformer: Point-to-Voxel Transformer for Scalable 3D
                    Object Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Leng%2C+Z">Zhaoqi Leng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+P">Pei Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+T">Tong He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Anguelov%2C+D">Dragomir Anguelov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tan%2C+M">Mingxing Tan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">3D object detectors for point clouds often rely on a pooling-based PointNet
                    to encode sparse points into grid-like voxels or pillars. In this paper, we
                    identify that the common PointNet design introduces an information bottleneck
                    that limits 3D object detection accuracy and scalability. To address this
                    limitation, we propose PVTransformer: a transformer-based point-to-voxel
                    architecture for 3D detection. Our key idea is to replace the PointNet pooling
                    operation with an attention module, leading to a better point-to-voxel
                    aggregation function. Our design respects the permutation invariance of sparse
                    3D points while being more expressive than the pooling-based PointNet.
                    Experimental results show our PVTransformer achieves much better performance
                    compared to the latest 3D object detectors. On the widely used Waymo Open
                    Dataset, our PVTransformer achieves state-of-the-art 76.5 mAPH L2,
                    outperforming the prior art of SWFormer by +1.7 mAPH L2.
                </p>
            </div>
        </dd>
        <dt><a name="item264">[264]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02813"
                    title="Abstract">arXiv:2405.02813</a> [<a href="/pdf/2405.02813" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02813" title="Download PostScript">ps</a>, <a href="/format/2405.02813"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Model Predictive Control for Joint Ramping and
                    Regulation-Type Service from Distributed Energy Resource Aggregations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Mathias%2C+J">Joel Mathias</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Anguluri%2C+R">Rajasekhar Anguluri</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Kosut%2C+O">Oliver Kosut</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Sankar%2C+L">Lalitha Sankar</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 3 figures, to be presented at IEEE PES GM 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>; Optimization and Control (math.OC)

                </div>
                <p class="mathjax">Distributed energy resources (DERs) such as grid-responsive loads and
                    batteries can be harnessed to provide ramping and regulation services across
                    the grid. This paper concerns the problem of optimal allocation of different
                    classes of DERs, where each class is an aggregation of similar DERs, to balance
                    net-demand forecasts. The resulting resource allocation problem is solved using
                    model-predictive control (MPC) that utilizes a rolling sequence of finite
                    time-horizon constrained optimizations. This is based on the concept that we
                    have more accurate estimates of the load forecast in the short term, so each
                    optimization in the rolling sequence of optimization problems uses more
                    accurate short term load forecasts while ensuring satisfaction of capacity and
                    dynamical constraints. Simulations demonstrate that the MPC solution can indeed
                    reduce the ramping required from bulk generation, while mitigating near-real
                    time grid disturbances.
                </p>
            </div>
        </dd>
        <dt><a name="item265">[265]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02814"
                    title="Abstract">arXiv:2405.02814</a> [<a href="/pdf/2405.02814" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02814" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> NegativePrompt: Leveraging Psychology for Large Language
                    Models Enhancement via Negative Emotional Stimuli
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Cheng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+Y">Yi Chang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jindong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuan Wu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper has been accepted by IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Large Language Models (LLMs) have become integral to a wide spectrum of
                    applications, ranging from traditional computing tasks to advanced artificial
                    intelligence (AI) applications. This widespread adoption has spurred extensive
                    research into LLMs across various disciplines, including the social sciences.
                    Notably, studies have revealed that LLMs possess emotional intelligence, which
                    can be further developed through positive emotional stimuli. This discovery
                    raises an intriguing question: can negative emotions similarly influence LLMs,
                    potentially enhancing their performance? In response to this question, we
                    introduce NegativePrompt, a novel approach underpinned by psychological
                    principles, involving ten specifically designed negative emotional stimuli. We
                    embark on rigorous experimental evaluations of five LLMs including
                    Flan-T5-Large, Vicuna, Llama 2, ChatGPT, and GPT-4, across a set of 45 tasks.
                    The results are revealing: NegativePrompt markedly enhances the performance of
                    LLMs, evidenced by relative improvements of 12.89% in Instruction Induction
                    tasks and 46.25% in BIG-Bench tasks. Moreover, we conduct attention
                    visualization experiments to decipher the underlying mechanisms of
                    NegativePrompt's influence. Our research contributes significantly to the
                    understanding of LLMs and emotion interaction, demonstrating the practical
                    efficacy of NegativePrompt as an emotion-driven method and offering novel
                    insights for the enhancement of LLMs in real-world applications. The code is
                    available at https://github.com/wangxu0820/NegativePrompt.
                </p>
            </div>
        </dd>
        <dt><a name="item266">[266]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02815"
                    title="Abstract">arXiv:2405.02815</a> [<a href="/pdf/2405.02815" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02815" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Region-specific Risk Quantification for Interpretable
                    Prognosis of COVID-19
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zhusi Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jie Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zhuoqi Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Collins%2C+S">Scott Collins</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bai%2C+H">Harrison Bai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+P">Paul Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Healey%2C+T">Terrance Healey</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+X">Xinbo Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Atalay%2C+M+K">Michael K. Atalay</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiao%2C+Z">Zhicheng Jiao</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">The COVID-19 pandemic has strained global public health, necessitating
                    accurate diagnosis and intervention to control disease spread and reduce
                    mortality rates. This paper introduces an interpretable deep survival
                    prediction model designed specifically for improved understanding and trust in
                    COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
                    pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
                    detection techniques, our approach produces regional interpretable outcomes
                    that effectively capture essential disease features while focusing on rare but
                    critical abnormal regions. Our model's predictive results provide enhanced
                    clarity and transparency through risk area localization, enabling clinicians to
                    make informed decisions regarding COVID-19 diagnosis with better understanding
                    of prognostic insights. We evaluate the proposed method on a multi-center
                    survival dataset and demonstrate its effectiveness via quantitative and
                    qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
                    time-dependent AUCs (0.799 and 0.691). These results suggest that our
                    explainable deep survival prediction model surpasses traditional survival
                    analysis methods in risk prediction, improving interpretability for clinical
                    decision making and enhancing AI system trustworthiness.
                </p>
            </div>
        </dd>
        <dt><a name="item267">[267]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02816"
                    title="Abstract">arXiv:2405.02816</a> [<a href="/pdf/2405.02816" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02816" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Stochastic RAG: End-to-End Retrieval-Augmented Generation
                    through Expected Utility Maximization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zamani%2C+H">Hamed Zamani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bendersky%2C+M">Michael Bendersky</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To appear in the proceedings of SIGIR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">This paper introduces Stochastic RAG--a novel approach for end-to-end
                    optimization of retrieval-augmented generation (RAG) models that relaxes the
                    simplifying assumptions of marginalization and document independence, made in
                    most prior work. Stochastic RAG casts the retrieval process in RAG as a
                    stochastic sampling without replacement process. Through this formulation, we
                    employ straight-through Gumbel-top-k that provides a differentiable
                    approximation for sampling without replacement and enables effective end-to-end
                    optimization for RAG. We conduct extensive experiments on seven diverse
                    datasets on a wide range of tasks, from open-domain question answering to fact
                    verification to slot-filling for relation extraction and to dialogue systems.
                    By applying this optimization method to a recent and effective RAG model, we
                    advance state-of-the-art results on six out of seven datasets.
                </p>
            </div>
        </dd>
        <dt><a name="item268">[268]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02817"
                    title="Abstract">arXiv:2405.02817</a> [<a href="/pdf/2405.02817" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02817" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> HuixiangDou-CR: Coreference Resolution in Group Chats
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kong%2C+H">Huanjun Kong</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages, 3 tables, 3 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">How to eliminate pronominal reference in group chats? In this work, we have
                    preprocessed 58k authentic chat data and manually annotated 2.3k questions. The
                    reliability of this annotation was confirmed by the scaling law. After this, we
                    conducted fine-tuning on Qwen models, ranging from 0.5B to 32B parameters. The
                    optimal version improved 29.07 in F1 score. This confirms the viability of
                    fine-tuning Large Language Model (LLM) for downstream Natural Language
                    Processing (NLP) tasks. Our contributions are: 1) Created Supervised
                    Fine-Tuning (SFT) training data in alpaca format, along with a set of Low-Rank
                    Adaptation (LoRA) weights, and 2) Developed a method for acquiring high-quality
                    data leveraging scaling law principle. The script, raw data with alpaca format
                    and experiments track are open-sourced on Github
                    https://github.com/InternLM/HuixiangDou/tree/main/web/tools, HuggingFace
                    https://huggingface.co/tpoisonooo and WandB
                    https://wandb.ai/tpoisonooo/huixiangdou-cr/table?nw=nwusertpoisonooo . The
                    privacy of the data involved has been authorized by users.
                </p>
            </div>
        </dd>
        <dt><a name="item269">[269]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02818"
                    title="Abstract">arXiv:2405.02818</a> [<a href="/pdf/2405.02818" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02818" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Site-Specific Deployment Optimization of Intelligent
                    Reflecting Surface for Coverage Enhancement
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+D">Dongsheng Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xintong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+J">Jiangbin Lyu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+L">Liqun Fu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 7 figures. To appear in VTC2024-Spring
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">Intelligent Reflecting Surface (IRS) is a promising technology for next
                    generation wireless networks. Despite substantial research in IRS-aided
                    communications, the assumed antenna and channel models are typically simplified
                    without considering site-specific characteristics, which in turn critically
                    affect the IRS deployment and performance in a given environment. In this
                    paper, we first investigate the link-level performance of active or passive IRS
                    taking into account the IRS element radiation pattern (ERP) as well as the
                    antenna radiation pattern of the access point (AP). Then the network-level
                    coverage performance is evaluated/optimized in site-specific multi-building
                    scenarios, by properly deploying multiple IRSs on candidate building facets to
                    serve a given set of users or Points of Interests (PoIs). The problem is
                    reduced to an integer linear programming (ILP) based on given link-level
                    metrics, which is then solved efficiently under moderate network sizes.
                    Numerical results confirm the impact of AP antenna/IRS element pattern on the
                    link-level performance. In addition, it is found that active IRSs, though
                    associated with higher hardware complexity and cost, significantly improve the
                    site-specific network coverage performance in terms of average ergodic rate and
                    fairness among the PoIs as well as the range of serving area, compared with
                    passive IRSs that have a much larger number of elements.
                </p>
            </div>
        </dd>
        <dt><a name="item270">[270]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02821"
                    title="Abstract">arXiv:2405.02821</a> [<a href="/pdf/2405.02821" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02821" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Sim2Real Transfer for Audio-Visual Navigation with
                    Frequency-Adaptive Acoustic Field Prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Changan Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ramos%2C+J">Jordi Ramos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tomar%2C+A">Anshul Tomar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Grauman%2C+K">Kristen Grauman</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO); Audio and Speech
                    Processing (eess.AS)

                </div>
                <p class="mathjax">Sim2real transfer has received increasing attention lately due to the success
                    of learning robotic tasks in simulation end-to-end. While there has been a lot
                    of progress in transferring vision-based navigation policies, the existing
                    sim2real strategy for audio-visual navigation performs data augmentation
                    empirically without measuring the acoustic gap. The sound differs from light in
                    that it spans across much wider frequencies and thus requires a different
                    solution for sim2real. We propose the first treatment of sim2real for
                    audio-visual navigation by disentangling it into acoustic field prediction
                    (AFP) and waypoint navigation. We first validate our design choice in the
                    SoundSpaces simulator and show improvement on the Continuous AudioGoal
                    navigation benchmark. We then collect real-world data to measure the spectral
                    difference between the simulation and the real world by training AFP models
                    that only take a specific frequency subband as input. We further propose a
                    frequency-adaptive strategy that intelligently selects the best frequency band
                    for prediction based on both the measured spectral difference and the energy
                    distribution of the received audio, which improves the performance on the real
                    data. Lastly, we build a real robot platform and show that the transferred
                    policy can successfully navigate to sounding objects. This work demonstrates
                    the potential of building intelligent agents that can see, hear, and act
                    entirely from simulation, and transferring them to the real world.
                </p>
            </div>
        </dd>
        <dt><a name="item271">[271]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02823"
                    title="Abstract">arXiv:2405.02823</a> [<a href="/pdf/2405.02823" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02823" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Reconfigurable Massive MIMO: Precoding Design and Channel
                    Estimation in the Electromagnetic Domain
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ying%2C+K">Keke Ying</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zhen Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+Y">Yu Su</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qin%2C+T">Tong Qin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matthaiou%2C+M">Michail Matthaiou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schober%2C+R">Robert Schober</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This work is being submitted to the IEEE for possible
                    publication. Copyright may be transferred without notice, after which this version may no longer be
                    accessible
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">Reconfigurable massive multiple-input multiple-output (RmMIMO) technology
                    offers increased flexibility for future communication systems by exploiting
                    previously untapped degrees of freedom in the electromagnetic (EM) domain. The
                    representation of the traditional spatial domain channel state information
                    (sCSI) limits the insights into the potential of EM domain channel properties,
                    constraining the base station's (BS) utmost capability for precoding design.
                    This paper leverages the EM domain channel state information (eCSI) for
                    radiation pattern design at the BS. We develop an orthogonal decomposition
                    method based on spherical harmonic functions to decompose the radiation pattern
                    into a linear combination of orthogonal bases. By formulating the radiation
                    pattern design as an optimization problem for the projection coefficients over
                    these bases, we develop a manifold optimization-based method for iterative
                    radiation pattern and digital precoder design. To address the eCSI estimation
                    problem, we capitalize on the inherent structure of the channel. Specifically,
                    we propose a subspace-based scheme to reduce the pilot overhead for wideband
                    sCSI estimation. Given the estimated full-band sCSI, we further employ
                    parameterized methods for angle of arrival estimation. Subsequently, the
                    complete eCSI can be reconstructed after estimating the equivalent channel gain
                    via the least squares method. Simulation results demonstrate that, in
                    comparison to traditional mMIMO systems with fixed antenna radiation patterns,
                    the proposed RmMIMO architecture offers significant throughput gains for
                    multi-user transmission at a low channel estimation overhead.
                </p>
            </div>
        </dd>
        <dt><a name="item272">[272]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02824"
                    title="Abstract">arXiv:2405.02824</a> [<a href="/pdf/2405.02824" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02824" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adaptive Guidance Learning for Camouflaged Object Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhennan Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xuying Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiang%2C+T">Tian-Zhu Xiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tai%2C+Y">Ying Tai</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Camouflaged object detection (COD) aims to segment objects visually embedded
                    in their surroundings, which is a very challenging task due to the high
                    similarity between the objects and the background. To address it, most methods
                    often incorporate additional information (e.g., boundary, texture, and
                    frequency clues) to guide feature learning for better detecting camouflaged
                    objects from the background. Although progress has been made, these methods are
                    basically individually tailored to specific auxiliary cues, thus lacking
                    adaptability and not consistently achieving high segmentation performance. To
                    this end, this paper proposes an adaptive guidance learning network, dubbed
                    \textit{AGLNet}, which is a unified end-to-end learnable model for exploring
                    and adapting different additional cues in CNN models to guide accurate
                    camouflaged feature learning. Specifically, we first design a straightforward
                    additional information generation (AIG) module to learn additional camouflaged
                    object cues, which can be adapted for the exploration of effective camouflaged
                    features. Then we present a hierarchical feature combination (HFC) module to
                    deeply integrate additional cues and image features to guide camouflaged
                    feature learning in a multi-level fusion manner.Followed by a recalibration
                    decoder (RD), different features are further aggregated and refined for
                    accurate object prediction. Extensive experiments on three widely used COD
                    benchmark datasets demonstrate that the proposed method achieves significant
                    performance improvements under different additional cues, and outperforms the
                    recent 20 state-of-the-art methods by a large margin. Our code will be made
                    publicly available at: \textcolor{blue}{{https://github.com/ZNan-Chen/AGLNet}}.
                </p>
            </div>
        </dd>
        <dt><a name="item273">[273]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02826"
                    title="Abstract">arXiv:2405.02826</a> [<a href="/pdf/2405.02826" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02826" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Nip in the Bud: Forecasting and Interpreting
                    Post-exploitation Attacks in Real-time through Cyber Threat Intelligence Reports
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+T">Tiantian Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ying%2C+J">Jie Ying</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tieming Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+C">Chunlin Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+W">Wenrui Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Q">Qixuan Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+A">Aohan Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lv%2C+M">Mingqi Lv</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yan Chen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Advanced Persistent Threat (APT) attacks have caused significant damage
                    worldwide. Various Endpoint Detection and Response (EDR) systems are deployed
                    by enterprises to fight against potential threats. However, EDR suffers from
                    high false positives. In order not to affect normal operations, analysts need
                    to investigate and filter detection results before taking countermeasures, in
                    which heavy manual labor and alarm fatigue cause analysts miss optimal response
                    time, thereby leading to information leakage and destruction. Therefore, we
                    propose Endpoint Forecasting and Interpreting (EFI), a real-time attack
                    forecast and interpretation system, which can automatically predict next move
                    during post-exploitation and explain it in technique-level, then dispatch
                    strategies to EDR for advance reinforcement. First, we use Cyber Threat
                    Intelligence (CTI) reports to extract the attack scene graph (ASG) that can be
                    mapped to low-level system logs to strengthen attack samples. Second, we build
                    a serialized graph forecast model, which is combined with the attack provenance
                    graph (APG) provided by EDR to generate an attack forecast graph (AFG) to
                    predict the next move. Finally, we utilize the attack template graph (ATG) and
                    graph alignment plus algorithm for technique-level interpretation to
                    automatically dispatch strategies for EDR to reinforce system in advance. EFI
                    can avoid the impact of existing EDR false positives, and can reduce the attack
                    surface of system without affecting the normal operations. We collect a total
                    of 3,484 CTI reports, generate 1,429 ASGs, label 8,000 sentences, tag 10,451
                    entities, and construct 256 ATGs. Experimental results on both DARPA Engagement
                    and large scale CTI dataset show that the alignment score between the AFG
                    predicted by EFI and the real attack graph is able to exceed 0.8, the forecast
                    and interpretation precision of EFI can reach 91.8%.
                </p>
            </div>
        </dd>
        <dt><a name="item274">[274]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02827"
                    title="Abstract">arXiv:2405.02827</a> [<a href="/pdf/2405.02827" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02827" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Probabilistic tube-based control synthesis of stochastic
                    multi-agent systems under signal temporal logic
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Vlahakis%2C+E+E">Eleftherios E. Vlahakis</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Lindemann%2C+L">Lars Lindemann</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Sopasakis%2C+P">Pantelis Sopasakis</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to CDC24
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">We consider the control design of stochastic discrete-time linear multi-agent
                    systems (MASs) under a global signal temporal logic (STL) specification to be
                    satisfied at a predefined probability. By decomposing the dynamics into
                    deterministic and error components, we construct a probabilistic reachable tube
                    (PRT) as the Cartesian product of reachable sets of the individual error
                    systems driven by disturbances lying in confidence regions (CRs) with a fixed
                    probability. By bounding the PRT probability with the specification
                    probability, we tighten all state constraints induced by the STL specification
                    by solving tractable optimization problems over segments of the PRT, and
                    convert the underlying stochastic problem into a deterministic one. This
                    approach reduces conservatism compared to tightening guided by the STL
                    structure. Additionally, we propose a recursively feasible algorithm to attack
                    the resulting problem by decomposing it into agent-level subproblems, which are
                    solved iteratively according to a scheduling policy. We demonstrate our method
                    on a ten-agent system, where existing approaches are impractical.
                </p>
            </div>
        </dd>
        <dt><a name="item275">[275]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02828"
                    title="Abstract">arXiv:2405.02828</a> [<a href="/pdf/2405.02828" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02828" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Trojans in Large Language Models of Code: A Critical Review
                    through a Trigger-Based Taxonomy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hussain%2C+A">Aftab Hussain</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+T">Toufique Ahmed</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+B">Bowen Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Devanbu%2C+P">Premkumar Devanbu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alipour%2C+M+A">Mohammad Amin Alipour</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a
                        href="/abs/2305.03803">arXiv:2305.03803</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Large language models (LLMs) have provided a lot of exciting new capabilities
                    in software development. However, the opaque nature of these models makes them
                    difficult to reason about and inspect. Their opacity gives rise to potential
                    security risks, as adversaries can train and deploy compromised models to
                    disrupt the software development process in the victims' organization.
                    <br>This work presents an overview of the current state-of-the-art trojan attacks
                    on large language models of code, with a focus on triggers -- the main design
                    point of trojans -- with the aid of a novel unifying trigger taxonomy
                    framework. We also aim to provide a uniform definition of the fundamental
                    concepts in the area of trojans in Code LLMs. Finally, we draw implications of
                    findings on how code models learn on trigger design.
                </p>
            </div>
        </dd>
        <dt><a name="item276">[276]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02829"
                    title="Abstract">arXiv:2405.02829</a> [<a href="/pdf/2405.02829" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02829" title="Download PostScript">ps</a>, <a href="/format/2405.02829"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An FPT Algorithm for the Exact Matching Problem and
                    NP-hardness of Related Problems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Murakami%2C+H">Hitoshi Murakami</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yamaguchi%2C+Y">Yutaro Yamaguchi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Combinatorics (math.CO)

                </div>
                <p class="mathjax">The exact matching problem is a constrained variant of the maximum matching
                    problem: given a graph with each edge having a weight <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-128-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-929"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-930"><span class="mn" id="MathJax-Span-931"
                                                style="font-family: MathJax_Main;">0</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-128">0</script> or <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-129-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-932"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-933"><span class="mn" id="MathJax-Span-934"
                                                style="font-family: MathJax_Main;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-129">1</script> and an integer
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-130-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-935"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-936"><span class="mi" id="MathJax-Span-937"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-130">k</script>, the goal is to find a perfect matching
                    of weight exactly <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-131-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-938"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-939"><span class="mi" id="MathJax-Span-940"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-131">k</script>. Mulmuley,
                    Vazirani, and Vazirani (1987) proposed a randomized polynomial-time algorithm
                    for this problem, and it is still open whether it can be derandomized. Very
                    recently, El Maalouly, Steiner, and Wulf (2023) showed that for bipartite
                    graphs there exists a deterministic FPT algorithm parameterized by the
                    (bipartite) independence number. In this paper, by extending a part of their
                    work, we propose a deterministic FPT algorithm in general parameterized by the
                    minimum size of an odd cycle transversal in addition to the (bipartite)
                    independence number. We also consider a relaxed problem called the correct
                    parity matching problem, and show that a slight generalization of an equivalent
                    problem is NP-hard.
                </p>
            </div>
        </dd>
        <dt><a name="item277">[277]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02830"
                    title="Abstract">arXiv:2405.02830</a> [<a href="/pdf/2405.02830" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02830" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> You Only Need Half: Boosting Data Augmentation by Using
                    Partial Content
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Juntao Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuan Wu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Technical report,16 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">We propose a novel data augmentation method termed You Only Need hAlf (YONA),
                    which simplifies the augmentation process. YONA bisects an image, substitutes
                    one half with noise, and applies data augmentation techniques to the remaining
                    half. This method reduces the redundant information in the original image,
                    encourages neural networks to recognize objects from incomplete views, and
                    significantly enhances neural networks' robustness. YONA is distinguished by
                    its properties of parameter-free, straightforward application, enhancing
                    various existing data augmentation strategies, and thereby bolstering neural
                    networks' robustness without additional computational cost. To demonstrate
                    YONA's efficacy, extensive experiments were carried out. These experiments
                    confirm YONA's compatibility with diverse data augmentation methods and neural
                    network architectures, yielding substantial improvements in CIFAR
                    classification tasks, sometimes outperforming conventional image-level data
                    augmentation methods. Furthermore, YONA markedly increases the resilience of
                    neural networks to adversarial attacks. Additional experiments exploring YONA's
                    variants conclusively show that masking half of an image optimizes performance.
                    The code is available at https://github.com/HansMoe/YONA.
                </p>
            </div>
        </dd>
        <dt><a name="item278">[278]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02832"
                    title="Abstract">arXiv:2405.02832</a> [<a href="/pdf/2405.02832" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02832" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fast One-Stage Unsupervised Domain Adaptive Person Search
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cui%2C+T">Tianxiang Cui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Huibing Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+J">Jinjia Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+R">Ruoxi Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+X">Xianping Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yang Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Unsupervised person search aims to localize a particular target person from a
                    gallery set of scene images without annotations, which is extremely challenging
                    due to the unexpected variations of the unlabeled domains. However, most
                    existing methods dedicate to developing multi-stage models to adapt domain
                    variations while using clustering for iterative model training, which
                    inevitably increases model complexity. To address this issue, we propose a Fast
                    One-stage Unsupervised person Search (FOUS) which complementary integrates
                    domain adaptaion with label adaptaion within an end-to-end manner without
                    iterative clustering. To minimize the domain discrepancy, FOUS introduced an
                    Attention-based Domain Alignment Module (ADAM) which can not only align various
                    domains for both detection and ReID tasks but also construct an attention
                    mechanism to reduce the adverse impacts of low-quality candidates resulting
                    from unsupervised detection. Moreover, to avoid the redundant iterative
                    clustering mode, FOUS adopts a prototype-guided labeling method which minimizes
                    redundant correlation computations for partial samples and assigns noisy coarse
                    label groups efficiently. The coarse label groups will be continuously refined
                    via label-flexible training network with an adaptive selection strategy. With
                    the adapted domains and labels, FOUS can achieve the state-of-the-art (SOTA)
                    performance on two benchmark datasets, CUHK-SYSU and PRW. The code is available
                    at https://github.com/whbdmu/FOUS.
                </p>
            </div>
        </dd>
        <dt><a name="item279">[279]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02834"
                    title="Abstract">arXiv:2405.02834</a> [<a href="/pdf/2405.02834" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02834" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Scene-Adaptive Person Search via Bilateral Modulations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yimin Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Huibing Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+J">Jinjia Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+X">Xianping Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yang Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Person search aims to localize specific a target person from a gallery set of
                    images with various scenes. As the scene of moving pedestrian changes, the
                    captured person image inevitably bring in lots of background noise and
                    foreground noise on the person feature, which are completely unrelated to the
                    person identity, leading to severe performance degeneration. To address this
                    issue, we present a Scene-Adaptive Person Search (SEAS) model by introducing
                    bilateral modulations to simultaneously eliminate scene noise and maintain a
                    consistent person representation to adapt to various scenes. In SEAS, a
                    Background Modulation Network (BMN) is designed to encode the feature extracted
                    from the detected bounding box into a multi-granularity embedding, which
                    reduces the input of background noise from multiple levels with norm-aware.
                    Additionally, to mitigate the effect of foreground noise on the person feature,
                    SEAS introduces a Foreground Modulation Network (FMN) to compute the clutter
                    reduction offset for the person embedding based on the feature map of the scene
                    image. By bilateral modulations on both background and foreground within an
                    end-to-end manner, SEAS obtains consistent feature representations without
                    scene noise. SEAS can achieve state-of-the-art (SOTA) performance on two
                    benchmark datasets, CUHK-SYSU with 97.1\% mAP and PRW with 60.5\% mAP. The code
                    is available at https://github.com/whbdmu/SEAS.
                </p>
            </div>
        </dd>
        <dt><a name="item280">[280]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02835"
                    title="Abstract">arXiv:2405.02835</a> [<a href="/pdf/2405.02835" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02835" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Algorithmic collusion in a two-sided market: A rideshare
                    example
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Koirala%2C+P">Pravesh Koirala</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Laine%2C+F">Forrest Laine</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

                </div>
                <p class="mathjax">With dynamic pricing on the rise, firms are using sophisticated algorithms
                    for price determination. These algorithms are often non-interpretable and there
                    has been a recent interest in their seemingly emergent ability to tacitly
                    collude with each other without any prior communication whatsoever. Most of the
                    previous works investigate algorithmic collusion on simple reinforcement
                    learning (RL) based algorithms operating on a basic market model. Instead, we
                    explore the collusive tendencies of Proximal Policy Optimization (PPO), a
                    state-of-the-art continuous state/action space RL algorithm, on a complex
                    double-sided hierarchical market model of rideshare. For this purpose, we
                    extend a mathematical program network (MPN) based rideshare model to a temporal
                    multi origin-destination setting and use PPO to solve for a repeated duopoly
                    game. Our results indicate that PPO can either converge to a competitive or a
                    collusive equilibrium depending upon the underlying market characteristics,
                    even when the hyper-parameters are held constant.
                </p>
            </div>
        </dd>
        <dt><a name="item281">[281]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02841"
                    title="Abstract">arXiv:2405.02841</a> [<a href="/pdf/2405.02841" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02841" title="Download PostScript">ps</a>, <a href="/format/2405.02841"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Two-weight rank-metric codes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zullo%2C+F">Ferdinando Zullo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Polverino%2C+O">Olga Polverino</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Santonastaso%2C+P">Paolo Santonastaso</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sheekey%2C+J">John Sheekey</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for publication in ISIT 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Combinatorics (math.CO)

                </div>
                <p class="mathjax">Two-weight linear codes are linear codes in which any nonzero codeword can
                    have only two possible distinct weights. Those in the Hamming metric have
                    proven to be very interesting for their connections with authentication codes,
                    association schemes, strongly regular graphs, and secret sharing schemes. In
                    this paper, we characterize two-weight codes in the rank metric, answering a
                    recent question posed by Pratihar and Randrianarisoa.
                </p>
            </div>
        </dd>
        <dt><a name="item282">[282]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02842"
                    title="Abstract">arXiv:2405.02842</a> [<a href="/pdf/2405.02842" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02842" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> IceFormer: Accelerated Inference with Long-Sequence
                    Transformers on CPUs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yuzhen Mao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ester%2C+M">Martin Ester</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+K">Ke Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">One limitation of existing Transformer-based models is that they cannot
                    handle very long sequences as input since their self-attention operations
                    exhibit quadratic time and space complexity. This problem becomes especially
                    acute when Transformers are deployed on hardware platforms equipped only with
                    CPUs. To address this issue, we propose a novel method for accelerating
                    self-attention at inference time that works with pretrained Transformer models
                    out-of-the-box without requiring retraining. We experiment using our method to
                    accelerate various long-sequence Transformers, including a leading LLaMA
                    2-based LLM, on various benchmarks and demonstrate a greater speedup of 2.73x -
                    7.63x while retaining 98.6% - 99.6% of the accuracy of the original pretrained
                    models. The code is available on our project website at
                    https://yuzhenmao.github.io/IceFormer/.
                </p>
            </div>
        </dd>
        <dt><a name="item283">[283]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02843"
                    title="Abstract">arXiv:2405.02843</a> [<a href="/pdf/2405.02843" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02843" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Residual-Conditioned Optimal Transport: Towards
                    Structure-preserving Unpaired and Paired Image Restoration
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+X">Xiaole Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xin Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+X">Xiang Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jian Sun</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Deep learning-based image restoration methods have achieved promising
                    performance. However, how to faithfully preserve the structure of the original
                    image remains challenging. To address this challenge, we propose a novel
                    Residual-Conditioned Optimal Transport (RCOT) approach, which models the image
                    restoration as an optimal transport (OT) problem for both unpaired and paired
                    settings, integrating the transport residual as a unique degradation-specific
                    cue for both the transport cost and the transport map. Specifically, we first
                    formalize a Fourier residual-guided OT objective by incorporating the
                    degradation-specific information of the residual into the transport cost. Based
                    on the dual form of the OT formulation, we design the transport map as a
                    two-pass RCOT map that comprises a base model and a refinement process, in
                    which the transport residual is computed by the base model in the first pass
                    and then encoded as a degradation-specific embedding to condition the
                    second-pass restoration. By duality, the RCOT problem is transformed into a
                    minimax optimization problem, which can be solved by adversarially training
                    neural networks. Extensive experiments on multiple restoration tasks show the
                    effectiveness of our approach in terms of both distortion measures and
                    perceptual quality. Particularly, RCOT restores images with more faithful
                    structural details compared to state-of-the-art methods.
                </p>
            </div>
        </dd>
        <dt><a name="item284">[284]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02844"
                    title="Abstract">arXiv:2405.02844</a> [<a href="/pdf/2405.02844" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02844" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SMCD: High Realism Motion Style Transfer via Mamba-based
                    Diffusion
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Qian%2C+Z">Ziyun Qian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+Z">Zeyu Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhenyi Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+D">Dingkang Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Mingcheng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shunli Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuaibing Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kou%2C+D">Dongliang Kou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lihua Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Motion style transfer is a significant research direction in multimedia
                    applications. It enables the rapid switching of different styles of the same
                    motion for virtual digital humans, thus vastly increasing the diversity and
                    realism of movements. It is widely applied in multimedia scenarios such as
                    movies, games, and the Metaverse. However, most of the current work in this
                    field adopts the GAN, which may lead to instability and convergence issues,
                    making the final generated motion sequence somewhat chaotic and unable to
                    reflect a highly realistic and natural style. To address these problems, we
                    consider style motion as a condition and propose the Style Motion Conditioned
                    Diffusion (SMCD) framework for the first time, which can more comprehensively
                    learn the style features of motion. Moreover, we apply Mamba model for the
                    first time in the motion style transfer field, introducing the Motion Style
                    Mamba (MSM) module to handle longer motion sequences. Thirdly, aiming at the
                    SMCD framework, we propose Diffusion-based Content Consistency Loss and Content
                    Consistency Loss to assist the overall framework's training. Finally, we
                    conduct extensive experiments. The results reveal that our method surpasses
                    state-of-the-art methods in both qualitative and quantitative comparisons,
                    capable of generating more realistic motion sequences.
                </p>
            </div>
        </dd>
        <dt><a name="item285">[285]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02845"
                    title="Abstract">arXiv:2405.02845</a> [<a href="/pdf/2405.02845" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02845" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Data-Efficient Molecular Generation with Hierarchical Textual
                    Inversion
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+S">Seojin Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nam%2C+J">Jaehyun Nam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+S">Sihyun Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shin%2C+Y">Younghoon Shin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shin%2C+J">Jinwoo Shin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Molecular Networks (q-bio.MN)

                </div>
                <p class="mathjax">Developing an effective molecular generation framework even with a limited
                    number of molecules is often important for its practical deployment, e.g., drug
                    discovery, since acquiring task-related molecular data requires expensive and
                    time-consuming experimental costs. To tackle this issue, we introduce
                    Hierarchical textual Inversion for Molecular generation (HI-Mol), a novel
                    data-efficient molecular generation method. HI-Mol is inspired by the
                    importance of hierarchical information, e.g., both coarse- and fine-grained
                    features, in understanding the molecule distribution. We propose to use
                    multi-level embeddings to reflect such hierarchical features based on the
                    adoption of the recent textual inversion technique in the visual domain, which
                    achieves data-efficient image generation. Compared to the conventional textual
                    inversion method in the image domain using a single-level token embedding, our
                    multi-level token embeddings allow the model to effectively learn the
                    underlying low-shot molecule distribution. We then generate molecules based on
                    the interpolation of the multi-level token embeddings. Extensive experiments
                    demonstrate the superiority of HI-Mol with notable data-efficiency. For
                    instance, on QM9, HI-Mol outperforms the prior state-of-the-art method with 50x
                    less training data. We also show the effectiveness of molecules generated by
                    HI-Mol in low-shot molecular property prediction.
                </p>
            </div>
        </dd>
        <dt><a name="item286">[286]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02846"
                    title="Abstract">arXiv:2405.02846</a> [<a href="/pdf/2405.02846" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02846" title="Download PostScript">ps</a>, <a href="/format/2405.02846"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Responsible AI: Portraits with Intelligent Bibliometrics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+M">Mengjia Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guangquan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+J">Jie Lu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">Shifting the focus from principles to practical implementation, responsible
                    artificial intelligence (AI) has garnered considerable attention across
                    academia, industry, and society at large. Despite being in its nascent stages,
                    this emerging field grapples with nebulous concepts and intricate knowledge
                    frameworks. By analyzing three prevailing concepts - explainable AI,
                    trustworthy AI, and ethical AI, this study defined responsible AI and
                    identified its core principles. Methodologically, this study successfully
                    demonstrated the implementation of leveraging AI's capabilities into
                    bibliometrics for enhanced knowledge discovery and the cross-validation of
                    experimentally examined models with domain insights. Empirically, this study
                    investigated 17,799 research articles contributed by the AI community since
                    2015. This involves recognizing key technological players and their
                    relationships, unveiling the topical landscape and hierarchy of responsible AI,
                    charting its evolution, and elucidating the interplay between the
                    responsibility principles and primary AI techniques. An analysis of a core
                    cohort comprising 380 articles from multiple disciplines captures the most
                    recent advancements in responsible AI. As one of the pioneering bibliometric
                    studies dedicated to exploring responsible AI, this study will provide
                    comprehensive macro-level insights, enhancing the understanding of responsible
                    AI while furnishing valuable knowledge support for AI regulation and governance
                    initiatives.
                </p>
            </div>
        </dd>
        <dt><a name="item287">[287]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02850"
                    title="Abstract">arXiv:2405.02850</a> [<a href="/pdf/2405.02850" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02850" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Halfway Escape Optimization: A Quantum-Inspired Solution for
                    Complex Optimization Problems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jiawen Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Majeed%2C+A+P+A">Anwar PP Abdul Majeed</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lefevre%2C+P">Pascal Lefevre</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

                </div>
                <p class="mathjax">This paper first proposes the Halfway Escape Optimization (HEO) algorithm, a
                    novel quantum-inspired metaheuristic designed to address complex optimization
                    problems characterized by rugged landscapes and high-dimensionality with an
                    efficient convergence rate. The study presents a comprehensive comparative
                    evaluation of HEO's performance against established optimization algorithms,
                    including Particle Swarm Optimization (PSO), Genetic Algorithm (GA), Artificial
                    Fish Swarm Algorithm (AFSA), Grey Wolf Optimizer (GWO), and Quantum behaved
                    Particle Swarm Optimization (QPSO). The primary analysis encompasses 14
                    benchmark functions with dimension 30, demonstrating HEO's effectiveness and
                    adaptability in navigating complex optimization landscapes and providing
                    valuable insights into its performance. The simple test of HEO in Traveling
                    Salesman Problem (TSP) also infers its feasibility in real-time applications.
                </p>
            </div>
        </dd>
        <dt><a name="item288">[288]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02858"
                    title="Abstract">arXiv:2405.02858</a> [<a href="/pdf/2405.02858" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02858" title="Download PostScript">ps</a>, <a href="/format/2405.02858"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Language Evolution for Evading Social Media Regulation via
                    LLM-based Multi-agent Simulation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+J">Jinyu Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jialong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Mingyue Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Munan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chen-Shu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tei%2C+K">Kenji Tei</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IEEE WCCI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information
                        Networks (cs.SI)</span>; Computation and Language (cs.CL)

                </div>
                <p class="mathjax">Social media platforms such as Twitter, Reddit, and Sina Weibo play a crucial
                    role in global communication but often encounter strict regulations in
                    geopolitically sensitive regions. This situation has prompted users to
                    ingeniously modify their way of communicating, frequently resorting to coded
                    language in these regulated social media environments. This shift in
                    communication is not merely a strategy to counteract regulation, but a vivid
                    manifestation of language evolution, demonstrating how language naturally
                    evolves under societal and technological pressures. Studying the evolution of
                    language in regulated social media contexts is of significant importance for
                    ensuring freedom of speech, optimizing content moderation, and advancing
                    linguistic research. This paper proposes a multi-agent simulation framework
                    using Large Language Models (LLMs) to explore the evolution of user language in
                    regulated social media environments. The framework employs LLM-driven agents:
                    supervisory agent who enforce dialogue supervision and participant agents who
                    evolve their language strategies while engaging in conversation, simulating the
                    evolution of communication styles under strict regulations aimed at evading
                    social media regulation. The study evaluates the framework's effectiveness
                    through a range of scenarios from abstract scenarios to real-world situations.
                    Key findings indicate that LLMs are capable of simulating nuanced language
                    dynamics and interactions in constrained settings, showing improvement in both
                    evading supervision and information accuracy as evolution progresses.
                    Furthermore, it was found that LLM agents adopt different strategies for
                    different scenarios.
                </p>
            </div>
        </dd>
        <dt><a name="item289">[289]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02859"
                    title="Abstract">arXiv:2405.02859</a> [<a href="/pdf/2405.02859" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02859" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MVIP-NeRF: Multi-view 3D Inpainting on NeRF Scenes via
                    Diffusion Prior
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Honghua Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Loy%2C+C+C">Chen Change Loy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pan%2C+X">Xingang Pan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 10 figures, conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Despite the emergence of successful NeRF inpainting methods built upon
                    explicit RGB and depth 2D inpainting supervisions, these methods are inherently
                    constrained by the capabilities of their underlying 2D inpainters. This is due
                    to two key reasons: (i) independently inpainting constituent images results in
                    view-inconsistent imagery, and (ii) 2D inpainters struggle to ensure
                    high-quality geometry completion and alignment with inpainted RGB images.
                    <br>To overcome these limitations, we propose a novel approach called MVIP-NeRF
                    that harnesses the potential of diffusion priors for NeRF inpainting,
                    addressing both appearance and geometry aspects. MVIP-NeRF performs joint
                    inpainting across multiple views to reach a consistent solution, which is
                    achieved via an iterative optimization process based on Score Distillation
                    Sampling (SDS). Apart from recovering the rendered RGB images, we also extract
                    normal maps as a geometric representation and define a normal SDS loss that
                    motivates accurate geometry inpainting and alignment with the appearance.
                    Additionally, we formulate a multi-view SDS score function to distill
                    generative priors simultaneously from different view images, ensuring
                    consistent visual completion when dealing with large view variations. Our
                    experimental results show better appearance and geometry recovery than previous
                    NeRF inpainting methods.
                </p>
            </div>
        </dd>
        <dt><a name="item290">[290]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02861"
                    title="Abstract">arXiv:2405.02861</a> [<a href="/pdf/2405.02861" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02861" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Revisiting a Pain in the Neck: Semantic Phrase Processing
                    Benchmark for Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qin%2C+M+X">Melissa Xiaohui Qin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Hongming Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+C">Chao Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 24 pages, 17 figures, 10 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">We introduce LexBench, a comprehensive evaluation suite enabled to test
                    language models (LMs) on ten semantic phrase processing tasks. Unlike prior
                    studies, it is the first work to propose a framework from the comparative
                    perspective to model the general semantic phrase (i.e., lexical collocation)
                    and three fine-grained semantic phrases, including idiomatic expression, noun
                    compound, and verbal construction. Thanks to \ourbenchmark, we assess the
                    performance of 15 LMs across model architectures and parameter scales in
                    classification, extraction, and interpretation tasks. Through the experiments,
                    we first validate the scaling law and find that, as expected, large models
                    excel better than the smaller ones in most tasks. Second, we investigate
                    further through the scaling semantic relation categorization and find that
                    few-shot LMs still lag behind vanilla fine-tuned models in the task. Third,
                    through human evaluation, we find that the performance of strong models is
                    comparable to the human level regarding semantic phrase processing. Our
                    benchmarking findings can serve future research aiming to improve the generic
                    capability of LMs on semantic phrase comprehension. Our source code and data
                    are available at https://github.com/jacklanda/LexBench
                </p>
            </div>
        </dd>
        <dt><a name="item291">[291]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02865"
                    title="Abstract">arXiv:2405.02865</a> [<a href="/pdf/2405.02865" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02865" title="Download PostScript">ps</a>, <a href="/format/2405.02865"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Non cooperative Liquidity Games and their application to bond
                    market trading
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Vidler%2C+A">Alicia Vidler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Walsh%2C+T">Toby Walsh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>; Trading and Market Microstructure (q-fin.TR)

                </div>
                <p class="mathjax">We present a new type of game, the Liquidity Game. We draw inspiration from
                    the UK government bond market and apply game theoretic approaches to its
                    analysis. In Liquidity Games, market participants (agents) use non-cooperative
                    games where the players' utility is directly defined by the liquidity of the
                    game itself, offering a paradigm shift in our understanding of market dynamics.
                    Each player's utility is intricately linked to the liquidity generated within
                    the game, making the utility endogenous and dynamic. Players are not just
                    passive recipients of utility based on external factors but active participants
                    whose strategies and actions collectively shape and are shaped by the liquidity
                    of the market. This reflexivity introduces a level of complexity and realism
                    previously unattainable in conventional models.
                    <br>We apply Liquidity Game theoretic approaches to a simple UK bond market
                    interaction and present results for market design and strategic behavior of
                    participants. We tackle one of the largest issues within this mechanism, namely
                    what strategy should market makers utilize when uncertain about the type of
                    market maker they are interacting with, and what structure might regulators
                    wish to see.
                </p>
            </div>
        </dd>
        <dt><a name="item292">[292]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02867"
                    title="Abstract">arXiv:2405.02867</a> [<a href="/pdf/2405.02867" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02867" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Practices, Challenges, and Opportunities When Inferring
                    Requirements From Regulations in the FinTech Sector - An Industrial Study
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Elahidoost%2C+P">Parisa Elahidoost</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mendez%2C+D">Daniel Mendez</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fischbach%2C+J">Jannik Fischbach</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feiler%2C+C">Christian Feiler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Streit%2C+J">Jonathan Streit</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">[Context and motivation]: Understanding and interpreting regulatory norms and
                    inferring software requirements from them is a critical step towards regulatory
                    compliance, a matter of significant importance in various industrial sectors.
                    [Question/ problem]: However, interpreting regulations still largely depends on
                    individual legal expertise and experience within the respective domain, with
                    little to no systematic methodologies and supportive tools to guide this
                    practice. In fact, research in this area is too often detached from
                    practitioners' experiences, rendering the proposed solutions not transferable
                    to industrial practice. As we argue, one reason is that we still lack a
                    profound understanding of industry- and domain-specific practices and
                    challenges. [Principal ideas/ results]: We aim to close this gap and provide
                    such an investigation at the example of the banking and insurance domain. We
                    conduct an industrial multi-case study as part of a long-term academia-industry
                    collaboration with a medium-sized software development and renovation company.
                    We explore contemporary industrial practices and challenges when inferring
                    requirements from regulations to support more problem-driven research. Our
                    study investigates the complexities of requirement engineering in regulatory
                    contexts, pinpointing various issues and discussing them in detail. We
                    highlight the gathered insights and the practical challenges encountered and
                    suggest avenues for future research. [Contribution]: Our contribution is a
                    comprehensive case study focused on the FinTech domain, offering a detailed
                    understanding of the specific needs within this sector. We have identified key
                    practices for managing regulatory requirements in software development, and
                    have pinpointed several challenges. We conclude by offering a set of
                    recommendations for future problem-driven research directions.
                </p>
            </div>
        </dd>
        <dt><a name="item293">[293]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02868"
                    title="Abstract">arXiv:2405.02868</a> [<a href="/pdf/2405.02868" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02868" title="Download PostScript">ps</a>, <a href="/format/2405.02868"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Continuous Monitoring for Road Flooding With Satellite
                    Onboard Computing For Navigation for OrbitalAI Φsat-2 challenge
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Vatsal%2C+V">Vishesh Vatsal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nandi%2C+G">Gouranga Nandi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Manilal%2C+P">Primo Manilal</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Continuous monitoring for road flooding could be achieved through onboard
                    computing of satellite imagery to generate near real-time insights made
                    available to generate dynamic information for maps used for navigation. Given
                    the existing computing hardware like the one considered for the PhiSat-2
                    mission, the paper describes the feasibility of running the road flooding
                    detection. The simulated onboard imagery dataset development and its annotation
                    process for the OrbitalAI {\Phi}sat-2 challenge is described. The flooding
                    events in the city of Bengaluru, India were considered for this challenge. This
                    is followed by the model architecture selection, training, optimization and
                    accuracy results for the model. The results indicate that it is possible to
                    build low size, high accuracy models for the road flooding use case.
                </p>
            </div>
        </dd>
        <dt><a name="item294">[294]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02872"
                    title="Abstract">arXiv:2405.02872</a> [<a href="/pdf/2405.02872" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02872" title="Download PostScript">ps</a>, <a href="/format/2405.02872"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The weighted and shifted seven-step BDF method for parabolic
                    equations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Akrivis%2C+G">Georgios Akrivis</a>,
                    <a href="/search/math?searchtype=author&amp;query=Chen%2C+M">Minghua Chen</a>,
                    <a href="/search/math?searchtype=author&amp;query=Yu%2C+F">Fan Yu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 23 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">Stability of the BDF methods of order up to five for parabolic equations can
                    be established by the energy technique via Nevanlinna--Odeh multipliers. The
                    nonexistence of Nevanlinna--Odeh multipliers makes the six-step BDF method
                    special; however, the energy technique was recently extended by the authors in
                    [Akrivis et al., SIAM J. Numer. Anal. \textbf{59} (2021) 2449--2472] and covers
                    all six stable BDF methods. The seven-step BDF method is unstable for parabolic
                    equations, since it is not even zero-stable. In this work, we construct and
                    analyze a stable linear combination of two non zero-stable schemes, the
                    seven-step BDF method and its shifted counterpart, referred to as WSBDF7
                    method. The stability regions of the WSBDF<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-132-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-941"
                                style="width: 3.938em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.244em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.623em, 1003.24em, 2.839em, -999.997em); top: -2.486em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-942"><span class="mi" id="MathJax-Span-943"
                                                style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-944"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-945"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-946"
                                                style="font-family: MathJax_AMS; padding-left: 0.292em;">⩽</span><span
                                                class="mn" id="MathJax-Span-947"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">7</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.491em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-132">q, q\leqslant 7</script>, with a weight
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-133-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-948"
                                style="width: 2.954em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.433em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.623em, 1002.38em, 2.781em, -999.997em); top: -2.486em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-949"><span class="mi" id="MathJax-Span-950"
                                                style="font-family: MathJax_Math-italic;">ϑ</span><span class="mo"
                                                id="MathJax-Span-951"
                                                style="font-family: MathJax_AMS; padding-left: 0.292em;">⩾</span><span
                                                class="mn" id="MathJax-Span-952"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.491em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-133">\vartheta\geqslant1</script>, increase as <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-134-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-953"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-954"><span class="mi" id="MathJax-Span-955"
                                                style="font-family: MathJax_Math-italic;">ϑ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-134">\vartheta</script> increases, are larger than the
                    stability regions of the classical BDF<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-135-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-956"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.7em, 2.491em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-957"><span class="mi" id="MathJax-Span-958"
                                                style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-959"
                                                style="font-family: MathJax_Main;">,</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-135">q,</script> corresponding to <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-136-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-960"
                                style="width: 2.954em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.433em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.38em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-961"><span class="mi" id="MathJax-Span-962"
                                                style="font-family: MathJax_Math-italic;">ϑ</span><span class="mo"
                                                id="MathJax-Span-963"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mn" id="MathJax-Span-964"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-136">\vartheta=1</script>. We
                    determine novel and suitable multipliers for the WSBDF7 method and establish
                    stability for parabolic equations by the energy technique. The proposed
                    approach is applicable for mean curvature flow, gradient flows, fractional
                    equations and nonlinear equations.
                </p>
            </div>
        </dd>
        <dt><a name="item295">[295]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02875"
                    title="Abstract">arXiv:2405.02875</a> [<a href="/pdf/2405.02875" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02875" title="Download PostScript">ps</a>, <a href="/format/2405.02875"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Insights Gained after a Decade of Cellular Automata-based
                    Cryptography
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mariot%2C+L">Luca Mariot</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 20 pages, 2 figures. Invited paper at AUTOMATA 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Cellular Automata (CA) have been extensively used to implement symmetric
                    cryptographic primitives, such as pseudorandom number generators and S-boxes.
                    However, most of the research in this field, except the very early works, seems
                    to be published in non-cryptographic venues. This phenomenon poses a problem of
                    relevance: are CA of any use to cryptographers nowadays? This paper provides
                    insights into this question by briefly outlining the history of CA-based
                    cryptography. In doing so, the paper identifies some shortcomings in the
                    research addressing the design of symmetric primitives exclusively from a CA
                    standpoint, alongside some recommendations for future research. Notably, the
                    paper remarks that researchers working in CA and cryptography often tackle
                    similar problems, albeit under different perspectives and terminologies. This
                    observation indicates that there is still ample room for fruitful
                    collaborations between the CA and cryptography communities in the future.
                </p>
            </div>
        </dd>
        <dt><a name="item296">[296]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02876"
                    title="Abstract">arXiv:2405.02876</a> [<a href="/pdf/2405.02876" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02876" title="Download PostScript">ps</a>, <a href="/format/2405.02876"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring the Improvement of Evolutionary Computation via
                    Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+J">Jinyu Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jinglue Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jialong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ymauchi%2C+T">Takuto Ymauchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Iba%2C+H">Hitoshi Iba</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tei%2C+K">Kenji Tei</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> accepted by GECCO 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Evolutionary computation (EC), as a powerful optimization algorithm, has been
                    applied across various domains. However, as the complexity of problems
                    increases, the limitations of EC have become more apparent. The advent of large
                    language models (LLMs) has not only transformed natural language processing but
                    also extended their capabilities to diverse fields. By harnessing LLMs' vast
                    knowledge and adaptive capabilities, we provide a forward-looking overview of
                    potential improvements LLMs can bring to EC, focusing on the algorithms
                    themselves, population design, and additional enhancements. This presents a
                    promising direction for future research at the intersection of LLMs and EC.
                </p>
            </div>
        </dd>
        <dt><a name="item297">[297]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02880"
                    title="Abstract">arXiv:2405.02880</a> [<a href="/pdf/2405.02880" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02880" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Blending Distributed NeRFs with Tri-stage Robust Pose
                    Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+B">Baijun Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Caiyun Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+X">Xiaoyu Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuantao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuhai Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Z">Zike Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yongliang Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+H">Hao Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+G">Guyue Zhou</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Robotics (cs.RO)

                </div>
                <p class="mathjax">Due to the limited model capacity, leveraging distributed Neural Radiance
                    Fields (NeRFs) for modeling extensive urban environments has become a
                    necessity. However, current distributed NeRF registration approaches encounter
                    aliasing artifacts, arising from discrepancies in rendering resolutions and
                    suboptimal pose precision. These factors collectively deteriorate the fidelity
                    of pose estimation within NeRF frameworks, resulting in occlusion artifacts
                    during the NeRF blending stage. In this paper, we present a distributed NeRF
                    system with tri-stage pose optimization. In the first stage, precise poses of
                    images are achieved by bundle adjusting Mip-NeRF 360 with a coarse-to-fine
                    strategy. In the second stage, we incorporate the inverting Mip-NeRF 360,
                    coupled with the truncated dynamic low-pass filter, to enable the achievement
                    of robust and precise poses, termed Frame2Model optimization. On top of this,
                    we obtain a coarse transformation between NeRFs in different coordinate
                    systems. In the third stage, we fine-tune the transformation between NeRFs by
                    Model2Model pose optimization. After obtaining precise transformation
                    parameters, we proceed to implement NeRF blending, showcasing superior
                    performance metrics in both real-world and simulation scenarios. Codes and data
                    will be publicly available at https://github.com/boilcy/Distributed-NeRF.
                </p>
            </div>
        </dd>
        <dt><a name="item298">[298]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02881"
                    title="Abstract">arXiv:2405.02881</a> [<a href="/pdf/2405.02881" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02881" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FedConPE: Efficient Federated Conversational Bandits with
                    Heterogeneous Clients
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuohua Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+M">Maoli Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lui%2C+J+C+S">John C.S. Lui</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in the 33rd International Joint Conference on
                    Artificial Intelligence (IJCAI), 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

                </div>
                <p class="mathjax">Conversational recommender systems have emerged as a potent solution for
                    efficiently eliciting user preferences. These systems interactively present
                    queries associated with "key terms" to users and leverage user feedback to
                    estimate user preferences more efficiently. Nonetheless, most existing
                    algorithms adopt a centralized approach. In this paper, we introduce FedConPE,
                    a phase elimination-based federated conversational bandit algorithm, where <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-137-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-965"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1001.04em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-966"><span class="mi" id="MathJax-Span-967"
                                                style="font-family: MathJax_Math-italic;">M<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-137">M</script>
                    agents collaboratively solve a global contextual linear bandit problem with the
                    help of a central server while ensuring secure data management. To effectively
                    coordinate all the clients and aggregate their collected data, FedConPE uses an
                    adaptive approach to construct key terms that minimize uncertainty across all
                    dimensions in the feature space. Furthermore, compared with existing federated
                    linear bandit algorithms, FedConPE offers improved computational and
                    communication efficiency as well as enhanced privacy protections. Our
                    theoretical analysis shows that FedConPE is minimax near-optimal in terms of
                    cumulative regret. We also establish upper bounds for communication costs and
                    conversation frequency. Comprehensive evaluations demonstrate that FedConPE
                    outperforms existing conversational bandit algorithms while using fewer
                    conversations.
                </p>
            </div>
        </dd>
        <dt><a name="item299">[299]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02882"
                    title="Abstract">arXiv:2405.02882</a> [<a href="/pdf/2405.02882" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02882" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A drone detector with modified backbone and multiple pyramid
                    featuremaps enhancement structure (MDDPE)
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Chenhao Wu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 20 pages, 10 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">This work presents a drone detector with modified backbone and multiple
                    pyramid feature maps enhancement structure (MDDPE). Novel feature maps improve
                    modules that uses different levels of information to produce more robust and
                    discriminatory features is proposed. These module includes the feature maps
                    supplement function and the feature maps recombination enhancement function.To
                    effectively handle the drone characteristics, auxiliary supervisions that are
                    implemented in the early stages by employing tailored anchors designed are
                    utilized. To further improve the modeling of real drone detection scenarios and
                    initialization of the regressor, an updated anchor matching technique is
                    introduced to match anchors and ground truth drone as closely as feasible. To
                    show the proposed MDDPE's superiority over the most advanced detectors,
                    extensive experiments are carried out using well-known drone detection
                    benchmarks.
                </p>
            </div>
        </dd>
        <dt><a name="item300">[300]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02887"
                    title="Abstract">arXiv:2405.02887</a> [<a href="/pdf/2405.02887" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02887" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Sentiment Analysis Across Languages: Evaluation Before and
                    After Machine Translation to English
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kathunia%2C+A">Aekansh Kathunia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kaif%2C+M">Mohammad Kaif</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Arora%2C+N">Nalin Arora</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Narotam%2C+N">N Narotam</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages, 3 Figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">People communicate in more than 7,000 languages around the world, with around
                    780 languages spoken in India alone. Despite this linguistic diversity,
                    research on Sentiment Analysis has predominantly focused on English text data,
                    resulting in a disproportionate availability of sentiment resources for
                    English. This paper examines the performance of transformer models in Sentiment
                    Analysis tasks across multilingual datasets and text that has undergone machine
                    translation. By comparing the effectiveness of these models in different
                    linguistic contexts, we gain insights into their performance variations and
                    potential implications for sentiment analysis across diverse languages. We also
                    discuss the shortcomings and potential for future work towards the end.
                </p>
            </div>
        </dd>
        <dt><a name="item301">[301]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02893"
                    title="Abstract">arXiv:2405.02893</a> [<a href="/pdf/2405.02893" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02893" title="Download PostScript">ps</a>, <a href="/format/2405.02893"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring the ethical sensitivity of Ph.D. students in
                    robotics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Battistuzzi%2C+L">Linda Battistuzzi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Grassi%2C+L">Lucrezia Grassi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sgorbissa%2C+A">Antonio Sgorbissa</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>

                </div>
                <p class="mathjax">Ethical sensitivity, generally defined as a person's ability to recognize
                    ethical issues and attribute importance to them, is considered to be a crucial
                    competency in the life of professionals and academics and an essential
                    prerequisite to successfully meeting ethical challenges. A concept that first
                    emerged in moral psychology almost 40 years ago, ethical sensitivity has been
                    widely studied in healthcare, business, and other domains. Conversely, it
                    appears to have received little to no attention within the robotics community,
                    even though choices in the design and deployment of robots are likely to have
                    wide-ranging, profound ethical impacts on society. Due to the negative
                    repercussions that a lack of ethical sensitivity can have in these contexts,
                    promoting the development of ethical sensitivity among roboticists is
                    imperative, and endeavoring to train this competency becomes a critical
                    undertaking. Therefore, as a first step in this direction and within the
                    context of a broader effort aimed at developing an online interactive ethics
                    training module for roboticists, we conducted a qualitative exploration of the
                    ethical sensitivity of a sample of Ph.D. students in robotics using case
                    vignettes that exemplified ethical tensions in disaster robotics.
                </p>
            </div>
        </dd>
        <dt><a name="item302">[302]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02897"
                    title="Abstract">arXiv:2405.02897</a> [<a href="/pdf/2405.02897" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02897" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DexiTac: Soft Dexterous Tactile Gripping
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+C">Chenghua Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+K">Kailuan Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+M">Max Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yue%2C+T">Tianqi Yue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lepora%2C+N+F">Nathan F. Lepora</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 12 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Grasping object,whether they are flat, round, or narrow and whether they have
                    regular or irregular shapes,introduces difficulties in determining the ideal
                    grasping posture, even for the most state-of-the-art grippers. In this article,
                    we presented a reconfigurable pneumatic gripper with fingers that could be set
                    in various configurations, such as hooking, supporting, closuring, and
                    pinching. Each finger incorporates a dexterous joint, a rotating joint, and a
                    customized plug-and-play visuotactile sensor, the DigiTac-v1.5, to control
                    manipulation in real time. We propose a tactile kernel density manipulation
                    strategy for simple and versatile control, including detecting grasp stability,
                    responding to disturbances and guiding dexterous manipulations. We develop a
                    double closed-loop control system that separately focuses on secure grasping
                    and task management, demonstrated with tasks that highlight the capabilities
                    above. The gripper is relatively easy to fabricate and customize, offering a
                    promising and extensible way to combine soft dexterity and tactile sensing for
                    diverse applications in robotic manipulation.
                </p>
            </div>
        </dd>
        <dt><a name="item303">[303]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02903"
                    title="Abstract">arXiv:2405.02903</a> [<a href="/pdf/2405.02903" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02903" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Predicting Open-Hole Laminates Failure Using Support Vector
                    Machines With Classical and Quantum Kernels
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Balducci%2C+G+T">Giorgio Tosti Balducci</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Boyang Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=M%C3%B6ller%2C+M">Matthias Möller</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gerritsma%2C+M">Marc Gerritsma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=De+Breuker%2C+R">Roeland De Breuker</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">Modeling open hole failure of composites is a complex task, consisting in a
                    highly nonlinear response with interacting failure modes. Numerical modeling of
                    this phenomenon has traditionally been based on the finite element method, but
                    requires to tradeoff between high fidelity and computational cost. To mitigate
                    this shortcoming, recent work has leveraged machine learning to predict the
                    strength of open hole composite specimens. Here, we also propose using
                    data-based models but to tackle open hole composite failure from a
                    classification point of view. More specifically, we show how to train surrogate
                    models to learn the ultimate failure envelope of an open hole composite plate
                    under in-plane loading. To achieve this, we solve the classification problem
                    via support vector machine (SVM) and test different classifiers by changing the
                    SVM kernel function. The flexibility of kernel-based SVM also allows us to
                    integrate the recently developed quantum kernels in our algorithm and compare
                    them with the standard radial basis function (RBF) kernel. Finally, thanks to
                    kernel-target alignment optimization, we tune the free parameters of all
                    kernels to best separate safe and failure-inducing loading states. The results
                    show classification accuracies higher than 90% for RBF, especially after
                    alignment, followed closely by the quantum kernel classifiers.
                </p>
            </div>
        </dd>
        <dt><a name="item304">[304]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02904"
                    title="Abstract">arXiv:2405.02904</a> [<a href="/pdf/2405.02904" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02904" title="Download PostScript">ps</a>, <a href="/format/2405.02904"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Distributed Structured Matrix Multiplication
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Malak%2C+D">Derya Malak</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Proc., IEEE ISIT 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">We devise achievable encoding schemes for distributed source compression for
                    computing inner products, symmetric matrix products, and more generally, square
                    matrix products, which are a class of nonlinear transformations. To that end,
                    our approach relies on devising nonlinear mappings of distributed sources,
                    which are then followed by the structured linear encoding scheme, introduced by
                    K\"orner and Marton. For different computation scenarios, we contrast our
                    findings on the achievable sum rate with the state of the art to demonstrate
                    the possible savings in compression rate. When the sources have special
                    correlation structures, it is possible to achieve unbounded gains, as
                    demonstrated by the analysis and numerical simulations.
                </p>
            </div>
        </dd>
        <dt><a name="item305">[305]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02906"
                    title="Abstract">arXiv:2405.02906</a> [<a href="/pdf/2405.02906" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02906" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SalFAU-Net: Saliency Fusion Attention U-Net for Salient
                    Object Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mulat%2C+K+A">Kassaw Abraham Mulat</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Z">Zhengyong Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eshetie%2C+T+S">Tegegne Solomon Eshetie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hasen%2C+A+E">Ahmed Endris Hasen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Salient object detection (SOD) remains an important task in computer vision,
                    with applications ranging from image segmentation to autonomous driving. Fully
                    convolutional network (FCN)-based methods have made remarkable progress in
                    visual saliency detection over the last few decades. However, these methods
                    have limitations in accurately detecting salient objects, particularly in
                    challenging scenes with multiple objects, small objects, or objects with low
                    resolutions. To address this issue, we proposed a Saliency Fusion Attention
                    U-Net (SalFAU-Net) model, which incorporates a saliency fusion module into each
                    decoder block of the attention U-net model to generate saliency probability
                    maps from each decoder block. SalFAU-Net employs an attention mechanism to
                    selectively focus on the most informative regions of an image and suppress
                    non-salient regions. We train SalFAU-Net on the DUTS dataset using a binary
                    cross-entropy loss function. We conducted experiments on six popular SOD
                    evaluation datasets to evaluate the effectiveness of the proposed method. The
                    experimental results demonstrate that our method, SalFAU-Net, achieves
                    competitive performance compared to other methods in terms of mean absolute
                    error (MAE), F-measure, s-measure, and e-measure.
                </p>
            </div>
        </dd>
        <dt><a name="item306">[306]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02911"
                    title="Abstract">arXiv:2405.02911</a> [<a href="/pdf/2405.02911" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02911" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multimodal Sense-Informed Prediction of 3D Human Motions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lou%2C+Z">Zhenyu Lou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cui%2C+Q">Qiongjie Cui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haofan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+X">Xu Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hong Zhou</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Predicting future human pose is a fundamental application for machine
                    intelligence, which drives robots to plan their behavior and paths ahead of
                    time to seamlessly accomplish human-robot collaboration in real-world 3D
                    scenarios. Despite encouraging results, existing approaches rarely consider the
                    effects of the external scene on the motion sequence, leading to pronounced
                    artifacts and physical implausibilities in the predictions. To address this
                    limitation, this work introduces a novel multi-modal sense-informed motion
                    prediction approach, which conditions high-fidelity generation on two modal
                    information: external 3D scene, and internal human gaze, and is able to
                    recognize their salience for future human activity. Furthermore, the gaze
                    information is regarded as the human intention, and combined with both motion
                    and scene features, we construct a ternary intention-aware attention to
                    supervise the generation to match where the human wants to reach. Meanwhile, we
                    introduce semantic coherence-aware attention to explicitly distinguish the
                    salient point clouds and the underlying ones, to ensure a reasonable
                    interaction of the generated sequence with the 3D scene. On two real-world
                    benchmarks, the proposed method achieves state-of-the-art performance both in
                    3D human pose and trajectory prediction.
                </p>
            </div>
        </dd>
        <dt><a name="item307">[307]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02913"
                    title="Abstract">arXiv:2405.02913</a> [<a href="/pdf/2405.02913" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02913" title="Download PostScript">ps</a>, <a href="/format/2405.02913"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fast TILs estimation in lung cancer WSIs based on
                    semi-stochastic patch sampling
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shvetsov%2C+N">Nikita Shvetsov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sildnes%2C+A">Anders Sildnes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Busund%2C+L+R">Lill-Tove Rasmussen Busund</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dalen%2C+S">Stig Dalen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=M%C3%B8llersen%2C+K">Kajsa Møllersen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bongo%2C+L+A">Lars Ailo Bongo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kilvaer%2C+T+K">Thomas K. Kilvaer</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages, 7 figures, 6 appendix pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Addressing the critical need for accurate prognostic biomarkers in cancer
                    treatment, quantifying tumor-infiltrating lymphocytes (TILs) in non-small cell
                    lung cancer (NSCLC) presents considerable challenges. Manual TIL quantification
                    in whole slide images (WSIs) is laborious and subject to variability,
                    potentially undermining patient outcomes. Our study introduces an automated
                    pipeline that utilizes semi-stochastic patch sampling, patch classification to
                    retain prognostically relevant patches, and cell quantification using the
                    HoVer-Net model to streamline the TIL evaluation process. This pipeline
                    efficiently excludes approximately 70% of areas not relevant for prognosis and
                    requires only 5% of the remaining patches to maintain prognostic accuracy
                    (c-index 0.65 +- 0.01). The computational efficiency achieved does not
                    sacrifice prognostic accuracy, as demonstrated by the TILs score's strong
                    correlation with patient survival, which surpasses traditional CD8 IHC scoring
                    methods. While the pipeline demonstrates potential for enhancing NSCLC
                    prognostication and personalization of treatment, comprehensive clinical
                    validation is still required. Future research should focus on verifying its
                    broader clinical utility and investigating additional biomarkers to improve
                    NSCLC prognosis.
                </p>
            </div>
        </dd>
        <dt><a name="item308">[308]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02914"
                    title="Abstract">arXiv:2405.02914</a> [<a href="/pdf/2405.02914" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02914" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Simulation of Optical Tactile Sensors Supporting Slip and
                    Rotation using Path Tracing and IMPM
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Z">Zirong Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuhao Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shixin Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zixi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+H">Heyi Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+F">Fuchun Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+B">Bin Fang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Optical tactile sensors are extensively utilized in intelligent robot
                    manipulation due to their ability to acquire high-resolution tactile
                    information at a lower cost. However, achieving adequate reality and
                    versatility in simulating optical tactile sensors is challenging. In this
                    paper, we propose a simulation method and validate its effectiveness through
                    experiments. We utilize path tracing for image rendering, achieving higher
                    similarity to real data than the baseline method in simulating pressing
                    scenarios. Additionally, we apply the improved Material Point Method(IMPM)
                    algorithm to simulate the relative rest between the object and the elastomer
                    surface when the object is in motion, enabling more accurate simulation of
                    complex manipulations such as slip and rotation.
                </p>
            </div>
        </dd>
        <dt><a name="item309">[309]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02917"
                    title="Abstract">arXiv:2405.02917</a> [<a href="/pdf/2405.02917" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02917" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Overconfidence is Key: Verbalized Uncertainty Evaluation in
                    Large Language and Vision-Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Groot%2C+T">Tobias Groot</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Valdenegro-Toro%2C+M">Matias Valdenegro-Toro</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, with appendix. To appear in TrustNLP workshop @
                    NAACL 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Language and Vision-Language Models (LLMs/VLMs) have revolutionized the field
                    of AI by their ability to generate human-like text and understand images, but
                    ensuring their reliability is crucial. This paper aims to evaluate the ability
                    of LLMs (GPT4, GPT-3.5, LLaMA2, and PaLM 2) and VLMs (GPT4V and Gemini Pro
                    Vision) to estimate their verbalized uncertainty via prompting. We propose the
                    new Japanese Uncertain Scenes (JUS) dataset, aimed at testing VLM capabilities
                    via difficult queries and object counting, and the Net Calibration Error (NCE)
                    to measure direction of miscalibration. Results show that both LLMs and VLMs
                    have a high calibration error and are overconfident most of the time,
                    indicating a poor capability for uncertainty estimation. Additionally we
                    develop prompts for regression tasks, and we show that VLMs have poor
                    calibration when producing mean/standard deviation and 95% confidence
                    intervals.
                </p>
            </div>
        </dd>
        <dt><a name="item310">[310]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02918"
                    title="Abstract">arXiv:2405.02918</a> [<a href="/pdf/2405.02918" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02918" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MERIT: Multi-view Evidential learning for Reliable and
                    Interpretable liver fibrosis sTaging
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuanye Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zheyao Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+N">Nannan Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+F">Fuping Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuxin Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qingchao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+X">Xiahai Zhuang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to Medical Image Analysis
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Accurate staging of liver fibrosis from magnetic resonance imaging (MRI) is
                    crucial in clinical practice. While conventional methods often focus on a
                    specific sub-region, multi-view learning captures more information by analyzing
                    multiple patches simultaneously. However, previous multi-view approaches could
                    not typically calculate uncertainty by nature, and they generally integrate
                    features from different views in a black-box fashion, hence compromising
                    reliability as well as interpretability of the resulting models. In this work,
                    we propose a new multi-view method based on evidential learning, referred to as
                    MERIT, which tackles the two challenges in a unified framework. MERIT enables
                    uncertainty quantification of the predictions to enhance reliability, and
                    employs a logic-based combination rule to improve interpretability.
                    Specifically, MERIT models the prediction from each sub-view as an opinion with
                    quantified uncertainty under the guidance of the subjective logic theory.
                    Furthermore, a distribution-aware base rate is introduced to enhance
                    performance, particularly in scenarios involving class distribution shifts.
                    Finally, MERIT adopts a feature-specific combination rule to explicitly fuse
                    multi-view predictions, thereby enhancing interpretability. Results have
                    showcased the effectiveness of the proposed MERIT, highlighting the reliability
                    and offering both ad-hoc and post-hoc interpretability. They also illustrate
                    that MERIT can elucidate the significance of each view in the decision-making
                    process for liver fibrosis staging.
                </p>
            </div>
        </dd>
        <dt><a name="item311">[311]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02922"
                    title="Abstract">arXiv:2405.02922</a> [<a href="/pdf/2405.02922" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02922" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Easy over Hard: A Simple Baseline for Test Failures Causes
                    Prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zhipeng Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+Z">Zhipeng Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xing Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shang%2C+W">Weiyi Shang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+X">Xin Xia</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">The test failure causes analysis is critical since it determines the
                    subsequent way of handling different types of bugs, which is the prerequisite
                    to get the bugs properly analyzed and fixed. After a test case fails, software
                    testers have to inspect the test execution logs line by line to identify its
                    root cause. However, manual root cause determination is often tedious and
                    time-consuming, which can cost 30-40% of the time needed to fix a problem.
                    Therefore, there is a need for automatically predicting the test failure causes
                    to lighten the burden of software testers. In this paper, we present a simple
                    but hard-to-beat approach, named NCChecker to automatically identify the
                    failure causes for failed test logs. Our approach can help developers
                    efficiently identify the test failure causes, and flag the most probable log
                    lines of indicating the root causes for investigation. Our approach has three
                    main stages: log abstraction, lookup table construction, and failure causes
                    prediction. We first perform log abstraction to parse the unstructured log
                    messages into structured log events. NCChecker then automatically maintains and
                    updates a lookup table via employing our heuristic rules, which record the
                    matching score between different log events and test failure causes. When it
                    comes to the failure cause prediction stage, for a newly generated failed test
                    log, NCChecker can easily infer its failed reason by checking out the
                    associated log events' scores from the lookup table. We have developed a
                    prototype and evaluated our tool on a real-world industrial dataset with more
                    than 10K test logs. The extensive experiments show the promising performance of
                    our model over a set of benchmarks. Moreover, our approach is highly efficient
                    and memory-saving, and can successfully handle the data imbalance problem.
                </p>
            </div>
        </dd>
        <dt><a name="item312">[312]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02923"
                    title="Abstract">arXiv:2405.02923</a> [<a href="/pdf/2405.02923" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02923" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Constructing <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-138-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-968"
                                style="width: 2.826em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.363em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.299em, 1002.27em, 2.549em, -999.998em); top: -2.174em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-969"><span class="mo" id="MathJax-Span-970"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-971"
                                                style="font-family: MathJax_Math-italic;">h</span><span class="mo"
                                                id="MathJax-Span-972" style="font-family: MathJax_Main;">,</span><span
                                                class="mi" id="MathJax-Span-973"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.188em;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span
                                                class="mo" id="MathJax-Span-974"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.178em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left: 0px solid; width: 0px; height: 1.336em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-138">(h,d)</script> cooperative MSR codes with
                    sub-packetization <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-139-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-975"
                                style="width: 13.845em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 11.53em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1011.53em, 2.549em, -999.998em); top: -2.174em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-976"><span class="mo" id="MathJax-Span-977"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-978" style="font-family: MathJax_Math-italic;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span
                                                class="mo" id="MathJax-Span-979"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mi" id="MathJax-Span-980"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">k</span><span
                                                class="mo" id="MathJax-Span-981"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mi" id="MathJax-Span-982"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">h</span><span
                                                class="mo" id="MathJax-Span-983"
                                                style="font-family: MathJax_Main;">)</span><span class="mo"
                                                id="MathJax-Span-984" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-985"
                                                style="font-family: MathJax_Math-italic;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span
                                                class="mo" id="MathJax-Span-986"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mi" id="MathJax-Span-987"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">k</span><span
                                                class="mo" id="MathJax-Span-988"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mn" id="MathJax-Span-989"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">1</span><span
                                                class="msubsup" id="MathJax-Span-990"><span
                                                    style="display: inline-block; position: relative; width: 2.225em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.104em, 1000.28em, 4.354em, -999.998em); top: -3.979em; left: 0em;"><span
                                                            class="mo" id="MathJax-Span-991"
                                                            style="font-family: MathJax_Main;">)</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span
                                                        style="position: absolute; top: -4.35em; left: 0.373em;"><span
                                                            class="texatom" id="MathJax-Span-992"><span class="mrow"
                                                                id="MathJax-Span-993"><span class="mo"
                                                                    id="MathJax-Span-994"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">⌈</span><span
                                                                    class="mi" id="MathJax-Span-995"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                                    class="texatom" id="MathJax-Span-996"><span
                                                                        class="mrow" id="MathJax-Span-997"><span
                                                                            class="mo" id="MathJax-Span-998"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="mn" id="MathJax-Span-999"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                                    class="mo" id="MathJax-Span-1000"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">⌉</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.178em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left: 0px solid; width: 0px; height: 1.503em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-139">(d-k+h)(d-k+1)^{\lceil n/2 \rceil}</script>
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zihao Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guodong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+S">Sihuang Hu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">We address the multi-node failure repair challenges for MDS array codes.
                    Presently, two primary models are employed for multi-node repairs: the
                    centralized model where all failed nodes are restored in a singular data
                    center, and the cooperative model where failed nodes acquire data from
                    auxiliary nodes and collaborate amongst themselves for the repair process.This
                    paper focuses on the cooperative model, and we provide explicit constructions
                    of optimal MDS array codes with <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-140-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1001"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1002"><span class="mi" id="MathJax-Span-1003"
                                                style="font-family: MathJax_Math-italic;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-140">d</script> helper nodes under this model. The
                    sub-packetization level of our new codes is <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-141-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1004"
                                style="width: 13.834em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 11.519em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1011.52em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1005"><span class="mo" id="MathJax-Span-1006"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1007" style="font-family: MathJax_Math-italic;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1008"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mi" id="MathJax-Span-1009"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">k</span><span
                                                class="mo" id="MathJax-Span-1010"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mi" id="MathJax-Span-1011"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">h</span><span
                                                class="mo" id="MathJax-Span-1012"
                                                style="font-family: MathJax_Main;">)</span><span class="mo"
                                                id="MathJax-Span-1013" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-1014"
                                                style="font-family: MathJax_Math-italic;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1015"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mi" id="MathJax-Span-1016"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">k</span><span
                                                class="mo" id="MathJax-Span-1017"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mn" id="MathJax-Span-1018"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">1</span><span
                                                class="msubsup" id="MathJax-Span-1019"><span
                                                    style="display: inline-block; position: relative; width: 2.202em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.07em, 1000.29em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mo" id="MathJax-Span-1020"
                                                            style="font-family: MathJax_Main;">)</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="texatom" id="MathJax-Span-1021"><span class="mrow"
                                                                id="MathJax-Span-1022"><span class="mo"
                                                                    id="MathJax-Span-1023"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">⌈</span><span
                                                                    class="mi" id="MathJax-Span-1024"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                                    class="texatom" id="MathJax-Span-1025"><span
                                                                        class="mrow" id="MathJax-Span-1026"><span
                                                                            class="mo" id="MathJax-Span-1027"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="mn" id="MathJax-Span-1028"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                                    class="mo" id="MathJax-Span-1029"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">⌉</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.531em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-141">(d-k+h)(d-k+1)^{\lceil n/2
    \rceil}</script> where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-142-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1030"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1031"><span class="mi" id="MathJax-Span-1032"
                                                style="font-family: MathJax_Math-italic;">h</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-142">h</script> is the number of failed nodes, <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-143-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1033"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1034"><span class="mi" id="MathJax-Span-1035"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-143">k</script> the number of information
                    nodes and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-144-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1036"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1037"><span class="mi" id="MathJax-Span-1038"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-144">n</script> the code length. This improves upon
                    recent constructions given by
                    Liu \emph{et al.} (IEEE Transactions on Information Theory, Vol. 69, 2023).
                </p>
            </div>
        </dd>
        <dt><a name="item313">[313]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02924"
                    title="Abstract">arXiv:2405.02924</a> [<a href="/pdf/2405.02924" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02924" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Optimal Sampling for Uncertainty-of-Information Minimization
                    in a Remote Monitoring System
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaomeng Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+A">Aimin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+S">Shaohua Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">In this paper, we study a remote monitoring system where a receiver observes
                    a remote binary Markov source and decides whether to sample and fetch the
                    source's state over a randomly delayed channel. Due to transmission delay, the
                    observation of the source is imperfect, resulting in the uncertainty of the
                    source's state at the receiver. We thus use uncertainty of information as the
                    metric to characterize the performance of the system. Measured by Shannon's
                    entropy, uncertainty of information reflects how much we do not know about the
                    latest source's state in the absence of new information. The current research
                    for uncertainty of information idealizes the transmission delay as one time
                    slot, but not under random delay. Moreover, uncertainty of information varies
                    with the latest observation of the source's state, making it different from
                    other age of information related functions. Motivated by the above reasons, we
                    formulate a uncertainty of information minimization problem under random delay.
                    Typically, such a problem which takes actions based on the imperfect
                    observations can be modeled as a partially observed Markov decision process. By
                    introducing belief state, we transform this process into a semi-Markov decision
                    process. To solve this problem, we first provide an optimal sampling policy
                    employing a two layered bisection relative value iteration algorithm.
                    Furthermore, we propose a sub-optimal index policy with low complexity based on
                    the special properties of belief state. Numerical simulations illustrate that
                    both of the proposed sampling policies outperforms two other benchmarks.
                    Moreover, the performance of the sub-optimal policy approaches to that of the
                    optimal policy, particularly under large delay.
                </p>
            </div>
        </dd>
        <dt><a name="item314">[314]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02925"
                    title="Abstract">arXiv:2405.02925</a> [<a href="/pdf/2405.02925" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02925" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Two-Stage Prediction-Aware Contrastive Learning Framework
                    for Multi-Intent NLU
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+G">Guanhua Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yutong Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wong%2C+D+F">Derek F. Wong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chao%2C+L+S">Lidia S. Chao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> LREC-COLING 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Multi-intent natural language understanding (NLU) presents a formidable
                    challenge due to the model confusion arising from multiple intents within a
                    single utterance. While previous works train the model contrastively to
                    increase the margin between different multi-intent labels, they are less suited
                    to the nuances of multi-intent NLU. They ignore the rich information between
                    the shared intents, which is beneficial to constructing a better embedding
                    space, especially in low-data scenarios. We introduce a two-stage
                    Prediction-Aware Contrastive Learning (PACL) framework for multi-intent NLU to
                    harness this valuable knowledge. Our approach capitalizes on shared intent
                    information by integrating word-level pre-training and prediction-aware
                    contrastive fine-tuning. We construct a pre-training dataset using a word-level
                    data augmentation strategy. Subsequently, our framework dynamically assigns
                    roles to instances during contrastive fine-tuning while introducing a
                    prediction-aware contrastive loss to maximize the impact of contrastive
                    learning. We present experimental results and empirical analysis conducted on
                    three widely used datasets, demonstrating that our method surpasses the
                    performance of three prominent baselines on both low-data and full-data
                    scenarios.
                </p>
            </div>
        </dd>
        <dt><a name="item315">[315]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02929"
                    title="Abstract">arXiv:2405.02929</a> [<a href="/pdf/2405.02929" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02929" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unified Dynamic Scanpath Predictors Outperform Individually
                    Trained Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Abawi%2C+F">Fares Abawi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+D">Di Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wermter%2C+S">Stefan Wermter</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Previous research on scanpath prediction has mainly focused on group models,
                    disregarding the fact that the scanpaths and attentional behaviors of
                    individuals are diverse. The disregard of these differences is especially
                    detrimental to social human-robot interaction, whereby robots commonly emulate
                    human gaze based on heuristics or predefined patterns. However, human gaze
                    patterns are heterogeneous and varying behaviors can significantly affect the
                    outcomes of such human-robot interactions. To fill this gap, we developed a
                    deep learning-based social cue integration model for saliency prediction to
                    instead predict scanpaths in videos. Our model learned scanpaths by recursively
                    integrating fixation history and social cues through a gating mechanism and
                    sequential attention. We evaluated our approach on gaze datasets of dynamic
                    social scenes, observed under the free-viewing condition. The introduction of
                    fixation history into our models makes it possible to train a single unified
                    model rather than the resource-intensive approach of training individual models
                    for each set of scanpaths. We observed that the late neural integration
                    approach surpasses early fusion when training models on a large dataset, in
                    comparison to a smaller dataset with a similar distribution. Results also
                    indicate that a single unified model, trained on all the observers' scanpaths,
                    performs on par or better than individually trained models. We hypothesize that
                    this outcome is a result of the group saliency representations instilling
                    universal attention in the model, while the supervisory signal guides it to
                    learn personalized attentional behaviors, providing the unified model a benefit
                    over individual models due to its implicit representation of universal
                    attention.
                </p>
            </div>
        </dd>
        <dt><a name="item316">[316]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02931"
                    title="Abstract">arXiv:2405.02931</a> [<a href="/pdf/2405.02931" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02931" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Optimal Signals and Detectors Based on Correlation and Energy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Marciano%2C+Y">Yossi Marciano</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Merhav%2C+N">Neri Merhav</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 27 pages, 5 figures; submitted for publication
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">In continuation of an earlier study, we explore a Neymann-Pearson hypothesis
                    testing scenario where, under the null hypothesis (<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-145-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1039"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.28em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1040"><span class="msubsup"
                                                id="MathJax-Span-1041"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.81em, 4.227em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1042"><span class="mrow"
                                                                id="MathJax-Span-1043"><span class="mi"
                                                                    id="MathJax-Span-1044"
                                                                    style="font-family: MathJax_Caligraphic;">H</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-1045"
                                                            style="font-size: 70.7%; font-family: MathJax_Caligraphic;">0</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-145">\cal{H}_0</script>), the received
                    signal is a white noise process <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-146-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1046"
                                style="width: 1.392em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.16em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1047"><span class="msubsup"
                                                id="MathJax-Span-1048"><span
                                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1049"
                                                            style="font-family: MathJax_Math-italic;">N<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-1050"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-146">N_t</script>, which is not Gaussian in general, and
                    under the alternative hypothesis (<span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-147-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1051"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.28em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1052"><span class="msubsup"
                                                id="MathJax-Span-1053"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.81em, 4.227em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1054"><span class="mrow"
                                                                id="MathJax-Span-1055"><span class="mi"
                                                                    id="MathJax-Span-1056"
                                                                    style="font-family: MathJax_Caligraphic;">H</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.871em;"><span
                                                            class="mn" id="MathJax-Span-1057"
                                                            style="font-size: 70.7%; font-family: MathJax_Caligraphic;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-147">\cal{H}_1</script>), the received signal comprises
                    a
                    deterministic transmitted signal <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-148-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1058"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.35em, 1000.81em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1059"><span class="msubsup"
                                                id="MathJax-Span-1060"><span
                                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1061"
                                                            style="font-family: MathJax_Math-italic;">s</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.466em;"><span
                                                            class="mi" id="MathJax-Span-1062"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.837em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-148">s_t</script> corrupted by additive white noise, the
                    sum of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-149-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1063"
                                style="width: 1.392em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.16em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1064"><span class="msubsup"
                                                id="MathJax-Span-1065"><span
                                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1066"
                                                            style="font-family: MathJax_Math-italic;">N<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-1067"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-149">N_t</script> and another noise process originating
                    from the transmitter,
                    denoted as <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-150-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1068"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.04em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1069"><span class="msubsup"
                                                id="MathJax-Span-1070"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.7em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1071"
                                                            style="font-family: MathJax_Math-italic;">Z<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mi" id="MathJax-Span-1072"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-150">Z_t</script>, which is not necessarily Gaussian
                    either. Our approach
                    focuses on detectors that are based on the correlation and energy of the
                    received signal, which are motivated by implementation simplicity. We optimize
                    the detector parameters to achieve the best trade-off between missed-detection
                    and false-alarm error exponents. First, we optimize the detectors for a given
                    signal, resulting in a non-linear relation between the signal and correlator
                    weights to be optimized. Subsequently, we optimize the transmitted signal and
                    the detector parameters jointly, revealing that the optimal signal is a
                    balanced ternary signal and the correlator has at most three different
                    coefficients, thus facilitating a computationally feasible solution.
                </p>
            </div>
        </dd>
        <dt><a name="item317">[317]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02933"
                    title="Abstract">arXiv:2405.02933</a> [<a href="/pdf/2405.02933" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02933" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Relay Decoding: Concatenating Large Language Models for
                    Machine Translation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+C">Chengpeng Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+X">Xiaocheng Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yichong Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huo%2C+W">Wenshuai Huo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Baohang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hui Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qin%2C+B">Bin Qin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Ting Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Work in progress
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Leveraging large language models for machine translation has demonstrated
                    promising results. However, it does require the large language models to
                    possess the capability of handling both the source and target languages in
                    machine translation. When it is challenging to find large models that support
                    the desired languages, resorting to continuous learning methods becomes a
                    costly endeavor. To mitigate these expenses, we propose an innovative approach
                    called RD (Relay Decoding), which entails concatenating two distinct large
                    models that individually support the source and target languages. By
                    incorporating a simple mapping layer to facilitate the connection between these
                    two models and utilizing a limited amount of parallel data for training, we
                    successfully achieve superior results in the machine translation task.
                    Experimental results conducted on the Multi30k and WikiMatrix datasets validate
                    the effectiveness of our proposed method.
                </p>
            </div>
        </dd>
        <dt><a name="item318">[318]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02935"
                    title="Abstract">arXiv:2405.02935</a> [<a href="/pdf/2405.02935" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02935" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enabling Patient-side Disease Prediction via the Integration
                    of Patient Narratives
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+Z">Zhixiang Su</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yinan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jing%2C+J">Jiazheng Jing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jie Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Z">Zhiqi Shen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Disease prediction holds considerable significance in modern healthcare,
                    because of its crucial role in facilitating early intervention and implementing
                    effective prevention measures. However, most recent disease prediction
                    approaches heavily rely on laboratory test outcomes (e.g., blood tests and
                    medical imaging from X-rays). Gaining access to such data for precise disease
                    prediction is often a complex task from the standpoint of a patient and is
                    always only available post-patient consultation. To make disease prediction
                    available from patient-side, we propose Personalized Medical Disease Prediction
                    (PoMP), which predicts diseases using patient health narratives including
                    textual descriptions and demographic information. By applying PoMP, patients
                    can gain a clearer comprehension of their conditions, empowering them to
                    directly seek appropriate medical specialists and thereby reducing the time
                    spent navigating healthcare communication to locate suitable doctors. We
                    conducted extensive experiments using real-world data from Haodf to showcase
                    the effectiveness of PoMP.
                </p>
            </div>
        </dd>
        <dt><a name="item319">[319]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02936"
                    title="Abstract">arXiv:2405.02936</a> [<a href="/pdf/2405.02936" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02936" title="Download PostScript">ps</a>, <a href="/format/2405.02936"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the tractability of SHAP explanations under Markovian
                    distributions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Marzouk%2C+R">Reda Marzouk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=de+La+Higuera%2C+C">Colin de La Higuera</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at ICML'24 (This version is a pre-print)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Thanks to its solid theoretical foundation, the SHAP framework is arguably
                    one the most widely utilized frameworks for local explainability of ML models.
                    Despite its popularity, its exact computation is known to be very challenging,
                    proven to be NP-Hard in various configurations. Recent works have unveiled
                    positive complexity results regarding the computation of the SHAP score for
                    specific model families, encompassing decision trees, random forests, and some
                    classes of boolean circuits. Yet, all these positive results hinge on the
                    assumption of feature independence, often simplistic in real-world scenarios.
                    In this article, we investigate the computational complexity of the SHAP score
                    by relaxing this assumption and introducing a Markovian perspective. We show
                    that, under the Markovian assumption, computing the SHAP score for the class of
                    Weighted automata, Disjoint DNFs and Decision Trees can be performed in
                    polynomial time, offering a first positive complexity result for the problem of
                    SHAP score computation that transcends the limitations of the feature
                    independence assumption.
                </p>
            </div>
        </dd>
        <dt><a name="item320">[320]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02937"
                    title="Abstract">arXiv:2405.02937</a> [<a href="/pdf/2405.02937" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02937" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unraveling the Dominance of Large Language Models Over
                    Transformer Models for Bangla Natural Language Inference: A Comprehensive Study
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Faria%2C+F+T+J">Fatema Tuj Johora Faria</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Moin%2C+M+B">Mukaffi Bin Moin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fahim%2C+A+I">Asif Iftekher Fahim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Debnath%2C+P">Pronay Debnath</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shah%2C+F+M">Faisal Muhammad Shah</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in 4th International Conference on Computing and
                    Communication Networks (ICCCNet-2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Natural Language Inference (NLI) is a cornerstone of Natural Language
                    Processing (NLP), providing insights into the entailment relationships between
                    text pairings. It is a critical component of Natural Language Understanding
                    (NLU), demonstrating the ability to extract information from spoken or written
                    interactions. NLI is mainly concerned with determining the entailment
                    relationship between two statements, known as the premise and hypothesis. When
                    the premise logically implies the hypothesis, the pair is labeled
                    ``entailment''. If the hypothesis contradicts the premise, the pair receives
                    the ``contradiction'' label. When there is insufficient evidence to establish a
                    connection, the pair is described as ``neutral''. Despite the success of Large
                    Language Models (LLMs) in various tasks, their effectiveness in NLI remains
                    constrained by issues like low-resource domain accuracy, model overconfidence,
                    and difficulty in capturing human judgment disagreements. This study addresses
                    the underexplored area of evaluating LLMs in low-resourced languages such as
                    Bengali. Through a comprehensive evaluation, we assess the performance of
                    prominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks,
                    focusing on natural language inference. Utilizing the XNLI dataset, we conduct
                    zero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and
                    Gemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT,
                    mBERT, and sahajBERT. Our findings reveal that while LLMs can achieve
                    comparable or superior performance to fine-tuned SOTA models in few-shot
                    scenarios, further research is necessary to enhance our understanding of LLMs
                    in languages with modest resources like Bengali. This study underscores the
                    importance of continued efforts in exploring LLM capabilities across diverse
                    linguistic contexts.
                </p>
            </div>
        </dd>
        <dt><a name="item321">[321]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02941"
                    title="Abstract">arXiv:2405.02941</a> [<a href="/pdf/2405.02941" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02941" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Boundary-aware Decoupled Flow Networks for Realistic Extreme
                    Rescaling
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jinmin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+T">Tao Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jingyun Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+K">Kang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jun Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shaoming Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+S">Shu-Tao Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=guo%2C+r">rizen guo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Recently developed generative methods, including invertible rescaling network
                    (IRN) based and generative adversarial network (GAN) based methods, have
                    demonstrated exceptional performance in image rescaling. However, IRN-based
                    methods tend to produce over-smoothed results, while GAN-based methods easily
                    generate fake details, which thus hinders their real applications. To address
                    this issue, we propose Boundary-aware Decoupled Flow Networks (BDFlow) to
                    generate realistic and visually pleasing results. Unlike previous methods that
                    model high-frequency information as standard Gaussian distribution directly,
                    our BDFlow first decouples the high-frequency information into \textit{semantic
                    high-frequency} that adheres to a Boundary distribution and
                    \textit{non-semantic high-frequency} counterpart that adheres to a Gaussian
                    distribution. Specifically, to capture semantic high-frequency parts
                    accurately, we use Boundary-aware Mask (BAM) to constrain the model to produce
                    rich textures, while non-semantic high-frequency part is randomly sampled from
                    a Gaussian distribution.Comprehensive experiments demonstrate that our BDFlow
                    significantly outperforms other state-of-the-art methods while maintaining
                    lower complexity. Notably, our BDFlow improves the PSNR by <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-151-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1073"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.22em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1074"><span class="mn" id="MathJax-Span-1075"
                                                style="font-family: MathJax_Main;">4.4</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-151">4.4</script> dB and the
                    SSIM by <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-152-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1076"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.22em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1077"><span class="mn" id="MathJax-Span-1078"
                                                style="font-family: MathJax_Main;">0.1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-152">0.1</script> on average over GRAIN, utilizing only
                    74\% of the parameters and
                    20\% of the computation. The code will be available at
                    https://github.com/THU-Kingmin/BAFlow.
                </p>
            </div>
        </dd>
        <dt><a name="item322">[322]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02944"
                    title="Abstract">arXiv:2405.02944</a> [<a href="/pdf/2405.02944" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02944" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Imaging Signal Recovery Using Neural Network Priors Under
                    Uncertain Forward Model Parameters
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiwen Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+W">Wenhui Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+P">Peijie Qiu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Razi%2C+A">Abolfazl Razi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by PBDL-CVPR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Inverse imaging problems (IIPs) arise in various applications, with the main
                    objective of reconstructing an image from its compressed measurements. This
                    problem is often ill-posed for being under-determined with multiple
                    interchangeably consistent solutions. The best solution inherently depends on
                    prior knowledge or assumptions, such as the sparsity of the image. Furthermore,
                    the reconstruction process for most IIPs relies significantly on the imaging
                    (i.e. forward model) parameters, which might not be fully known, or the
                    measurement device may undergo calibration drifts. These uncertainties in the
                    forward model create substantial challenges, where inaccurate reconstructions
                    usually happen when the postulated parameters of the forward model do not fully
                    match the actual ones. In this work, we devoted to tackling accurate
                    reconstruction under the context of a set of possible forward model parameters
                    that exist. Here, we propose a novel Moment-Aggregation (MA) framework that is
                    compatible with the popular IIP solution by using a neural network prior.
                    Specifically, our method can reconstruct the signal by considering all
                    candidate parameters of the forward model simultaneously during the update of
                    the neural network. We theoretically demonstrate the convergence of the MA
                    framework, which has a similar complexity with reconstruction under the known
                    forward model parameters. Proof-of-concept experiments demonstrate that the
                    proposed MA achieves performance comparable to the forward model with the known
                    precise parameter in reconstruction across both compressive sensing and phase
                    retrieval applications, with a PSNR gap of 0.17 to 1.94 over various datasets,
                    including MNIST, X-ray, Glas, and MoNuseg. This highlights our method's
                    significant potential in reconstruction under an uncertain forward model.
                </p>
            </div>
        </dd>
        <dt><a name="item323">[323]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02945"
                    title="Abstract">arXiv:2405.02945</a> [<a href="/pdf/2405.02945" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02945" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Invertible Residual Rescaling Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jinmin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+T">Tao Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zha%2C+Y">Yaohua Zha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yilu Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+L">Longfei Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Bin Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhi Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+S">Shu-Tao Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jingyun Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Invertible Rescaling Networks (IRNs) and their variants have witnessed
                    remarkable achievements in various image processing tasks like image rescaling.
                    However, we observe that IRNs with deeper networks are difficult to train, thus
                    hindering the representational ability of IRNs. To address this issue, we
                    propose Invertible Residual Rescaling Models (IRRM) for image rescaling by
                    learning a bijection between a high-resolution image and its low-resolution
                    counterpart with a specific distribution. Specifically, we propose IRRM to
                    build a deep network, which contains several Residual Downscaling Modules
                    (RDMs) with long skip connections. Each RDM consists of several Invertible
                    Residual Blocks (IRBs) with short connections. In this way, RDM allows rich
                    low-frequency information to be bypassed by skip connections and forces models
                    to focus on extracting high-frequency information from the image. Extensive
                    experiments show that our IRRM performs significantly better than other
                    state-of-the-art methods with much fewer parameters and complexity.
                    Particularly, our IRRM has respectively PSNR gains of at least 0.3 dB over
                    HCFlow and IRN in the <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-153-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1079"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.22em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1080"><span class="mo" id="MathJax-Span-1081"
                                                style="font-family: MathJax_Main;">×</span><span class="mn"
                                                id="MathJax-Span-1082"
                                                style="font-family: MathJax_Main;">4</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-153">\times 4</script> rescaling while only using 60\%
                    parameters and
                    50\% FLOPs. The code will be available at https://github.com/THU-Kingmin/IRRM.
                </p>
            </div>
        </dd>
        <dt><a name="item324">[324]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02951"
                    title="Abstract">arXiv:2405.02951</a> [<a href="/pdf/2405.02951" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02951" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> iSEARLE: Improving Textual Inversion for Zero-Shot Composed
                    Image Retrieval
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Agnolucci%2C+L">Lorenzo Agnolucci</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baldrati%2C+A">Alberto Baldrati</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bertini%2C+M">Marco Bertini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Del+Bimbo%2C+A">Alberto Del Bimbo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Extended version of the ICCV2023 paper <a
                        href="/abs/2303.15247">arXiv:2303.15247</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

                </div>
                <p class="mathjax">Given a query consisting of a reference image and a relative caption,
                    Composed Image Retrieval (CIR) aims to retrieve target images visually similar
                    to the reference one while incorporating the changes specified in the relative
                    caption. The reliance of supervised methods on labor-intensive manually labeled
                    datasets hinders their broad applicability. In this work, we introduce a new
                    task, Zero-Shot CIR (ZS-CIR), that addresses CIR without the need for a labeled
                    training dataset. We propose an approach named iSEARLE (improved zero-Shot
                    composEd imAge Retrieval with textuaL invErsion) that involves mapping the
                    visual information of the reference image into a pseudo-word token in CLIP
                    token embedding space and combining it with the relative caption. To foster
                    research on ZS-CIR, we present an open-domain benchmarking dataset named CIRCO
                    (Composed Image Retrieval on Common Objects in context), the first CIR dataset
                    where each query is labeled with multiple ground truths and a semantic
                    categorization. The experimental results illustrate that iSEARLE obtains
                    state-of-the-art performance on three different CIR datasets -- FashionIQ,
                    CIRR, and the proposed CIRCO -- and two additional evaluation settings, namely
                    domain conversion and object composition. The dataset, the code, and the model
                    are publicly available at https://github.com/miccunifi/SEARLE.
                </p>
            </div>
        </dd>
        <dt><a name="item325">[325]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02952"
                    title="Abstract">arXiv:2405.02952</a> [<a href="/pdf/2405.02952" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02952" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Accelerating Legacy Numerical Solvers by Non-intrusive
                    Gradient-based Meta-solving
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Arisaka%2C+S">Sohei Arisaka</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qianxiao Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">Scientific computing is an essential tool for scientific discovery and
                    engineering design, and its computational cost is always a main concern in
                    practice. To accelerate scientific computing, it is a promising approach to use
                    machine learning (especially meta-learning) techniques for selecting
                    hyperparameters of traditional numerical methods. There have been numerous
                    proposals to this direction, but many of them require automatic-differentiable
                    numerical methods. However, in reality, many practical applications still
                    depend on well-established but non-automatic-differentiable legacy codes, which
                    prevents practitioners from applying the state-of-the-art research to their own
                    problems. To resolve this problem, we propose a non-intrusive methodology with
                    a novel gradient estimation technique to combine machine learning and legacy
                    numerical codes without any modification. We theoretically and numerically show
                    the advantage of the proposed method over other baselines and present
                    applications of accelerating established non-automatic-differentiable numerical
                    solvers implemented in PETSc, a widely used open-source numerical software
                    library.
                </p>
            </div>
        </dd>
        <dt><a name="item326">[326]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02953"
                    title="Abstract">arXiv:2405.02953</a> [<a href="/pdf/2405.02953" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02953" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Analysis of the Identifying Regulation with Adversarial
                    Surrogates Algorithm
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Teichner%2C+R">Ron Teichner</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Meir%2C+R">Ron Meir</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Margaliot%2C+M">Michael Margaliot</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Given a time-series of noisy measured outputs of a dynamical system z[k],
                    k=1...N, the Identifying Regulation with Adversarial Surrogates (IRAS)
                    algorithm aims to find a non-trivial first integral of the system, namely, a
                    scalar function g() such that g(z[i]) = g(z[j]), for all i,j. IRAS has been
                    suggested recently and was used successfully in several learning tasks in
                    models from biology and physics. Here, we give the first rigorous analysis of
                    this algorithm in a specific setting. We assume that the observations admit a
                    linear first integral and that they are contaminated by Gaussian noise. We show
                    that in this case the IRAS iterations are closely related to the
                    self-consistent-field (SCF) iterations for solving a generalized Rayleigh
                    quotient minimization problem. Using this approach, we derive several
                    sufficient conditions guaranteeing local convergence of IRAS to the correct
                    first integral.
                </p>
            </div>
        </dd>
        <dt><a name="item327">[327]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02954"
                    title="Abstract">arXiv:2405.02954</a> [<a href="/pdf/2405.02954" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02954" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Source-Free Domain Adaptation Guided by Vision and
                    Vision-Language Pre-Training
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenyu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+L">Li Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Foo%2C+C">Chuan-Sheng Foo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Extension of ICCV paper <a
                        href="/abs/2212.07585">arXiv:2212.07585</a>, submitted to IJCV
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Source-free domain adaptation (SFDA) aims to adapt a source model trained on
                    a fully-labeled source domain to a related but unlabeled target domain. While
                    the source model is a key avenue for acquiring target pseudolabels, the
                    generated pseudolabels may exhibit source bias. In the conventional SFDA
                    pipeline, a large data (e.g. ImageNet) pre-trained feature extractor is used to
                    initialize the source model at the start of source training, and subsequently
                    discarded. Despite having diverse features important for generalization, the
                    pre-trained feature extractor can overfit to the source data distribution
                    during source training and forget relevant target domain knowledge. Rather than
                    discarding this valuable knowledge, we introduce an integrated framework to
                    incorporate pre-trained networks into the target adaptation process. The
                    proposed framework is flexible and allows us to plug modern pre-trained
                    networks into the adaptation process to leverage their stronger representation
                    learning capabilities. For adaptation, we propose the Co-learn algorithm to
                    improve target pseudolabel quality collaboratively through the source model and
                    a pre-trained feature extractor. Building on the recent success of the
                    vision-language model CLIP in zero-shot image recognition, we present an
                    extension Co-learn++ to further incorporate CLIP's zero-shot classification
                    decisions. We evaluate on 3 benchmark datasets and include more challenging
                    scenarios such as open-set, partial-set and open-partial SFDA. Experimental
                    results demonstrate that our proposed strategy improves adaptation performance
                    and can be successfully integrated with existing SFDA methods.
                </p>
            </div>
        </dd>
        <dt><a name="item328">[328]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02957"
                    title="Abstract">arXiv:2405.02957</a> [<a href="/pdf/2405.02957" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02957" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Agent Hospital: A Simulacrum of Hospital with Evolvable
                    Medical Agents
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Junkai Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Siyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Meng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Weitao Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lai%2C+Y">Yunghwei Lai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kang%2C+X">Xinhui Kang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+W">Weizhi Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">In this paper, we introduce a simulacrum of hospital called Agent Hospital
                    that simulates the entire process of treating illness. All patients, nurses,
                    and doctors are autonomous agents powered by large language models (LLMs). Our
                    central goal is to enable a doctor agent to learn how to treat illness within
                    the simulacrum. To do so, we propose a method called MedAgent-Zero. As the
                    simulacrum can simulate disease onset and progression based on knowledge bases
                    and LLMs, doctor agents can keep accumulating experience from both successful
                    and unsuccessful cases. Simulation experiments show that the treatment
                    performance of doctor agents consistently improves on various tasks. More
                    interestingly, the knowledge the doctor agents have acquired in Agent Hospital
                    is applicable to real-world medicare benchmarks. After treating around ten
                    thousand patients (real-world doctors may take over two years), the evolved
                    doctor agent achieves a state-of-the-art accuracy of 93.06% on a subset of the
                    MedQA dataset that covers major respiratory diseases. This work paves the way
                    for advancing the applications of LLM-powered agent techniques in medical
                    scenarios.
                </p>
            </div>
        </dd>
        <dt><a name="item329">[329]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02958"
                    title="Abstract">arXiv:2405.02958</a> [<a href="/pdf/2405.02958" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02958" title="Download PostScript">ps</a>, <a href="/format/2405.02958"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Score-based Generative Priors Guided Model-driven Network for
                    MRI Reconstruction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Qiao%2C+X">Xiaoyu Qiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Weisheng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yuping Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L">Lijian Yang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible
                    publication. Copyright may be transferred without notice, after which this version may no longer be
                    accessible
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Score matching with Langevin dynamics (SMLD) method has been successfully
                    applied to accelerated MRI. However, the hyperparameters in the sampling
                    process require subtle tuning, otherwise the results can be severely corrupted
                    by hallucination artifacts, particularly with out-of-distribution test data. In
                    this study, we propose a novel workflow in which SMLD results are regarded as
                    additional priors to guide model-driven network training. First, we adopted a
                    pretrained score network to obtain samples as preliminary guidance images (PGI)
                    without the need for network retraining, parameter tuning and in-distribution
                    test data. Although PGIs are corrupted by hallucination artifacts, we believe
                    that they can provide extra information through effective denoising steps to
                    facilitate reconstruction. Therefore, we designed a denoising module (DM) in
                    the second step to improve the quality of PGIs. The features are extracted from
                    the components of Langevin dynamics and the same score network with
                    fine-tuning; hence, we can directly learn the artifact patterns. Third, we
                    designed a model-driven network whose training is guided by denoised PGIs
                    (DGIs). DGIs are densely connected with intermediate reconstructions in each
                    cascade to enrich the features and are periodically updated to provide more
                    accurate guidance. Our experiments on different sequences revealed that despite
                    the low average quality of PGIs, the proposed workflow can effectively extract
                    valuable information to guide the network training, even with severely reduced
                    training data and sampling steps. Our method outperforms other cutting-edge
                    techniques by effectively mitigating hallucination artifacts, yielding robust
                    and high-quality reconstruction results.
                </p>
            </div>
        </dd>
        <dt><a name="item330">[330]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02961"
                    title="Abstract">arXiv:2405.02961</a> [<a href="/pdf/2405.02961" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02961" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> JOSENet: A Joint Stream Embedding Network for Violence
                    Detection in Surveillance Videos
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nardelli%2C+P">Pietro Nardelli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Comminiello%2C+D">Danilo Comminiello</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to the International Journal of Computer Vision
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

                </div>
                <p class="mathjax">Due to the ever-increasing availability of video surveillance cameras and the
                    growing need for crime prevention, the violence detection task is attracting
                    greater attention from the research community. With respect to other action
                    recognition tasks, violence detection in surveillance videos shows additional
                    issues, such as the presence of a significant variety of real fight scenes.
                    Unfortunately, available datasets seem to be very small compared with other
                    action recognition datasets. Moreover, in surveillance applications, people in
                    the scenes always differ for each video and the background of the footage
                    differs for each camera. Also, violent actions in real-life surveillance videos
                    must be detected quickly to prevent unwanted consequences, thus models would
                    definitely benefit from a reduction in memory usage and computational costs.
                    Such problems make classical action recognition methods difficult to be
                    adopted. To tackle all these issues, we introduce JOSENet, a novel
                    self-supervised framework that provides outstanding performance for violence
                    detection in surveillance videos. The proposed model receives two
                    spatiotemporal video streams, i.e., RGB frames and optical flows, and involves
                    a new regularized self-supervised learning approach for videos. JOSENet
                    provides improved performance compared to self-supervised state-of-the-art
                    methods, while requiring one-fourth of the number of frames per video segment
                    and a reduced frame rate. The source code and the instructions to reproduce our
                    experiments are available at https://github.com/ispamm/JOSENet.
                </p>
            </div>
        </dd>
        <dt><a name="item331">[331]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02962"
                    title="Abstract">arXiv:2405.02962</a> [<a href="/pdf/2405.02962" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02962" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> VectorPainter: A Novel Approach to Stylized Vector Graphics
                    Synthesis with Vectorized Strokes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Juncheng Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xing%2C+X">Ximing Xing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhengqi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jing Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Q">Qian Yu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">We propose a novel method, VectorPainter, for the task of stylized vector
                    graphics synthesis. Given a text prompt and a reference style image,
                    VectorPainter generates a vector graphic that aligns in content with the text
                    prompt and remains faithful in style to the reference image. We recognize that
                    the key to this task lies in fully leveraging the intrinsic properties of
                    vector graphics. Innovatively, we conceptualize the stylization process as the
                    rearrangement of vectorized strokes extracted from the reference image.
                    VectorPainter employs an optimization-based pipeline. It begins by extracting
                    vectorized strokes from the reference image, which are then used to initialize
                    the synthesis process. To ensure fidelity to the reference style, a novel style
                    preservation loss is introduced. Extensive experiments have been conducted to
                    demonstrate that our method is capable of aligning with the text description
                    while remaining faithful to the reference image.
                </p>
            </div>
        </dd>
        <dt><a name="item332">[332]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02963"
                    title="Abstract">arXiv:2405.02963</a> [<a href="/pdf/2405.02963" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02963" title="Download PostScript">ps</a>, <a href="/format/2405.02963"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Preventive Audits for Data Applications Before Data Sharing
                    in the Power IoT
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bohong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Q">Qinglai Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yanxi Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yang Yu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 19 pages, 18 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">With the increase in data volume, more types of data are being used and
                    shared, especially in the power Internet of Things (IoT). However, the
                    processes of data sharing may lead to unexpected information leakage because of
                    the ubiquitous relevance among the different data, thus it is necessary for
                    data owners to conduct preventive audits for data applications before data
                    sharing to avoid the risk of key information leakage. Considering that the same
                    data may play completely different roles in different application scenarios,
                    data owners should know the expected data applications of the data buyers in
                    advance and provide modified data that are less relevant to the private
                    information of the data owners and more relevant to the nonprivate information
                    that the data buyers need. In this paper, data sharing in the power IoT is
                    regarded as the background, and the mutual information of the data and their
                    implicit information is selected as the data feature parameter to indicate the
                    relevance between the data and their implicit information or the ability to
                    infer the implicit information from the data. Therefore, preventive audits
                    should be conducted based on changes in the data feature parameters before and
                    after data sharing. The probability exchange adjustment method is proposed as
                    the theoretical basis of preventive audits under simplified consumption, and
                    the corresponding optimization models are constructed and extended to more
                    practical scenarios with multivariate characteristics. Finally, case studies
                    are used to validate the effectiveness of the proposed preventive audits.
                </p>
            </div>
        </dd>
        <dt><a name="item333">[333]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02965"
                    title="Abstract">arXiv:2405.02965</a> [<a href="/pdf/2405.02965" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02965" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Robust Collaborative Perception without External Localization
                    and Clock Devices
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lei%2C+Z">Zixing Lei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ni%2C+Z">Zhenyang Ni</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+R">Ruize Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+S">Shuo Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+C">Chen Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Siheng Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yanfeng Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6pages, accepted to ICRA 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Robotics (cs.RO)

                </div>
                <p class="mathjax">A consistent spatial-temporal coordination across multiple agents is
                    fundamental for collaborative perception, which seeks to improve perception
                    abilities through information exchange among agents. To achieve this
                    spatial-temporal alignment, traditional methods depend on external devices to
                    provide localization and clock signals. However, hardware-generated signals
                    could be vulnerable to noise and potentially malicious attack, jeopardizing the
                    precision of spatial-temporal alignment. Rather than relying on external
                    hardwares, this work proposes a novel approach: aligning by recognizing the
                    inherent geometric patterns within the perceptual data of various agents.
                    Following this spirit, we propose a robust collaborative perception system that
                    operates independently of external localization and clock devices. The key
                    module of our system,~\emph{FreeAlign}, constructs a salient object graph for
                    each agent based on its detected boxes and uses a graph neural network to
                    identify common subgraphs between agents, leading to accurate relative pose and
                    time. We validate \emph{FreeAlign} on both real-world and simulated datasets.
                    The results show that, the ~\emph{FreeAlign} empowered robust collaborative
                    perception system perform comparably to systems relying on precise localization
                    and clock devices.
                </p>
            </div>
        </dd>
        <dt><a name="item334">[334]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02967"
                    title="Abstract">arXiv:2405.02967</a> [<a href="/pdf/2405.02967" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02967" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring Text-based Realistic Building Facades Editing
                    Applicaiton
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jing Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xin Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">This paper explores the utilization of diffusion models and textual guidance
                    for achieving localized editing of building facades, addressing the escalating
                    demand for sophisticated editing methodologies in architectural design and
                    urban planning. Leveraging the robust generative capabilities of diffusion
                    models, this study presents a promising avenue for realistically synthesizing
                    and modifying architectural facades. Through iterative diffusion and text
                    descriptions, these models adeptly capture both the intricate global and local
                    structures inherent in architectural facades, thus effectively navigating the
                    complexity of such designs. Additionally, the paper examines the expansive
                    potential of diffusion models in various facets, including the generation of
                    novel facade designs, the enhancement of existing facades, and the realization
                    of personalized customization. Despite their promise, diffusion models
                    encounter obstacles such as computational resource constraints and data
                    imbalances. To address these challenges, the study introduces the innovative
                    Blended Latent Diffusion method for architectural facade editing, accompanied
                    by a comprehensive visual analysis of its viability and efficacy. Through these
                    endeavors, we aims to propel forward the field of architectural facade editing,
                    contributing to its advancement and practical application.
                </p>
            </div>
        </dd>
        <dt><a name="item335">[335]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02968"
                    title="Abstract">arXiv:2405.02968</a> [<a href="/pdf/2405.02968" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02968" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CoverLib: Classifiers-equipped Experience Library by
                    Iterative Problem Distribution Coverage Maximization for Domain-tuned Motion Planning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ishida%2C+H">Hirokazu Ishida</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hiraoka%2C+N">Naoki Hiraoka</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Okada%2C+K">Kei Okada</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Inaba%2C+M">Masayuki Inaba</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Library-based methods are known to be very effective for fast motion planning
                    by adapting an experience retrieved from a precomputed library. This article
                    presents CoverLib, a principled approach for constructing and utilizing such a
                    library. CoverLib iteratively adds an experience-classifier-pair to the
                    library, where each classifier corresponds to an adaptable region of the
                    experience within the problem space. This iterative process is an active
                    procedure, as it selects the next experience based on its ability to
                    effectively cover the uncovered region. During the query phase, these
                    classifiers are utilized to select an experience that is expected to be
                    adaptable for a given problem. Experimental results demonstrate that CoverLib
                    effectively mitigates the trade-off between plannability and speed observed in
                    global (e.g. sampling-based) and local (e.g. optimization-based) methods. As a
                    result, it achieves both fast planning and high success rates over the problem
                    domain. Moreover, due to its adaptation-algorithm-agnostic nature, CoverLib
                    seamlessly integrates with various adaptation methods, including nonlinear
                    programming-based and sampling-based algorithms.
                </p>
            </div>
        </dd>
        <dt><a name="item336">[336]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02969"
                    title="Abstract">arXiv:2405.02969</a> [<a href="/pdf/2405.02969" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02969" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards a Flexible and High-Fidelity Approach to Distributed
                    DNN Training Emulation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+B">Banruo Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ojewale%2C+M+A">Mubarak Adetunji Ojewale</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+Y">Yuhan Ding</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Canini%2C+M">Marco Canini</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">We propose NeuronaBox, a flexible, user-friendly, and high-fidelity approach
                    to emulate DNN training workloads. We argue that to accurately observe
                    performance, it is possible to execute the training workload on a subset of
                    real nodes and emulate the networked execution environment along with the
                    collective communication operations. Initial results from a proof-of-concept
                    implementation show that NeuronaBox replicates the behavior of actual systems
                    with high accuracy, with an error margin of less than 1% between the emulated
                    measurements and the real system.
                </p>
            </div>
        </dd>
        <dt><a name="item337">[337]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02971"
                    title="Abstract">arXiv:2405.02971</a> [<a href="/pdf/2405.02971" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02971" title="Download PostScript">ps</a>, <a href="/format/2405.02971"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Achieving Narrative Change Through AR: Displacing the Single
                    Story to Create Spatial Justice
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Samuels%2C+J+T">Janice Tisha Samuels</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Presented at CHI 2024 (<a
                        href="/abs/2404.05889">arXiv:2404.05889</a>)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">The ability of Augmented Reality to overcome the bias of single stories
                    through multidimensionality is explored in the artifacts of a youth gun
                    violence prevention project and its goal of narrative change.
                </p>
            </div>
        </dd>
        <dt><a name="item338">[338]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02972"
                    title="Abstract">arXiv:2405.02972</a> [<a href="/pdf/2405.02972" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02972" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multi-Agent RL-Based Industrial AIGC Service Offloading over
                    Wireless Edge Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Siyuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+X">Xi Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hansong Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hua%2C+K">Kun Hua</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+X">Xiaomin Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Gaolei Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jianhua Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Currently, the generative model has garnered considerable attention due to
                    its application in addressing the challenge of scarcity of abnormal samples in
                    the industrial Internet of Things (IoT). However, challenges persist regarding
                    the edge deployment of generative models and the optimization of joint edge
                    AI-generated content (AIGC) tasks. In this paper, we focus on the edge
                    optimization of AIGC task execution and propose GMEL, a generative model-driven
                    industrial AIGC collaborative edge learning framework. This framework aims to
                    facilitate efficient few-shot learning by leveraging realistic sample synthesis
                    and edge-based optimization capabilities. First, a multi-task AIGC
                    computational offloading model is presented to ensure the efficient execution
                    of heterogeneous AIGC tasks on edge servers. Then, we propose an
                    attention-enhanced multi-agent reinforcement learning (AMARL) algorithm aimed
                    at refining offloading policies within the IoT system, thereby supporting
                    generative model-driven edge learning. Finally, our experimental results
                    demonstrate the effectiveness of the proposed algorithm in optimizing the total
                    system latency of the edge-based AIGC task completion.
                </p>
            </div>
        </dd>
        <dt><a name="item339">[339]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02973"
                    title="Abstract">arXiv:2405.02973</a> [<a href="/pdf/2405.02973" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02973" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FairRelay: Fair and Cost-Efficient Peer-to-Peer Content
                    Delivery through Payment Channel Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jingyu Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+Y">Yingjie Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Z">Zifan Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+C">Chao Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xinyi Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 27 pages, 21 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Peer-to-Peer (P2P) content delivery, known for scalability and resilience,
                    offers a decentralized alternative to traditional centralized Content Delivery
                    Networks (CDNs). A significant challenge in P2P content delivery remains: the
                    fair compensation of relayers for their bandwidth contributions. Existing
                    solutions employ blockchains for payment settlements, however, they are not
                    practical due to high on-chain costs and over-simplified network assumptions.
                    In this paper, we introduce FairRelay, a fair and cost-efficient protocol that
                    ensures all participants get fair payoff in complex content delivery network
                    settings. We introduce a novel primitive, Enforceable Accumulative Hashed
                    TimeLock Contract (Enforceable A-HTLC), designed to guarantee payment atomicity
                    - ensuring all participants receive their payments upon successful content
                    delivery.
                    <br>The fairness of FairRelay is proved using the Universal Composability (UC)
                    framework. Our evaluation demonstrates that, in optimistic scenarios, FairRelay
                    employs zero on-chain costs. In pessimistic scenarios, the on-chain dispute
                    costs for relayers and customers are constant, irrespective of the network
                    complexity. Specifically, empirical results indicate that the on-chain dispute
                    costs for relayers and customers are 24,902 gas (equivalent to 0.01 USD on
                    Optimism L2) and 290,797 gas (0.07 USD), respectively. In a 10-hop relay path,
                    FairRelay introduces less than 1.5% additional overhead compared to pure data
                    transmission, showcasing the efficiency of FairRelay.
                </p>
            </div>
        </dd>
        <dt><a name="item340">[340]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02977"
                    title="Abstract">arXiv:2405.02977</a> [<a href="/pdf/2405.02977" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02977" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SkelCap: Automated Generation of Descriptive Text from
                    Skeleton Keypoint Sequences
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Keskin%2C+A+E">Ali Emre Keskin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Keles%2C+H+Y">Hacer Yalim Keles</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 5 figures, 7 tables, submitted to IEEE conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Numerous sign language datasets exist, yet they typically cover only a
                    limited selection of the thousands of signs used globally. Moreover, creating
                    diverse sign language datasets is an expensive and challenging task due to the
                    costs associated with gathering a varied group of signers. Motivated by these
                    challenges, we aimed to develop a solution that addresses these limitations. In
                    this context, we focused on textually describing body movements from skeleton
                    keypoint sequences, leading to the creation of a new dataset. We structured
                    this dataset around AUTSL, a comprehensive isolated Turkish sign language
                    dataset. We also developed a baseline model, SkelCap, which can generate
                    textual descriptions of body movements. This model processes the skeleton
                    keypoints data as a vector, applies a fully connected layer for embedding, and
                    utilizes a transformer neural network for sequence-to-sequence modeling. We
                    conducted extensive evaluations of our model, including signer-agnostic and
                    sign-agnostic assessments. The model achieved promising results, with a ROUGE-L
                    score of 0.98 and a BLEU-4 score of 0.94 in the signer-agnostic evaluation. The
                    dataset we have prepared, namely the AUTSL-SkelCap, will be made publicly
                    available soon.
                </p>
            </div>
        </dd>
        <dt><a name="item341">[341]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02979"
                    title="Abstract">arXiv:2405.02979</a> [<a href="/pdf/2405.02979" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02979" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Long-Short-Term Mixed-Integer Formulation for Highway Lane
                    Change Planning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Reiter%2C+R">Rudolf Reiter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nurkanovic%2C+A">Armin Nurkanovic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bernadini%2C+D">Daniele Bernadini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Diehl%2C+M">Moritz Diehl</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bemporad%2C+A">Alberto Bemporad</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Systems and Control (eess.SY)

                </div>
                <p class="mathjax">This work considers the problem of optimal lane changing in a structured
                    multi-agent road environment. A novel motion planning algorithm that can
                    capture long-horizon dependencies as well as short-horizon dynamics is
                    presented. Pivotal to our approach is a geometric approximation of the
                    long-horizon combinatorial transition problem which we formulate in the
                    continuous time-space domain. Moreover, a discrete-time formulation of a
                    short-horizon optimal motion planning problem is formulated and combined with
                    the long-horizon planner. Both individual problems, as well as their
                    combination, are formulated as MIQP and solved in real-time by using
                    state-of-the-art solvers. We show how the presented algorithm outperforms two
                    other state-of-the-art motion planning algorithms in closed-loop performance
                    and computation time in lane changing problems. Evaluations are performed using
                    the traffic simulator SUMO, a custom low-level tracking model predictive
                    controller, and high-fidelity vehicle models and scenarios, provided by the
                    CommonRoad environment.
                </p>
            </div>
        </dd>
        <dt><a name="item342">[342]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02980"
                    title="Abstract">arXiv:2405.02980</a> [<a href="/pdf/2405.02980" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02980" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Self-Organized Construction by Minimal Surprise
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kaiser%2C+T+K">Tanja Katharina Kaiser</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hamann%2C+H">Heiko Hamann</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published in 2019 IEEE 4th International Workshops on
                    Foundations and Applications of Self* Systems (FAS*W)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Multiagent Systems (cs.MA); Neural and Evolutionary Computing (cs.NE)

                </div>
                <p class="mathjax">For the robots to achieve a desired behavior, we can program them directly,
                    train them, or give them an innate driver that makes the robots themselves
                    desire the targeted behavior. With the minimal surprise approach, we implant in
                    our robots the desire to make their world predictable. Here, we apply minimal
                    surprise to collective construction. Simulated robots push blocks in a 2D torus
                    grid world. In two variants of our experiment we either allow for emergent
                    behaviors or predefine the expected environment of the robots. In either way,
                    we evolve robot behaviors that move blocks to structure their environment and
                    make it more predictable. The resulting controllers can be applied in
                    collective construction by robots.
                </p>
            </div>
        </dd>
        <dt><a name="item343">[343]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02981"
                    title="Abstract">arXiv:2405.02981</a> [<a href="/pdf/2405.02981" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02981" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Over-the-Air Majority Vote Computation with Modulation on
                    Conjugate-Reciprocal Zeros
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sahin%2C+A">Alphan Sahin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This work is being submitted to the IEEE for possible
                    publication. Copyright may be transferred without notice, after which this version may no longer be
                    accessible
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">In this study, we propose a new approach to compute the majority vote (MV)
                    function based on modulation on conjugate-reciprocal zeros (MOCZ) and introduce
                    three different methods. The proposed methods rely on the fact that when a
                    linear combination of polynomials is evaluated at one of the roots of a
                    polynomial in the combination, that polynomial does contribute to the
                    evaluation. To utilize this property, each transmitter maps the votes to the
                    zeros of a Huffman polynomial, and the corresponding polynomial coefficients
                    are transmitted. The receiver evaluates the polynomial constructed by the
                    elements of the superposed sequence at conjugate-reciprocal zero pairs and
                    detects the MV with a direct zero-testing (DiZeT) decoder. With differential
                    and index-based encoders, we eliminate the need for power-delay information at
                    the receiver while improving the computation error rate (CER) performance. The
                    proposed methods do not use instantaneous channel state information at the
                    transmitters and receiver. Thus, they provide robustness against phase and time
                    synchronization errors. We theoretically analyze the CERs of the proposed
                    methods. Finally, we demonstrate their efficacy in a distributed median
                    computation scenario in a fading channel.
                </p>
            </div>
        </dd>
        <dt><a name="item344">[344]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02982"
                    title="Abstract">arXiv:2405.02982</a> [<a href="/pdf/2405.02982" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02982" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Paintings and Drawings Aesthetics Assessment with Rich
                    Attributes for Various Artistic Categories
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+X">Xin Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiao%2C+Q">Qianqian Qiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yi Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+S">Shan Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Heng Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guangdong Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Image aesthetic evaluation is a highly prominent research domain in the field
                    of computer vision. In recent years, there has been a proliferation of datasets
                    and corresponding evaluation methodologies for assessing the aesthetic quality
                    of photographic works, leading to the establishment of a relatively mature
                    research environment. However, in contrast to the extensive research in
                    photographic aesthetics, the field of aesthetic evaluation for paintings and
                    Drawings has seen limited attention until the introduction of the BAID dataset
                    in March 2023. This dataset solely comprises overall scores for high-quality
                    artistic images. Our research marks the pioneering introduction of a
                    multi-attribute, multi-category dataset specifically tailored to the field of
                    painting: Aesthetics of Paintings and Drawings Dataset (APDD). The construction
                    of APDD received active participation from 28 professional artists worldwide,
                    along with dozens of students specializing in the field of art. This dataset
                    encompasses 24 distinct artistic categories and 10 different aesthetic
                    attributes. Each image in APDD has been evaluated by six professionally trained
                    experts in the field of art, including assessments for both total aesthetic
                    scores and aesthetic attribute scores. The final APDD dataset comprises a total
                    of 4985 images, with an annotation count exceeding 31100 entries. Concurrently,
                    we propose an innovative approach: Art Assessment Network for Specific Painting
                    Styles (AANSPS), designed for the assessment of aesthetic attributes in
                    mixed-attribute art datasets. Through this research, our goal is to catalyze
                    advancements in the field of aesthetic evaluation for paintings and drawings,
                    while enriching the available resources and methodologies for its further
                    development and application.
                </p>
            </div>
        </dd>
        <dt><a name="item345">[345]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02984"
                    title="Abstract">arXiv:2405.02984</a> [<a href="/pdf/2405.02984" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02984" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> E-TSL: A Continuous Educational Turkish Sign Language Dataset
                    with Baseline Methods
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=%C3%96zt%C3%BCrk%2C+%C5%9E">Şükrü Öztürk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Keles%2C+H+Y">Hacer Yalim Keles</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 3 figures, 4 tables, submitted to IEEE conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">This study introduces the continuous Educational Turkish Sign Language
                    (E-TSL) dataset, collected from online Turkish language lessons for 5th, 6th,
                    and 8th grades. The dataset comprises 1,410 videos totaling nearly 24 hours and
                    includes performances from 11 signers. Turkish, an agglutinative language,
                    poses unique challenges for sign language translation, particularly with a
                    vocabulary where 64% are singleton words and 85% are rare words, appearing less
                    than five times. We developed two baseline models to address these challenges:
                    the Pose to Text Transformer (P2T-T) and the Graph Neural Network based
                    Transformer (GNN-T) models. The GNN-T model achieved 19.13% BLEU-1 score and
                    3.28% BLEU-4 score, presenting a significant challenge compared to existing
                    benchmarks. The P2T-T model, while demonstrating slightly lower performance in
                    BLEU scores, achieved a higher ROUGE-L score of 22.09%. Additionally, we
                    benchmarked our model using the well-known PHOENIX-Weather 2014T dataset to
                    validate our approach.
                </p>
            </div>
        </dd>
        <dt><a name="item346">[346]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02985"
                    title="Abstract">arXiv:2405.02985</a> [<a href="/pdf/2405.02985" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.02985" title="Download PostScript">ps</a>, <a href="/format/2405.02985"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Can Large Language Models Make the Grade? An Empirical Study
                    Evaluating LLMs Ability to Mark Short Answer Questions in K-12 Education
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Henkel%2C+O">Owen Henkel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boxer%2C+A">Adam Boxer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hills%2C+L">Libby Hills</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roberts%2C+B">Bill Roberts</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">This paper presents reports on a series of experiments with a novel dataset
                    evaluating how well Large Language Models (LLMs) can mark (i.e. grade) open
                    text responses to short answer questions, Specifically, we explore how well
                    different combinations of GPT version and prompt engineering strategies
                    performed at marking real student answers to short answer across different
                    domain areas (Science and History) and grade-levels (spanning ages 5-16) using
                    a new, never-used-before dataset from Carousel, a quizzing platform. We found
                    that GPT-4, with basic few-shot prompting performed well (Kappa, 0.70) and,
                    importantly, very close to human-level performance (0.75). This research builds
                    on prior findings that GPT-4 could reliably score short answer reading
                    comprehension questions at a performance-level very close to that of expert
                    human raters. The proximity to human-level performance, across a variety of
                    subjects and grade levels suggests that LLMs could be a valuable tool for
                    supporting low-stakes formative assessment tasks in K-12 education and has
                    important implications for real-world education delivery.
                </p>
            </div>
        </dd>
        <dt><a name="item347">[347]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02986"
                    title="Abstract">arXiv:2405.02986</a> [<a href="/pdf/2405.02986" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02986" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Harvesting Energy from Soil-Air Temperature Differences for
                    Batteryless IoT Devices: A Case Study
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Puluckul%2C+P+P">Priyesh Pappinisseri
                        Puluckul</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Weyn%2C+M">Maarten Weyn</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper is under review at IEEE Access. Copyright may
                    be transferred without notice, after which this version may no longer be accessible
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">The temperature difference between soil and air holds the potential to
                    generate energy to power many low-power IoT devices. However, there is a lack
                    of studies in the literature that explore the nuances of soil-air thermal
                    energy harvesting. This paper offers a comprehensive discussion on soil-air
                    thermal energy harvesting. We engineer a custom Soil-air Thermoelectric
                    Generator (SoTEG) that incorporates an off-the-shelf TEG and an efficient heat
                    transfer network. A detailed discussion of the design and analysis of SoTEG is
                    presented along with a versatile simulation model which can be used to simulate
                    the performance of the harvester under different ambient conditions.
                    Investigations using the model and results gathered from experiments
                    demonstrate that the SoTEG has a heat transfer efficiency of 34.5% with room
                    for improvement and can power a load from temperature differences as low as 3
                    {\deg}C between soil and air, or 1 {\deg}C across the TEG. Power generated by
                    SoTEG at 3 {\deg}C difference amounts to 110 {\mu}Wor a power density of
                    11.58mW/m2. When connected to a Power Management Unit (PMU), the combined
                    system generates around 30 {\mu}Wat 3 {\deg}C. During a 14-day outdoor
                    deployment in a winter month, the maximum power generated by the combined
                    system is 337 {\mu}W when the temperature difference across the TEG is 2.75
                    {\deg}C. Additionally, the model analysis reveals that the weather conditions
                    have an impact on the harvester. While Solar radiation enhances power
                    generation, wind can either improve or diminish the harvested energy depending
                    on whether it is day or night.
                </p>
            </div>
        </dd>
        <dt><a name="item348">[348]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02989"
                    title="Abstract">arXiv:2405.02989</a> [<a href="/pdf/2405.02989" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02989" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Defense against Joint Poison and Evasion Attacks: A Case
                    Study of DERMS
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Abdeen%2C+Z+u">Zain ul Abdeen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roy%2C+P">Padmaksha Roy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Al-Tawaha%2C+A">Ahmad Al-Tawaha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jia%2C+R">Rouxi Jia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Freeman%2C+L">Laura Freeman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Beling%2C+P">Peter Beling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chen-Ching Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sangiovanni-Vincentelli%2C+A">Alberto
                        Sangiovanni-Vincentelli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+M">Ming Jin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">There is an upward trend of deploying distributed energy resource management
                    systems (DERMS) to control modern power grids. However, DERMS controller
                    communication lines are vulnerable to cyberattacks that could potentially
                    impact operational reliability. While a data-driven intrusion detection system
                    (IDS) can potentially thwart attacks during deployment, also known as the
                    evasion attack, the training of the detection algorithm may be corrupted by
                    adversarial data injected into the database, also known as the poisoning
                    attack. In this paper, we propose the first framework of IDS that is robust
                    against joint poisoning and evasion attacks. We formulate the defense mechanism
                    as a bilevel optimization, where the inner and outer levels deal with attacks
                    that occur during training time and testing time, respectively. We verify the
                    robustness of our method on the IEEE-13 bus feeder model against a diverse set
                    of poisoning and evasion attack scenarios. The results indicate that our
                    proposed method outperforms the baseline technique in terms of accuracy,
                    precision, and recall for intrusion detection.
                </p>
            </div>
        </dd>
        <dt><a name="item349">[349]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02991"
                    title="Abstract">arXiv:2405.02991</a> [<a href="/pdf/2405.02991" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02991" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Steered Response Power for Sound Source Localization: A
                    Tutorial Review
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Grinstein%2C+E">Eric Grinstein</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tengan%2C+E">Elisa Tengan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=%C3%87akmak%2C+B">Bilgesu Çakmak</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dietzen%2C+T">Thomas Dietzen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nunes%2C+L">Leonardo Nunes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=van+Waterschoot%2C+T">Toon van Waterschoot</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brookes%2C+M">Mike Brookes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Naylor%2C+P+A">Patrick A. Naylor</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio
                    and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">In the last three decades, the Steered Response Power (SRP) method has been
                    widely used for the task of Sound Source Localization (SSL), due to its
                    satisfactory localization performance on moderately reverberant and noisy
                    scenarios. Many works have analyzed and extended the original SRP method to
                    reduce its computational cost, to allow it to locate multiple sources, or to
                    improve its performance in adverse environments. In this work, we review over
                    200 papers on the SRP method and its variants, with emphasis on the SRP-PHAT
                    method. We also present eXtensible-SRP, or X-SRP, a generalized and modularized
                    version of the SRP algorithm which allows the reviewed extensions to be
                    implemented. We provide a Python implementation of the algorithm which includes
                    selected extensions from the literature.
                </p>
            </div>
        </dd>
        <dt><a name="item350">[350]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02994"
                    title="Abstract">arXiv:2405.02994</a> [<a href="/pdf/2405.02994" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02994" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Extended State Observer for Mismatch Disturbances Using
                    Taylor Approximation of the Integral
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+C+D">Cuong Duc Nguyen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">The development of disturbance estimators using extended state observers
                    (ESOs) typically assumes that the system is observable. This paper introduces
                    an improved method for systems that are initially unobservable, leveraging
                    Taylor expansion to approximate the integral of disturbance dynamics. A new
                    extended system is formulated based on this approximation, enabling the design
                    of an observer that achieves exponential stability of the error dynamics. The
                    proposed method's efficacy is demonstrated through a practical example,
                    highlighting its potential for robust disturbance estimation in dynamic
                    systems.
                </p>
            </div>
        </dd>
        <dt><a name="item351">[351]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02995"
                    title="Abstract">arXiv:2405.02995</a> [<a href="/pdf/2405.02995" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02995" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Analysis about Theoretical Foundations for Method to
                    Enhancing ASR Performance using OCR Word Frequency Differences
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Jung%2C+K">Kyudan Jung</a>,
                    <a href="/search/math?searchtype=author&amp;query=Kim%2C+N">Nam-Joon Kim</a>,
                    <a href="/search/math?searchtype=author&amp;query=Ryu%2C+H+G">Hyun Gon Ryu</a>,
                    <a href="/search/math?searchtype=author&amp;query=Lee%2C+H">Hyuk-Jae Lee</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">As interest in large language models (LLMs) grows, the importance of accuracy
                    in automatic speech recognition (ASR) has become more pronounced. This is
                    particularly true for lectures that include specialized terminology, where the
                    success rate of traditional ASR models tends to be low, posing a challenging
                    problem. A method to improve ASR performance for specialized terminology using
                    the word frequency difference approach has been proposed. Through experiments
                    and data analysis, we investigate whether this proposal effectively addresses
                    the issue. Additionally, we introduce the power law as the theoretical
                    foundation for the relative frequency
                </p>
            </div>
        </dd>
        <dt><a name="item352">[352]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02996"
                    title="Abstract">arXiv:2405.02996</a> [<a href="/pdf/2405.02996" title="Download PDF">pdf</a>, <a
                    href="/format/2405.02996" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> RepAugment: Input-Agnostic Representation-Level Augmentation
                    for Respiratory Sound Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">June-Woo Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Toikkanen%2C+M">Miika Toikkanen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bae%2C+S">Sangmin Bae</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+M">Minseok Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jung%2C+H">Ho-Young Jung</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted EMBC 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">Recent advancements in AI have democratized its deployment as a healthcare
                    assistant. While pretrained models from large-scale visual and audio datasets
                    have demonstrably generalized to this task, surprisingly, no studies have
                    explored pretrained speech models, which, as human-originated sounds,
                    intuitively would share closer resemblance to lung sounds. This paper explores
                    the efficacy of pretrained speech models for respiratory sound classification.
                    We find that there is a characterization gap between speech and lung sound
                    samples, and to bridge this gap, data augmentation is essential. However, the
                    most widely used augmentation technique for audio and speech, SpecAugment,
                    requires 2-dimensional spectrogram format and cannot be applied to models
                    pretrained on speech waveforms. To address this, we propose RepAugment, an
                    input-agnostic representation-level augmentation technique that outperforms
                    SpecAugment, but is also suitable for respiratory sound classification with
                    waveform pretrained models. Experimental results show that our approach
                    outperforms the SpecAugment, demonstrating a substantial improvement in the
                    accuracy of minority disease classes, reaching up to 7.14%.
                </p>
            </div>
        </dd>
        <dt><a name="item353">[353]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03000"
                    title="Abstract">arXiv:2405.03000</a> [<a href="/pdf/2405.03000" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03000" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MedAdapter: Efficient Test-Time Adaptation of Large Language
                    Models towards Medical Reasoning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+W">Wenqi Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Ran Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+Y">Yuchen Zhuang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yue Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Hang Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+C">Carl Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M+D">May D. Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Work in Progress
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Despite their improved capabilities in generation and reasoning, adapting
                    large language models (LLMs) to the biomedical domain remains challenging due
                    to their immense size and corporate privacy. In this work, we propose
                    MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards
                    biomedical applications. Instead of fine-tuning the entire LLM, MedAdapter
                    effectively adapts the original model by fine-tuning only a small BERT-sized
                    adapter to rank candidate solutions generated by LLMs. Experiments demonstrate
                    that MedAdapter effectively adapts both white-box and black-box LLMs in
                    biomedical reasoning, achieving average performance improvements of 25.48% and
                    11.31%, respectively, without requiring extensive computational resources or
                    sharing data with third parties. MedAdapter also yields superior performance
                    when combined with train-time adaptation, highlighting a flexible and
                    complementary solution to existing adaptation methods. Faced with the
                    challenges of balancing model performance, computational resources, and data
                    privacy, MedAdapter provides an efficient, privacy-preserving, cost-effective,
                    and transparent solution for adapting LLMs to the biomedical domain.
                </p>
            </div>
        </dd>
        <dt><a name="item354">[354]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03003"
                    title="Abstract">arXiv:2405.03003</a> [<a href="/pdf/2405.03003" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03003" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Parameter-Efficient Fine-Tuning with Discrete Fourier
                    Transform
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Ziqi Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qichao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+A">Aochuan Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zijing Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+B">Bingzhe Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Liang Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jia Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">Low-rank adaptation~(LoRA) has recently gained much interest in fine-tuning
                    foundation models. It effectively reduces the number of trainable parameters by
                    incorporating low-rank matrices <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-154-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1083"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.75em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1084"><span class="mi" id="MathJax-Span-1085"
                                                style="font-family: MathJax_Math-italic;">A</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-154">A</script> and <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-155-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1086"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.75em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1087"><span class="mi" id="MathJax-Span-1088"
                                                style="font-family: MathJax_Math-italic;">B</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-155">B</script> to represent the weight change,
                    i.e., <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-156-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1089"
                                style="width: 5.732em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.748em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1004.75em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1090"><span class="mi" id="MathJax-Span-1091"
                                                style="font-family: MathJax_Main;">Δ</span><span class="mi"
                                                id="MathJax-Span-1092" style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-1093"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mi" id="MathJax-Span-1094"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">B</span><span
                                                class="mi" id="MathJax-Span-1095"
                                                style="font-family: MathJax_Math-italic;">A</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-156">\Delta W=BA</script>. Despite LoRA's progress, it
                    faces storage challenges when
                    handling extensive customization adaptations or larger base models. In this
                    work, we aim to further compress trainable parameters by enjoying the powerful
                    expressiveness of the Fourier transform. Specifically, we introduce FourierFT,
                    which treats <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-157-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1096"
                                style="width: 2.318em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.913em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.91em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1097"><span class="mi" id="MathJax-Span-1098"
                                                style="font-family: MathJax_Main;">Δ</span><span class="mi"
                                                id="MathJax-Span-1099" style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-157">\Delta W</script> as a matrix in the spatial domain
                    and learns only a
                    small fraction of its spectral coefficients. With the trained spectral
                    coefficients, we implement the inverse discrete Fourier transform to recover
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-158-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1100"
                                style="width: 2.318em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.913em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.91em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1101"><span class="mi" id="MathJax-Span-1102"
                                                style="font-family: MathJax_Main;">Δ</span><span class="mi"
                                                id="MathJax-Span-1103" style="font-family: MathJax_Math-italic;">W<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-158">\Delta W</script>. Empirically, our FourierFT
                    method shows comparable or better
                    performance with fewer parameters than LoRA on various tasks, including natural
                    language understanding, natural language generation, instruction tuning, and
                    image classification. For example, when performing instruction tuning on the
                    LLaMA2-7B model, FourierFT surpasses LoRA with only 0.064M trainable
                    parameters, compared to LoRA's 33.5M. Our code is released at
                    \url{https://github.com/Chaos96/fourierft}.
                </p>
            </div>
        </dd>
        <dt><a name="item355">[355]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03004"
                    title="Abstract">arXiv:2405.03004</a> [<a href="/pdf/2405.03004" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03004" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring prompts to elicit memorization in masked language
                    model-based named entity recognition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+Y">Yuxi Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sedova%2C+A">Anastasiia Sedova</a>,
                    <a href="/search/cs?searchtype=author&amp;query=de+Araujo%2C+P+H+L">Pedro Henrique Luz de
                        Araujo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kougia%2C+V">Vasiliki Kougia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nu%C3%9Fbaumer%2C+L">Lisa Nußbaumer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roth%2C+B">Benjamin Roth</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Training data memorization in language models impacts model capability
                    (generalization) and safety (privacy risk). This paper focuses on analyzing
                    prompts' impact on detecting the memorization of 6 masked language model-based
                    named entity recognition models. Specifically, we employ a diverse set of 400
                    automatically generated prompts, and a pairwise dataset where each pair
                    consists of one person's name from the training set and another name out of the
                    set. A prompt completed with a person's name serves as input for getting the
                    model's confidence in predicting this name. Finally, the prompt performance of
                    detecting model memorization is quantified by the percentage of name pairs for
                    which the model has higher confidence for the name from the training set. We
                    show that the performance of different prompts varies by as much as 16
                    percentage points on the same model, and prompt engineering further increases
                    the gap. Moreover, our experiments demonstrate that prompt performance is
                    model-dependent but does generalize across different name sets. A comprehensive
                    analysis indicates how prompt performance is influenced by prompt properties,
                    contained tokens, and the model's self-attention weights on the prompt.
                </p>
            </div>
        </dd>
        <dt><a name="item356">[356]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03005"
                    title="Abstract">arXiv:2405.03005</a> [<a href="/pdf/2405.03005" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03005" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Safe Reinforcement Learning with Learned Non-Markovian Safety
                    Constraints
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Low%2C+S+M">Siow Meng Low</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+A">Akshat Kumar</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">In safe Reinforcement Learning (RL), safety cost is typically defined as a
                    function dependent on the immediate state and actions. In practice, safety
                    constraints can often be non-Markovian due to the insufficient fidelity of
                    state representation, and safety cost may not be known. We therefore address a
                    general setting where safety labels (e.g., safe or unsafe) are associated with
                    state-action trajectories. Our key contributions are: first, we design a safety
                    model that specifically performs credit assignment to assess contributions of
                    partial state-action trajectories on safety. This safety model is trained using
                    a labeled safety dataset. Second, using RL-as-inference strategy we derive an
                    effective algorithm for optimizing a safe policy using the learned safety
                    model. Finally, we devise a method to dynamically adapt the tradeoff
                    coefficient between reward maximization and safety compliance. We rewrite the
                    constrained optimization problem into its dual problem and derive a
                    gradient-based method to dynamically adjust the tradeoff coefficient during
                    training. Our empirical results demonstrate that this approach is highly
                    scalable and able to satisfy sophisticated non-Markovian safety constraints.
                </p>
            </div>
        </dd>
        <dt><a name="item357">[357]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03007"
                    title="Abstract">arXiv:2405.03007</a> [<a href="/pdf/2405.03007" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03007" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the performativity of SDG classifications in large
                    bibliometric databases
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ottaviani%2C+M">Matteo Ottaviani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stahlschmidt%2C+S">Stephan Stahlschmidt</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries
                        (cs.DL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">Large bibliometric databases, such as Web of Science, Scopus, and OpenAlex,
                    facilitate bibliometric analyses, but are performative, affecting the
                    visibility of scientific outputs and the impact measurement of participating
                    entities. Recently, these databases have taken up the UN's Sustainable
                    Development Goals (SDGs) in their respective classifications, which have been
                    criticised for their diverging nature. This work proposes using the feature of
                    large language models (LLMs) to learn about the "data bias" injected by diverse
                    SDG classifications into bibliometric data by exploring five SDGs. We build a
                    LLM that is fine-tuned in parallel by the diverse SDG classifications inscribed
                    into the databases' SDG classifications. Our results show high sensitivity in
                    model architecture, classified publications, fine-tuning process, and natural
                    language generation. The wide arbitrariness at different levels raises concerns
                    about using LLM in research practice.
                </p>
            </div>
        </dd>
        <dt><a name="item358">[358]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03009"
                    title="Abstract">arXiv:2405.03009</a> [<a href="/pdf/2405.03009" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03009" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Explainable Malware Detection with Tailored Logic Explained
                    Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Anthony%2C+P">Peter Anthony</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Giannini%2C+F">Francesco Giannini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Diligenti%2C+M">Michelangelo Diligenti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Homola%2C+M">Martin Homola</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gori%2C+M">Marco Gori</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Balogh%2C+S">Stefan Balogh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mojzis%2C+J">Jan Mojzis</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Malware detection is a constant challenge in cybersecurity due to the rapid
                    development of new attack techniques. Traditional signature-based approaches
                    struggle to keep pace with the sheer volume of malware samples. Machine
                    learning offers a promising solution, but faces issues of generalization to
                    unseen samples and a lack of explanation for the instances identified as
                    malware. However, human-understandable explanations are especially important in
                    security-critical fields, where understanding model decisions is crucial for
                    trust and legal compliance. While deep learning models excel at malware
                    detection, their black-box nature hinders explainability. Conversely,
                    interpretable models often fall short in performance. To bridge this gap in
                    this application domain, we propose the use of Logic Explained Networks (LENs),
                    which are a recently proposed class of interpretable neural networks providing
                    explanations in the form of First-Order Logic (FOL) rules. This paper extends
                    the application of LENs to the complex domain of malware detection,
                    specifically using the large-scale EMBER dataset. In the experimental results
                    we show that LENs achieve robustness that exceeds traditional interpretable
                    methods and that are rivaling black-box models. Moreover, we introduce a
                    tailored version of LENs that is shown to generate logic explanations with
                    higher fidelity with respect to the model's predictions.
                </p>
            </div>
        </dd>
        <dt><a name="item359">[359]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03010"
                    title="Abstract">arXiv:2405.03010</a> [<a href="/pdf/2405.03010" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03010" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> High Order Reasoning for Time Critical Recommendation in
                    Evidence-based Medicine
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+M">Manjiang Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xue Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages, 15 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">In time-critical decisions, human decision-makers can interact with
                    AI-enabled situation-aware software to evaluate many imminent and possible
                    scenarios, retrieve billions of facts, and estimate different outcomes based on
                    trillions of parameters in a fraction of a second. In high-order reasoning,
                    "what-if" questions can be used to challenge the assumptions or pre-conditions
                    of the reasoning, "why-not" questions can be used to challenge on the method
                    applied in the reasoning, "so-what" questions can be used to challenge the
                    purpose of the decision, and "how-about" questions can be used to challenge the
                    applicability of the method. When above high-order reasoning questions are
                    applied to assist human decision-making, it can help humans to make
                    time-critical decisions and avoid false-negative or false-positive types of
                    errors. In this paper, we present a model of high-order reasoning to offer
                    recommendations in evidence-based medicine in a time-critical fashion for the
                    applications in ICU. The Large Language Model (LLM) is used in our system. The
                    experiments demonstrated the LLM exhibited optimal performance in the "What-if"
                    scenario, achieving a similarity of 88.52% with the treatment plans of human
                    doctors. In the "Why-not" scenario, the best-performing model tended to opt for
                    alternative treatment plans in 70% of cases for patients who died after being
                    discharged from the ICU. In the "So-what" scenario, the optimal model provided
                    a detailed analysis of the motivation and significance of treatment plans for
                    ICU patients, with its reasoning achieving a similarity of 55.6% with actual
                    diagnostic information. In the "How-about" scenario, the top-performing LLM
                    demonstrated a content similarity of 66.5% in designing treatment plans
                    transferring for similar diseases. Meanwhile, LLMs managed to predict the life
                    status of patients after their discharge from the ICU with an accuracy of 70%.
                </p>
            </div>
        </dd>
        <dt><a name="item360">[360]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03011"
                    title="Abstract">arXiv:2405.03011</a> [<a href="/pdf/2405.03011" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03011" title="Download PostScript">ps</a>, <a href="/format/2405.03011"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AC-MAMBASEG: An adaptive convolution and Mamba-based
                    architecture for enhanced skin lesion segmentation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+V">Viet-Thanh Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pham%2C+V">Van-Truong Pham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tran%2C+T">Thi-Thao Tran</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 7 figures, 4 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Skin lesion segmentation is a critical task in computer-aided diagnosis
                    systems for dermatological diseases. Accurate segmentation of skin lesions from
                    medical images is essential for early detection, diagnosis, and treatment
                    planning. In this paper, we propose a new model for skin lesion segmentation
                    namely AC-MambaSeg, an enhanced model that has the hybrid CNN-Mamba backbone,
                    and integrates advanced components such as Convolutional Block Attention Module
                    (CBAM), Attention Gate, and Selective Kernel Bottleneck. AC-MambaSeg leverages
                    the Vision Mamba framework for efficient feature extraction, while CBAM and
                    Selective Kernel Bottleneck enhance its ability to focus on informative regions
                    and suppress background noise. We evaluate the performance of AC-MambaSeg on
                    diverse datasets of skin lesion images including ISIC-2018 and PH2; then
                    compare it against existing segmentation methods. Our model shows promising
                    potential for improving computer-aided diagnosis systems and facilitating early
                    detection and treatment of dermatological diseases. Our source code will be
                    made available at: https://github.com/vietthanh2710/AC-MambaSeg.
                </p>
            </div>
        </dd>
        <dt><a name="item361">[361]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03016"
                    title="Abstract">arXiv:2405.03016</a> [<a href="/pdf/2405.03016" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03016" title="Download PostScript">ps</a>, <a href="/format/2405.03016"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Pathwise uniform convergence of a full discretization for a
                    three-dimensional stochastic Allen-Cahn equation with multiplicative noise
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Li%2C+B">Binjie Li</a>,
                    <a href="/search/math?searchtype=author&amp;query=Zhou%2C+Q">Qin Zhou</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">This paper analyzes a full discretization of a three-dimensional stochastic
                    Allen-Cahn equation with multiplicative noise. The discretization uses the
                    Euler scheme for temporal discretization and the finite element method for
                    spatial discretization. By deriving a stability estimate of a discrete
                    stochastic convolution and utilizing this stability estimate along with the
                    discrete stochastic maximal <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-159-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1104"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.1em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1105"><span class="msubsup"
                                                id="MathJax-Span-1106"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1107"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.697em;"><span
                                                            class="mi" id="MathJax-Span-1108"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-159">L^p</script>-regularity estimate, a pathwise
                    uniform
                    convergence rate with the general spatial <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-160-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1109"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.1em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1110"><span class="msubsup"
                                                id="MathJax-Span-1111"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1112"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.697em;"><span
                                                            class="mi" id="MathJax-Span-1113"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">q<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-160"> L^q </script>-norms is derived.
                </p>
            </div>
        </dd>
        <dt><a name="item362">[362]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03017"
                    title="Abstract">arXiv:2405.03017</a> [<a href="/pdf/2405.03017" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03017" title="Download PostScript">ps</a>, <a href="/format/2405.03017"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fault-tolerant Consensus in Anonymous Dynamic Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qinzi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tseng%2C+L">Lewis Tseng</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>

                </div>
                <p class="mathjax">This paper studies the feasibility of reaching consensus in an anonymous
                    dynamic network. In our model, <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-161-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1114"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1115"><span class="mi" id="MathJax-Span-1116"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-161">n</script> anonymous nodes proceed in synchronous
                    rounds. We adopt a hybrid fault model in which up to <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-162-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1117"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.318em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1118"><span class="mi" id="MathJax-Span-1119"
                                                style="font-family: MathJax_Math-italic;">f<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-162">f</script> nodes may suffer crash
                    or Byzantine faults, and the dynamic message adversary chooses a communication
                    graph for each round.
                    <br>We introduce a stability property of the dynamic network --
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-163-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1120"
                                style="width: 3.359em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.781em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.66em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1121"><span class="mo" id="MathJax-Span-1122"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1123" style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-1124"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1125"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">D</span><span
                                                class="mo" id="MathJax-Span-1126"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-163">(T,D)</script>-dynaDegree for <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-164-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1127"
                                style="width: 3.07em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.549em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.49em, 2.433em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1128"><span class="mi" id="MathJax-Span-1129"
                                                style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-1130"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≥</span><span
                                                class="mn" id="MathJax-Span-1131"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-164">T \geq 1</script> and <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-165-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1132"
                                style="width: 7.758em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.427em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1006.37em, 2.433em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1133"><span class="mi" id="MathJax-Span-1134"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-1135"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mn" id="MathJax-Span-1136"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">1</span><span
                                                class="mo" id="MathJax-Span-1137"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≥</span><span
                                                class="mi" id="MathJax-Span-1138"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">D</span><span
                                                class="mo" id="MathJax-Span-1139"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≥</span><span
                                                class="mn" id="MathJax-Span-1140"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-165">n-1 \geq D \geq 1</script> -- which requires
                    that for every <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-166-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1141"
                                style="width: 0.871em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.7em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1142"><span class="mi" id="MathJax-Span-1143"
                                                style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-166">T</script> consecutive rounds, any fault-free node
                    must have incoming
                    directed links from at least <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-167-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1144"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.81em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1145"><span class="mi" id="MathJax-Span-1146"
                                                style="font-family: MathJax_Math-italic;">D</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-167">D</script> distinct neighbors. These links might
                    occur in
                    different rounds during a <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-168-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1147"
                                style="width: 0.871em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.7em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1148"><span class="mi" id="MathJax-Span-1149"
                                                style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-168">T</script>-round interval. <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-169-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1150"
                                style="width: 4.98em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.112em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1151"><span class="mo" id="MathJax-Span-1152"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-1153" style="font-family: MathJax_Main;">1</span><span
                                                class="mo" id="MathJax-Span-1154"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1155"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="mo" id="MathJax-Span-1156"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mn" id="MathJax-Span-1157"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">1</span><span
                                                class="mo" id="MathJax-Span-1158"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-169">(1,n-1)</script>-dynaDegree means that
                    the graph is a complete graph in every round. <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-170-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1159"
                                style="width: 2.723em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.14em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1160"><span class="mo" id="MathJax-Span-1161"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-1162" style="font-family: MathJax_Main;">1</span><span
                                                class="mo" id="MathJax-Span-1163"
                                                style="font-family: MathJax_Main;">,</span><span class="mn"
                                                id="MathJax-Span-1164"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">1</span><span
                                                class="mo" id="MathJax-Span-1165"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-170">(1,1)</script>-dynaDegree means that
                    each node has at least one incoming neighbor in every round, but the set of
                    incoming neighbor(s) at each node may change arbitrarily between rounds.
                    <br>We show that exact consensus is impossible even with <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-171-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1166"
                                style="width: 4.98em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.112em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1167"><span class="mo" id="MathJax-Span-1168"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-1169" style="font-family: MathJax_Main;">1</span><span
                                                class="mo" id="MathJax-Span-1170"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1171"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="mo" id="MathJax-Span-1172"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mn" id="MathJax-Span-1173"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">2</span><span
                                                class="mo" id="MathJax-Span-1174"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-171">(1,n-2)</script>-dynaDegree.
                    For an arbitrary <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-172-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1175"
                                style="width: 0.871em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.7em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1176"><span class="mi" id="MathJax-Span-1177"
                                                style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-172">T</script>, we show that for crash-tolerant
                    approximate consensus,
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-173-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1178"
                                style="width: 5.327em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.401em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.28em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1179"><span class="mo" id="MathJax-Span-1180"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1181" style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-1182"
                                                style="font-family: MathJax_Main;">,</span><span class="mo"
                                                id="MathJax-Span-1183"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">⌊</span><span
                                                class="mi" id="MathJax-Span-1184"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="texatom"
                                                id="MathJax-Span-1185"><span class="mrow" id="MathJax-Span-1186"><span
                                                        class="mo" id="MathJax-Span-1187"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="mn" id="MathJax-Span-1188"
                                                style="font-family: MathJax_Main;">2</span><span class="mo"
                                                id="MathJax-Span-1189" style="font-family: MathJax_Main;">⌋</span><span
                                                class="mo" id="MathJax-Span-1190"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-173">(T,\lfloor n/2 \rfloor)</script>-dynaDegree and
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-174-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1191"
                                style="width: 3.649em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.012em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1003.01em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1192"><span class="mi" id="MathJax-Span-1193"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-1194"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">&gt;</span><span
                                                class="mn" id="MathJax-Span-1195"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">2</span><span
                                                class="mi" id="MathJax-Span-1196"
                                                style="font-family: MathJax_Math-italic;">f<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-174">n > 2f</script> are together necessary and
                    sufficient, whereas for Byzantine approximate consensus, <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-175-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1197"
                                style="width: 9.031em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 7.526em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1007.41em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1198"><span class="mo" id="MathJax-Span-1199"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1200" style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-1201"
                                                style="font-family: MathJax_Main;">,</span><span class="mo"
                                                id="MathJax-Span-1202"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">⌊</span><span
                                                class="mo" id="MathJax-Span-1203"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1204"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-1205"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mn" id="MathJax-Span-1206"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">3</span><span
                                                class="mi" id="MathJax-Span-1207"
                                                style="font-family: MathJax_Math-italic;">f<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="mo" id="MathJax-Span-1208"
                                                style="font-family: MathJax_Main;">)</span><span class="texatom"
                                                id="MathJax-Span-1209"><span class="mrow" id="MathJax-Span-1210"><span
                                                        class="mo" id="MathJax-Span-1211"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="mn" id="MathJax-Span-1212"
                                                style="font-family: MathJax_Main;">2</span><span class="mo"
                                                id="MathJax-Span-1213" style="font-family: MathJax_Main;">⌋</span><span
                                                class="mo" id="MathJax-Span-1214"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-175">(T,\lfloor (n+3f)/2
    \rfloor)</script>-dynaDegree and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-176-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1215"
                                style="width: 3.649em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.012em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1003.01em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1216"><span class="mi" id="MathJax-Span-1217"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-1218"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">&gt;</span><span
                                                class="mn" id="MathJax-Span-1219"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">5</span><span
                                                class="mi" id="MathJax-Span-1220"
                                                style="font-family: MathJax_Math-italic;">f<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-176">n > 5f</script> are together necessary and
                    sufficient.
                </p>
            </div>
        </dd>
        <dt><a name="item363">[363]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03018"
                    title="Abstract">arXiv:2405.03018</a> [<a href="/pdf/2405.03018" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03018" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TSP Escapes the <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-177-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1221"
                                style="width: 4.308em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.567em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.206em, 1003.48em, 2.549em, -999.998em); top: -2.174em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1222"><span class="mi" id="MathJax-Span-1223"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-1224" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-1225"><span
                                                    style="display: inline-block; position: relative; width: 1.021em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.197em, 1000.47em, 4.123em, -999.998em); top: -3.979em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-1226"
                                                            style="font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span
                                                        style="position: absolute; top: -4.35em; left: 0.512em;"><span
                                                            class="mi" id="MathJax-Span-1227"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-1228"><span
                                                    style="display: inline-block; position: relative; width: 1.021em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.382em, 1000.6em, 4.123em, -999.998em); top: -3.979em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1229"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span
                                                        style="position: absolute; top: -4.35em; left: 0.604em;"><span
                                                            class="mn" id="MathJax-Span-1230"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1231"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.178em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.331em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-177">O(2^n n^2)</script> Curse
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Stoian%2C+M">Mihail Stoian</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

                </div>
                <p class="mathjax">The dynamic programming solution to the traveling salesman problem due to
                    Bellman, and independently Held and Karp, runs in time <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-178-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1232"
                                style="width: 4.343em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.591em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1003.48em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1233"><span class="mi" id="MathJax-Span-1234"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-1235" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-1236"><span
                                                    style="display: inline-block; position: relative; width: 0.987em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.47em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-1237"
                                                            style="font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.524em;"><span
                                                            class="mi" id="MathJax-Span-1238"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-1239"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1240"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-1241"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1242"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-178">O(2^n n^2)</script>, with no
                    improvement in the last sixty years. We break this barrier for the first time
                    by designing an algorithm that runs in deterministic time <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-179-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1243"
                                style="width: 7.642em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.369em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.987em, 1006.37em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1244"><span class="msubsup"
                                                id="MathJax-Span-1245"><span
                                                    style="display: inline-block; position: relative; width: 0.987em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.47em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-1246"
                                                            style="font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.524em;"><span
                                                            class="mi" id="MathJax-Span-1247"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-1248"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1249"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-1250"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="texatom" id="MathJax-Span-1251"><span class="mrow"
                                                    id="MathJax-Span-1252"><span class="mo" id="MathJax-Span-1253"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="msubsup" id="MathJax-Span-1254"><span
                                                    style="display: inline-block; position: relative; width: 3.822em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.47em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-1255"
                                                            style="font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.524em;"><span
                                                            class="texatom" id="MathJax-Span-1256"><span class="mrow"
                                                                id="MathJax-Span-1257"><span class="mi"
                                                                    id="MathJax-Span-1258"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">Ω</span><span
                                                                    class="mo" id="MathJax-Span-1259"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span
                                                                    class="msqrt" id="MathJax-Span-1260"><span
                                                                        style="display: inline-block; position: relative; width: 2.202em; height: 0px;"><span
                                                                            style="position: absolute; clip: rect(3.359em, 1001.51em, 4.343em, -999.997em); top: -3.99em; left: 0.697em;"><span
                                                                                class="mrow"
                                                                                id="MathJax-Span-1261"><span class="mi"
                                                                                    id="MathJax-Span-1262"
                                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">log</span><span
                                                                                    class="mo" id="MathJax-Span-1263"
                                                                                    style="font-size: 70.7%;"></span><span
                                                                                    class="mi" id="MathJax-Span-1264"
                                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic; padding-left: 0.234em;">n</span></span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                            style="position: absolute; clip: rect(0.987em, 1001.51em, 1.334em, -999.997em); top: -1.733em; left: 0.697em;"><span
                                                                                style="display: inline-block; overflow: hidden; vertical-align: -0.055em; border-top: 1.3px solid; width: 1.508em; height: 0px;"></span><span
                                                                                style="display: inline-block; width: 0px; height: 1.102em;"></span></span><span
                                                                            style="position: absolute; clip: rect(3.244em, 1000.7em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span><span
                                                                                    style="font-size: 70.7%; font-family: MathJax_Size1;">√</span></span><span
                                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                                    class="mo" id="MathJax-Span-1265"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.601em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-179">2^n n^2 /
    2^{\Omega(\sqrt{\log n})}</script>. We achieve this by strategically remodeling the
                    dynamic programming recursion as a min-plus matrix product, for which
                    faster-than-na\"ive algorithms exist.
                </p>
            </div>
        </dd>
        <dt><a name="item364">[364]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03025"
                    title="Abstract">arXiv:2405.03025</a> [<a href="/pdf/2405.03025" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03025" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Matten: Video Generation with Mamba-Attention
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yu Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jiancheng Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+X">Xiaopeng Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jie%2C+Z">Zequn Jie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yujie Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+L">Lin Ma</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">In this paper, we introduce Matten, a cutting-edge latent diffusion model
                    with Mamba-Attention architecture for video generation. With minimal
                    computational cost, Matten employs spatial-temporal attention for local video
                    content modeling and bidirectional Mamba for global video content modeling. Our
                    comprehensive experimental evaluation demonstrates that Matten has competitive
                    performance with the current Transformer-based and GAN-based models in
                    benchmark performance, achieving superior FVD scores and efficiency.
                    Additionally, we observe a direct positive correlation between the complexity
                    of our designed model and the improvement in video quality, indicating the
                    excellent scalability of Matten.
                </p>
            </div>
        </dd>
        <dt><a name="item365">[365]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03026"
                    title="Abstract">arXiv:2405.03026</a> [<a href="/pdf/2405.03026" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03026" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhanced Detection Classification via Clustering SVM for
                    Various Robot Collaboration Task
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+R">Rui Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xuanzhen Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yuwei Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+A">Armando Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+C">Chang Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tianjian Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Ye Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper has been received by CISCE 2024 Conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">We introduce an advanced, swift pattern recognition strategy for various
                    multiple robotics during curve negotiation. This method, leveraging a
                    sophisticated k-means clustering-enhanced Support Vector Machine algorithm,
                    distinctly categorizes robotics into flying or mobile robots. Initially, the
                    paradigm considers robot locations and features as quintessential parameters
                    indicative of divergent robot patterns. Subsequently, employing the k-means
                    clustering technique facilitates the efficient segregation and consolidation of
                    robotic data, significantly optimizing the support vector delineation process
                    and expediting the recognition phase. Following this preparatory phase, the SVM
                    methodology is adeptly applied to construct a discriminative hyperplane,
                    enabling precise classification and prognostication of the robot category. To
                    substantiate the efficacy and superiority of the k-means framework over
                    traditional SVM approaches, a rigorous cross-validation experiment was
                    orchestrated, evidencing the former's enhanced performance in robot group
                    classification.
                </p>
            </div>
        </dd>
        <dt><a name="item366">[366]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03029"
                    title="Abstract">arXiv:2405.03029</a> [<a href="/pdf/2405.03029" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03029" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Optimal Box Contraction for Solving Linear Systems via
                    Simulated and Quantum Annealing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Suresh%2C+S">Sanjay Suresh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Suresh%2C+K">Krishnan Suresh</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>

                </div>
                <p class="mathjax">Solving linear systems of equations is an important problem in science and
                    engineering. Many quantum algorithms, such as the Harrow-Hassidim-Lloyd (HHL)
                    algorithm (for quantum-gate computers) and the box algorithm (for
                    quantum-annealing machines), have been proposed for solving such systems.
                    <br>The focus of this paper is on improving the efficiency of the box algorithm.
                    The basic principle behind this algorithm is to transform the linear system
                    into a series of quadratic unconstrained binary optimization (QUBO) problems,
                    which are then solved on annealing machines.
                    <br>The computational efficiency of the box algorithm is entirely determined by
                    the number of iterations, which, in turn, depends on the box contraction ratio,
                    typically set to 0.5. Here, we show through theory that a contraction ratio of
                    0.5 is sub-optimal and that we can achieve a speed-up with a contraction ratio
                    of 0.2. This is confirmed through numerical experiments where a speed-up
                    between <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-180-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1266"
                                style="width: 2.26em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.855em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.8em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1267"><span class="mn" id="MathJax-Span-1268"
                                                style="font-family: MathJax_Main;">20</span><span class="mi"
                                                id="MathJax-Span-1269"
                                                style="font-family: MathJax_Main;">%</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-180">20 \%</script> to <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-181-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1270"
                                style="width: 2.26em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.855em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.8em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1271"><span class="mn" id="MathJax-Span-1272"
                                                style="font-family: MathJax_Main;">60</span><span class="mi"
                                                id="MathJax-Span-1273"
                                                style="font-family: MathJax_Main;">%</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-181">60 \%</script> is observed when the optimal
                    contraction ratio is
                    used.
                </p>
            </div>
        </dd>
        <dt><a name="item367">[367]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03031"
                    title="Abstract">arXiv:2405.03031</a> [<a href="/pdf/2405.03031" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03031" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Distributed Learning for Dynamic Congestion Games
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Hongbo Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Duan%2C+L">Lingjie Duan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper has been accepted by IEEE ISIT 2024. arXiv
                    admin note: substantial text overlap with <a href="/abs/2404.15599">arXiv:2404.15599</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>

                </div>
                <p class="mathjax">Today mobile users learn and share their traffic observations via
                    crowdsourcing platforms (e.g., Google Maps and Waze). Yet such platforms
                    myopically recommend the currently shortest path to users, and selfish users
                    are unwilling to travel to longer paths of varying traffic conditions to
                    explore. Prior studies focus on one-shot congestion games without information
                    learning, while our work studies how users learn and alter traffic conditions
                    on stochastic paths in a distributed manner. Our analysis shows that, as
                    compared to the social optimum in minimizing the long-term social cost via
                    optimal exploration-exploitation tradeoff, the myopic routing policy leads to
                    severe under-exploration of stochastic paths with the price of anarchy (PoA)
                    greater than \(2\). Besides, it fails to ensure the correct learning
                    convergence about users' traffic hazard beliefs. To mitigate the efficiency
                    loss, we first show that existing information-hiding mechanisms and
                    deterministic path-recommendation mechanisms in Bayesian persuasion literature
                    do not work with even \(\text{PoA}=\infty\). Accordingly, we propose a new
                    combined hiding and probabilistic recommendation (CHAR) mechanism to hide all
                    information from a selected user group and provide state-dependent
                    probabilistic recommendations to the other user group. Our CHAR successfully
                    ensures PoA less than \(\frac{5}{4}\), which cannot be further reduced by any
                    other informational mechanism. Additionally, we experiment with real-world data
                    to verify our CHAR's good average performance.
                </p>
            </div>
        </dd>
        <dt><a name="item368">[368]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03034"
                    title="Abstract">arXiv:2405.03034</a> [<a href="/pdf/2405.03034" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03034" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FlexKalmanNet: A Modular AI-Enhanced Kalman Filter Framework
                    Applied to Spacecraft Motion Estimation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Vogt%2C+M+D+P">Moritz D. Pinheiro-Torres Vogt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huwald%2C+M">Markus Huwald</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ben-Larbi%2C+M+K">M. Khalil Ben-Larbi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stoll%2C+E">Enrico Stoll</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Earth and Planetary Astrophysics (astro-ph.EP)

                </div>
                <p class="mathjax">The estimation of relative motion between spacecraft increasingly relies on
                    feature-matching computer vision, which feeds data into a recursive filtering
                    algorithm. Kalman filters, although efficient in noise compensation, demand
                    extensive tuning of system and noise models. This paper introduces
                    FlexKalmanNet, a novel modular framework that bridges this gap by integrating a
                    deep fully connected neural network with Kalman filter-based motion estimation
                    algorithms. FlexKalmanNet's core innovation is its ability to learn any Kalman
                    filter parameter directly from measurement data, coupled with the flexibility
                    to utilize various Kalman filter variants. This is achieved through a notable
                    design decision to outsource the sequential computation from the neural network
                    to the Kalman filter variant, enabling a purely feedforward neural network
                    architecture. This architecture, proficient at handling complex, nonlinear
                    features without the dependency on recurrent network modules, captures global
                    data patterns more effectively. Empirical evaluation using data from NASA's
                    Astrobee simulation environment focuses on learning unknown parameters of an
                    Extended Kalman filter for spacecraft pose and twist estimation. The results
                    demonstrate FlexKalmanNet's rapid training convergence, high accuracy, and
                    superior performance against manually tuned Extended Kalman filters.
                </p>
            </div>
        </dd>
        <dt><a name="item369">[369]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03035"
                    title="Abstract">arXiv:2405.03035</a> [<a href="/pdf/2405.03035" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03035" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Probabilistic Finite Automaton Emptiness is undecidable
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Rote%2C+G">Günter Rote</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 45 pages, 10 figures, 2 tables, 30 footnotes, 10 sections
                    plus 1 appendix
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and
                        Automata Theory (cs.FL)</span>

                </div>
                <p class="mathjax">It is undecidable whether the language recognized by a probabilistic finite
                    automaton is empty. Several other undecidability results, in particular
                    regarding problems about matrix products, are based on this important theorem.
                    We present two proofs of this theorem from the literature in a self-contained
                    way, and we derive some strengthenings. For example, we show that the problem
                    remains undecidable for a fixed probabilistic finite automaton with 11 states,
                    where only the starting distribution is given as input.
                </p>
            </div>
        </dd>
        <dt><a name="item370">[370]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03038"
                    title="Abstract">arXiv:2405.03038</a> [<a href="/pdf/2405.03038" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03038" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the use of dynamical systems in cryptography
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Everett%2C+S">Samuel Everett</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages, 1 figure, to appear in Chaos, Solitons and
                    Fractals
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Ever since the link between nonlinear science and cryptography became
                    apparent, the problem of applying chaotic dynamics to the construction of
                    cryptographic systems has gained a broad audience and has been the subject of
                    thousands of papers. Yet, the field has not found its place in mainstream
                    cryptography, largely due to persistent weaknesses in the presented systems.
                    The goal of this paper is to help remedy this problem in two ways. The first is
                    by providing a new algorithm that can be used to attack -- and hence test the
                    security of -- stream ciphers based on the iteration of a chaotic map of the
                    interval. The second is to cast discrete dynamical systems problems in a modern
                    cryptographic and complexity theoretic language, so that researchers working in
                    chaos-based cryptography can begin designing cryptographic protocols that have
                    a better chance of meeting the extreme standards of modern cryptography.
                </p>
            </div>
        </dd>
        <dt><a name="item371">[371]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03039"
                    title="Abstract">arXiv:2405.03039</a> [<a href="/pdf/2405.03039" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03039" title="Download PostScript">ps</a>, <a href="/format/2405.03039"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Performance Evaluation of Real-Time Object Detection for
                    Electric Scooters
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+D">Dong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hosseini%2C+A">Arman Hosseini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Smith%2C+A">Arik Smith</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nikkhah%2C+A+F">Amir Farzin Nikkhah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Heydarian%2C+A">Arsalan Heydarian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shoghli%2C+O">Omid Shoghli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Campbell%2C+B">Bradford Campbell</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 3 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">Electric scooters (e-scooters) have rapidly emerged as a popular mode of
                    transportation in urban areas, yet they pose significant safety challenges. In
                    the United States, the rise of e-scooters has been marked by a concerning
                    increase in related injuries and fatalities. Recently, while deep-learning
                    object detection holds paramount significance in autonomous vehicles to avoid
                    potential collisions, its application in the context of e-scooters remains
                    relatively unexplored. This paper addresses this gap by assessing the
                    effectiveness and efficiency of cutting-edge object detectors designed for
                    e-scooters. To achieve this, the first comprehensive benchmark involving 22
                    state-of-the-art YOLO object detectors, including five versions (YOLOv3,
                    YOLOv5, YOLOv6, YOLOv7, and YOLOv8), has been established for real-time traffic
                    object detection using a self-collected dataset featuring e-scooters. The
                    detection accuracy, measured in terms of mAP@0.5, ranges from 27.4%
                    (YOLOv7-E6E) to 86.8% (YOLOv5s). All YOLO models, particularly YOLOv3-tiny,
                    have displayed promising potential for real-time object detection in the
                    context of e-scooters. Both the traffic scene dataset
                    (https://zenodo.org/records/10578641) and software program codes
                    (https://github.com/DongChen06/ScooterDet) for model benchmarking in this study
                    are publicly available, which will not only improve e-scooter safety with
                    advanced object detection but also lay the groundwork for tailored solutions,
                    promising a safer and more sustainable urban micromobility landscape.
                </p>
            </div>
        </dd>
        <dt><a name="item372">[372]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03045"
                    title="Abstract">arXiv:2405.03045</a> [<a href="/pdf/2405.03045" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03045" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Swipe2Pair: Secure and Fast In-Band Wireless Device Pairing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+Y">Yaqi He</a> (1),
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+K">Kai Zeng</a> (1),
                    <a href="/search/cs?searchtype=author&amp;query=Jiao%2C+L">Long Jiao</a> (2),
                    <a href="/search/cs?searchtype=author&amp;query=Mark%2C+B+L">Brian L. Mark</a> (1),
                    <a href="/search/cs?searchtype=author&amp;query=Khasawneh%2C+K+N">Khaled N. Khasawneh</a> (1) ((1)
                    George Mason University, (2) University of Massachusetts Dartmouth)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

                </div>
                <p class="mathjax">Wireless device pairing is a critical security mechanism to bootstrap the
                    secure communication between two devices without a pre-shared secret. It has
                    been widely used in many Internet of Things (IoT) applications, such as
                    smart-home and smart-health. Most existing device pairing mechanisms are based
                    on out-of-band channels, e.g., extra sensors or hardware, to validate the
                    proximity of pairing devices. However, out-of-band channels are not universal
                    across all wireless devices, so such a scheme is limited to certain application
                    scenarios or conditions. On the other hand, in-band channel-based device
                    pairing seeks universal applicability by only relying on wireless interfaces.
                    Existing in-band channel-based pairing schemes either require multiple antennas
                    separated by a good distance on one pairing device, which is not feasible in
                    certain scenarios, or require users to repeat multiple sweeps, which is not
                    optimal in terms of usability.
                    <br>Therefore, an in-band wireless device pairing scheme providing high security
                    while maintaining high usability (simple pairing process and minimal user
                    intervention) is highly desired. In this work, we propose an easy-to-use mutual
                    authentication device pairing scheme, named Swipe2Pair, based on the proximity
                    of pairing devices and randomization of wireless transmission power. We conduct
                    extensive security analysis and collect considerable experimental data under
                    various settings across different environments. Experimental results show that
                    Swipe2Pair achieves high security and usability. It only takes less than one
                    second to complete the pairing process with a simple swipe of one device in
                    front of the other.
                </p>
            </div>
        </dd>
        <dt><a name="item373">[373]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03052"
                    title="Abstract">arXiv:2405.03052</a> [<a href="/pdf/2405.03052" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03052" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A View on Out-of-Distribution Identification from a
                    Statistical Testing Theory Perspective
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Caron%2C+A">Alberto Caron</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hicks%2C+C">Chris Hicks</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mavroudis%2C+V">Vasilios Mavroudis</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">We study the problem of efficiently detecting Out-of-Distribution (OOD)
                    samples at test time in supervised and unsupervised learning contexts. While ML
                    models are typically trained under the assumption that training and test data
                    stem from the same distribution, this is often not the case in realistic
                    settings, thus reliably detecting distribution shifts is crucial at deployment.
                    We re-formulate the OOD problem under the lenses of statistical testing and
                    then discuss conditions that render the OOD problem identifiable in statistical
                    terms. Building on this framework, we study convergence guarantees of an OOD
                    test based on the Wasserstein distance, and provide a simple empirical
                    evaluation.
                </p>
            </div>
        </dd>
        <dt><a name="item374">[374]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03055"
                    title="Abstract">arXiv:2405.03055</a> [<a href="/pdf/2405.03055" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03055" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multi-hop graph transformer network for 3D human pose
                    estimation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Islam%2C+Z">Zaedul Islam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hamza%2C+A+B">A. Ben Hamza</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Journal of Visual Communication and Image
                    Representation, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Accurate 3D human pose estimation is a challenging task due to occlusion and
                    depth ambiguity. In this paper, we introduce a multi-hop graph transformer
                    network designed for 2D-to-3D human pose estimation in videos by leveraging the
                    strengths of multi-head self-attention and multi-hop graph convolutional
                    networks with disentangled neighborhoods to capture spatio-temporal
                    dependencies and handle long-range interactions. The proposed network
                    architecture consists of a graph attention block composed of stacked layers of
                    multi-head self-attention and graph convolution with learnable adjacency
                    matrix, and a multi-hop graph convolutional block comprised of multi-hop
                    convolutional and dilated convolutional layers. The combination of multi-head
                    self-attention and multi-hop graph convolutional layers enables the model to
                    capture both local and global dependencies, while the integration of dilated
                    convolutional layers enhances the model's ability to handle spatial details
                    required for accurate localization of the human body joints. Extensive
                    experiments demonstrate the effectiveness and generalization ability of our
                    model, achieving competitive performance on benchmark datasets.
                </p>
            </div>
        </dd>
        <dt><a name="item375">[375]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03056"
                    title="Abstract">arXiv:2405.03056</a> [<a href="/pdf/2405.03056" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03056" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Convolutional Learning on Directed Acyclic Graphs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Rey%2C+S">Samuel Rey</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ajorlou%2C+H">Hamed Ajorlou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mateos%2C+G">Gonzalo Mateos</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">We develop a novel convolutional architecture tailored for learning from data
                    defined over directed acyclic graphs (DAGs). DAGs can be used to model causal
                    relationships among variables, but their nilpotent adjacency matrices pose
                    unique challenges towards developing DAG signal processing and machine learning
                    tools. To address this limitation, we harness recent advances offering
                    alternative definitions of causal shifts and convolutions for signals on DAGs.
                    We develop a novel convolutional graph neural network that integrates learnable
                    DAG filters to account for the partial ordering induced by the graph topology,
                    thus providing valuable inductive bias to learn effective representations of
                    DAG-supported data. We discuss the salient advantages and potential limitations
                    of the proposed DAG convolutional network (DCN) and evaluate its performance on
                    two learning tasks using synthetic data: network diffusion estimation and
                    source identification. DCN compares favorably relative to several baselines,
                    showcasing its promising potential.
                </p>
            </div>
        </dd>
        <dt><a name="item376">[376]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03057"
                    title="Abstract">arXiv:2405.03057</a> [<a href="/pdf/2405.03057" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03057" title="Download PostScript">ps</a>, <a href="/format/2405.03057"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Verifying SQL Queries using Theories of Tables and Relations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mohamed%2C+M">Mudathir Mohamed</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reynolds%2C+A">Andrew Reynolds</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tinelli%2C+C">Cesare Tinelli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Barrett%2C+C">Clark Barrett</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>

                </div>
                <p class="mathjax">We present a number of first- and second-order extensions to SMT theories
                    specifically aimed at representing and analyzing SQL queries with join,
                    projection, and selection operations. We support reasoning about SQL queries
                    with either bag or set semantics for database tables. We provide the former via
                    an extension of a theory of finite bags and the latter via an extension of the
                    theory of finite relations. Furthermore, we add the ability to reason about
                    tables with null values by introducing a theory of nullable sorts based on an
                    extension of the theory of algebraic datatypes. We implemented solvers for
                    these theories in the SMT solver cvc5 and evaluated them on a set of benchmarks
                    derived from public sets of SQL equivalence problems.
                </p>
            </div>
        </dd>
        <dt><a name="item377">[377]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03058"
                    title="Abstract">arXiv:2405.03058</a> [<a href="/pdf/2405.03058" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03058" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing High-Level Synthesis with Automated Pragma
                    Insertion and Code Transformation Framework
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pouget%2C+S">Stèphane Pouget</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pouchet%2C+L">Louis-Noël Pouchet</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cong%2C+J">Jason Cong</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">High-level synthesis, source-to-source compilers, and various Design Space
                    Exploration techniques for pragma insertion have significantly improved the
                    Quality of Results of generated designs. These tools offer benefits such as
                    reduced development time and enhanced performance. However, achieving
                    high-quality results often requires additional manual code transformations and
                    tiling selections, which are typically performed separately or as
                    pre-processing steps. Although DSE techniques enable code transformation
                    upfront, the vastness of the search space often limits the exploration of all
                    possible code transformations, making it challenging to determine which
                    transformations are necessary. Additionally, ensuring correctness remains
                    challenging, especially for complex transformations and optimizations.
                    <br>To tackle this obstacle, we first propose a comprehensive framework
                    leveraging HLS compilers. Our system streamlines code transformation, pragma
                    insertion, and tiles size selection for on-chip data caching through a unified
                    optimization problem, aiming to enhance parallelization, particularly
                    beneficial for computation-bound kernels. Them employing a novel Non-Linear
                    Programming (NLP) approach, we simultaneously ascertain transformations,
                    pragmas, and tile sizes, focusing on regular loop-based kernels. Our evaluation
                    demonstrates that our framework adeptly identifies the appropriate
                    transformations, including scenarios where no transformation is necessary, and
                    inserts pragmas to achieve a favorable Quality of Results.
                </p>
            </div>
        </dd>
        <dt><a name="item378">[378]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03059"
                    title="Abstract">arXiv:2405.03059</a> [<a href="/pdf/2405.03059" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03059" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Active Preference Learning for Ordering Items In- and
                    Out-of-sample
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bergstr%C3%B6m%2C+H">Herman Bergström</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Carlsson%2C+E">Emil Carlsson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dubhashi%2C+D">Devdatt Dubhashi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Johansson%2C+F+D">Fredrik D. Johansson</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
                <p class="mathjax">Learning an ordering of items based on noisy pairwise comparisons is useful
                    when item-specific labels are difficult to assign, for example, when annotators
                    have to make subjective assessments. Algorithms have been proposed for actively
                    sampling comparisons of items to minimize the number of annotations necessary
                    for learning an accurate ordering. However, many ignore shared structure
                    between items, treating them as unrelated, limiting sample efficiency and
                    precluding generalization to new items. In this work, we study active learning
                    with pairwise preference feedback for ordering items with contextual
                    attributes, both in- and out-of-sample. We give an upper bound on the expected
                    ordering error incurred by active learning strategies under a logistic
                    preference model, in terms of the aleatoric and epistemic uncertainty in
                    comparisons, and propose two algorithms designed to greedily minimize this
                    bound. We evaluate these algorithms in two realistic image ordering tasks,
                    including one with comparisons made by human annotators, and demonstrate
                    superior sample efficiency compared to non-contextual ranking approaches and
                    active preference learning baselines.
                </p>
            </div>
        </dd>
        <dt><a name="item379">[379]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03060"
                    title="Abstract">arXiv:2405.03060</a> [<a href="/pdf/2405.03060" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03060" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Tree-based Ensemble Learning for Out-of-distribution
                    Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Z">Zhaiming Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Menglun Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+G">Guang Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lai%2C+M">Ming-Jun Lai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mu%2C+L">Lin Mu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+R">Ruihao Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qi Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+H">Hao Zhu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Being able to successfully determine whether the testing samples has similar
                    distribution as the training samples is a fundamental question to address
                    before we can safely deploy most of the machine learning models into practice.
                    In this paper, we propose TOOD detection, a simple yet effective tree-based
                    out-of-distribution (TOOD) detection mechanism to determine if a set of unseen
                    samples will have similar distribution as of the training samples. The TOOD
                    detection mechanism is based on computing pairwise hamming distance of testing
                    samples' tree embeddings, which are obtained by fitting a tree-based ensemble
                    model through in-distribution training samples. Our approach is interpretable
                    and robust for its tree-based nature. Furthermore, our approach is efficient,
                    flexible to various machine learning tasks, and can be easily generalized to
                    unsupervised setting. Extensive experiments are conducted to show the proposed
                    method outperforms other state-of-the-art out-of-distribution detection methods
                    in distinguishing the in-distribution from out-of-distribution on various
                    tabular, image, and text data.
                </p>
            </div>
        </dd>
        <dt><a name="item380">[380]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03064"
                    title="Abstract">arXiv:2405.03064</a> [<a href="/pdf/2405.03064" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03064" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> RICE: Breaking Through the Training Bottlenecks of
                    Reinforcement Learning with Explanation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Z">Zelei Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xian Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+J">Jiahao Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+S">Sabrina Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+G">Gang Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xing%2C+X">Xinyu Xing</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

                </div>
                <p class="mathjax">Deep reinforcement learning (DRL) is playing an increasingly important role
                    in real-world applications. However, obtaining an optimally performing DRL
                    agent for complex tasks, especially with sparse rewards, remains a significant
                    challenge. The training of a DRL agent can be often trapped in a bottleneck
                    without further progress. In this paper, we propose RICE, an innovative
                    refining scheme for reinforcement learning that incorporates explanation
                    methods to break through the training bottlenecks. The high-level idea of RICE
                    is to construct a new initial state distribution that combines both the default
                    initial states and critical states identified through explanation methods,
                    thereby encouraging the agent to explore from the mixed initial states. Through
                    careful design, we can theoretically guarantee that our refining scheme has a
                    tighter sub-optimality bound. We evaluate RICE in various popular RL
                    environments and real-world applications. The results demonstrate that RICE
                    significantly outperforms existing refining schemes in enhancing agent
                    performance.
                </p>
            </div>
        </dd>
        <dt><a name="item381">[381]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03065"
                    title="Abstract">arXiv:2405.03065</a> [<a href="/pdf/2405.03065" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03065" title="Download PostScript">ps</a>, <a href="/format/2405.03065"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Powering the Future of IoT: Federated Learning for Optimized
                    Power Consumption and Enhanced Privacy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shirvani%2C+G">Ghazaleh Shirvani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghasemshirazi%2C+S">Saeid Ghasemshirazi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">The widespread use of the Internet of Things has led to the development of
                    large amounts of perception data, making it necessary to develop effective and
                    scalable data analysis tools. Federated Learning emerges as a promising
                    paradigm to address the inherent challenges of power consumption and data
                    privacy in IoT environments. This paper explores the transformative potential
                    of FL in enhancing the longevity of IoT devices by mitigating power consumption
                    and enhancing privacy and security measures. We delve into the intricacies of
                    FL, elucidating its components and applications within IoT ecosystems.
                    Additionally, we discuss the critical characteristics and challenges of IoT,
                    highlighting the need for such machine learning solutions in processing
                    perception data. While FL introduces many benefits for IoT sustainability, it
                    also has limitations. Through a comprehensive discussion and analysis, this
                    paper elucidates the opportunities and constraints of FL in shaping the future
                    of sustainable and secure IoT systems. Our findings highlight the importance of
                    developing new approaches and conducting additional research to maximise the
                    benefits of FL in creating a secure and privacy-focused IoT environment.
                </p>
            </div>
        </dd>
        <dt><a name="item382">[382]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03066"
                    title="Abstract">arXiv:2405.03066</a> [<a href="/pdf/2405.03066" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03066" title="Download PostScript">ps</a>, <a href="/format/2405.03066"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A scoping review of using Large Language Models (LLMs) to
                    investigate Electronic Health Records (EHRs)
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Lingyao Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jiayan Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zhenxiang Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hua%2C+W">Wenyue Hua</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+L">Lizhou Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Huizi Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hagen%2C+L">Loni Hagen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yonfeng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Assimes%2C+T+L">Themistocles L. Assimes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hemphill%2C+L">Libby Hemphill</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+S">Siyuan Ma</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies
                        (cs.ET)</span>

                </div>
                <p class="mathjax">Electronic Health Records (EHRs) play an important role in the healthcare
                    system. However, their complexity and vast volume pose significant challenges
                    to data interpretation and analysis. Recent advancements in Artificial
                    Intelligence (AI), particularly the development of Large Language Models
                    (LLMs), open up new opportunities for researchers in this domain. Although
                    prior studies have demonstrated their potential in language understanding and
                    processing in the context of EHRs, a comprehensive scoping review is lacking.
                    This study aims to bridge this research gap by conducting a scoping review
                    based on 329 related papers collected from OpenAlex. We first performed a
                    bibliometric analysis to examine paper trends, model applications, and
                    collaboration networks. Next, we manually reviewed and categorized each paper
                    into one of the seven identified topics: named entity recognition, information
                    extraction, text similarity, text summarization, text classification, dialogue
                    system, and diagnosis and prediction. For each topic, we discussed the unique
                    capabilities of LLMs, such as their ability to understand context, capture
                    semantic relations, and generate human-like text. Finally, we highlighted
                    several implications for researchers from the perspectives of data resources,
                    prompt engineering, fine-tuning, performance measures, and ethical concerns. In
                    conclusion, this study provides valuable insights into the potential of LLMs to
                    transform EHR research and discusses their applications and ethical
                    considerations.
                </p>
            </div>
        </dd>
        <dt><a name="item383">[383]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03067"
                    title="Abstract">arXiv:2405.03067</a> [<a href="/pdf/2405.03067" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03067" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Automated Deep Learning Optimization via DSL-Based Source
                    Code Transformation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+R">Ruixin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+M">Minghai Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+C+H">Cody Hao Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lai%2C+Y">Yi-Hsiang Lai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianyi Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 6 figures
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> In Proceedings of the 33rd ACM SIGSOFT International
                    Symposium on
                    Software Testing and Analysis (ISSTA 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">As deep learning models become increasingly bigger and more complex, it is
                    critical to improve model training and inference efficiency. Though a variety
                    of highly optimized libraries and packages (known as DL kernels) have been
                    developed, it is tedious and time-consuming to figure out which kernel to use,
                    where to use, and how to use them correctly. To address this challenge, we
                    propose an Automated Deep learning OPTimization approach called Adopter. We
                    design a Domain-Specific Language (DSL) to represent DL model architectures and
                    leverage this DSL to specify model transformation rules required to integrate a
                    DL kernel into a model. Given the source code of a DL model and the
                    transformation rules for a set of kernels, Adopter first performs
                    inter-procedural analysis to identify and express the model architecture in our
                    DSL. Then, Adopter performs scope analysis and sub-sequence matching to
                    identify locations in the model architecture where the transformation rules can
                    be applied. Finally, Adopter proposes a synthesis-based code transformation
                    method to apply the transformation rule. We curated a benchmark with 199 models
                    from Hugging Face and a diverse set of DL kernels. We found that, compared to a
                    state-of-the-art automated code transformation technique, Adopter helps improve
                    the precision and recall by 3% and 56%, respectively. An in-depth analysis of 9
                    models revealed that on average, Adopter improved the training speed by 22.7%
                    while decreasing the GPU memory usage by 10.5%.
                </p>
            </div>
        </dd>
        <dt><a name="item384">[384]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03070"
                    title="Abstract">arXiv:2405.03070</a> [<a href="/pdf/2405.03070" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03070" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Layered Graph Security Games
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=%C4%8Cern%C3%BD%2C+J">Jakub Černý</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ling%2C+C+K">Chun Kai Ling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kroer%2C+C">Christian Kroer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Iyengar%2C+G">Garud Iyengar</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> In Proceedings of the Thirty-Third International Joint
                    Conference on Artificial Intelligence. AAAI Press, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>

                </div>
                <p class="mathjax">Security games model strategic interactions in adversarial real-world
                    applications. Such applications often involve extremely large but highly
                    structured strategy sets (e.g., selecting a distribution over all patrol routes
                    in a given graph). In this paper, we represent each player's strategy space
                    using a layered graph whose paths represent an exponentially large strategy
                    space. Our formulation entails not only classic pursuit-evasion games, but also
                    other security games, such as those modeling anti-terrorism and logistical
                    interdiction. We study two-player zero-sum games under two distinct utility
                    models: linear and binary utilities. We show that under linear utilities, Nash
                    equilibrium can be computed in polynomial time, while binary utilities may lead
                    to situations where even computing a best-response is computationally
                    intractable. To this end, we propose a practical algorithm based on incremental
                    strategy generation and mixed integer linear programs. We show through
                    extensive experiments that our algorithm efficiently computes
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-182-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1274"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.41em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1275"><span class="mi" id="MathJax-Span-1276"
                                                style="font-family: MathJax_Math-italic;">ϵ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-182">\epsilon</script>-equilibrium for many games of
                    interest. We find that target values
                    and graph structure often have a larger influence on running times as compared
                    to the size of the graph per se.
                </p>
            </div>
        </dd>
        <dt><a name="item385">[385]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03075"
                    title="Abstract">arXiv:2405.03075</a> [<a href="/pdf/2405.03075" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03075" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AnoGAN for Tabular Data: A Novel Approach to Anomaly
                    Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Singh%2C+A">Aditya Singh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reddy%2C+P">Pavan Reddy</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 6 figures, accepted as Short paper at HCII 2024
                    (<a href="https://2024.hci.international">this https URL</a>)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Anomaly detection, a critical facet in data analysis, involves identifying
                    patterns that deviate from expected behavior. This research addresses the
                    complexities inherent in anomaly detection, exploring challenges and adapting
                    to sophisticated malicious activities. With applications spanning
                    cybersecurity, healthcare, finance, and surveillance, anomalies often signify
                    critical information or potential threats. Inspired by the success of Anomaly
                    Generative Adversarial Network (AnoGAN) in image domains, our research extends
                    its principles to tabular data. Our contributions include adapting AnoGAN's
                    principles to a new domain and promising advancements in detecting previously
                    undetectable anomalies. This paper delves into the multifaceted nature of
                    anomaly detection, considering the dynamic evolution of normal behavior,
                    context-dependent anomaly definitions, and data-related challenges like noise
                    and imbalances.
                </p>
            </div>
        </dd>
        <dt><a name="item386">[386]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03076"
                    title="Abstract">arXiv:2405.03076</a> [<a href="/pdf/2405.03076" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03076" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Traffic Performance GPT (TP-GPT): Real-Time Data Informed
                    Intelligent ChatBot for Transportation Surveillance and Management
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bingzhang Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhiyu">Zhiyu</a> (Joey)Cai,
                    <a href="/search/cs?searchtype=author&amp;query=Karim%2C+M+M">Muhammad Monjurul Karim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chenxi Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yinhai Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 5 figures, submitted to 27th IEEE International
                    Conference on Intelligent Transportation Systems (IEEE ITSC 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems
                        (cs.MA)</span>

                </div>
                <p class="mathjax">The digitization of traffic sensing infrastructure has significantly
                    accumulated an extensive traffic data warehouse, which presents unprecedented
                    challenges for transportation analytics. The complexities associated with
                    querying large-scale multi-table databases require specialized programming
                    expertise and labor-intensive development. Additionally, traditional analysis
                    methods have focused mainly on numerical data, often neglecting the semantic
                    aspects that could enhance interpretability and understanding. Furthermore,
                    real-time traffic data access is typically limited due to privacy concerns. To
                    bridge this gap, the integration of Large Language Models (LLMs) into the
                    domain of traffic management presents a transformative approach to addressing
                    the complexities and challenges inherent in modern transportation systems. This
                    paper proposes an intelligent online chatbot, TP-GPT, for efficient customized
                    transportation surveillance and management empowered by a large real-time
                    traffic database. The innovative framework leverages contextual and generative
                    intelligence of language models to generate accurate SQL queries and natural
                    language interpretations by employing transportation-specialized prompts,
                    Chain-of-Thought prompting, few-shot learning, multi-agent collaboration
                    strategy, and chat memory. Experimental study demonstrates that our approach
                    outperforms state-of-the-art baselines such as GPT-4 and PaLM 2 on a
                    challenging traffic-analysis benchmark TransQuery. TP-GPT would aid researchers
                    and practitioners in real-time transportation surveillance and management in a
                    privacy-preserving, equitable, and customizable manner.
                </p>
            </div>
        </dd>
        <dt><a name="item387">[387]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03080"
                    title="Abstract">arXiv:2405.03080</a> [<a href="/pdf/2405.03080" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03080" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Homophilic organization of egocentric communities in ICT
                    services
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Roy%2C+C">Chandreyee Roy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jo%2C+H">Hang-Hyun Jo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kert%C3%A9sz%2C+J">János Kertész</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kaski%2C+K">Kimmo Kaski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=T%C3%B6r%C3%B6k%2C+J">János Török</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 7 figures, 1 table
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information
                        Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

                </div>
                <p class="mathjax">Members of a society can be characterized by a large number of features, such
                    as gender, age, ethnicity, religion, social status, and shared activities. One
                    of the main tie-forming factors between individuals in human societies is
                    homophily, the tendency of being attracted to similar others. Homophily has
                    been mainly studied with focus on one of the features and little is known about
                    the roles of similarities of different origins in the formation of communities.
                    To close this gap, we analyze three datasets from Information and
                    Communications Technology (ICT) services, namely, two online social networks
                    and a network deduced from mobile phone calls, in all of which metadata about
                    individual features are available. We identify communities within egocentric
                    networks and surprisingly find that the larger the community is, the more
                    overlap is found between features of its members and the ego. We interpret this
                    finding in terms of the effort needed to manage the communities; the larger
                    diversity requires more effort such that to maintain a large diverse group may
                    exceed the capacity of the members. As the ego reaches out to her alters on an
                    ICT service, we observe that the first alter in each community tends to have a
                    higher feature overlap with the ego than the rest. Moreover the feature overlap
                    of the ego with all her alters displays a non-monotonic behaviors as a function
                    of the ego's degree. We propose a simple mechanism of how people add links in
                    their egocentric networks of alters that reproduces all the empirical
                    observations and shows the reason behind non-monotonic tendency of the
                    egocentric feature overlap as a function of the ego's degree.
                </p>
            </div>
        </dd>
        <dt><a name="item388">[388]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03081"
                    title="Abstract">arXiv:2405.03081</a> [<a href="/pdf/2405.03081" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03081" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Design optimization in unilateral contact using pressure
                    constraints and Bayesian optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Wang%2C+J">Jingyi Wang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Solberg%2C+J">Jerome Solberg</a>,
                    <a href="/search/math?searchtype=author&amp;query=Puso%2C+M+A">Mike A. Puso</a>,
                    <a href="/search/math?searchtype=author&amp;query=Chin%2C+E+B">Eric B. Chin</a>,
                    <a href="/search/math?searchtype=author&amp;query=Petra%2C+C+G">Cosmin G. Petra</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">Design optimization problems, e.g., shape optimization, that involve
                    deformable bodies in unilateral contact are challenging as they require robust
                    contact solvers, complex optimization methods that are typically
                    gradient-based, and sensitivity derivations. Notably, the problems are
                    nonsmooth, adding significant difficulty to the optimization process. We study
                    design optimization problems in frictionless unilateral contact subject to
                    pressure constraints, using both gradient-based and gradient-free optimization
                    methods, namely Bayesian optimization. The contact simulation problem is solved
                    via the mortar contact and finite element methods. For the gradient-based
                    method, we use the direct differentiation method to compute the sensitivities
                    of the cost and constraint function with respect to the design variables. Then,
                    we use Ipopt to solve the optimization problems. For the gradient-free
                    approach, we use a constrained Bayesian optimization algorithm based on the
                    standard Gaussian Process surrogate model. We present numerical examples that
                    control the contact pressure, inspired by real-life engineering applications,
                    to demonstrate the effectiveness, strengths and shortcomings of both methods.
                    Our results suggest that both optimization methods perform reasonably well for
                    these nonsmooth problems.
                </p>
            </div>
        </dd>
        <dt><a name="item389">[389]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03082"
                    title="Abstract">arXiv:2405.03082</a> [<a href="/pdf/2405.03082" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03082" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Finite-Time Convergence and Sample Complexity of Actor-Critic
                    Multi-Objective Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+T">Tianchen Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hairi%2C+F">FNU Hairi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H">Haibo Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jia Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tong%2C+T">Tian Tong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+F">Fan Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Momma%2C+M">Michinari Momma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yan Gao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Reinforcement learning with multiple, potentially conflicting objectives is
                    pervasive in real-world applications, while this problem remains theoretically
                    under-explored. This paper tackles the multi-objective reinforcement learning
                    (MORL) problem and introduces an innovative actor-critic algorithm named MOAC
                    which finds a policy by iteratively making trade-offs among conflicting reward
                    signals. Notably, we provide the first analysis of finite-time
                    Pareto-stationary convergence and corresponding sample complexity in both
                    discounted and average reward settings. Our approach has two salient features:
                    (a) MOAC mitigates the cumulative estimation bias resulting from finding an
                    optimal common gradient descent direction out of stochastic samples. This
                    enables provable convergence rate and sample complexity guarantees independent
                    of the number of objectives; (b) With proper momentum coefficient, MOAC
                    initializes the weights of individual policy gradients using samples from the
                    environment, instead of manual initialization. This enhances the practicality
                    and robustness of our algorithm. Finally, experiments conducted on a real-world
                    dataset validate the effectiveness of our proposed method.
                </p>
            </div>
        </dd>
        <dt><a name="item390">[390]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03084"
                    title="Abstract">arXiv:2405.03084</a> [<a href="/pdf/2405.03084" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03084" title="Download PostScript">ps</a>, <a href="/format/2405.03084"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Analyzing Emotional Trends from X platform using SenticNet: A
                    Comparative Analysis with Cryptocurrency Price
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tash%2C+M+S">Moein Shahiki Tash</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ahani%2C+Z">Zahra Ahani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kolesnikova%2C+O">Olga Kolesnikova</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sidorov%2C+G">Grigori Sidorov</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">This study delves into the relationship between emotional trends from X
                    platform data and the market dynamics of well-known cryptocurrencies Cardano,
                    Binance, Fantom, Matic, and Ripple over the period from October 2022 to March
                    2023. Leveraging SenticNet, we identified emotions like Fear and Anxiety, Rage
                    and Anger, Grief and Sadness, Delight and Pleasantness, Enthusiasm and
                    Eagerness, and Delight and Joy. Following data extraction, we segmented each
                    month into bi-weekly intervals, replicating this process for price data
                    obtained from Finance-Yahoo. Consequently, a comparative analysis was
                    conducted, establishing connections between emotional trends observed across
                    bi-weekly intervals and cryptocurrency prices, uncovering significant
                    correlations between emotional sentiments and coin valuations.
                </p>
            </div>
        </dd>
        <dt><a name="item391">[391]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03085"
                    title="Abstract">arXiv:2405.03085</a> [<a href="/pdf/2405.03085" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03085" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Compressing Long Context for Enhancing RAG with AMR-based
                    Concept Distillation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+K">Kaize Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+X">Xueyao Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qing Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+G">Guandong Xu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Large Language Models (LLMs) have made significant strides in information
                    acquisition. However, their overreliance on potentially flawed parametric
                    knowledge leads to hallucinations and inaccuracies, particularly when handling
                    long-tail, domain-specific queries. Retrieval Augmented Generation (RAG)
                    addresses this limitation by incorporating external, non-parametric knowledge.
                    Nevertheless, the retrieved long-context documents often contain noisy,
                    irrelevant information alongside vital knowledge, negatively diluting LLMs'
                    attention. Inspired by the supportive role of essential concepts in
                    individuals' reading comprehension, we propose a novel concept-based RAG
                    framework with the Abstract Meaning Representation (AMR)-based concept
                    distillation algorithm. The proposed algorithm compresses the cluttered raw
                    retrieved documents into a compact set of crucial concepts distilled from the
                    informative nodes of AMR by referring to reliable linguistic features. The
                    concepts explicitly constrain LLMs to focus solely on vital information in the
                    inference process. We conduct extensive experiments on open-domain
                    question-answering datasets to empirically evaluate the proposed method's
                    effectiveness. The results indicate that the concept-based RAG framework
                    outperforms other baseline methods, particularly as the number of supporting
                    documents increases, while also exhibiting robustness across various backbone
                    LLMs. This emphasizes the distilled concepts are informative for augmenting the
                    RAG process by filtering out interference information. To the best of our
                    knowledge, this is the first work introducing AMR to enhance the RAG,
                    presenting a potential solution to augment inference performance with
                    semantic-based context compression.
                </p>
            </div>
        </dd>
        <dt><a name="item392">[392]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03089"
                    title="Abstract">arXiv:2405.03089</a> [<a href="/pdf/2405.03089" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03089" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Structure-Preserving Network Compression Via Low-Rank Induced
                    Training Through Linear Layers Composition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xitong Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alkhouri%2C+I+R">Ismail R. Alkhouri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+R">Rongrong Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Deep Neural Networks (DNNs) have achieved remarkable success in addressing
                    many previously unsolvable tasks. However, the storage and computational
                    requirements associated with DNNs pose a challenge for deploying these trained
                    models on resource-limited devices. Therefore, a plethora of compression and
                    pruning techniques have been proposed in recent years. Low-rank decomposition
                    techniques are among the approaches most utilized to address this problem.
                    Compared to post-training compression, compression-promoted training is still
                    under-explored. In this paper, we present a theoretically-justified novel
                    approach, termed Low-Rank Induced Training (LoRITa), that promotes low-rankness
                    through the composition of linear layers and compresses by using singular value
                    truncation. This is achieved without the need to change the structure at
                    inference time or require constrained and/or additional optimization, other
                    than the standard weight decay regularization. Moreover, LoRITa eliminates the
                    need to (i) initialize with pre-trained models and (ii) specify rank selection
                    prior to training. Our experimental results (i) demonstrate the effectiveness
                    of our approach using MNIST on Fully Connected Networks, CIFAR10 on Vision
                    Transformers, and CIFAR10/100 on Convolutional Neural Networks, and (ii)
                    illustrate that we achieve either competitive or SOTA results when compared to
                    leading structured pruning methods in terms of FLOPs and parameters drop.
                </p>
            </div>
        </dd>
        <dt><a name="item393">[393]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03090"
                    title="Abstract">arXiv:2405.03090</a> [<a href="/pdf/2405.03090" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03090" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A continuum and computational framework for
                    viscoelastodynamics: III. A nonlinear theory
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Liu%2C+J">Ju Liu</a>,
                    <a href="/search/math?searchtype=author&amp;query=Guan%2C+J">Jiashen Guan</a>,
                    <a href="/search/math?searchtype=author&amp;query=Zhao%2C+C">Chongran Zhao</a>,
                    <a href="/search/math?searchtype=author&amp;query=Luo%2C+J">Jiawei Luo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">We continue our investigation of viscoelasticity by extending the
                    Holzapfel-Simo approach discussed in Part I to the fully nonlinear regime. By
                    scrutinizing the relaxation property for the non-equilibrium stresses, it is
                    revealed that a kinematic assumption akin to the Green-Naghdi type is necessary
                    in the design of the potential. This insight underscores a link between the
                    so-called additive plasticity and the viscoelasticity model under
                    consideration, further inspiring our development of a nonlinear viscoelasticity
                    theory. Our strategy is based on Hill's hyperelasticity framework and leverages
                    the concept of generalized strains. Notably, the adopted kinematic assumption
                    makes the proposed theory fundamentally different from the existing models
                    rooted in the notion of the intermediate configuration. The computation
                    aspects, including the consistent linearization, constitutive integration, and
                    modular implementation, are addressed in detail. A suite of numerical examples
                    is provided to demonstrate the capability of the proposed model in
                    characterizing viscoelastic material behaviors at large strains.
                </p>
            </div>
        </dd>
        <dt><a name="item394">[394]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03091"
                    title="Abstract">arXiv:2405.03091</a> [<a href="/pdf/2405.03091" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03091" title="Download PostScript">ps</a>, <a href="/format/2405.03091"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Research on Image Recognition Technology Based on Multimodal
                    Deep Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jinyin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xingchen Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Y">Yixuan Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yihao Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+K">Keke Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+C">Chang Zhou</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">This project investigates the human multi-modal behavior identification
                    algorithm utilizing deep neural networks. According to the characteristics of
                    different modal information, different deep neural networks are used to adapt
                    to different modal video information. Through the integration of various deep
                    neural networks, the algorithm successfully identifies behaviors across
                    multiple modalities. In this project, multiple cameras developed by Microsoft
                    Kinect were used to collect corresponding bone point data based on acquiring
                    conventional images. In this way, the motion features in the image can be
                    extracted. Ultimately, the behavioral characteristics discerned through both
                    approaches are synthesized to facilitate the precise identification and
                    categorization of behaviors. The performance of the suggested algorithm was
                    evaluated using the MSR3D data set. The findings from these experiments
                    indicate that the accuracy in recognizing behaviors remains consistently high,
                    suggesting that the algorithm is reliable in various scenarios. Additionally,
                    the tests demonstrate that the algorithm substantially enhances the accuracy of
                    detecting pedestrian behaviors in video footage.
                </p>
            </div>
        </dd>
        <dt><a name="item395">[395]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03095"
                    title="Abstract">arXiv:2405.03095</a> [<a href="/pdf/2405.03095" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03095" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Loss Jump During Loss Switch in Solving PDEs with Neural
                    Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhiwei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lulu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhongwang Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z+J">Zhi-Qin John Xu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Mathematical Physics (math-ph)

                </div>
                <p class="mathjax">Using neural networks to solve partial differential equations (PDEs) is
                    gaining popularity as an alternative approach in the scientific computing
                    community. Neural networks can integrate different types of information into
                    the loss function. These include observation data, governing equations, and
                    variational forms, etc. These loss functions can be broadly categorized into
                    two types: observation data loss directly constrains and measures the model
                    output, while other loss functions indirectly model the performance of the
                    network, which can be classified as model loss. However, this alternative
                    approach lacks a thorough understanding of its underlying mechanisms, including
                    theoretical foundations and rigorous characterization of various phenomena.
                    This work focuses on investigating how different loss functions impact the
                    training of neural networks for solving PDEs. We discover a stable loss-jump
                    phenomenon: when switching the loss function from the data loss to the model
                    loss, which includes different orders of derivative information, the neural
                    network solution significantly deviates from the exact solution immediately.
                    Further experiments reveal that this phenomenon arises from the different
                    frequency preferences of neural networks under different loss functions. We
                    theoretically analyze the frequency preference of neural networks under model
                    loss. This loss-jump phenomenon provides a valuable perspective for examining
                    the underlying mechanisms of neural networks in solving PDEs.
                </p>
            </div>
        </dd>
        <dt><a name="item396">[396]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03097"
                    title="Abstract">arXiv:2405.03097</a> [<a href="/pdf/2405.03097" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03097" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> To Each (Textual Sequence) Its Own: Improving Memorized-Data
                    Unlearning in Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Barbulescu%2C+G">George-Octavian Barbulescu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Triantafillou%2C+P">Peter Triantafillou</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published as a conference paper at ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">LLMs have been found to memorize training textual sequences and regurgitate
                    verbatim said sequences during text generation time. This fact is known to be
                    the cause of privacy and related (e.g., copyright) problems. Unlearning in LLMs
                    then takes the form of devising new algorithms that will properly deal with
                    these side-effects of memorized data, while not hurting the model's utility. We
                    offer a fresh perspective towards this goal, namely, that each textual sequence
                    to be forgotten should be treated differently when being unlearned based on its
                    degree of memorization within the LLM. We contribute a new metric for measuring
                    unlearning quality, an adversarial attack showing that SOTA algorithms lacking
                    this perspective fail for privacy, and two new unlearning methods based on
                    Gradient Ascent and Task Arithmetic, respectively. A comprehensive performance
                    evaluation across an extensive suite of NLP tasks then mapped the solution
                    space, identifying the best solutions under different scales in model
                    capacities and forget set sizes and quantified the gains of the new approaches.
                </p>
            </div>
        </dd>
        <dt><a name="item397">[397]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03098"
                    title="Abstract">arXiv:2405.03098</a> [<a href="/pdf/2405.03098" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03098" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FairMonitor: A Dual-framework for Detecting Stereotypes and
                    Biases in Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bai%2C+Y">Yanhong Bai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jiabao Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+J">Jinxin Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhentao Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xingjiao Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+L">Liang He</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Detecting stereotypes and biases in Large Language Models (LLMs) is crucial
                    for enhancing fairness and reducing adverse impacts on individuals or groups
                    when these models are applied. Traditional methods, which rely on embedding
                    spaces or are based on probability metrics, fall short in revealing the nuanced
                    and implicit biases present in various contexts. To address this challenge, we
                    propose the FairMonitor framework and adopt a static-dynamic detection method
                    for a comprehensive evaluation of stereotypes and biases in LLMs. The static
                    component consists of a direct inquiry test, an implicit association test, and
                    an unknown situation test, including 10,262 open-ended questions with 9
                    sensitive factors and 26 educational scenarios. And it is effective for
                    evaluating both explicit and implicit biases. Moreover, we utilize the
                    multi-agent system to construst the dynamic scenarios for detecting subtle
                    biases in more complex and realistic setting. This component detects the biases
                    based on the interaction behaviors of LLMs across 600 varied educational
                    scenarios. The experimental results show that the cooperation of static and
                    dynamic methods can detect more stereotypes and biased in LLMs.
                </p>
            </div>
        </dd>
        <dt><a name="item398">[398]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03099"
                    title="Abstract">arXiv:2405.03099</a> [<a href="/pdf/2405.03099" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03099" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SketchGPT: Autoregressive Modeling for Sketch Generation and
                    Recognition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tiwari%2C+A">Adarsh Tiwari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Biswas%2C+S">Sanket Biswas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Llad%C3%B3s%2C+J">Josep Lladós</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in ICDAR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">We present SketchGPT, a flexible framework that employs a
                    sequence-to-sequence autoregressive model for sketch generation, and
                    completion, and an interpretation case study for sketch recognition. By mapping
                    complex sketches into simplified sequences of abstract primitives, our approach
                    significantly streamlines the input for autoregressive modeling. SketchGPT
                    leverages the next token prediction objective strategy to understand sketch
                    patterns, facilitating the creation and completion of drawings and also
                    categorizing them accurately. This proposed sketch representation strategy aids
                    in overcoming existing challenges of autoregressive modeling for continuous
                    stroke data, enabling smoother model training and competitive performance. Our
                    findings exhibit SketchGPT's capability to generate a diverse variety of
                    drawings by adding both qualitative and quantitative comparisons with existing
                    state-of-the-art, along with a comprehensive human evaluation study. The code
                    and pretrained models will be released on our official GitHub.
                </p>
            </div>
        </dd>
        <dt><a name="item399">[399]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03101"
                    title="Abstract">arXiv:2405.03101</a> [<a href="/pdf/2405.03101" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03101" title="Download PostScript">ps</a>, <a href="/format/2405.03101"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Double Self-Sustainable Reconfigurable Intelligent Surfaces
                    Aided Wireless Communications
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Ji Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+S">Suhong Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yixuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+W">Wenwu Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xingwang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nallanathan%2C+A">Arumugam Nallanathan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">A double self-sustainable reconfigurable intelligent surfaces (RISs) assisted
                    multi-user multiple input multiple output (MIMO) system is investigated. Two
                    RISs are equipped with energy harvesting circuit to achieve self-sustainable
                    transmission. The aim is to minimize the transmission power at the base station
                    (BS), while guaranteeing the quality of service (QoS) requirements of the users
                    and meeting the power consumption requirements of the RISs. A block coordinate
                    descent (BCD) algorithm based on the penalty-based method and successive convex
                    approximation (SCA) is employed to alternatively optimize the active
                    beamforming at the BS and the phase shifts, as well as amplitude coefficients
                    of two RISs. Simulation results show that the required power consumption at the
                    BS for the proposed double self-sustainable RISs system is significantly
                    reduced compared to conventional RIS systems.
                </p>
            </div>
        </dd>
        <dt><a name="item400">[400]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03103"
                    title="Abstract">arXiv:2405.03103</a> [<a href="/pdf/2405.03103" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03103" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Learning from Students: Applying t-Distributions to Explore
                    Accurate and Efficient Formats for LLMs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dotzel%2C+J">Jordan Dotzel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yuzong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kotb%2C+B">Bahaa Kotb</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Prasad%2C+S">Sushma Prasad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+G">Gang Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Sheng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abdelfattah%2C+M+S">Mohamed S. Abdelfattah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhiru Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Large language models (LLMs) have recently achieved state-of-the-art
                    performance across various tasks, yet due to their large computational
                    requirements, they struggle with strict latency and power demands. Deep neural
                    network (DNN) quantization has traditionally addressed these limitations by
                    converting models to low-precision integer formats. Yet recently alternative
                    formats, such as Normal Float (NF4), have been shown to consistently increase
                    model accuracy, albeit at the cost of increased chip area. In this work, we
                    first conduct a large-scale analysis of LLM weights and activations across 30
                    networks to conclude most distributions follow a Student's t-distribution. We
                    then derive a new theoretically optimal format, Student Float (SF4), with
                    respect to this distribution, that improves over NF4 across modern LLMs, for
                    example increasing the average accuracy on LLaMA2-7B by 0.76% across tasks.
                    Using this format as a high-accuracy reference, we then propose augmenting E2M1
                    with two variants of supernormal support for higher model accuracy. Finally, we
                    explore the quality and performance frontier across 11 datatypes, including
                    non-traditional formats like Additive-Powers-of-Two (APoT), by evaluating their
                    model accuracy and hardware complexity. We discover a Pareto curve composed of
                    INT4, E2M1, and E2M1 with supernormal support, which offers a continuous
                    tradeoff between model accuracy and chip area. For example, E2M1 with
                    supernormal support increases the accuracy of Phi-2 by up to 2.19% with 1.22%
                    area overhead, enabling more LLM-based applications to be run at four bits.
                </p>
            </div>
        </dd>
        <dt><a name="item401">[401]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03104"
                    title="Abstract">arXiv:2405.03104</a> [<a href="/pdf/2405.03104" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03104" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GeoContrastNet: Contrastive Key-Value Edge Learning for
                    Language-Agnostic Document Understanding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Biescas%2C+N">Nil Biescas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boned%2C+C">Carlos Boned</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Llad%C3%B3s%2C+J">Josep Lladós</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Biswas%2C+S">Sanket Biswas</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in ICDAR 2024 (Athens, Greece)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">This paper presents GeoContrastNet, a language-agnostic framework to
                    structured document understanding (DU) by integrating a contrastive learning
                    objective with graph attention networks (GATs), emphasizing the significant
                    role of geometric features. We propose a novel methodology that combines
                    geometric edge features with visual features within an overall two-staged
                    GAT-based framework, demonstrating promising results in both link prediction
                    and semantic entity recognition performance. Our findings reveal that combining
                    both geometric and visual features could match the capabilities of large DU
                    models that rely heavily on Optical Character Recognition (OCR) features in
                    terms of performance accuracy and efficiency. This approach underscores the
                    critical importance of relational layout information between the named text
                    entities in a semi-structured layout of a page. Specifically, our results
                    highlight the model's proficiency in identifying key-value relationships within
                    the FUNSD dataset for forms and also discovering the spatial relationships in
                    table-structured layouts for RVLCDIP business invoices. Our code and pretrained
                    models will be accessible on our official GitHub.
                </p>
            </div>
        </dd>
        <dt><a name="item402">[402]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03106"
                    title="Abstract">arXiv:2405.03106</a> [<a href="/pdf/2405.03106" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03106" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Compression-based Privacy Preservation for Distributed Nash
                    Equilibrium Seeking in Aggregative Games
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Huo%2C+W">Wei Huo</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Chen%2C+X">Xiaomeng Chen</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Ding%2C+K">Kemi Ding</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Dey%2C+S">Subhrakanti Dey</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Shi%2C+L">Ling Shi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>; Computer Science and Game Theory (cs.GT)

                </div>
                <p class="mathjax">This paper explores distributed aggregative games in multi-agent systems.
                    Current methods for finding distributed Nash equilibrium require players to
                    send original messages to their neighbors, leading to communication burden and
                    privacy issues. To jointly address these issues, we propose an algorithm that
                    uses stochastic compression to save communication resources and conceal
                    information through random errors induced by compression. Our theoretical
                    analysis shows that the algorithm guarantees convergence accuracy, even with
                    aggressive compression errors used to protect privacy. We prove that the
                    algorithm achieves differential privacy through a stochastic quantization
                    scheme. Simulation results for energy consumption games support the
                    effectiveness of our approach.
                </p>
            </div>
        </dd>
        <dt><a name="item403">[403]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03109"
                    title="Abstract">arXiv:2405.03109</a> [<a href="/pdf/2405.03109" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03109" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Intra-task Mutual Attention based Vision Transformer for
                    Few-Shot Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+W">Weihao Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Humans possess remarkable ability to accurately classify new, unseen images
                    after being exposed to only a few examples. Such ability stems from their
                    capacity to identify common features shared between new and previously seen
                    images while disregarding distractions such as background variations. However,
                    for artificial neural network models, determining the most relevant features
                    for distinguishing between two images with limited samples presents a
                    challenge. In this paper, we propose an intra-task mutual attention method for
                    few-shot learning, that involves splitting the support and query samples into
                    patches and encoding them using the pre-trained Vision Transformer (ViT)
                    architecture. Specifically, we swap the class (CLS) token and patch tokens
                    between the support and query sets to have the mutual attention, which enables
                    each set to focus on the most useful information. This facilitates the
                    strengthening of intra-class representations and promotes closer proximity
                    between instances of the same class. For implementation, we adopt the ViT-based
                    network architecture and utilize pre-trained model parameters obtained through
                    self-supervision. By leveraging Masked Image Modeling as a self-supervised
                    training task for pre-training, the pre-trained model yields semantically
                    meaningful representations while successfully avoiding supervision collapse. We
                    then employ a meta-learning method to fine-tune the last several layers and CLS
                    token modules. Our strategy significantly reduces the num- ber of parameters
                    that require fine-tuning while effectively uti- lizing the capability of
                    pre-trained model. Extensive experiments show that our framework is simple,
                    effective and computationally efficient, achieving superior performance as
                    compared to the state-of-the-art baselines on five popular few-shot
                    classification benchmarks under the 5-shot and 1-shot scenarios
                </p>
            </div>
        </dd>
        <dt><a name="item404">[404]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03110"
                    title="Abstract">arXiv:2405.03110</a> [<a href="/pdf/2405.03110" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03110" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Vector Quantization for Recommender Systems: A Review and
                    Outlook
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qijiong Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+X">Xiaoyu Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jiaren Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+N">Nuo Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Hengchang Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jieming Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+C">Chenxu Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sakai%2C+T">Tetsuya Sakai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiao-Ming Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">Vector quantization, renowned for its unparalleled feature compression
                    capabilities, has been a prominent topic in signal processing and machine
                    learning research for several decades and remains widely utilized today. With
                    the emergence of large models and generative AI, vector quantization has gained
                    popularity in recommender systems, establishing itself as a preferred solution.
                    This paper starts with a comprehensive review of vector quantization
                    techniques. It then explores systematic taxonomies of vector quantization
                    methods for recommender systems (VQ4Rec), examining their applications from
                    multiple perspectives. Further, it provides a thorough introduction to research
                    efforts in diverse recommendation scenarios, including efficiency-oriented
                    approaches and quality-oriented approaches. Finally, the survey analyzes the
                    remaining challenges and anticipates future trends in VQ4Rec, including the
                    challenges associated with the training of vector quantization, the
                    opportunities presented by large language models, and emerging trends in
                    multimodal recommender systems. We hope this survey can pave the way for future
                    researchers in the recommendation community and accelerate their exploration in
                    this promising field.
                </p>
            </div>
        </dd>
        <dt><a name="item405">[405]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03111"
                    title="Abstract">arXiv:2405.03111</a> [<a href="/pdf/2405.03111" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03111" title="Download PostScript">ps</a>, <a href="/format/2405.03111"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Active Inference Agent for Simulating Human Translation
                    Processes in a Hierarchical Architecture: Integrating the Task Segment Framework and the HOF
                    taxonomy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Carl%2C+M">Michael Carl</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">In this paper, we propose modelling human translation production as a
                    hierarchy of three embedded translation processes. The proposed architecture
                    replicates the temporal dynamics of keystroke production across sensorimotor,
                    cognitive, and phenomenal layers. Utilizing data from the CRITT TPR-DB, the
                    Task Segment Framework, and the HOF taxonomy, we demonstrate the temporal
                    breakdown of the typing flow on distinct timelines within these three layers.
                </p>
            </div>
        </dd>
        <dt><a name="item406">[406]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03113"
                    title="Abstract">arXiv:2405.03113</a> [<a href="/pdf/2405.03113" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03113" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Robot Air Hockey: A Manipulation Testbed for Robot Learning
                    with Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chuck%2C+C">Caleb Chuck</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qi%2C+C">Carl Qi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Munje%2C+M+J">Michael J. Munje</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shuozhe Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rudolph%2C+M">Max Rudolph</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+C">Chang Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Agarwal%2C+S">Siddhant Agarwal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sikchi%2C+H">Harshit Sikchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peri%2C+A">Abhinav Peri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dayal%2C+S">Sarthak Dayal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kuo%2C+E">Evan Kuo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mehta%2C+K">Kavan Mehta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+A">Anthony Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stone%2C+P">Peter Stone</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+A">Amy Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Niekum%2C+S">Scott Niekum</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Reinforcement Learning is a promising tool for learning complex policies even
                    in fast-moving and object-interactive domains where human teleoperation or
                    hard-coded policies might fail. To effectively reflect this challenging
                    category of tasks, we introduce a dynamic, interactive RL testbed based on
                    robot air hockey. By augmenting air hockey with a large family of tasks ranging
                    from easy tasks like reaching, to challenging ones like pushing a block by
                    hitting it with a puck, as well as goal-based and human-interactive tasks, our
                    testbed allows a varied assessment of RL capabilities. The robot air hockey
                    testbed also supports sim-to-real transfer with three domains: two simulators
                    of increasing fidelity and a real robot system. Using a dataset of
                    demonstration data gathered through two teleoperation systems: a virtualized
                    control environment, and human shadowing, we assess the testbed with behavior
                    cloning, offline RL, and RL from scratch.
                </p>
            </div>
        </dd>
        <dt><a name="item407">[407]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03118"
                    title="Abstract">arXiv:2405.03118</a> [<a href="/pdf/2405.03118" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03118" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Determined Multichannel Blind Source Separation with
                    Clustered Source Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guan%2C+S">Shanzheng Guan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio
                    and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">The independent low-rank matrix analysis (ILRMA) method stands out as a
                    prominent technique for multichannel blind audio source separation. It
                    leverages nonnegative matrix factorization (NMF) and nonnegative canonical
                    polyadic decomposition (NCPD) to model source parameters. While it effectively
                    captures the low-rank structure of sources, the NMF model overlooks
                    inter-channel dependencies. On the other hand, NCPD preserves intrinsic
                    structure but lacks interpretable latent factors, making it challenging to
                    incorporate prior information as constraints. To address these limitations, we
                    introduce a clustered source model based on nonnegative block-term
                    decomposition (NBTD). This model defines blocks as outer products of vectors
                    (clusters) and matrices (for spectral structure modeling), offering
                    interpretable latent vectors. Moreover, it enables straightforward integration
                    of orthogonality constraints to ensure independence among source images.
                    Experimental results demonstrate that our proposed method outperforms ILRMA and
                    its extensions in anechoic conditions and surpasses the original ILRMA in
                    simulated reverberant environments.
                </p>
            </div>
        </dd>
        <dt><a name="item408">[408]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03119"
                    title="Abstract">arXiv:2405.03119</a> [<a href="/pdf/2405.03119" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03119" title="Download PostScript">ps</a>, <a href="/format/2405.03119"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DAFT-Spread Affine Frequency Division Multiple Access for
                    Downlink Transmission
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tao%2C+Y">Yiwei Tao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wen%2C+M">Miaowen Wen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ge%2C+Y">Yao Ge</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mao%2C+T">Tianqi Mao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+L">Lixia Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jun Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">Affine frequency division multiplexing (AFDM) and orthogonal AFDM access
                    (O-AFDMA) are promising techniques based on chirp signals, which are able to
                    suppress the performance deterioration caused by Doppler shifts in
                    high-mobility scenarios. However, the high peak-to-average power ratio (PAPR)
                    in AFDM or O-AFDMA is still a crucial problem, which severely limits their
                    practical applications. In this paper, we propose a discrete affine Fourier
                    transform (DAFT)-spread AFDMA scheme based on the properties of the AFDM
                    systems, named DAFT-s-AFDMA to significantly reduce the PAPR by resorting to
                    the DAFT. We formulate the transmitted time-domain signals of the proposed
                    DAFT-s-AFDMA schemes with localized and interleaved chirp subcarrier allocation
                    strategies. Accordingly, we derive the guidelines for setting the DAFT
                    parameters, revealing the insights of PAPR reduction. Finally, simulation
                    results of PAPR comparison in terms of the complementary cumulative
                    distribution function (CCDF) show that the proposed DAFT-s-AFDMA schemes with
                    localized and interleaved strategies can both attain better PAPR performances
                    than the conventional O-AFDMA scheme.
                </p>
            </div>
        </dd>
        <dt><a name="item409">[409]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03121"
                    title="Abstract">arXiv:2405.03121</a> [<a href="/pdf/2405.03121" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03121" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AniTalker: Animate Vivid and Diverse Talking Faces through
                    Identity-Decoupled Facial Motion Encoding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Tao Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+F">Feilong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+S">Shuai Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Du%2C+C">Chenpeng Du</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xie Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+K">Kai Yu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 7 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">The paper introduces AniTalker, an innovative framework designed to generate
                    lifelike talking faces from a single portrait. Unlike existing models that
                    primarily focus on verbal cues such as lip synchronization and fail to capture
                    the complex dynamics of facial expressions and nonverbal cues, AniTalker
                    employs a universal motion representation. This innovative representation
                    effectively captures a wide range of facial dynamics, including subtle
                    expressions and head movements. AniTalker enhances motion depiction through two
                    self-supervised learning strategies: the first involves reconstructing target
                    video frames from source frames within the same identity to learn subtle motion
                    representations, and the second develops an identity encoder using metric
                    learning while actively minimizing mutual information between the identity and
                    motion encoders. This approach ensures that the motion representation is
                    dynamic and devoid of identity-specific details, significantly reducing the
                    need for labeled data. Additionally, the integration of a diffusion model with
                    a variance adapter allows for the generation of diverse and controllable facial
                    animations. This method not only demonstrates AniTalker's capability to create
                    detailed and realistic facial movements but also underscores its potential in
                    crafting dynamic avatars for real-world applications. Synthetic results can be
                    viewed at https://github.com/X-LANCE/AniTalker.
                </p>
            </div>
        </dd>
        <dt><a name="item410">[410]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03122"
                    title="Abstract">arXiv:2405.03122</a> [<a href="/pdf/2405.03122" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03122" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Automatic Retrieval-augmented Generation of 6G Network
                    Specifications for Use Cases
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yun Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+W">Weisi Guo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 6 figures, Submitted
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>

                </div>
                <p class="mathjax">6G Open Radio Access Networks (ORAN) promises to open data interfaces to
                    enable plug-and-play service Apps, many of which are consumer and
                    business-facing. Opening up 6G access lowers the barrier to innovation but
                    raises the challenge that the required communication specifications are not
                    fully known to all service designers. As such, business innovators must either
                    be familiar with 6G standards or consult with experts. Enabling consistent,
                    unbiased, rapid, and low-cost requirement assessment and specification
                    generation is crucial to the ORAN innovation ecosystem.
                    <br>Here, we discuss our initiative to bridge service specification generation
                    gaps between network service providers and business innovators. We first review
                    the state-of-the-art and motivation in 6G plug-and-play services and
                    capabilities, potential use cases, and relevant advances in Large Language
                    Models (LLMs). We identify an ample innovation space for hybrid use cases that
                    may require diverse and variational wireless functionalities across its
                    operating time. We show that the network specification can be automated and
                    present the first automatic retrieval-augmented specification generation (RAG)
                    framework for 6G use cases. To enable public acceptance and feedback, a website
                    interface is also published for the research and industrial community to
                    experiment with the RAG framework. We hope this review highlights the need and
                    the emerging foundation models that advance this area and motivate researchers
                    to engage with the framework.
                </p>
            </div>
        </dd>
        <dt><a name="item411">[411]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03125"
                    title="Abstract">arXiv:2405.03125</a> [<a href="/pdf/2405.03125" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03125" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MambaJSCC: Deep Joint Source-Channel Coding with Visual State
                    Space Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+T">Tong Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhiyong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tao%2C+M">Meixia Tao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiaodong Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenjun Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+P">Ping Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> submitted to IEEE conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">Lightweight and efficient deep joint source-channel coding (JSCC) is a key
                    technology for semantic communications. In this paper, we design a novel JSCC
                    scheme named MambaJSCC, which utilizes a visual state space model with channel
                    adaptation (VSSM-CA) block as its backbone for transmitting images over
                    wireless channels. The VSSM-CA block utilizes VSSM to integrate two-dimensional
                    images with the state space, enabling feature extraction and encoding processes
                    to operate with linear complexity. It also incorporates channel state
                    information (CSI) via a newly proposed CSI embedding method. This method
                    deploys a shared CSI encoding module within both the encoder and decoder to
                    encode and inject the CSI into each VSSM-CA block, improving the adaptability
                    of a single model to varying channel conditions. Experimental results show that
                    MambaJSCC not only outperforms Swin Transformer based JSCC (SwinJSCC) but also
                    significantly reduces parameter size, computational overhead, and inference
                    delay (ID). For example, with employing an equal number of the VSSM-CA blocks
                    and the Swin Transformer blocks, MambaJSCC achieves a 0.48 dB gain in
                    peak-signal-to-noise ratio (PSNR) over SwinJSCC while requiring only 53.3%
                    multiply-accumulate operations, 53.8% of the parameters, and 44.9% of ID.
                </p>
            </div>
        </dd>
        <dt><a name="item412">[412]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03131"
                    title="Abstract">arXiv:2405.03131</a> [<a href="/pdf/2405.03131" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03131" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> WDMoE: Wireless Distributed Large Language Models with
                    Mixture of Experts
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+N">Nan Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yaping Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhiyong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tao%2C+M">Meixia Tao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xiaodong Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qian%2C+L">Liang Qian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cui%2C+S">Shuguang Cui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+P">Ping Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> submitted to IEEE conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Large Language Models (LLMs) have achieved significant success in various
                    natural language processing tasks, but how wireless communications can support
                    LLMs has not been extensively studied. In this paper, we propose a wireless
                    distributed LLMs paradigm based on Mixture of Experts (MoE), named WDMoE,
                    deploying LLMs collaboratively across edge servers of base station (BS) and
                    mobile devices in the wireless communications system. Specifically, we
                    decompose the MoE layer in LLMs by deploying the gating network and the
                    preceding neural network layer at BS, while distributing the expert networks
                    across the devices. This arrangement leverages the parallel capabilities of
                    expert networks on distributed devices. Moreover, to overcome the instability
                    of wireless communications, we design an expert selection policy by taking into
                    account both the performance of the model and the end-to-end latency, which
                    includes both transmission delay and inference delay. Evaluations conducted
                    across various LLMs and multiple datasets demonstrate that WDMoE not only
                    outperforms existing models, such as Llama 2 with 70 billion parameters, but
                    also significantly reduces end-to-end latency.
                </p>
            </div>
        </dd>
        <dt><a name="item413">[413]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03132"
                    title="Abstract">arXiv:2405.03132</a> [<a href="/pdf/2405.03132" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03132" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Multi-Agent Rollout Approach for Highway Bottleneck
                    Decongenston in Mixed Autonomy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+L">Lu Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Maonan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pun%2C+M">Man-On Pun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+X">Xi Xiong</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems
                        (cs.MA)</span>

                </div>
                <p class="mathjax">The integration of autonomous vehicles (AVs) into the existing transportation
                    infrastructure offers a promising solution to alleviate congestion and enhance
                    mobility. This research explores a novel approach to traffic optimization by
                    employing a multi-agent rollout approach within a mixed autonomy environment.
                    The study concentrates on coordinating the speed of human-driven vehicles by
                    longitudinally controlling AVs, aiming to dynamically optimize traffic flow and
                    alleviate congestion at highway bottlenecks in real-time. We model the problem
                    as a decentralized partially observable Markov decision process (Dec-POMDP) and
                    propose an improved multi-agent rollout algorithm. By employing agent-by-agent
                    policy iterations, our approach implicitly considers cooperation among multiple
                    agents and seamlessly adapts to complex scenarios where the number of agents
                    dynamically varies. Validated in a real-world network with varying AV
                    penetration rates and traffic flow, the simulations demonstrate that the
                    multi-agent rollout algorithm significantly enhances performance, reducing
                    average travel time on bottleneck segments by 9.42% with a 10% AV penetration
                    rate.
                </p>
            </div>
        </dd>
        <dt><a name="item414">[414]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03133"
                    title="Abstract">arXiv:2405.03133</a> [<a href="/pdf/2405.03133" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03133" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Lory: Fully Differentiable Mixture-of-Experts for
                    Autoregressive Language Model Pre-training
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Z">Zexuan Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+M">Mengzhou Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+D">Danqi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lewis%2C+M">Mike Lewis</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 21 pages, 12 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Mixture-of-experts (MoE) models facilitate efficient scaling; however,
                    training the router network introduces the challenge of optimizing a
                    non-differentiable, discrete objective. Recently, a fully-differentiable MoE
                    architecture, SMEAR, was proposed (Muqeeth et al., 2023), which softly merges
                    experts in the parameter space; nevertheless, its effectiveness was only
                    demonstrated in downstream fine-tuning on classification tasks. In this paper,
                    we present Lory, the first approach that scales such architectures to
                    autoregressive language model pre-training. Lory introduces two key techniques:
                    (1) a causal segment routing strategy that achieves high efficiency for expert
                    merging operations while preserving the autoregressive nature of language
                    models; (2) a similarity-based data batching method that encourages expert
                    specialization by grouping similar documents in training instances. We
                    pre-train a series of Lory models on 150B tokens from scratch, with up to 32
                    experts and 30B (1.5B active) parameters. Experimental results show significant
                    performance gains over parameter-matched dense models on both perplexity
                    (+13.9%) and a variety of downstream tasks (+1.5%-11.1%). Despite segment-level
                    routing, Lory models achieve competitive performance compared to
                    state-of-the-art MoE models with token-level routing. We further demonstrate
                    that the trained experts in Lory capture domain-level specialization without
                    supervision. Our work highlights the potential of fully-differentiable MoE
                    architectures for language model pre-training and advocates future research in
                    this area.
                </p>
            </div>
        </dd>
        <dt><a name="item415">[415]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03134"
                    title="Abstract">arXiv:2405.03134</a> [<a href="/pdf/2405.03134" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03134" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Transhuman Ansambl - Voice Beyond Language
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ivsic%2C+L">Lucija Ivsic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McCormack%2C+J">Jon McCormack</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dziekan%2C+V">Vince Dziekan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">In this paper we present the design and development of the Transhuman
                    Ansambl, a novel interactive singing-voice interface which senses its
                    environment and responds to vocal input with vocalisations using human voice.
                    Designed for live performance with a human performer and as a standalone sound
                    installation, the ansambl consists of sixteen bespoke virtual singers arranged
                    in a circle. When performing live, the virtual singers listen to the human
                    performer and respond to their singing by reading pitch, intonation and volume
                    cues. In a standalone sound installation mode, singers use ultrasonic distance
                    sensors to sense audience presence. Developed as part of the 1st author's
                    practice-based PhD and artistic practice as a live performer, this work employs
                    the singing-voice to explore voice interactions in HCI beyond language, and
                    innovative ways of live performing. How is technology supporting the effect of
                    intimacy produced through voice? Does the act of surrounding the audience with
                    responsive virtual singers challenge the traditional roles of
                    performer-listener? To answer these questions, we draw upon the 1st author's
                    experience with the system, and the interdisciplinary field of voice studies
                    that consider the voice as the sound medium independent of language, capable of
                    enacting a reciprocal connection between bodies.
                </p>
            </div>
        </dd>
        <dt><a name="item416">[416]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03136"
                    title="Abstract">arXiv:2405.03136</a> [<a href="/pdf/2405.03136" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03136" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FOBNN: Fast Oblivious Binarized Neural Network Inference
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xin Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhili Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+B">Benchang Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+S">Shiwen Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Lin Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+D">Daojing He</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">The superior performance of deep learning has propelled the rise of Deep
                    Learning as a Service, enabling users to transmit their private data to service
                    providers for model execution and inference retrieval. Nevertheless, the
                    primary concern remains safeguarding the confidentiality of sensitive user data
                    while optimizing the efficiency of secure protocols. To address this, we
                    develop a fast oblivious binarized neural network inference framework, FOBNN.
                    Specifically, we customize binarized convolutional neural networks to enhance
                    oblivious inference, design two fast algorithms for binarized convolutions, and
                    optimize network structures experimentally under constrained costs. Initially,
                    we meticulously analyze the range of intermediate values in binarized
                    convolutions to minimize bit representation, resulting in the Bit Length
                    Bounding (BLB) algorithm. Subsequently, leveraging the efficiency of bitwise
                    operations in BLB, we further enhance performance by employing pure bitwise
                    operations for each binary digit position, yielding the Layer-wise Bit
                    Accumulation (LBA) algorithm. Theoretical analysis validates FOBNN's security
                    and indicates up to <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-183-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1277"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.1em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1278"><span class="mn" id="MathJax-Span-1279"
                                                style="font-family: MathJax_Main;">2</span><span class="mo"
                                                id="MathJax-Span-1280"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-183">2 \times</script> improvement in computational and
                    communication
                    costs compared to the state-of-the-art method. We demonstrates our framework's
                    effectiveness in RNA function prediction within bioinformatics. Rigorous
                    experimental assessments confirm that our oblivious inference solutions not
                    only maintain but often exceed the original accuracy, surpassing prior efforts.
                </p>
            </div>
        </dd>
        <dt><a name="item417">[417]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03138"
                    title="Abstract">arXiv:2405.03138</a> [<a href="/pdf/2405.03138" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03138" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CRAFT: Extracting and Tuning Cultural Instructions from the
                    Wild
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+G">Geyu Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhengyuan Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+C">Chengwei Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+N+F">Nancy F. Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Large language models (LLMs) have rapidly evolved as the foundation of
                    various natural language processing (NLP) applications. Despite their wide use
                    cases, their understanding of culturally-related concepts and reasoning remains
                    limited. Meantime, there is a significant need to enhance these models'
                    cultural reasoning capabilities, especially concerning underrepresented
                    regions. This paper introduces a novel pipeline for extracting high-quality,
                    culturally-related instruction tuning datasets from vast unstructured corpora.
                    We utilize a self-instruction generation pipeline to identify cultural concepts
                    and trigger instruction. By integrating with a general-purpose instruction
                    tuning dataset, our model demonstrates enhanced capabilities in recognizing and
                    understanding regional cultural nuances, thereby enhancing its reasoning
                    capabilities. We conduct experiments across three regions: Singapore, the
                    Philippines, and the United States, achieving performance improvement of up to
                    6%. Our research opens new avenues for extracting cultural instruction tuning
                    sets directly from unstructured data, setting a precedent for future
                    innovations in the field.
                </p>
            </div>
        </dd>
        <dt><a name="item418">[418]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03140"
                    title="Abstract">arXiv:2405.03140</a> [<a href="/pdf/2405.03140" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03140" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TimeMIL: Advancing Multivariate Time Series Classification
                    via a Time-aware Multiple Instance Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiwen Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+P">Peijie Qiu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+W">Wenhui Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Huayu Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sotiras%2C+A">Aristeidis Sotiras</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yalin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Razi%2C+A">Abolfazl Razi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Deep neural networks, including transformers and convolutional neural
                    networks, have significantly improved multivariate time series classification
                    (MTSC). However, these methods often rely on supervised learning, which does
                    not fully account for the sparsity and locality of patterns in time series data
                    (e.g., diseases-related anomalous points in ECG). To address this challenge, we
                    formally reformulate MTSC as a weakly supervised problem, introducing a novel
                    multiple-instance learning (MIL) framework for better localization of patterns
                    of interest and modeling time dependencies within time series. Our novel
                    approach, TimeMIL, formulates the temporal correlation and ordering within a
                    time-aware MIL pooling, leveraging a tokenized transformer with a specialized
                    learnable wavelet positional token. The proposed method surpassed 26 recent
                    state-of-the-art methods, underscoring the effectiveness of the weakly
                    supervised TimeMIL in MTSC.
                </p>
            </div>
        </dd>
        <dt><a name="item419">[419]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03143"
                    title="Abstract">arXiv:2405.03143</a> [<a href="/pdf/2405.03143" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03143" title="Download PostScript">ps</a>, <a href="/format/2405.03143"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A novel fourth-order scheme for two-dimensional Riesz space
                    fractional nonlinear reaction-diffusion equations and its optimal preconditioned solver
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Qu%2C+W">Wei Qu</a>,
                    <a href="/search/math?searchtype=author&amp;query=Huang%2C+Y">Yuan-Yuan Huang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Hon%2C+S">Sean Hon</a>,
                    <a href="/search/math?searchtype=author&amp;query=Lei%2C+S">Siu-Long Lei</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">A novel fourth-order finite difference formula coupling the Crank-Nicolson
                    explicit linearized method is proposed to solve Riesz space fractional
                    nonlinear reaction-diffusion equations in two dimensions. Theoretically, under
                    the Lipschitz assumption on the nonlinear term, the proposed high-order scheme
                    is proved to be unconditionally stable and convergent in the discrete
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-184-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1281"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.1em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1282"><span class="msubsup"
                                                id="MathJax-Span-1283"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1284"
                                                            style="font-family: MathJax_Math-italic;">L</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-1285"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-184">L_2</script>-norm. Moreover, a <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-185-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1286"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1287"><span class="mi" id="MathJax-Span-1288"
                                                style="font-family: MathJax_Math-italic;">τ<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-185">\tau</script>-matrix based preconditioner is
                    developed to
                    speed up the convergence of the conjugate gradient method with an optimal
                    convergence rate (a convergence rate independent of mesh sizes) for solving the
                    symmetric discrete linear system. Theoretical analysis shows that the spectra
                    of the preconditioned matrices are uniformly bounded in the open interval
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-186-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1289"
                                style="width: 3.938em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.244em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1003.13em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1290"><span class="mo" id="MathJax-Span-1291"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-1292" style="font-family: MathJax_Main;">3</span><span
                                                class="texatom" id="MathJax-Span-1293"><span class="mrow"
                                                    id="MathJax-Span-1294"><span class="mo" id="MathJax-Span-1295"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="mn" id="MathJax-Span-1296"
                                                style="font-family: MathJax_Main;">8</span><span class="mo"
                                                id="MathJax-Span-1297" style="font-family: MathJax_Main;">,</span><span
                                                class="mn" id="MathJax-Span-1298"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">2</span><span
                                                class="mo" id="MathJax-Span-1299"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-186">(3/8,2)</script>. To the best of our knowledge,
                    this is the first attempt to develop a
                    preconditioned iterative solver with a mesh-independent convergence rate for
                    the linearized high-order scheme. Numerical examples are given to validate the
                    accuracy of the scheme and the effectiveness of the proposed preconditioned
                    solver.
                </p>
            </div>
        </dd>
        <dt><a name="item420">[420]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03144"
                    title="Abstract">arXiv:2405.03144</a> [<a href="/pdf/2405.03144" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03144" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PTQ4SAM: Post-Training Quantization for Segment Anything
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lv%2C+C">Chengtao Lv</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+J">Jinyang Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+Y">Yifu Ding</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xianglong Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> CVPR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Segment Anything Model (SAM) has achieved impressive performance in many
                    computer vision tasks. However, as a large-scale model, the immense memory and
                    computation costs hinder its practical deployment. In this paper, we propose a
                    post-training quantization (PTQ) framework for Segment Anything Model, namely
                    PTQ4SAM. First, we investigate the inherent bottleneck of SAM quantization
                    attributed to the bimodal distribution in post-Key-Linear activations. We
                    analyze its characteristics from both per-tensor and per-channel perspectives,
                    and propose a Bimodal Integration strategy, which utilizes a mathematically
                    equivalent sign operation to transform the bimodal distribution into a
                    relatively easy-quantized normal distribution offline. Second, SAM encompasses
                    diverse attention mechanisms (i.e., self-attention and two-way
                    cross-attention), resulting in substantial variations in the post-Softmax
                    distributions. Therefore, we introduce an Adaptive Granularity Quantization for
                    Softmax through searching the optimal power-of-two base, which is
                    hardware-friendly. Extensive experimental results across various vision tasks
                    (instance segmentation, semantic segmentation and object detection), datasets
                    and model variants show the superiority of PTQ4SAM. For example, when
                    quantizing SAM-L to 6-bit, we achieve lossless accuracy for instance
                    segmentation, about 0.5\% drop with theoretical 3.9<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-187-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1300"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1301"><span class="mo" id="MathJax-Span-1302"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-187">\times</script> acceleration. The
                    code is available at \url{https://github.com/chengtao-lv/PTQ4SAM}.
                </p>
            </div>
        </dd>
        <dt><a name="item421">[421]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03145"
                    title="Abstract">arXiv:2405.03145</a> [<a href="/pdf/2405.03145" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03145" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Projection-Free Method for the Full Frank-Oseen Model of
                    Liquid Crystals
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Bouck%2C+L">Lucas Bouck</a>,
                    <a href="/search/math?searchtype=author&amp;query=Nochetto%2C+R+H">Ricardo H. Nochetto</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 32 pages, 8 figures, 4 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">Liquid crystals are materials that experience an intermediate phase where the
                    material can flow like a liquid, but the molecules maintain an orientation
                    order. The Frank-Oseen model is a continuum model of a liquid crystal. The
                    model represents the liquid crystal orientation as a vector field and posits
                    that the vector field minimizes some elastic energy subject to a pointwise unit
                    length constraint, which is a nonconvex constraint. Previous numerical methods
                    in the literature assumed restrictions on the physical constants or had
                    regularity assumptions that ruled out point defects, which are important
                    physical phenomena to model. We present a finite element discretization of the
                    full Frank-Oseen model and a projection free gradient flow algorithm for the
                    discrete problem in the spirit of Bartels (2016). We prove Gamma-convergence of
                    the discrete to the continuous problem: weak convergence of subsequences of
                    discrete minimizers and convergence of energies. We also prove that the
                    gradient flow algorithm has a desirable energy decrease property. Our analysis
                    only requires that the physical constants are positive, which presents
                    challenges due to the additional nonlinearities from the elastic energy.
                </p>
            </div>
        </dd>
        <dt><a name="item422">[422]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03146"
                    title="Abstract">arXiv:2405.03146</a> [<a href="/pdf/2405.03146" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03146" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Quantifying the Capabilities of LLMs across Scale and
                    Precision
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Badshah%2C+S">Sher Badshah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sajjad%2C+H">Hassan Sajjad</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">Scale is often attributed as one of the factors that cause an increase in the
                    performance of LLMs, resulting in models with billion and trillion parameters.
                    One of the limitations of such large models is the high computational
                    requirements that limit their usage, deployment, and debugging in
                    resource-constrained scenarios. Two commonly used alternatives to bypass these
                    limitations are to use the smaller versions of LLMs (e.g. Llama 7B instead of
                    Llama 70B) and lower the memory requirements by using quantization. While these
                    approaches effectively address the limitation of resources, their impact on
                    model performance needs thorough examination. In this study, we perform a
                    comprehensive evaluation to investigate the effect of model scale and
                    quantization on the performance. We experiment with two major families of
                    open-source instruct models ranging from 7 billion to 70 billion parameters.
                    Our extensive zero-shot experiments across various tasks including natural
                    language understanding, reasoning, misinformation detection, and hallucination
                    reveal that larger models generally outperform their smaller counterparts,
                    suggesting that scale remains an important factor in enhancing performance. We
                    found that larger models show exceptional resilience to precision reduction and
                    can maintain high accuracy even at 4-bit quantization for numerous tasks and
                    they serve as a better solution than using smaller models at high precision
                    under similar memory requirements.
                </p>
            </div>
        </dd>
        <dt><a name="item423">[423]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03150"
                    title="Abstract">arXiv:2405.03150</a> [<a href="/pdf/2405.03150" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03150" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Video Diffusion Models: A Survey
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Melnik%2C+A">Andrew Melnik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ljubljanac%2C+M">Michal Ljubljanac</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+C">Cong Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Q">Qi Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+W">Weiming Ren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ritter%2C+H">Helge Ritter</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Diffusion generative models have recently become a robust technique for
                    producing and modifying coherent, high-quality video. This survey offers a
                    systematic overview of critical elements of diffusion models for video
                    generation, covering applications, architectural choices, and the modeling of
                    temporal dynamics. Recent advancements in the field are summarized and grouped
                    into development trends. The survey concludes with an overview of remaining
                    challenges and an outlook on the future of the field. Website:
                    https://github.com/ndrwmlnk/Awesome-Video-Diffusion-Models
                </p>
            </div>
        </dd>
        <dt><a name="item424">[424]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03151"
                    title="Abstract">arXiv:2405.03151</a> [<a href="/pdf/2405.03151" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03151" title="Download PostScript">ps</a>, <a href="/format/2405.03151"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Time Series Stock Price Forecasting Based on Genetic
                    Algorithm (GA)-Long Short-Term Memory Network (LSTM) Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sha%2C+X">Xinye Sha</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">In this paper, a time series algorithm based on Genetic Algorithm (GA) and
                    Long Short-Term Memory Network (LSTM) optimization is used to forecast stock
                    prices effectively, taking into account the trend of the big data era. The data
                    are first analyzed by descriptive statistics, and then the model is built and
                    trained and tested on the dataset. After optimization and adjustment, the mean
                    absolute error (MAE) of the model gradually decreases from 0.11 to 0.01 and
                    tends to be stable, indicating that the model prediction effect is gradually
                    close to the real value. The results on the test set show that the time series
                    algorithm optimized based on Genetic Algorithm (GA)-Long Short-Term Memory
                    Network (LSTM) is able to accurately predict the stock prices, and is highly
                    consistent with the actual price trends and values, with strong generalization
                    ability. The MAE on the test set is 2.41, the MSE is 9.84, the RMSE is 3.13,
                    and the R2 is 0.87. This research result not only provides a novel stock price
                    prediction method, but also provides a useful reference for financial market
                    analysis using computer technology and big data.
                </p>
            </div>
        </dd>
        <dt><a name="item425">[425]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03153"
                    title="Abstract">arXiv:2405.03153</a> [<a href="/pdf/2405.03153" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03153" title="Download PostScript">ps</a>, <a href="/format/2405.03153"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring the Potential of the Large Language Models (LLMs)
                    in Identifying Misleading News Headlines
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Rony%2C+M+M+U">Md Main Uddin Rony</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Haque%2C+M+M">Md Mahfuzul Haque</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ali%2C+M">Mohammad Ali</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alam%2C+A+S">Ahmed Shatil Alam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hassan%2C+N">Naeemul Hassan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages, 2 tables, 1st HEAL Workshop at CHI Conference on
                    Human Factors in Computing Systems, May 12, Honolulu, HI, USA 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In the digital age, the prevalence of misleading news headlines poses a
                    significant challenge to information integrity, necessitating robust detection
                    mechanisms. This study explores the efficacy of Large Language Models (LLMs) in
                    identifying misleading versus non-misleading news headlines. Utilizing a
                    dataset of 60 articles, sourced from both reputable and questionable outlets
                    across health, science &amp; tech, and business domains, we employ three LLMs-
                    ChatGPT-3.5, ChatGPT-4, and Gemini-for classification. Our analysis reveals
                    significant variance in model performance, with ChatGPT-4 demonstrating
                    superior accuracy, especially in cases with unanimous annotator agreement on
                    misleading headlines. The study emphasizes the importance of human-centered
                    evaluation in developing LLMs that can navigate the complexities of
                    misinformation detection, aligning technical proficiency with nuanced human
                    judgment. Our findings contribute to the discourse on AI ethics, emphasizing
                    the need for models that are not only technically advanced but also ethically
                    aligned and sensitive to the subtleties of human interpretation.
                </p>
            </div>
        </dd>
        <dt><a name="item426">[426]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03155"
                    title="Abstract">arXiv:2405.03155</a> [<a href="/pdf/2405.03155" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03155" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CushSense: Soft, Stretchable, and Comfortable Tactile-Sensing
                    Skin for Physical Human-Robot Interaction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+B">Boxin Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+L">Luoyan Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Grace Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liang%2C+X">Xiaoyu Liang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Virtue%2C+D">Diego Virtue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Madan%2C+R">Rishabh Madan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bhattacharjee%2C+T">Tapomayukh Bhattacharjee</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 8 figures, ICRA2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Whole-arm tactile feedback is crucial for robots to ensure safe physical
                    interaction with their surroundings. This paper introduces CushSense, a
                    fabric-based soft and stretchable tactile-sensing skin designed for physical
                    human-robot interaction (pHRI) tasks such as robotic caregiving. Using
                    stretchable fabric and hyper-elastic polymer, CushSense identifies contacts by
                    monitoring capacitive changes due to skin deformation. CushSense is
                    cost-effective (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-188-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1303"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.623em, 1000.7em, 2.202em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1304"><span class="mo" id="MathJax-Span-1305"
                                                style="font-family: MathJax_Main;">∼</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: 0.073em; border-left: 0px solid; width: 0px; height: 0.42em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-188">\sim</script>US<span>$</span>7 per taxel) and easy
                    to fabricate. We detail the
                    sensor design and fabrication process and perform characterization,
                    highlighting its high sensing accuracy (relative error of 0.58%) and durability
                    (0.054% accuracy drop after 1000 interactions). We also present a user study
                    underscoring its perceived safety and comfort for the assistive task of limb
                    manipulation. We open source all sensor-related resources on
                    https://emprise.cs.cornell.edu/cushsense.
                </p>
            </div>
        </dd>
        <dt><a name="item427">[427]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03158"
                    title="Abstract">arXiv:2405.03158</a> [<a href="/pdf/2405.03158" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03158" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Decentralized Online Learning in General-Sum Stackelberg
                    Games
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yaolong Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Haipeng Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for the 40th Conference on Uncertainty in
                    Artificial Intelligence (UAI 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">We study an online learning problem in general-sum Stackelberg games, where
                    players act in a decentralized and strategic manner. We study two settings
                    depending on the type of information for the follower: (1) the limited
                    information setting where the follower only observes its own reward, and (2)
                    the side information setting where the follower has extra side information
                    about the leader's reward. We show that for the follower, myopically best
                    responding to the leader's action is the best strategy for the limited
                    information setting, but not necessarily so for the side information setting --
                    the follower can manipulate the leader's reward signals with strategic actions,
                    and hence induce the leader's strategy to converge to an equilibrium that is
                    better off for itself. Based on these insights, we study decentralized online
                    learning for both players in the two settings. Our main contribution is to
                    derive last-iterate convergence and sample complexity results in both settings.
                    Notably, we design a new manipulation strategy for the follower in the latter
                    setting, and show that it has an intrinsic advantage against the best response
                    strategy. Our theories are also supported by empirical results.
                </p>
            </div>
        </dd>
        <dt><a name="item428">[428]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03159"
                    title="Abstract">arXiv:2405.03159</a> [<a href="/pdf/2405.03159" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03159" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DeepMpMRI: Tensor-decomposition Regularized Learning for Fast
                    and High-Fidelity Multi-Parametric Microstructural MR Imaging
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+W">Wenxin Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jian Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Cheng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+X">Xinrui Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jing Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zou%2C+J">Juan Zou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+R">Ruoyou Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zan Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yuanjing Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+H">Hairong Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shanshan Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Deep learning has emerged as a promising approach for learning the nonlinear
                    mapping between diffusion-weighted MR images and tissue parameters, which
                    enables automatic and deep understanding of the brain microstructures. However,
                    the efficiency and accuracy in the multi-parametric estimations are still
                    limited since previous studies tend to estimate multi-parametric maps with
                    dense sampling and isolated signal modeling. This paper proposes DeepMpMRI, a
                    unified framework for fast and high-fidelity multi-parametric estimation from
                    various diffusion models using sparsely sampled q-space data. DeepMpMRI is
                    equipped with a newly designed tensor-decomposition-based regularizer to
                    effectively capture fine details by exploiting the correlation across
                    parameters. In addition, we introduce a Nesterov-based adaptive learning
                    algorithm that optimizes the regularization parameter dynamically to enhance
                    the performance. DeepMpMRI is an extendable framework capable of incorporating
                    flexible network architecture. Experimental results demonstrate the superiority
                    of our approach over 5 state-of-the-art methods in simultaneously estimating
                    multi-parametric maps for various diffusion models with fine-grained details
                    both quantitatively and qualitatively, achieving 4.5 - 22.5<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-189-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1306"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1307"><span class="mo" id="MathJax-Span-1308"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-189">\times</script>
                    acceleration compared to the dense sampling of a total of 270 diffusion
                    gradients.
                </p>
            </div>
        </dd>
        <dt><a name="item429">[429]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03162"
                    title="Abstract">arXiv:2405.03162</a> [<a href="/pdf/2405.03162" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03162" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Advancing Multimodal Medical Capabilities of Gemini
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L">Lin Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+S">Shawn Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sellergren%2C+A">Andrew Sellergren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kohlberger%2C+T">Timo Kohlberger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuchen Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ktena%2C+I">Ira Ktena</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kiraly%2C+A">Atilla Kiraly</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ahmed%2C+F">Faruk Ahmed</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hormozdiari%2C+F">Farhad Hormozdiari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jaroensri%2C+T">Tiam Jaroensri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+E">Eric Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wulczyn%2C+E">Ellery Wulczyn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jamil%2C+F">Fayaz Jamil</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guidroz%2C+T">Theo Guidroz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lau%2C+C">Chuck Lau</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiao%2C+S">Siyuan Qiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yun Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goel%2C+A">Akshay Goel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+K">Kendall Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Agharwal%2C+A">Arnav Agharwal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=George%2C+N">Nick George</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yang Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tanno%2C+R">Ryutaro Tanno</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Barrett%2C+D+G+T">David G. T. Barrett</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Weng%2C+W">Wei-Hung Weng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mahdavi%2C+S+S">S. Sara Mahdavi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saab%2C+K">Khaled Saab</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tu%2C+T">Tao Tu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kalidindi%2C+S+R">Sreenivasa Raju Kalidindi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Etemadi%2C+M">Mozziyar Etemadi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cuadros%2C+J">Jorge Cuadros</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sorensen%2C+G">Gregory Sorensen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matias%2C+Y">Yossi Matias</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chou%2C+K">Katherine Chou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Corrado%2C+G">Greg Corrado</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Barral%2C+J">Joelle Barral</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shetty%2C+S">Shravya Shetty</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fleet%2C+D">David Fleet</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eslami%2C+S+M+A">S. M. Ali Eslami</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tse%2C+D">Daniel Tse</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Prabhakara%2C+S">Shruthi Prabhakara</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McLean%2C+C">Cory McLean</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Steiner%2C+D">Dave Steiner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pilgrim%2C+R">Rory Pilgrim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kelly%2C+C">Christopher Kelly</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Azizi%2C+S">Shekoofeh Azizi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Golden%2C+D">Daniel Golden</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL);
                    Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Many clinical tasks require an understanding of specialized data, such as
                    medical images and genomics, which is not typically found in general-purpose
                    large multimodal models. Building upon Gemini's multimodal models, we develop
                    several models within the new Med-Gemini family that inherit core capabilities
                    of Gemini and are optimized for medical use via fine-tuning with 2D and 3D
                    radiology, histopathology, ophthalmology, dermatology and genomic data.
                    Med-Gemini-2D sets a new standard for AI-based chest X-ray (CXR) report
                    generation based on expert evaluation, exceeding previous best results across
                    two separate datasets by an absolute margin of 1% and 12%, where 57% and 96% of
                    AI reports on normal cases, and 43% and 65% on abnormal cases, are evaluated as
                    "equivalent or better" than the original radiologists' reports. We demonstrate
                    the first ever large multimodal model-based report generation for 3D computed
                    tomography (CT) volumes using Med-Gemini-3D, with 53% of AI reports considered
                    clinically acceptable, although additional research is needed to meet expert
                    radiologist reporting quality. Beyond report generation, Med-Gemini-2D
                    surpasses the previous best performance in CXR visual question answering (VQA)
                    and performs well in CXR classification and radiology VQA, exceeding SoTA or
                    baselines on 17 of 20 tasks. In histopathology, ophthalmology, and dermatology
                    image classification, Med-Gemini-2D surpasses baselines across 18 out of 20
                    tasks and approaches task-specific model performance. Beyond imaging,
                    Med-Gemini-Polygenic outperforms the standard linear polygenic risk score-based
                    approach for disease risk prediction and generalizes to genetically correlated
                    diseases for which it has never been trained. Although further development and
                    evaluation are necessary in the safety-critical medical domain, our results
                    highlight the potential of Med-Gemini across a wide range of medical tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item430">[430]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03164"
                    title="Abstract">arXiv:2405.03164</a> [<a href="/pdf/2405.03164" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03164" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Role of Predictive Uncertainty and Diversity in Embodied
                    AI and Robot Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Senanayake%2C+R">Ransalu Senanayake</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Uncertainty has long been a critical area of study in robotics, particularly
                    when robots are equipped with analytical models. As we move towards the
                    widespread use of deep neural networks in robots, which have demonstrated
                    remarkable performance in research settings, understanding the nuances of
                    uncertainty becomes crucial for their real-world deployment. This guide offers
                    an overview of the importance of uncertainty and provides methods to quantify
                    and evaluate it from an applications perspective.
                </p>
            </div>
        </dd>
        <dt><a name="item431">[431]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03166"
                    title="Abstract">arXiv:2405.03166</a> [<a href="/pdf/2405.03166" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03166" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Efficient All-to-All GCD Algorithm for Low Entropy RSA Key
                    Factorization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pelofske%2C+E">Elijah Pelofske</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">RSA is an incredibly successful and useful asymmetric encryption algorithm.
                    One of the types of implementation flaws in RSA is low entropy of the key
                    generation, specifically the prime number creation stage. This can occur due to
                    flawed usage of random prime number generator libraries, or on computers where
                    there is a lack of a source of external entropy. These implementation flaws
                    result in some RSA keys sharing prime factors, which means that the full
                    factorization of the public modulus can be recovered incredibly efficiently by
                    performing a computation GCD between the two public key moduli that share the
                    prime factor. However, since one does not know which of the composite moduli
                    share a prime factor a-priori, to determine if any such shared prime factors
                    exist, an all-to-all GCD attack (also known as a batch GCD attack, or a bulk
                    GCD attack) can be performed on the available public keys so as to recover any
                    shared prime factors. This study describes a novel all-to-all batch GCD
                    algorithm, which will be referred to as the binary tree batch GCD algorithm,
                    that is more efficient than the current best batch GCD algorithm (the remainder
                    tree batch GCD algorithm). A comparison against the best existing batch GCD
                    method (which is a product tree followed by a remainder tree computation) is
                    given using a dataset of random RSA moduli that are constructed such that some
                    of the moduli share prime factors. This proposed binary tree batch GCD
                    algorithm has better runtime than the existing remainder tree batch GCD
                    algorithm, although asymptotically it has nearly identical scaling and its
                    complexity is dependent on how many shared prime factors exist in the set of
                    RSA keys. In practice, the implementation of the proposed binary tree batch GCD
                    algorithm has a roughly 6x speedup compared to the standard remainder tree
                    batch GCD approach.
                </p>
            </div>
        </dd>
        <dt><a name="item432">[432]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03167"
                    title="Abstract">arXiv:2405.03167</a> [<a href="/pdf/2405.03167" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03167" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TF4CTR: Twin Focus Framework for CTR Prediction via Adaptive
                    Sample Differentiation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Honghao Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yiwen Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sang%2C+L">Lei Sang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yun Yang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">Effective feature interaction modeling is critical for enhancing the accuracy
                    of click-through rate (CTR) prediction in industrial recommender systems. Most
                    of the current deep CTR models resort to building complex network architectures
                    to better capture intricate feature interactions or user behaviors. However, we
                    identify two limitations in these models: (1) the samples given to the model
                    are undifferentiated, which may lead the model to learn a larger number of easy
                    samples in a single-minded manner while ignoring a smaller number of hard
                    samples, thus reducing the model's generalization ability; (2) differentiated
                    feature interaction encoders are designed to capture different interactions
                    information but receive consistent supervision signals, thereby limiting the
                    effectiveness of the encoder. To bridge the identified gaps, this paper
                    introduces a novel CTR prediction framework by integrating the plug-and-play
                    Twin Focus (TF) Loss, Sample Selection Embedding Module (SSEM), and Dynamic
                    Fusion Module (DFM), named the Twin Focus Framework for CTR (TF4CTR).
                    Specifically, the framework employs the SSEM at the bottom of the model to
                    differentiate between samples, thereby assigning a more suitable encoder for
                    each sample. Meanwhile, the TF Loss provides tailored supervision signals to
                    both simple and complex encoders. Moreover, the DFM dynamically fuses the
                    feature interaction information captured by the encoders, resulting in more
                    accurate predictions. Experiments on five real-world datasets confirm the
                    effectiveness and compatibility of the framework, demonstrating its capacity to
                    enhance various representative baselines in a model-agnostic manner. To
                    facilitate reproducible research, our open-sourced code and detailed running
                    logs will be made available at: https://github.com/salmon1802/TF4CTR.
                </p>
            </div>
        </dd>
        <dt><a name="item433">[433]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03169"
                    title="Abstract">arXiv:2405.03169</a> [<a href="/pdf/2405.03169" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03169" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SOC-MartNet: A Martingale Neural Network for the
                    Hamilton-Jacobi-Bellman Equation without Explicit inf H in Stochastic Optimal Controls
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Cai%2C+W">Wei Cai</a>,
                    <a href="/search/math?searchtype=author&amp;query=Fang%2C+S">Shuixin Fang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Zhou%2C+T">Tao Zhou</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">In this work, we propose a martingale based neural network, SOC-MartNet, for
                    solving high-dimensional Hamilton-Jacobi-Bellman (HJB) equations where no
                    explicit expression is needed for the Hamiltonian <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-190-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1309"
                                style="width: 10.593em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 8.799em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1008.68em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1310"><span class="munderover"
                                                id="MathJax-Span-1311"><span
                                                    style="display: inline-block; position: relative; width: 2.665em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.22em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mo" id="MathJax-Span-1312"
                                                            style="font-family: MathJax_Main;">inf</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 1.16em;"><span
                                                            class="texatom" id="MathJax-Span-1313"><span class="mrow"
                                                                id="MathJax-Span-1314"><span class="mi"
                                                                    id="MathJax-Span-1315"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">u</span><span
                                                                    class="mo" id="MathJax-Span-1316"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">∈</span><span
                                                                    class="mi" id="MathJax-Span-1317"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">U<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mi" id="MathJax-Span-1318"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">H<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="mo" id="MathJax-Span-1319"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1320"
                                                style="font-family: MathJax_Math-italic;">t</span><span class="mo"
                                                id="MathJax-Span-1321" style="font-family: MathJax_Main;">,</span><span
                                                class="mi" id="MathJax-Span-1322"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">x</span><span
                                                class="mo" id="MathJax-Span-1323"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1324"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">u</span><span
                                                class="mo" id="MathJax-Span-1325"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1326"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">z<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1327"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1328"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">p</span><span
                                                class="mo" id="MathJax-Span-1329"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-190">\inf_{u \in U} H(t,x,u,
    z,p)</script>, and stochastic optimal control problems with controls on both drift and
                    volatility. We reformulate the HJB equations into a stochastic neural network
                    learning process, i.e., training a control network and a value network such
                    that the associated Hamiltonian process is minimized and the cost process
                    becomes a martingale.To enforce the martingale property for the cost process,
                    we employ an adversarial network and construct a loss function based on the
                    projection property of conditional expectations. Then, the control/value
                    networks and the adversarial network are trained adversarially, such that the
                    cost process is driven towards a martingale and the minimum principle is
                    satisfied for the control.Numerical results show that the proposed SOC-MartNet
                    is effective and efficient for solving HJB-type equations and SOCP with a
                    dimension up to <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-191-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1330"
                                style="width: 1.855em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.508em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.45em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1331"><span class="mn" id="MathJax-Span-1332"
                                                style="font-family: MathJax_Main;">500</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-191">500</script> in a small number of training epochs.
                </p>
            </div>
        </dd>
        <dt><a name="item434">[434]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03170"
                    title="Abstract">arXiv:2405.03170</a> [<a href="/pdf/2405.03170" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03170" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Oracle-Checker Scheme for Evaluating a Generative Large
                    Language Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+Y+J">Yueling Jenny Zeng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Li-C. Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ibbetson%2C+T">Thomas Ibbetson</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">This work presents a novel approach called oracle-checker scheme for
                    evaluating the answer given by a generative large language model (LLM). Two
                    types of checkers are presented. The first type of checker follows the idea of
                    property testing. The second type of checker follows the idea of program
                    checking. Their applications are demonstrated in two separate contexts, entity
                    extraction and paraphrase decision, respectively.
                </p>
            </div>
        </dd>
        <dt><a name="item435">[435]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03176"
                    title="Abstract">arXiv:2405.03176</a> [<a href="/pdf/2405.03176" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03176" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FIMP-HGA: A Novel Approach to Addressing the Partitioning
                    Min-Max Weighted Matching Problem
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuxuan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+J">Jiongzhi Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+J">Jinyao Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+K">Kun He</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>

                </div>
                <p class="mathjax">The Partitioning Min-Max Weighted Matching (PMMWM) problem, being a practical
                    NP-hard problem, integrates the task of partitioning the vertices of a
                    bipartite graph into disjoint sets of limited size with the classical
                    Maximum-Weight Perfect Matching (MPWM) problem. Initially introduced in 2015,
                    the state-of-the-art method for addressing PMMWM is the MP<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-192-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1333"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.466em, 1000.93em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1334"><span class="msubsup"
                                                id="MathJax-Span-1335"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.822em, 1000em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1336"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1337"><span class="mrow"
                                                                id="MathJax-Span-1338"><span class="mtext"
                                                                    id="MathJax-Span-1339"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">LS</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.767em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-192">_{\text{LS}}</script>. In
                    this paper, we present a novel approach, the Fast Iterative Match-Partition
                    Hybrid Genetic Algorithm (FIMP-HGA), for addressing PMMWM. Similar to
                    MP<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-193-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1340"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.466em, 1000.93em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1341"><span class="msubsup"
                                                id="MathJax-Span-1342"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.822em, 1000em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1343"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1344"><span class="mrow"
                                                                id="MathJax-Span-1345"><span class="mtext"
                                                                    id="MathJax-Span-1346"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">LS</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.767em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-193">_{\text{LS}}</script>, FIMP-HGA divides the solving
                    into match and partition stages,
                    iteratively refining the solution. In the match stage, we propose the KM-M
                    algorithm, which reduces matching complexity through incremental adjustments,
                    significantly enhancing runtime efficiency. For the partition stage, we
                    introduce a Hybrid Genetic Algorithm (HGA) incorporating an elite strategy and
                    design a Greedy Partition Crossover (GPX) operator alongside a Multilevel Local
                    Search (MLS) to optimize individuals in the population. Population
                    initialization employs various methods, including the multi-way Karmarkar-Karp
                    (KK) algorithm, ensuring both quality and diversity. At each iteration, the
                    bipartite graph is adjusted based on the current solution, aiming for
                    continuous improvement. To conduct comprehensive experiments, we develop a new
                    instance generation method compatible with existing approaches, resulting in
                    four benchmark groups. Extensive experiments evaluate various algorithm
                    modules, accurately assessing each module's impact on improvement. Evaluation
                    results on our benchmarks demonstrate that the proposed FIMP-HGA significantly
                    enhances solution quality compared to MP<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-194-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1347"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.466em, 1000.93em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1348"><span class="msubsup"
                                                id="MathJax-Span-1349"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.822em, 1000em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1350"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1351"><span class="mrow"
                                                                id="MathJax-Span-1352"><span class="mtext"
                                                                    id="MathJax-Span-1353"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">LS</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.767em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-194">_{\text{LS}}</script>, meanwhile reducing
                    runtime by 3 to 20 times.
                </p>
            </div>
        </dd>
        <dt><a name="item436">[436]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03177"
                    title="Abstract">arXiv:2405.03177</a> [<a href="/pdf/2405.03177" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03177" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Transformer-based RGB-T Tracking with Channel and Spatial
                    Feature Fusion
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yunfeng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bo Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Ye Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhiwen Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Liang Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible
                    publication. Copyright may be transferred without notice, after which this version may no longer be
                    accessible
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Complementary RGB and TIR modalities enable RGB-T tracking to achieve
                    competitive performance in challenging scenarios. Therefore, how to better fuse
                    cross-modal features is the core issue of RGB-T tracking. Some previous methods
                    either insufficiently fuse RGB and TIR features, or depend on intermediaries
                    containing information from both modalities to achieve cross-modal information
                    interaction. The former does not fully exploit the potential of using only RGB
                    and TIR information of the template or search region for channel and spatial
                    feature fusion, and the latter lacks direct interaction between the template
                    and search area, which limits the model's ability to fully exploit the original
                    semantic information of both modalities. To alleviate these limitations, we
                    explore how to improve the performance of a visual Transformer by using direct
                    fusion of cross-modal channels and spatial features, and propose CSTNet. CSTNet
                    uses ViT as a backbone and inserts cross-modal channel feature fusion modules
                    (CFM) and cross-modal spatial feature fusion modules (SFM) for direct
                    interaction between RGB and TIR features. The CFM performs parallel joint
                    channel enhancement and joint multilevel spatial feature modeling of RGB and
                    TIR features and sums the features, and then globally integrates the sum
                    feature with the original features. The SFM uses cross-attention to model the
                    spatial relationship of cross-modal features and then introduces a
                    convolutional feedforward network for joint spatial and channel integration of
                    multimodal features. Comprehensive experiments show that CSTNet achieves
                    state-of-the-art performance on three public RGB-T tracking benchmarks. Code is
                    available at https://github.com/LiYunfengLYF/CSTNet.
                </p>
            </div>
        </dd>
        <dt><a name="item437">[437]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03178"
                    title="Abstract">arXiv:2405.03178</a> [<a href="/pdf/2405.03178" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03178" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> POPDG: Popular 3D Dance Generation with PopDanceSet
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Z">Zhenye Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+M">Min Ren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xuecai Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yongzhen Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+L">Li Yao</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio
                    and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">Generating dances that are both lifelike and well-aligned with music
                    continues to be a challenging task in the cross-modal domain. This paper
                    introduces PopDanceSet, the first dataset tailored to the preferences of young
                    audiences, enabling the generation of aesthetically oriented dances. And it
                    surpasses the AIST++ dataset in music genre diversity and the intricacy and
                    depth of dance movements. Moreover, the proposed POPDG model within the iDDPM
                    framework enhances dance diversity and, through the Space Augmentation
                    Algorithm, strengthens spatial physical connections between human body joints,
                    ensuring that increased diversity does not compromise generation quality. A
                    streamlined Alignment Module is also designed to improve the temporal alignment
                    between dance and music. Extensive experiments show that POPDG achieves SOTA
                    results on two datasets. Furthermore, the paper also expands on current
                    evaluation metrics. The dataset and code are available at
                    https://github.com/Luke-Luo1/POPDG.
                </p>
            </div>
        </dd>
        <dt><a name="item438">[438]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03181"
                    title="Abstract">arXiv:2405.03181</a> [<a href="/pdf/2405.03181" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03181" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Collaborative Satellite Computing through Adaptive DNN Task
                    Splitting and Offloading
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+S">Shifeng Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hou%2C+X">Xuefeng Hou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Z">Zhishu Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+Q">Qiushi Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+J">Jiong Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tagami%2C+A">Atsushi Tagami</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+J">Jingling Yuan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by 29th IEEE Symposium on Computers and
                    Communications (ISCC)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>

                </div>
                <p class="mathjax">Satellite computing has emerged as a promising technology for next-generation
                    wireless networks. This innovative technology provides data processing
                    capabilities, which facilitates the widespread implementation of artificial
                    intelligence (AI)-based applications, especially for image processing tasks
                    involving deep neural network (DNN). With the limited computing resources of an
                    individual satellite, independently handling DNN tasks generated by diverse
                    user equipments (UEs) becomes a significant challenge. One viable solution is
                    dividing a DNN task into multiple subtasks and subsequently distributing them
                    across multiple satellites for collaborative computing. However, it is
                    challenging to partition DNN appropriately and allocate subtasks into suitable
                    satellites while ensuring load balancing. To this end, we propose a
                    collaborative satellite computing system designed to improve task processing
                    efficiency in satellite networks. Based on this system, a workload-balanced
                    adaptive task splitting scheme is developed to equitably distribute the
                    workload of DNN slices for collaborative inference, consequently enhancing the
                    utilization of satellite computing resources. Additionally, a self-adaptive
                    task offloading scheme based on a genetic algorithm (GA) is introduced to
                    determine optimal offloading decisions within dynamic network environments. The
                    numerical results illustrate that our proposal can outperform comparable
                    methods in terms of task completion rate, delay, and resource utilization.
                </p>
            </div>
        </dd>
        <dt><a name="item439">[439]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03183"
                    title="Abstract">arXiv:2405.03183</a> [<a href="/pdf/2405.03183" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03183" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Impact of EIP-4844 on Ethereum: Consensus Security, Ethereum
                    Usage, Rollup Transaction Dynamics, and Blob Gas Fee Markets
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+S">Seongwan Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mun%2C+B">Bosul Mun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+S">Seungyun Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jeong%2C+W">Woojin Jeong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Jaewook Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eom%2C+H">Hyeonsang Eom</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jang%2C+H">Huisu Jang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR); Numerical Analysis
                    (math.NA)

                </div>
                <p class="mathjax">On March 13, 2024, Ethereum implemented EIP-4844, designed to enhance its
                    role as a data availability layer. While this upgrade reduces data posting
                    costs for rollups, it also raises concerns about its impact on the consensus
                    layer due to increased propagation sizes. Moreover, the broader effects on the
                    overall Ethereum ecosystem remain largely unexplored. In this paper, we conduct
                    an empirical analysis of the impact of EIP-4844 on consensus security, Ethereum
                    usage, rollup transaction dynamics, and the blob gas fee mechanism. We explore
                    changes in synchronization times, provide quantitative assessments of rollup
                    and user behaviors, and deepen the understanding of the blob gas fee mechanism,
                    highlighting both enhancements and areas of concern post-upgrade.
                </p>
            </div>
        </dd>
        <dt><a name="item440">[440]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03185"
                    title="Abstract">arXiv:2405.03185</a> [<a href="/pdf/2405.03185" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03185" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spatiotemporal Implicit Neural Representation as a
                    Generalized Traffic Data Learner
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nie%2C+T">Tong Nie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qin%2C+G">Guoyang Qin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+W">Wei Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jian Sun</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Spatiotemporal Traffic Data (STTD) measures the complex dynamical behaviors
                    of the multiscale transportation system. Existing methods aim to reconstruct
                    STTD using low-dimensional models. However, they are limited to data-specific
                    dimensions or source-dependent patterns, restricting them from unifying
                    representations. Here, we present a novel paradigm to address the STTD learning
                    problem by parameterizing STTD as an implicit neural representation. To discern
                    the underlying dynamics in low-dimensional regimes, coordinate-based neural
                    networks that can encode high-frequency structures are employed to directly map
                    coordinates to traffic variables. To unravel the entangled spatial-temporal
                    interactions, the variability is decomposed into separate processes. We further
                    enable modeling in irregular spaces such as sensor graphs using spectral
                    embedding. Through continuous representations, our approach enables the
                    modeling of a variety of STTD with a unified input, thereby serving as a
                    generalized learner of the underlying traffic dynamics. It is also shown that
                    it can learn implicit low-rank priors and smoothness regularization from the
                    data, making it versatile for learning different dominating data patterns. We
                    validate its effectiveness through extensive experiments in real-world
                    scenarios, showcasing applications from corridor to network scales. Empirical
                    results not only indicate that our model has significant superiority over
                    conventional low-rank models, but also highlight that the versatility of the
                    approach extends to different data domains, output resolutions, and network
                    topologies. Comprehensive model analyses provide further insight into the
                    inductive bias of STTD. We anticipate that this pioneering modeling perspective
                    could lay the foundation for universal representation of STTD in various
                    real-world tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item441">[441]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03188"
                    title="Abstract">arXiv:2405.03188</a> [<a href="/pdf/2405.03188" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03188" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Hyperbolic Geometric Latent Diffusion Model for Graph
                    Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+X">Xingcheng Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yisen Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Y">Yuecen Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qingyun Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+H">Hao Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jianxin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xianxian Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by the 41st International Conference on Machine
                    Learning (ICML 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Diffusion models have made significant contributions to computer vision,
                    sparking a growing interest in the community recently regarding the application
                    of them to graph generation. Existing discrete graph diffusion models exhibit
                    heightened computational complexity and diminished training efficiency. A
                    preferable and natural way is to directly diffuse the graph within the latent
                    space. However, due to the non-Euclidean structure of graphs is not isotropic
                    in the latent space, the existing latent diffusion models effectively make it
                    difficult to capture and preserve the topological information of graphs. To
                    address the above challenges, we propose a novel geometrically latent diffusion
                    framework HypDiff. Specifically, we first establish a geometrically latent
                    space with interpretability measures based on hyperbolic geometry, to define
                    anisotropic latent diffusion processes for graphs. Then, we propose a
                    geometrically latent diffusion process that is constrained by both radial and
                    angular geometric properties, thereby ensuring the preservation of the original
                    topological properties in the generative graphs. Extensive experimental results
                    demonstrate the superior effectiveness of HypDiff for graph generation with
                    various topologies.
                </p>
            </div>
        </dd>
        <dt><a name="item442">[442]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03190"
                    title="Abstract">arXiv:2405.03190</a> [<a href="/pdf/2405.03190" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03190" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adapting Dual-encoder Vision-language Models for Paraphrased
                    Retrieval
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jiacheng Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shin%2C+H+V">Hijung Valentina Shin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vasconcelos%2C+N">Nuno Vasconcelos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Russell%2C+B">Bryan Russell</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Heilbron%2C+F+C">Fabian Caba Heilbron</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">In the recent years, the dual-encoder vision-language models (\eg CLIP) have
                    achieved remarkable text-to-image retrieval performance. However, we discover
                    that these models usually results in very different retrievals for a pair of
                    paraphrased queries. Such behavior might render the retrieval system less
                    predictable and lead to user frustration. In this work, we consider the task of
                    paraphrased text-to-image retrieval where a model aims to return similar
                    results given a pair of paraphrased queries. To start with, we collect a
                    dataset of paraphrased image descriptions to facilitate quantitative evaluation
                    for this task. We then hypothesize that the undesired behavior of existing
                    dual-encoder model is due to their text towers which are trained on
                    image-sentence pairs and lack the ability to capture the semantic similarity
                    between paraphrased queries. To improve on this, we investigate multiple
                    strategies for training a dual-encoder model starting from a language model
                    pretrained on a large text corpus. Compared to public dual-encoder models such
                    as CLIP and OpenCLIP, the model trained with our best adaptation strategy
                    achieves a significantly higher ranking similarity for paraphrased queries
                    while maintaining similar zero-shot classification and retrieval accuracy.
                </p>
            </div>
        </dd>
        <dt><a name="item443">[443]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03191"
                    title="Abstract">arXiv:2405.03191</a> [<a href="/pdf/2405.03191" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03191" title="Download PostScript">ps</a>, <a href="/format/2405.03191"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploiting Matrix Information Geometry for Integrated
                    Decoding of Massive Uncoupled Unsourced Random Access
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+F">Feiyan Tian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaoming Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+C">Chongwen Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoyang Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">In this paper, we explore an efficient uncoupled unsourced random access
                    (UURA) scheme for 6G massive communication. UURA is a typical framework of
                    unsourced random access that addresses the problems of codeword detection and
                    message stitching, without the use of check bits. Firstly, we establish a
                    framework for UURA, allowing for immediate decoding of sub-messages upon
                    arrival. Thus, the processing delay is effectively reduced due to the
                    decreasing waiting time. Next, we propose an integrated decoding algorithm for
                    sub-messages by leveraging matrix information geometry (MIG) theory.
                    Specifically, MIG is applied to measure the feature similarities of codewords
                    belonging to the same user equipment, and thus sub-message can be stitched once
                    it is received. This enables the timely recovery of a portion of the original
                    message by simultaneously detecting and stitching codewords within the current
                    sub-slot. Furthermore, we analyze the performance of the proposed integrated
                    decoding-based UURA scheme in terms of computational complexity and convergence
                    rate. Finally, we present extensive simulation results to validate the
                    effectiveness of the proposed scheme in 6G wireless networks.
                </p>
            </div>
        </dd>
        <dt><a name="item444">[444]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03192"
                    title="Abstract">arXiv:2405.03192</a> [<a href="/pdf/2405.03192" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03192" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> QuadraNet V2: Efficient and Sustainable Training of
                    High-Order Neural Networks with Quadratic Adaptation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Chenhui Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinyao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+F">Fuxun Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+J">JInjun Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiang Chen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Machine learning is evolving towards high-order models that necessitate
                    pre-training on extensive datasets, a process associated with significant
                    overheads. Traditional models, despite having pre-trained weights, are becoming
                    obsolete due to architectural differences that obstruct the effective transfer
                    and initialization of these weights. To address these challenges, we introduce
                    a novel framework, QuadraNet V2, which leverages quadratic neural networks to
                    create efficient and sustainable high-order learning models. Our method
                    initializes the primary term of the quadratic neuron using a standard neural
                    network, while the quadratic term is employed to adaptively enhance the
                    learning of data non-linearity or shifts. This integration of pre-trained
                    primary terms with quadratic terms, which possess advanced modeling
                    capabilities, significantly augments the information characterization capacity
                    of the high-order network. By utilizing existing pre-trained weights, QuadraNet
                    V2 reduces the required GPU hours for training by 90\% to 98.4\% compared to
                    training from scratch, demonstrating both efficiency and effectiveness.
                </p>
            </div>
        </dd>
        <dt><a name="item445">[445]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03193"
                    title="Abstract">arXiv:2405.03193</a> [<a href="/pdf/2405.03193" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03193" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring Frequencies via Feature Mixing and Meta-Learning
                    for Improving Adversarial Transferability
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Weng%2C+J">Juanjuan Weng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Z">Zhiming Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shaozi Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Recent studies have shown that Deep Neural Networks (DNNs) are susceptible to
                    adversarial attacks, with frequency-domain analysis underscoring the
                    significance of high-frequency components in influencing model predictions.
                    Conversely, targeting low-frequency components has been effective in enhancing
                    attack transferability on black-box models. In this study, we introduce a
                    frequency decomposition-based feature mixing method to exploit these frequency
                    characteristics in both clean and adversarial samples. Our findings suggest
                    that incorporating features of clean samples into adversarial features
                    extracted from adversarial examples is more effective in attacking
                    normally-trained models, while combining clean features with the adversarial
                    features extracted from low-frequency parts decomposed from the adversarial
                    samples yields better results in attacking defense models. However, a conflict
                    issue arises when these two mixing approaches are employed simultaneously. To
                    tackle the issue, we propose a cross-frequency meta-optimization approach
                    comprising the meta-train step, meta-test step, and final update. In the
                    meta-train step, we leverage the low-frequency components of adversarial
                    samples to boost the transferability of attacks against defense models.
                    Meanwhile, in the meta-test step, we utilize adversarial samples to stabilize
                    gradients, thereby enhancing the attack's transferability against normally
                    trained models. For the final update, we update the adversarial sample based on
                    the gradients obtained from both meta-train and meta-test steps. Our proposed
                    method is evaluated through extensive experiments on the ImageNet-Compatible
                    dataset, affirming its effectiveness in improving the transferability of
                    attacks on both normally-trained CNNs and defense models.
                    <br>The source code is available at https://github.com/WJJLL/MetaSSA.
                </p>
            </div>
        </dd>
        <dt><a name="item446">[446]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03194"
                    title="Abstract">arXiv:2405.03194</a> [<a href="/pdf/2405.03194" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03194" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CityLLaVA: Efficient Fine-Tuning for VLMs in City Scenario
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Duan%2C+Z">Zhizhao Duan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+H">Hao Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+D">Duo Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xi Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiangxie Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+X">Xi Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhen Xie</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by AICITY2024 Workshop Track2 at CVPR2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">In the vast and dynamic landscape of urban settings, Traffic Safety
                    Description and Analysis plays a pivotal role in applications ranging from
                    insurance inspection to accident prevention. This paper introduces CityLLaVA, a
                    novel fine-tuning framework for Visual Language Models (VLMs) designed for
                    urban scenarios. CityLLaVA enhances model comprehension and prediction accuracy
                    through (1) employing bounding boxes for optimal visual data preprocessing,
                    including video best-view selection and visual prompt engineering during both
                    training and testing phases; (2) constructing concise Question-Answer sequences
                    and designing textual prompts to refine instruction comprehension; (3)
                    implementing block expansion to fine-tune large VLMs efficiently; and (4)
                    advancing prediction accuracy via a unique sequential questioning-based
                    prediction augmentation. Demonstrating top-tier performance, our method
                    achieved a benchmark score of 33.4308, securing the leading position on the
                    leaderboard. The code can be found:
                    https://github.com/alibaba/AICITY2024_Track2_AliOpenTrek_CityLLaVA
                </p>
            </div>
        </dd>
        <dt><a name="item447">[447]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03196"
                    title="Abstract">arXiv:2405.03196</a> [<a href="/pdf/2405.03196" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03196" title="Download PostScript">ps</a>, <a href="/format/2405.03196"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Design and Analysis of Massive Uncoupled Unsourced Random
                    Access with Bayesian Joint Decoding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+F">Feiyan Tian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaoming Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guan%2C+Y+L">Yong Liang Guan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuen%2C+C">Chau Yuen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">In this paper, we investigate unsourced random access for massive
                    machine-type communications (mMTC) in the sixth-generation (6G) wireless
                    networks. Firstly, we establish a high-efficiency uncoupled framework for
                    massive unsourced random access without extra parity check bits. Then, we
                    design a low-complexity Bayesian joint decoding algorithm, including codeword
                    detection and stitching. In particular, we present a Bayesian codeword
                    detection approach by exploiting Bayes-optimal divergence-free orthogonal
                    approximate message passing in the case of unknown priors. The output long-term
                    channel statistic information is well leveraged to stitch codewords for
                    recovering the original message. Thus, the spectral efficiency is improved by
                    avoiding the use of parity bits. Moreover, we analyze the performance of the
                    proposed Bayesian joint decoding-based massive uncoupled unsourced random
                    access scheme in terms of computational complexity and error probability of
                    decoding. Furthermore, by asymptotic analysis, we obtain some useful insights
                    for the design of massive unsourced random access. Finally, extensive
                    simulation results confirm the effectiveness of the proposed scheme in 6G
                    wireless networks.
                </p>
            </div>
        </dd>
        <dt><a name="item448">[448]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03197"
                    title="Abstract">arXiv:2405.03197</a> [<a href="/pdf/2405.03197" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03197" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> StyleSeg V2: Towards Robust One-shot Segmentation of Brain
                    Tissue via Optimization-free Registration Error Perception
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhiwei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+X">Xiaoyu Zeng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Chongwei Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=lv%2C+J">Jinxin lv</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+W">Wei Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qiang Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 8 figures, 2 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">One-shot segmentation of brain tissue requires training
                    registration-segmentation (reg-seg) dual-model iteratively, where reg-model
                    aims to provide pseudo masks of unlabeled images for seg-model by warping a
                    carefully-labeled atlas. However, the imperfect reg-model induces image-mask
                    misalignment, poisoning the seg-model subsequently. Recent StyleSeg bypasses
                    this bottleneck by replacing the unlabeled images with their warped copies of
                    atlas, but needs to borrow the diverse image patterns via style transformation.
                    Here, we present StyleSeg V2, inherited from StyleSeg but granted the ability
                    of perceiving the registration errors. The motivation is that good registration
                    behaves in a mirrored fashion for mirrored images. Therefore, almost at no
                    cost, StyleSeg V2 can have reg-model itself "speak out" incorrectly-aligned
                    regions by simply mirroring (symmetrically flipping the brain) its input, and
                    the registration errors are symmetric inconsistencies between the outputs of
                    original and mirrored inputs. Consequently, StyleSeg V2 allows the seg-model to
                    make use of correctly-aligned regions of unlabeled images and also enhances the
                    fidelity of style-transformed warped atlas image by weighting the local
                    transformation strength according to registration errors. The experimental
                    results on three public datasets demonstrate that our proposed StyleSeg V2
                    outperforms other state-of-the-arts by considerable margins, and exceeds
                    StyleSeg by increasing the average Dice by at least 2.4%.
                </p>
            </div>
        </dd>
        <dt><a name="item449">[449]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03199"
                    title="Abstract">arXiv:2405.03199</a> [<a href="/pdf/2405.03199" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03199" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Boosting MLPs with a Coarsening Strategy for Long-Term Time
                    Series Forecasting
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bian%2C+N">Nannan Bian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+M">Minhong Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Li Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+W">Weiran Cai</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Deep learning methods have been exerting their strengths in long-term time
                    series forecasting. However, they often struggle to strike a balance between
                    expressive power and computational efficiency. Here, we propose the Coarsened
                    Perceptron Network (CP-Net), a novel architecture that efficiently enhances the
                    predictive capability of MLPs while maintains a linear computational
                    complexity. It utilizes a coarsening strategy as the backbone that leverages
                    two-stage convolution-based sampling blocks. Based purely on convolution, they
                    provide the functionality of extracting short-term semantic and contextual
                    patterns, which is relatively deficient in the global point-wise projection of
                    the MLP layer. With the architectural simplicity and low runtime, our
                    experiments on seven time series forecasting benchmarks demonstrate that CP-Net
                    achieves an improvement of 4.1% compared to the SOTA method. The model further
                    shows effective utilization of the exposed information with a consistent
                    improvement as the look-back window expands.
                </p>
            </div>
        </dd>
        <dt><a name="item450">[450]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03201"
                    title="Abstract">arXiv:2405.03201</a> [<a href="/pdf/2405.03201" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03201" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Experimental Investigation of Repurposed Kaplan Turbines as
                    Variable-Speed Propellers for Maximizing Frequency Containment Reserve
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Gerini%2C+F">Francesco Gerini</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Vagnoni%2C+E">Elena Vagnoni</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Seydoux%2C+M">Martin Seydoux</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Cherkaoui%2C+R">Rachid Cherkaoui</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Paolone%2C+M">Mario Paolone</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to PSCC 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">This study explores the practical viability of repurposing aging Kaplan
                    turbines into variable-speed propellers by employing full-size frequency
                    converters. The motivation behind this approach is to improve the provision of
                    \emph{Frequency Containment Reserve} (FCR) while reducing fatigue in the Kaplan
                    blades servomechanism. We evaluate the performance of these modified Kaplan
                    turbines against the one of another hydro asset composed of the same Kaplan
                    turbine hybridized with a \emph{Battery Energy Storage System} (BESS).
                    Experiments are conducted on a one-of-its-kind reduced-scale model testing
                    platform. Our findings reveal that Kaplan turbines repurposed as variable-speed
                    propellers exhibit similar dynamic response characteristics compared to the
                    standalone Kaplan operation, with the added benefit of effectively eliminating
                    blade movements. Furthermore, the ability to control the speed increases the
                    hydraulic efficiency for certain operating points. In summary, investment in
                    variable speed technology emerges as a viable alternative to BESS-based
                    hydropower hybridization.
                </p>
            </div>
        </dd>
        <dt><a name="item451">[451]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03202"
                    title="Abstract">arXiv:2405.03202</a> [<a href="/pdf/2405.03202" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03202" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Hierarchical Space-Time Attention for Micro-Expression
                    Recognition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hao%2C+H">Haihong Hao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuo Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ben%2C+H">Huixia Ben</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hao%2C+Y">Yanbin Hao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yansong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Weiwei Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Micro-expression recognition (MER) aims to recognize the short and subtle
                    facial movements from the Micro-expression (ME) video clips, which reveal real
                    emotions. Recent MER methods mostly only utilize special frames from ME video
                    clips or extract optical flow from these special frames. However, they neglect
                    the relationship between movements and space-time, while facial cues are hidden
                    within these relationships. To solve this issue, we propose the Hierarchical
                    Space-Time Attention (HSTA). Specifically, we first process ME video frames and
                    special frames or data parallelly by our cascaded Unimodal Space-Time Attention
                    (USTA) to establish connections between subtle facial movements and specific
                    facial areas. Then, we design Crossmodal Space-Time Attention (CSTA) to achieve
                    a higher-quality fusion for crossmodal data. Finally, we hierarchically
                    integrate USTA and CSTA to grasp the deeper facial cues. Our model emphasizes
                    temporal modeling without neglecting the processing of special data, and it
                    fuses the contents in different modalities while maintaining their respective
                    uniqueness. Extensive experiments on the four benchmarks show the effectiveness
                    of our proposed HSTA. Specifically, compared with the latest method on the
                    CASME3 dataset, it achieves about 3% score improvement in seven-category
                    classification.
                </p>
            </div>
        </dd>
        <dt><a name="item452">[452]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03205"
                    title="Abstract">arXiv:2405.03205</a> [<a href="/pdf/2405.03205" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03205" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Anchored Answers: Unravelling Positional Bias in GPT-2's
                    Multiple-Choice Questions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Ruizhe Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yanjun Gao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Work in process
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Large Language Models (LLMs), such as the GPT-4 and LLaMA families, have
                    demonstrated considerable success across diverse tasks, including
                    multiple-choice questions (MCQs). However, these models exhibit a positional
                    bias, particularly an even worse anchored bias in the GPT-2 family, where they
                    consistently favour the first choice 'A' in MCQs during inference. This
                    anchored bias challenges the integrity of GPT-2's decision-making process, as
                    it skews performance based on the position rather than the content of the
                    choices in MCQs. In this study, we utilise the mechanistic interpretability
                    approach to identify the internal modules within GPT-2 models responsible for
                    this bias. We focus on the Multi-Layer Perceptron (MLP) layers and attention
                    heads, using the "logit lens" method to trace and modify the specific value
                    vectors that contribute to the bias. By updating these vectors within MLP and
                    recalibrating attention patterns to neutralise the preference for the first
                    choice 'A', we effectively mitigate the anchored bias. Our interventions not
                    only correct the bias but also improve the overall MCQ prediction accuracy for
                    the GPT-2 family across various datasets. This work represents the first
                    comprehensive mechanistic analysis of anchored bias in MCQs within the GPT-2
                    models, introducing targeted, minimal-intervention strategies that
                    significantly enhance GPT2 model robustness and accuracy in MCQs. Our code is
                    available at https://github.com/ruizheliUOA/Anchored_Bias_GPT2.
                </p>
            </div>
        </dd>
        <dt><a name="item453">[453]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03206"
                    title="Abstract">arXiv:2405.03206</a> [<a href="/pdf/2405.03206" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03206" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Vietnamese AI Generated Text Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tran%2C+Q">Quang-Dan Tran</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+V">Van-Quan Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pham%2C+Q">Quang-Huy Pham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+K+B+T">K. B. Thang Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Do%2C+T">Trong-Hop Do</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">In recent years, Large Language Models (LLMs) have become integrated into our
                    daily lives, serving as invaluable assistants in completing tasks. Widely
                    embraced by users, the abuse of LLMs is inevitable, particularly in using them
                    to generate text content for various purposes, leading to difficulties in
                    distinguishing between text generated by LLMs and that written by humans. In
                    this study, we present a dataset named ViDetect, comprising 6.800 samples of
                    Vietnamese essay, with 3.400 samples authored by humans and the remainder
                    generated by LLMs, serving the purpose of detecting text generated by AI. We
                    conducted evaluations using state-of-the-art methods, including ViT5, BartPho,
                    PhoBERT, mDeberta V3, and mBERT. These results contribute not only to the
                    growing body of research on detecting text generated by AI but also demonstrate
                    the adaptability and effectiveness of different methods in the Vietnamese
                    language context. This research lays the foundation for future advancements in
                    AI-generated text detection and provides valuable insights for researchers in
                    the field of natural language processing.
                </p>
            </div>
        </dd>
        <dt><a name="item454">[454]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03207"
                    title="Abstract">arXiv:2405.03207</a> [<a href="/pdf/2405.03207" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03207" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Philosophical Introduction to Language Models - Part II:
                    The Way Forward
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Milli%C3%A8re%2C+R">Raphaël Millière</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Buckner%2C+C">Cameron Buckner</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">In this paper, the second of two companion pieces, we explore novel
                    philosophical questions raised by recent progress in large language models
                    (LLMs) that go beyond the classical debates covered in the first part. We focus
                    particularly on issues related to interpretability, examining evidence from
                    causal intervention methods about the nature of LLMs' internal representations
                    and computations. We also discuss the implications of multimodal and modular
                    extensions of LLMs, recent debates about whether such systems may meet minimal
                    criteria for consciousness, and concerns about secrecy and reproducibility in
                    LLM research. Finally, we discuss whether LLM-like systems may be relevant to
                    modeling aspects of human cognition, if their architectural characteristics and
                    learning scenario are adequately constrained.
                </p>
            </div>
        </dd>
        <dt><a name="item455">[455]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03215"
                    title="Abstract">arXiv:2405.03215</a> [<a href="/pdf/2405.03215" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03215" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> OMP-Engineer: Bridging Syntax Analysis and In-Context
                    Learning for Efficient Automated OpenMP Parallelization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Weidong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+H">Haoran Zhu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>

                </div>
                <p class="mathjax">In advancing parallel programming, particularly with OpenMP, the shift
                    towards NLP-based methods marks a significant innovation beyond traditional S2S
                    tools like Autopar and Cetus. These NLP approaches train on extensive datasets
                    of examples to efficiently generate optimized parallel code, streamlining the
                    development process. This method's strength lies in its ability to swiftly
                    produce parallelized code that runs efficiently. However, this reliance on NLP
                    models, without direct code analysis, can introduce inaccuracies, as these
                    models might not fully grasp the nuanced semantics of the code they
                    parallelize. We build OMP-Engineer, which balances the efficiency and
                    scalability of NLP models with the accuracy and reliability of traditional
                    methods, aiming to enhance the performance of automating parallelization while
                    navigating its inherent challenges.
                </p>
            </div>
        </dd>
        <dt><a name="item456">[456]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03217"
                    title="Abstract">arXiv:2405.03217</a> [<a href="/pdf/2405.03217" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03217" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PCG: Mitigating Conflict-based Cache Side-channel Attacks
                    with Prefetching
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+F">Fang Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tong%2C+F">Fei Tong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hongyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xiaoyu Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zhe Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ling%2C+M">Ming Ling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yuxing Mao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 9 figures, submitting to a journal
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Hardware Architecture (cs.AR)

                </div>
                <p class="mathjax">To defend against conflict-based cache side-channel attacks, cache
                    partitioning or remapping techniques were proposed to prevent set conflicts
                    between different security domains or obfuscate the locations of such
                    conflicts. But such techniques complicate cache design and may result in
                    significant performance penalties. Therefore, there have been lightweight
                    prefetching-based schemes proposed to introduce noise to confuse attackers'
                    observation. However, we have validated experimentally that relying on
                    prefetching to only introduce noise is insufficient, as attackers can still
                    reliably distinguish the victim's cache accesses. This paper proposes a novel
                    prefetching-based scheme, called PCG. It combines adding victim-irrelevant
                    cache occupancy changes and reducing victim-relevant cache occupancy changes to
                    disrupt attackers by generating noisy and indistinguishable cache access
                    patterns. Additionally, PCG can either work independently or seamlessly be
                    integrated with most of the commonly used prefetchers. We have implemented and
                    evaluated PCG in both gem5 and the open-source RISC-V core BOOMv3. The
                    evaluation results show the PCG's robust security superior to the existing
                    solutions, while without resulting in significant performance degradation.
                    According to the evaluation based on the SPEC CPU 2017 benchmark suite, PCG
                    even shows an average performance improvement of about 1.64%. Moreover, it
                    incurs only 1.26% overhead on hardware resource consumption.
                </p>
            </div>
        </dd>
        <dt><a name="item457">[457]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03218"
                    title="Abstract">arXiv:2405.03218</a> [<a href="/pdf/2405.03218" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03218" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Elevator, Escalator or Neither? Classifying Pedestrian
                    Conveyor State Using Inertial Navigation System
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+T">Tianlang He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+Z">Zhiqiu Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+S+-+G">S.-H. Gary Chan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Classifying a pedestrian in one of the three conveyor states of "elevator,"
                    "escalator" and "neither" is fundamental to many applications such as indoor
                    localization and people flow analysis. We estimate, for the first time, the
                    pedestrian conveyor state given the inertial navigation system (INS) readings
                    of accelerometer, gyroscope and magnetometer sampled from the phone. Our
                    problem is challenging because the INS signals of the conveyor state are
                    coupled and perturbed by unpredictable arbitrary human actions, confusing the
                    decision process. We propose ELESON, a novel, effective and lightweight
                    INS-based deep learning approach to classify whether a pedestrian is in an
                    elevator, escalator or neither. ELESON utilizes a motion feature extractor to
                    decouple the conveyor state from human action in the feature space, and a
                    magnetic feature extractor to account for the speed difference between elevator
                    and escalator. Given the results of the extractors, it employs an evidential
                    state classifier to estimate the confidence of the pedestrian states. Based on
                    extensive experiments conducted on twenty hours of real pedestrian data, we
                    demonstrate that ELESON outperforms significantly the state-of-the-art
                    approaches (where combined INS signals of both the conveyor state and human
                    actions are processed together), with 15% classification improvement in F1
                    score, stronger confidence discriminability with 10% increase in AUROC (Area
                    Under the Receiver Operating Characteristics), and low computational and memory
                    requirements on smartphones.
                </p>
            </div>
        </dd>
        <dt><a name="item458">[458]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03221"
                    title="Abstract">arXiv:2405.03221</a> [<a href="/pdf/2405.03221" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03221" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spatial and Surface Correspondence Field for Interaction
                    Transfer
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zeyu Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Honghao Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Haibin Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+C">Chongyang Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Hui Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+R">Ruizhen Hu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to SIGGRAPH 2024, project page at <a
                        href="https://vcc.tech/research/2024/InterTransfer">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In this paper, we introduce a new method for the task of interaction
                    transfer. Given an example interaction between a source object and an agent,
                    our method can automatically infer both surface and spatial relationships for
                    the agent and target objects within the same category, yielding more accurate
                    and valid transfers. Specifically, our method characterizes the example
                    interaction using a combined spatial and surface representation. We correspond
                    the agent points and object points related to the representation to the target
                    object space using a learned spatial and surface correspondence field, which
                    represents objects as deformed and rotated signed distance fields. With the
                    corresponded points, an optimization is performed under the constraints of our
                    spatial and surface interaction representation and additional regularization.
                    Experiments conducted on human-chair and hand-mug interaction transfer tasks
                    show that our approach can handle larger geometry and topology variations
                    between source and target shapes, significantly outperforming state-of-the-art
                    methods.
                </p>
            </div>
        </dd>
        <dt><a name="item459">[459]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03223"
                    title="Abstract">arXiv:2405.03223</a> [<a href="/pdf/2405.03223" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03223" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Kansei Engineering Approach in Web Design:Case of
                    Transportation Website
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Akram%2C+A">Alisher Akram</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kozhamuratova%2C+A">Aray Kozhamuratova</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shamoi%2C+P">Pakizar Shamoi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> submitted to Springer journal for consideration
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">Kansei Engineering (KE) is a user-centered design approach that emphasizes
                    the emotional aspects of user experience. This paper explores the integration
                    of KE in the case of a transportation company that focuses on connecting cargo
                    owners with transportation providers. The methodology involves aligning the
                    design process with the company's strategy, collecting and semantic scaling
                    Kansei words, and evaluating website design through experimental and
                    statistical analyses. Initially, we collaborated with the company to understand
                    their strategic goals, using Use Case and Entity Relationship diagrams to learn
                    about the website functionality. Subsequent steps involved collecting Kansei
                    words that resonate with the company's vision. Website samples from comparable
                    transportation companies were then evaluated by X subject in the survey.
                    Participants were asked to arrange samples based on emotional feedback using a
                    5-point SD scale. We used Principal Component Analysis (PCA) to identify
                    critical factors affecting users' perceptions of the design. Based on these
                    results, we collaborated with designers to reformulate the website, ensuring
                    the design features aligned with the Kansei principles. The outcome is a
                    user-centric web design to enhance the site's user experience. This study shows
                    that KE can be effective in creating more user-friendly web interfaces in the
                    transportation industry.
                </p>
            </div>
        </dd>
        <dt><a name="item460">[460]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03224"
                    title="Abstract">arXiv:2405.03224</a> [<a href="/pdf/2405.03224" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03224" title="Download PostScript">ps</a>, <a href="/format/2405.03224"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Two-Step Method Coupling Eddy Currents and Magneto-Statics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Busetto%2C+M">Martina Busetto</a>,
                    <a href="/search/math?searchtype=author&amp;query=Winkelmann%2C+C">Christoph Winkelmann</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">We present the mathematical theory and its numerical validation of a method
                    tailored to include eddy-current effects only in a part of the domain. This
                    results in a heterogeneous problem combining an eddy-current model in a subset
                    of the computational domain with a magneto-static model in the remainder of the
                    domain. We adopt a two-domain two-step approach in which the primary variables
                    of the problem are the electric scalar potential and the magnetic vector
                    potential. We show numerical results that validate the formulation.
                </p>
            </div>
        </dd>
        <dt><a name="item461">[461]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03228"
                    title="Abstract">arXiv:2405.03228</a> [<a href="/pdf/2405.03228" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03228" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TED: Accelerate Model Training by Internal Generalization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+J">Jinying Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+P">Ping Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nie%2C+J">Jie Nie</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Large language models have demonstrated strong performance in recent years,
                    but the high cost of training drives the need for efficient methods to compress
                    dataset sizes. We propose TED pruning, a method that addresses the challenge of
                    overfitting under high pruning ratios by quantifying the model's ability to
                    improve performance on pruned data while fitting retained data, known as
                    Internal Generalization (IG). TED uses an optimization objective based on
                    Internal Generalization Distance (IGD), measuring changes in IG before and
                    after pruning to align with true generalization performance and achieve
                    implicit regularization. The IGD optimization objective was verified to allow
                    the model to achieve the smallest upper bound on generalization error. The
                    impact of small mask fluctuations on IG is studied through masks and Taylor
                    approximation, and fast estimation of IGD is enabled. In analyzing continuous
                    training dynamics, the prior effect of IGD is validated, and a progressive
                    pruning strategy is proposed. Experiments on image classification, natural
                    language understanding, and large language model fine-tuning show TED achieves
                    lossless performance with 60-70\% of the data. Upon acceptance, our code will
                    be made publicly available.
                </p>
            </div>
        </dd>
        <dt><a name="item462">[462]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03232"
                    title="Abstract">arXiv:2405.03232</a> [<a href="/pdf/2405.03232" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03232" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Successive Interference Cancellation for Optical Fiber Using
                    Discrete Constellations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=J%C3%A4ger%2C+A">Alex Jäger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kramer%2C+G">Gerhard Kramer</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to European Conference on Optical Communications
                    (ECOC) 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">Successive interference cancellation is used to detect discrete modulation
                    symbols transmitted over a 1000 km fiber-optic link. A transmitter and receiver
                    are presented that have linear complexity in the number of transmitted symbols
                    and achieve the information rates of previous studies that use continuous
                    modulations.
                </p>
            </div>
        </dd>
        <dt><a name="item463">[463]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03234"
                    title="Abstract">arXiv:2405.03234</a> [<a href="/pdf/2405.03234" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03234" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Reliable Framework for Human-in-the-Loop Anomaly Detection
                    in Time Series
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Z">Ziquan Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xuan%2C+X">Xiwei Xuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+K">Kwan-Liu Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kong%2C+Z">Zhaodan Kong</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> The manuscript is currently under review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Time series anomaly detection is a critical machine learning task for
                    numerous applications, such as finance, healthcare, and industrial systems.
                    However, even high-performed models may exhibit potential issues such as
                    biases, leading to unreliable outcomes and misplaced confidence. While model
                    explanation techniques, particularly visual explanations, offer valuable
                    insights to detect such issues by elucidating model attributions of their
                    decision, many limitations still exist -- They are primarily instance-based and
                    not scalable across dataset, and they provide one-directional information from
                    the model to the human side, lacking a mechanism for users to address detected
                    issues. To fulfill these gaps, we introduce HILAD, a novel framework designed
                    to foster a dynamic and bidirectional collaboration between humans and AI for
                    enhancing anomaly detection models in time series. Through our visual
                    interface, HILAD empowers domain experts to detect, interpret, and correct
                    unexpected model behaviors at scale. Our evaluation with two time series
                    datasets and user studies demonstrates the effectiveness of HILAD in fostering
                    a deeper human understanding, immediate corrective actions, and the reliability
                    enhancement of models.
                </p>
            </div>
        </dd>
        <dt><a name="item464">[464]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03235"
                    title="Abstract">arXiv:2405.03235</a> [<a href="/pdf/2405.03235" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03235" title="Download PostScript">ps</a>, <a href="/format/2405.03235"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Cross-Modal Domain Adaptation in Brain Disease Diagnosis:
                    Maximum Mean Discrepancy-based Convolutional Neural Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xuran Zhu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Brain disorders are a major challenge to global health, causing millions of
                    deaths each year. Accurate diagnosis of these diseases relies heavily on
                    advanced medical imaging techniques such as Magnetic Resonance Imaging (MRI)
                    and Computed Tomography (CT). However, the scarcity of annotated data poses a
                    significant challenge in deploying machine learning models for medical
                    diagnosis. To address this limitation, deep learning techniques have shown
                    considerable promise. Domain adaptation techniques enhance a model's ability to
                    generalize across imaging modalities by transferring knowledge from one domain
                    (e.g., CT images) to another (e.g., MRI images). Such cross-modality adaptation
                    is essential to improve the ability of models to consistently generalize across
                    different imaging modalities. This study collected relevant resources from the
                    Kaggle website and employed the Maximum Mean Difference (MMD) method - a
                    popular domain adaptation method - to reduce the differences between imaging
                    domains. By combining MMD with Convolutional Neural Networks (CNNs), the
                    accuracy and utility of the model is obviously enhanced. The excellent
                    experimental results highlight the great potential of data-driven domain
                    adaptation techniques to improve diagnostic accuracy and efficiency, especially
                    in resource-limited environments. By bridging the gap between different imaging
                    modalities, the study aims to provide clinicians with more reliable diagnostic
                    tools.
                </p>
            </div>
        </dd>
        <dt><a name="item465">[465]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03236"
                    title="Abstract">arXiv:2405.03236</a> [<a href="/pdf/2405.03236" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03236" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Federated Reinforcement Learning with Constraint
                    Heterogeneity
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+H">Hao Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Liangyu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhihua Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
                <p class="mathjax">We study a Federated Reinforcement Learning (FedRL) problem with constraint
                    heterogeneity. In our setting, we aim to solve a reinforcement learning problem
                    with multiple constraints while <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-195-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1354"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1355"><span class="mi" id="MathJax-Span-1356"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-195">N</script> training agents are located in <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-196-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1357"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1358"><span class="mi" id="MathJax-Span-1359"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-196">N</script>
                    different environments with limited access to the constraint signals and they
                    are expected to collaboratively learn a policy satisfying all constraint
                    signals. Such learning problems are prevalent in scenarios of Large Language
                    Model (LLM) fine-tuning and healthcare applications. To solve the problem, we
                    propose federated primal-dual policy optimization methods based on traditional
                    policy gradient methods. Specifically, we introduce <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-197-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1360"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1361"><span class="mi" id="MathJax-Span-1362"
                                                style="font-family: MathJax_Math-italic;">N<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-197">N</script> local Lagrange
                    functions for agents to perform local policy updates, and these agents are then
                    scheduled to periodically communicate on their local policies. Taking natural
                    policy gradient (NPG) and proximal policy optimization (PPO) as policy
                    optimization methods, we mainly focus on two instances of our algorithms, ie,
                    {FedNPG} and {FedPPO}. We show that FedNPG achieves global convergence with an
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-198-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1363"
                                style="width: 4.98em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.112em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1004em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1364"><span class="texatom"
                                                id="MathJax-Span-1365"><span class="mrow" id="MathJax-Span-1366"><span
                                                        class="munderover" id="MathJax-Span-1367"><span
                                                            style="display: inline-block; position: relative; width: 0.755em; height: 0px;"><span
                                                                style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                    class="mi" id="MathJax-Span-1368"
                                                                    style="font-family: MathJax_Math-italic;">O</span><span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; clip: rect(3.533em, 1000.41em, 3.938em, -999.997em); top: -4.627em; left: 0.234em;"><span
                                                                    class="mo" id="MathJax-Span-1369"
                                                                    style="font-family: MathJax_Main;">~</span><span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1370"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-1371" style="font-family: MathJax_Main;">1</span><span
                                                class="texatom" id="MathJax-Span-1372"><span class="mrow"
                                                    id="MathJax-Span-1373"><span class="mo" id="MathJax-Span-1374"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="msqrt" id="MathJax-Span-1375"><span
                                                    style="display: inline-block; position: relative; width: 1.565em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.7em, 4.17em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                            class="mrow" id="MathJax-Span-1376"><span class="mi"
                                                                id="MathJax-Span-1377"
                                                                style="font-family: MathJax_Math-italic;">T<span
                                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1000.75em, 3.938em, -999.997em); top: -4.569em; left: 0.813em;"><span
                                                            style="display: inline-block; position: relative; width: 0.755em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: 0.061em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -4.048em; left: 0em;"><span
                                                            style="font-family: MathJax_Main;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1378"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.601em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-198">\tilde{O}(1/\sqrt{T})</script> rate, and FedPPO
                    efficiently solves complicated
                    learning tasks with the use of deep neural networks.
                </p>
            </div>
        </dd>
        <dt><a name="item466">[466]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03239"
                    title="Abstract">arXiv:2405.03239</a> [<a href="/pdf/2405.03239" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03239" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Learning for Detecting and Early Predicting Chronic
                    Obstructive Pulmonary Disease from Spirogram Time Series: A UK Biobank Study
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mei%2C+S">Shuhao Mei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yuxi Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Jiahao Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wan%2C+Y">Yuxuan Wan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+S">Shan Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qinghao Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Geng%2C+S">Shijia Geng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+J">Junqing Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hong%2C+S">Shenda Hong</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Chronic Obstructive Pulmonary Disease (COPD) is a chronic inflammatory lung
                    condition that causes airflow obstruction. The existing methods can only detect
                    patients who already have COPD based on obvious features shown in the spirogram
                    (In this article, the spirogram specifically involves measuring Volume-Flow
                    curve time series). Early prediction of COPD risk is vital for monitoring COPD
                    disease progression, slowing it down, or even preventing its onset. However,
                    these methods fail to early predict an individual's probability of COPD in the
                    future based on subtle features in the spirogram. To address this gap, for the
                    first time, we propose DeepSpiro, a method based on deep learning for early
                    prediction of future COPD risk. DeepSpiro consists of four parts. First, we
                    construct Volume-Flow curves guided by Time-Volume instability smoothing
                    (SpiroSmoother) to enhance the stability of the original Volume-Flow curves
                    precisely. Second, we extract critical features from the evolution of
                    varied-length key patches (SpiroEncoder) to capture the key temporal evolution
                    from original high-dimensional dynamic sequences to a unified low-dimensional
                    temporal representation. Third, we explain the model based on temporal
                    attention and heterogeneous feature fusion (SpiroExplainer), which integrates
                    information from heterogeneous data such as spirogram and demographic
                    information. Fourth, we predict the risk of COPD based on the evolution of key
                    patch concavity (SpiroPredictor), enabling accurate prediction of the risk of
                    disease in high-risk patients who are not yet diagnosed, for up to 1, 2, 3, 4,
                    5 years, and beyond. We conduct experiments on the UK Biobank dataset. Results
                    show that DeepSpiro achieves an AUC value of 0.8328 in the task of detecting
                    COPD. In early prediction tasks, high-risk and low-risk groups show significant
                    differences in the future, with a p-value of &lt;0.001.
                </p>
            </div>
        </dd>
        <dt><a name="item467">[467]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03243"
                    title="Abstract">arXiv:2405.03243</a> [<a href="/pdf/2405.03243" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03243" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mind the Gap Between Synthetic and Real: Utilizing Transfer
                    Learning to Probe the Boundaries of Stable Diffusion Generated Data
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hennicke%2C+L">Leonhard Hennicke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Adriano%2C+C+M">Christian Medeiros Adriano</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Giese%2C+H">Holger Giese</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Koehler%2C+J+M">Jan Mathias Koehler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schott%2C+L">Lukas Schott</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Generative foundation models like Stable Diffusion comprise a diverse
                    spectrum of knowledge in computer vision with the potential for transfer
                    learning, e.g., via generating data to train student models for downstream
                    tasks. This could circumvent the necessity of collecting labeled real-world
                    data, thereby presenting a form of data-free knowledge distillation. However,
                    the resultant student models show a significant drop in accuracy compared to
                    models trained on real data. We investigate possible causes for this drop and
                    focus on the role of the different layers of the student model. By training
                    these layers using either real or synthetic data, we reveal that the drop
                    mainly stems from the model's final layers. Further, we briefly investigate
                    other factors, such as differences in data-normalization between synthetic and
                    real, the impact of data augmentations, texture vs.\ shape learning, and
                    assuming oracle prompts. While we find that some of those factors can have an
                    impact, they are not sufficient to close the gap towards real data. Building
                    upon our insights that mainly later layers are responsible for the drop, we
                    investigate the data-efficiency of fine-tuning a synthetically trained model
                    with real data applied to only those last layers. Our results suggest an
                    improved trade-off between the amount of real training data used and the
                    model's accuracy. Our findings contribute to the understanding of the gap
                    between synthetic and real data and indicate solutions to mitigate the scarcity
                    of labeled real data.
                </p>
            </div>
        </dd>
        <dt><a name="item468">[468]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03244"
                    title="Abstract">arXiv:2405.03244</a> [<a href="/pdf/2405.03244" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03244" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Examining Changes in Internal Representations of Continual
                    Learning Models Through Tensor Decomposition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Aswani%2C+N+S">Nishant Suresh Aswani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guesmi%2C+A">Amira Guesmi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hanif%2C+M+A">Muhammad Abdullah Hanif</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shafique%2C+M">Muhammad Shafique</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Continual learning (CL) has spurred the development of several methods aimed
                    at consolidating previous knowledge across sequential learning. Yet, the
                    evaluations of these methods have primarily focused on the final output, such
                    as changes in the accuracy of predicted classes, overlooking the issue of
                    representational forgetting within the model. In this paper, we propose a novel
                    representation-based evaluation framework for CL models. This approach involves
                    gathering internal representations from throughout the continual learning
                    process and formulating three-dimensional tensors. The tensors are formed by
                    stacking representations, such as layer activations, generated from several
                    inputs and model `snapshots', throughout the learning process. By conducting
                    tensor component analysis (TCA), we aim to uncover meaningful patterns about
                    how the internal representations evolve, expecting to highlight the merits or
                    shortcomings of examined CL strategies. We conduct our analyses across
                    different model architectures and importance-based continual learning
                    strategies, with a curated task selection. While the results of our approach
                    mirror the difference in performance of various CL strategies, we found that
                    our methodology did not directly highlight specialized clusters of neurons, nor
                    provide an immediate understanding the evolution of filters. We believe a
                    scaled down version of our approach will provide insight into the benefits and
                    pitfalls of using TCA to study continual learning dynamics.
                </p>
            </div>
        </dd>
        <dt><a name="item469">[469]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03245"
                    title="Abstract">arXiv:2405.03245</a> [<a href="/pdf/2405.03245" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03245" title="Download PostScript">ps</a>, <a href="/format/2405.03245"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> How improving performance may imply losing consistency in
                    event-triggered consensus
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Meister%2C+D">David Meister</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Antunes%2C+D+J">Duarte J. Antunes</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Allg%C3%B6wer%2C+F">Frank Allgöwer</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">Event-triggered control is often argued to lower the average triggering rate
                    compared to time-triggered control while still achieving a desired control
                    goal, e.g., the same performance level. However, this property, often called
                    consistency, cannot be taken for granted and can be hard to analyze in many
                    settings. In particular, although numerous decentralized event-triggered
                    control schemes have been proposed in the past years, their performance
                    properties with respect to time-triggered control remain mostly unexplored. In
                    this paper, we therefore examine the performance properties of event-triggered
                    control (relative to time-triggered control) for a single-integrator consensus
                    problem with a level-triggering rule. We consider the long-term average
                    quadratic deviation from consensus as a performance measure. For this setting,
                    we show that enriching the information the local controllers use improves the
                    performance of the consensus algorithm but renders a previously consistent
                    event-triggered control scheme inconsistent. In addition, we do so while
                    deploying optimal control inputs which we derive for both information cases and
                    all triggering schemes. With this insight, we can furthermore explain the
                    relationship between two contrasting consistency results from the literature on
                    decentralized event-triggered control. We support our theoretical findings with
                    simulation results.
                </p>
            </div>
        </dd>
        <dt><a name="item470">[470]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03248"
                    title="Abstract">arXiv:2405.03248</a> [<a href="/pdf/2405.03248" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03248" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Communication-Efficient Federated Learning with Adaptive
                    Compression under Dynamic Bandwidth
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhuansun%2C+Y">Ying Zhuansun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dandan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaohong Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+C">Caijun Sun</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Federated learning can train models without directly providing local data to
                    the server. However, the frequent updating of the local model brings the
                    problem of large communication overhead. Recently, scholars have achieved the
                    communication efficiency of federated learning mainly by model compression. But
                    they ignore two problems: 1) network state of each client changes dynamically;
                    2) network state among clients is not the same. The clients with poor bandwidth
                    update local model slowly, which leads to low efficiency. To address this
                    challenge, we propose a communication-efficient federated learning algorithm
                    with adaptive compression under dynamic bandwidth (called AdapComFL).
                    Concretely, each client performs bandwidth awareness and bandwidth prediction.
                    Then, each client adaptively compresses its local model via the improved sketch
                    mechanism based on his predicted bandwidth. Further, the server aggregates
                    sketched models with different sizes received. To verify the effectiveness of
                    the proposed method, the experiments are based on real bandwidth data which are
                    collected from the network topology we build, and benchmark datasets which are
                    obtained from open repositories. We show the performance of AdapComFL
                    algorithm, and compare it with existing algorithms. The experimental results
                    show that our AdapComFL achieves more efficient communication as well as
                    competitive accuracy compared to existing algorithms.
                </p>
            </div>
        </dd>
        <dt><a name="item471">[471]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03249"
                    title="Abstract">arXiv:2405.03249</a> [<a href="/pdf/2405.03249" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03249" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> V-line tensor tomography: numerical results
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Ambartsoumian%2C+G">Gaik Ambartsoumian</a>,
                    <a href="/search/math?searchtype=author&amp;query=Mishra%2C+R+K">Rohit Kumar Mishra</a>,
                    <a href="/search/math?searchtype=author&amp;query=Zamindar%2C+I">Indrani Zamindar</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">This article presents the numerical verification and validation of several
                    inversion algorithms for V-line transforms (VLTs) acting on symmetric 2-tensor
                    fields in the plane. The analysis of these transforms and the theoretical
                    foundation of their inversion methods were studied in a recent work [G.
                    Ambartsoumian, R. K. Mishra, and I. Zamindar, Inverse Problems, 40 (2024),
                    035003]. We demonstrate the efficient recovery of an unknown symmetric 2-tensor
                    field from various combinations of the longitudinal, transverse, and mixed
                    VLTs, their corresponding first moments, and the star VLT. The paper examines
                    the performance of the proposed algorithms in different settings and
                    illustrates the results with numerical simulations on smooth and non-smooth
                    phantoms.
                </p>
            </div>
        </dd>
        <dt><a name="item472">[472]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03250"
                    title="Abstract">arXiv:2405.03250</a> [<a href="/pdf/2405.03250" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03250" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A survey to measure cognitive biases influencing mobility
                    choices
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Adam%2C+C">Carole Adam</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>; Multiagent Systems (cs.MA)

                </div>
                <p class="mathjax">In this paper, we describe a survey about the perceptions of 4 mobility modes
                    (car, bus, bicycle, walking) and the preferences of users for 6 modal choice
                    factors. This survey has gathered 650 answers in 2023, that are published as
                    open data. In this study, we analyse these results to highlight the influence
                    of 3 cognitive biases on mobility decisions: halo bias, choice-supportive bias,
                    and reactance. These cognitive biases are proposed as plausible explanations of
                    the observed behaviour, where the population tends to stick to individual cars
                    despite urban policies aiming at favouring soft mobility. This model can serve
                    as the basis for a simulator of mobility decisions in a virtual town, and the
                    gathered data can be used to initialise this population with realistic
                    attributes. Work is ongoing to design a simulation-based serious game where the
                    player takes the role of an urban manager faced with planning choices to make
                    their city more sustainable.
                </p>
            </div>
        </dd>
        <dt><a name="item473">[473]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03251"
                    title="Abstract">arXiv:2405.03251</a> [<a href="/pdf/2405.03251" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03251" title="Download PostScript">ps</a>, <a href="/format/2405.03251"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring the Frontiers of Softmax: Provable Optimization,
                    Applications in Diffusion Model, and Beyond
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+J">Jiuxiang Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chenyang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yingyu Liang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zhenmei Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+Z">Zhao Song</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 53 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">The softmax activation function plays a crucial role in the success of large
                    language models (LLMs), particularly in the self-attention mechanism of the
                    widely adopted Transformer architecture. However, the underlying learning
                    dynamics that contribute to the effectiveness of softmax remain largely
                    unexplored. As a step towards better understanding, this paper provides a
                    theoretical study of the optimization and generalization properties of
                    two-layer softmax neural networks, providing theoretical insights into their
                    superior performance as other activation functions, such as ReLU and
                    exponential. Leveraging the Neural Tangent Kernel (NTK) framework, our analysis
                    reveals that the normalization effect of the softmax function leads to a good
                    perturbation property of the induced NTK matrix, resulting in a good convex
                    region of the loss landscape. Consequently, softmax neural networks can learn
                    the target function in the over-parametrization regime. To demonstrate the
                    broad applicability of our theoretical findings, we apply them to the task of
                    learning score estimation functions in diffusion models, a promising approach
                    for generative modeling. Our analysis shows that gradient-based algorithms can
                    learn the score function with a provable accuracy. Our work provides a deeper
                    understanding of the effectiveness of softmax neural networks and their
                    potential in various domains, paving the way for further advancements in
                    natural language processing and beyond.
                </p>
            </div>
        </dd>
        <dt><a name="item474">[474]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03252"
                    title="Abstract">arXiv:2405.03252</a> [<a href="/pdf/2405.03252" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03252" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Universal List Decoding Algorithm with Application to
                    Decoding of Polar Codes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+X">Xiangping Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiao Ma</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 47 pages, 24 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">This paper is concerned with a guessing codeword decoding (GCD) of linear
                    block codes. Compared with the guessing noise decoding (GND), which is only
                    efficient for high-rate codes, the GCD is efficient for not only high-rate
                    codes but also low-rate codes. We prove that the GCD typically requires a fewer
                    number of queries than the GND. Compared with the ordered statistics decoding
                    (OSD), the GCD does not require the online Gaussian elimination (GE). In
                    addition to limiting the maximum number of searches, we suggest limiting the
                    radius of searches in terms of soft weights or tolerated performance loss to
                    further reduce the decoding complexity, resulting in the so-called truncated
                    GCD. The performance gap between the truncated GCD and the optimal decoding can
                    be upper bounded approximately by the saddlepoint approach or other numerical
                    approaches. The derived upper bound captures the relationship between the
                    performance and the decoding parameters, enabling us to balance the performance
                    and the complexity by optimizing the decoding parameters of the truncated GCD.
                    We also introduce a parallel implementation of the (truncated) GCD algorithm to
                    reduce decoding latency without compromising performance. Another contribution
                    of this paper is the application of the GCD to the polar codes. We propose a
                    multiple-bit-wise decoding algorithm over a pruned tree for the polar codes,
                    referred to as the successive-cancellation list (SCL) decoding algorithm by
                    GCD. First, we present a strategy for pruning the conventional polar decoding
                    tree based on the complexity analysis rather than the specific bit patterns.
                    Then we apply the GCD algorithm in parallel aided by the early stopping
                    criteria to the leaves of the pruned tree. Simulation results show that,
                    without any performance loss as justified by analysis, the proposed decoding
                    algorithm can significantly reduce the decoding latency of the polar codes.
                </p>
            </div>
        </dd>
        <dt><a name="item475">[475]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03255"
                    title="Abstract">arXiv:2405.03255</a> [<a href="/pdf/2405.03255" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03255" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multi-Modality Spatio-Temporal Forecasting via
                    Self-Supervised Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+J">Jiewen Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+R">Renhe Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaqi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+X">Xuan Song</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IJCAI 2024 Main Track
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Multi-modality spatio-temporal (MoST) data extends spatio-temporal (ST) data
                    by incorporating multiple modalities, which is prevalent in monitoring systems,
                    encompassing diverse traffic demands and air quality assessments. Despite
                    significant strides in ST modeling in recent years, there remains a need to
                    emphasize harnessing the potential of information from different modalities.
                    Robust MoST forecasting is more challenging because it possesses (i)
                    high-dimensional and complex internal structures and (ii) dynamic heterogeneity
                    caused by temporal, spatial, and modality variations. In this study, we propose
                    a novel MoST learning framework via Self-Supervised Learning, namely MoSSL,
                    which aims to uncover latent patterns from temporal, spatial, and modality
                    perspectives while quantifying dynamic heterogeneity. Experiment results on two
                    real-world MoST datasets verify the superiority of our approach compared with
                    the state-of-the-art baselines. Model implementation is available at
                    https://github.com/beginner-sketch/MoSSL.
                </p>
            </div>
        </dd>
        <dt><a name="item476">[476]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03256"
                    title="Abstract">arXiv:2405.03256</a> [<a href="/pdf/2405.03256" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03256" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MARE: Multi-Agents Collaboration Framework for Requirements
                    Engineering
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+D">Dongming Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+Z">Zhi Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaohong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chunhui Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">Requirements Engineering (RE) is a critical phase in the software development
                    process that generates requirements specifications from stakeholders' needs.
                    Recently, deep learning techniques have been successful in several RE tasks.
                    However, obtaining high-quality requirements specifications requires
                    collaboration across multiple tasks and roles. In this paper, we propose an
                    innovative framework called MARE, which leverages collaboration among large
                    language models (LLMs) throughout the entire RE process. MARE divides the RE
                    process into four tasks: elicitation, modeling, verification, and
                    specification. Each task is conducted by engaging one or two specific agents
                    and each agent can conduct several actions. MARE has five agents and nine
                    actions. To facilitate collaboration between agents, MARE has designed a
                    workspace for agents to upload their generated intermediate requirements
                    artifacts and obtain the information they need. We conduct experiments on five
                    public cases, one dataset, and four new cases created by this work. We compared
                    MARE with three baselines using three widely used metrics for the generated
                    requirements models. Experimental results show that MARE can generate more
                    correct requirements models and outperform the state-of-the-art approaches by
                    15.4%. For the generated requirements specifications, we conduct a human
                    evaluation in three aspects and provide insights about the quality
                </p>
            </div>
        </dd>
        <dt><a name="item477">[477]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03262"
                    title="Abstract">arXiv:2405.03262</a> [<a href="/pdf/2405.03262" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03262" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> End-to-End Reinforcement Learning of Curative Curtailment
                    with Partial Measurement Availability
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wolf%2C+H">Hinrikus Wolf</a>,
                    <a href="/search/cs?searchtype=author&amp;query=B%C3%B6ttcher%2C+L">Luis Böttcher</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bouchkati%2C+S">Sarra Bouchkati</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lutat%2C+P">Philipp Lutat</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Breitung%2C+J">Jens Breitung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jung%2C+B">Bastian Jung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=M%C3%B6llemann%2C+T">Tina Möllemann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Todosijevi%C4%87%2C+V">Viktor Todosijević</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schiefelbein-Lach%2C+J">Jan Schiefelbein-Lach</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pohl%2C+O">Oliver Pohl</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ulbig%2C+A">Andreas Ulbig</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Grohe%2C+M">Martin Grohe</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">In the course of the energy transition, the expansion of generation and
                    consumption will change, and many of these technologies, such as PV systems,
                    electric cars and heat pumps, will influence the power flow, especially in the
                    distribution grids. Scalable methods that can make decisions for each grid
                    connection are needed to enable congestion-free grid operation in the
                    distribution grids. This paper presents a novel end-to-end approach to
                    resolving congestion in distribution grids with deep reinforcement learning.
                    Our architecture learns to curtail power and set appropriate reactive power to
                    determine a non-congested and, thus, feasible grid state. State-of-the-art
                    methods such as the optimal power flow (OPF) demand high computational costs
                    and detailed measurements of every bus in a grid. In contrast, the presented
                    method enables decisions under sparse information with just some buses
                    observable in the grid. Distribution grids are generally not yet fully
                    digitized and observable, so this method can be used for decision-making on the
                    majority of low-voltage grids. On a real low-voltage grid the approach resolves
                    100\% of violations in the voltage band and 98.8\% of asset overloads. The
                    results show that decisions can also be made on real grids that guarantee
                    sufficient quality for congestion-free grid operation.
                </p>
            </div>
        </dd>
        <dt><a name="item478">[478]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03264"
                    title="Abstract">arXiv:2405.03264</a> [<a href="/pdf/2405.03264" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03264" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Delooping generated groups in homotopy type theory
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Champin%2C+C">Camil Champin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mimram%2C+S">Samuel Mimram</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Oleon%2C+E">Emile Oleon</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>; Category Theory (math.CT)

                </div>
                <p class="mathjax">Homotopy type theory is a logical setting based on Martin-L\"of type theory
                    in which one can perform geometric constructions and proofs in a synthetic way.
                    Namely, types can be interpreted as spaces (up to continuous deformation) and
                    proofs as homotopy invariant constructions. In this context, the loop spaces of
                    types with a distinguished element (more precisely, pointed connected
                    groupoids), provide a natural representation of groups, what we call here
                    internal groups. The construction which internalizes a given group is called
                    delooping, because it is a formal inverse to the loop space operator. As we
                    recall in the article, this delooping operation has a concrete definition for
                    any group G given by the type of G-torsors. Those are particular sets together
                    with an action of G, which means that they come equipped with an endomorphism
                    for every element of G. We show that, when a generating set is known for the
                    group, we can construct a smaller representation of the type of G-torsors,
                    using the fact that we only need automorphisms for the elements of the
                    generating set. We thus obtain a concise definition of (internal) groups in
                    homotopy type theory, which can be useful to define deloopings without
                    resorting to higher inductive types, or to perform computations on those. We
                    also investigate an abstract construction for the Cayley group of a generated
                    group. Most of the developments performed in the article have been formalized
                    using the cubical version of the Agda proof assistant.
                </p>
            </div>
        </dd>
        <dt><a name="item479">[479]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03266"
                    title="Abstract">arXiv:2405.03266</a> [<a href="/pdf/2405.03266" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03266" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient computation of Katz centrality for very dense
                    networks via "negative parameter Katz"
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Noferini%2C+V">Vanni Noferini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wood%2C+R">Ryan Wood</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information
                        Networks (cs.SI)</span>; Combinatorics (math.CO)

                </div>
                <p class="mathjax">Katz centrality (and its limiting case, eigenvector centrality) is a
                    frequently used tool to measure the importance of a node in a network, and to
                    rank the nodes accordingly. One reason for its popularity is that Katz
                    centrality can be computed very efficiently when the network is sparse, i.e.,
                    having only <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-199-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1379"
                                style="width: 2.607em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.144em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.03em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1380"><span class="mi" id="MathJax-Span-1381"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-1382" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-1383"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-1384"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-199">O(n)</script> edges between its <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-200-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1385"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1386"><span class="mi" id="MathJax-Span-1387"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-200">n</script> nodes. While sparsity is common in
                    practice, in some applications one faces the opposite situation of a very dense
                    network, where only <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-201-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1388"
                                style="width: 2.607em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.144em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.03em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1389"><span class="mi" id="MathJax-Span-1390"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-1391" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-1392"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-1393"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-201">O(n)</script> potential edges are missing with
                    respect to a
                    complete graph. We explain why and how, even for very dense networks, it is
                    possible to efficiently compute the ranking stemming from Katz centrality for
                    unweighted graphs, possibly directed and possibly with loops, by working on the
                    complement graph. Our approach also provides an interpretation, regardless of
                    sparsity, of "Katz centrality with negative parameter" as usual Katz centrality
                    on the complement graph. For weighted graphs, we provide instead an
                    approximation method that is based on removing sufficiently many edges from the
                    network (or from its complement), and we give sufficient conditions for this
                    approximation to provide the correct ranking. We include numerical experiments
                    to illustrate the advantages of the proposed approach.
                </p>
            </div>
        </dd>
        <dt><a name="item480">[480]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03267"
                    title="Abstract">arXiv:2405.03267</a> [<a href="/pdf/2405.03267" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03267" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Characterizing the Dilemma of Performance and Index Size in
                    Billion-Scale Vector Search and Breaking It with Second-Tier Memory
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+R">Rongxin Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yifan Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+X">Xingda Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+H">Hongrui Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+R">Rong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+S">Sijie Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Haibo Chen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

                </div>
                <p class="mathjax">Vector searches on large-scale datasets are critical to modern online
                    services like web search and RAG, which necessity storing the datasets and
                    their index on the secondary storage like SSD. In this paper, we are the first
                    to characterize the trade-off of performance and index size in existing
                    SSD-based graph and cluster indexes: to improve throughput by {5.7\,<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-202-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1394"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1395"><span class="mo" id="MathJax-Span-1396"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-202">\times</script>}
                    and {1.7\,<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-203-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1397"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1398"><span class="mo" id="MathJax-Span-1399"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-203">\times</script>}, these indexes have to pay a
                    {5.8\,<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-204-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1400"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1401"><span class="mo" id="MathJax-Span-1402"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-204">\times</script>} storage
                    amplification and {7.7\,<span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-205-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1403"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1404"><span class="mo" id="MathJax-Span-1405"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-205">\times</script>} with respect to the dataset size,
                    respectively. The root cause is that the coarse-grained access of SSD
                    mismatches the fine-grained random read required by vector indexes with small
                    amplification.
                    <br>This paper argues that second-tier memory, such as remote DRAM/NVM connected
                    via RDMA or CXL, is a powerful storage for addressing the problem from a
                    system's perspective, thanks to its fine-grained access granularity. However,
                    putting existing indexes -- primarily designed for SSD -- directly on
                    second-tier memory cannot fully utilize its power. Meanwhile, second-tier
                    memory still behaves more like storage, so using it as DRAM is also
                    inefficient. To this end, we build a graph and cluster index that centers
                    around the performance features of second-tier memory. With careful execution
                    engine and index layout designs, we show that vector indexes can achieve
                    optimal performance with orders of magnitude smaller index amplification, on a
                    variety of second-tier memory devices.
                    <br>Based on our improved graph and vector indexes on second-tier memory, we
                    further conduct a systematic study between them to facilitate developers
                    choosing the right index for their workloads. Interestingly, the findings on
                    the second-tier memory contradict the ones on SSDs.
                </p>
            </div>
        </dd>
        <dt><a name="item481">[481]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03272"
                    title="Abstract">arXiv:2405.03272</a> [<a href="/pdf/2405.03272" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03272" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> WorldQA: Multimodal World Knowledge in Videos through
                    Long-Chain Reasoning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuanhan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kaichen Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pu%2C+F">Fanyi Pu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Setiadharma%2C+C+A">Christopher Arif
                        Setiadharma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jingkang Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziwei Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Multimodal information, together with our knowledge, help us to understand
                    the complex and dynamic world. Large language models (LLM) and large multimodal
                    models (LMM), however, still struggle to emulate this capability. In this
                    paper, we present WorldQA, a video understanding dataset designed to push the
                    boundaries of multimodal world models with three appealing properties: (1)
                    Multimodal Inputs: The dataset comprises 1007 question-answer pairs and 303
                    videos, necessitating the analysis of both auditory and visual data for
                    successful interpretation. (2) World Knowledge: We identify five essential
                    types of world knowledge for question formulation. This approach challenges
                    models to extend their capabilities beyond mere perception. (3) Long-Chain
                    Reasoning: Our dataset introduces an average reasoning step of 4.45, notably
                    surpassing other videoQA datasets. Furthermore, we introduce WorldRetriever, an
                    agent designed to synthesize expert knowledge into a coherent reasoning chain,
                    thereby facilitating accurate responses to WorldQA queries. Extensive
                    evaluations of 13 prominent LLMs and LMMs reveal that WorldRetriever, although
                    being the most effective model, achieved only 70% of humanlevel performance in
                    multiple-choice questions. This finding highlights the necessity for further
                    advancement in the reasoning and comprehension abilities of models. Our
                    experiments also yield several key insights. For instance, while humans tend to
                    perform better with increased frames, current LMMs, including WorldRetriever,
                    show diminished performance under similar conditions. We hope that WorldQA,our
                    methodology, and these insights could contribute to the future development of
                    multimodal world models.
                </p>
            </div>
        </dd>
        <dt><a name="item482">[482]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03273"
                    title="Abstract">arXiv:2405.03273</a> [<a href="/pdf/2405.03273" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03273" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Evaluation of Drivers' Interaction Ability at Social
                    Scenarios: A Process-Based Framework
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiaqi Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hang%2C+P">Peng Hang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xiangwang Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jian Sun</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Assessing drivers' interaction capabilities is crucial for understanding
                    human driving behavior and enhancing the interactive abilities of autonomous
                    vehicles. In scenarios involving strong interaction, existing metrics focused
                    on interaction outcomes struggle to capture the evolutionary process of
                    drivers' interactive behaviors, making it challenging for autonomous vehicles
                    to dynamically assess and respond to other agents during interactions. To
                    address this issue, we propose a framework for assessing drivers' interaction
                    capabilities, oriented towards the interactive process itself, which includes
                    three components: Interaction Risk Perception, Interaction Process Modeling,
                    and Interaction Ability Scoring. We quantify interaction risks through motion
                    state estimation and risk field theory, followed by introducing a dynamic
                    action assessment benchmark based on a game-theoretical rational agent model,
                    and designing a capability scoring metric based on morphological similarity
                    distance. By calculating real-time differences between a driver's actions and
                    the assessment benchmark, the driver's interaction capabilities are scored
                    dynamically. We validated our framework at unsignalized intersections as a
                    typical scenario. Validation analysis on driver behavior datasets from China
                    and the USA shows that our framework effectively distinguishes and evaluates
                    conservative and aggressive driving states during interactions, demonstrating
                    good adaptability and effectiveness in various regional settings.
                </p>
            </div>
        </dd>
        <dt><a name="item483">[483]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03278"
                    title="Abstract">arXiv:2405.03278</a> [<a href="/pdf/2405.03278" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03278" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Approximate Realizations for Outerplanaric Degree Sequences
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bar-Noy%2C+A">Amotz Bar-Noy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bohnlein%2C+T">Toni Bohnlein</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peleg%2C+D">David Peleg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ran%2C+Y">Yingli Ran</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rawitz%2C+D">Dror Rawitz</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper has published in 35th IWOCA
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

                </div>
                <p class="mathjax">We study the question of whether a sequence d = (d_1,d_2, \ldots, d_n) of
                    positive integers is the degree sequence of some outerplanar (a.k.a. 1-page
                    book embeddable) graph G. If so, G is an outerplanar realization of d and d is
                    an outerplanaric sequence. The case where \sum d \leq 2n - 2 is easy, as d has
                    a realization by a forest (which is trivially an outerplanar graph). In this
                    paper, we consider the family \cD of all sequences d of even sum 2n\leq \sum d
                    \le 4n-6-2\multipl_1, where \multipl_x is the number of x's in d. (The second
                    inequality is a necessary condition for a sequence d with \sum d\geq 2n to be
                    outerplanaric.) We partition \cD into two disjoint subfamilies,
                    \cD=\cD_{NOP}\cup\cD_{2PBE}, such that every sequence in \cD_{NOP} is provably
                    non-outerplanaric, and every sequence in \cD_{2PBE} is given a realizing graph
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-206-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1406"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.81em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1407"><span class="mi" id="MathJax-Span-1408"
                                                style="font-family: MathJax_Math-italic;">G</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-206">G</script> enjoying a 2-page book embedding (and
                    moreover, one of the pages is also
                    bipartite).
                </p>
            </div>
        </dd>
        <dt><a name="item484">[484]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03279"
                    title="Abstract">arXiv:2405.03279</a> [<a href="/pdf/2405.03279" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03279" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Lifelong Knowledge Editing for LLMs with Retrieval-Augmented
                    Continuous Prompt Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qizhou Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Taolin Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dongyang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+L">Longtao Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+H">Hui Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chengyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+X">Xiaofeng He</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 4 figures, 6 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Model editing aims to correct outdated or erroneous knowledge in large
                    language models (LLMs) without the need for costly retraining. Lifelong model
                    editing is the most challenging task that caters to the continuous editing
                    requirements of LLMs. Prior works primarily focus on single or batch editing;
                    nevertheless, these methods fall short in lifelong editing scenarios due to
                    catastrophic knowledge forgetting and the degradation of model performance.
                    Although retrieval-based methods alleviate these issues, they are impeded by
                    slow and cumbersome processes of integrating the retrieved knowledge into the
                    model. In this work, we introduce RECIPE, a RetriEval-augmented ContInuous
                    Prompt lEarning method, to boost editing efficacy and inference efficiency in
                    lifelong learning. RECIPE first converts knowledge statements into short and
                    informative continuous prompts, prefixed to the LLM's input query embedding, to
                    efficiently refine the response grounded on the knowledge. It further
                    integrates the Knowledge Sentinel (KS) that acts as an intermediary to
                    calculate a dynamic threshold, determining whether the retrieval repository
                    contains relevant knowledge. Our retriever and prompt encoder are jointly
                    trained to achieve editing properties, i.e., reliability, generality, and
                    locality. In our experiments, RECIPE is assessed extensively across multiple
                    LLMs and editing datasets, where it achieves superior editing performance.
                    RECIPE also demonstrates its capability to maintain the overall performance of
                    LLMs alongside showcasing fast editing and inference speed.
                </p>
            </div>
        </dd>
        <dt><a name="item485">[485]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03280"
                    title="Abstract">arXiv:2405.03280</a> [<a href="/pdf/2405.03280" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03280" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Animate Your Thoughts: Decoupled Reconstruction of Dynamic
                    Natural Vision from Slow Brain Activity
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yizhuo Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Du%2C+C">Changde Du</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+X">Xuanliu Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+L">Liuyun Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+H">Huiguang He</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Reconstructing human dynamic vision from brain activity is a challenging task
                    with great scientific significance. The difficulty stems from two primary
                    issues: (1) vision-processing mechanisms in the brain are highly intricate and
                    not fully revealed, making it challenging to directly learn a mapping between
                    fMRI and video; (2) the temporal resolution of fMRI is significantly lower than
                    that of natural videos. To overcome these issues, this paper propose a
                    two-stage model named Mind-Animator, which achieves state-of-the-art
                    performance on three public datasets. Specifically, during the fMRI-to-feature
                    stage, we decouple semantic, structural, and motion features from fMRI through
                    fMRI-vision-language tri-modal contrastive learning and sparse causal
                    attention. In the feature-to-video stage, these features are merged to videos
                    by an inflated Stable Diffusion. We substantiate that the reconstructed video
                    dynamics are indeed derived from fMRI, rather than hallucinations of the
                    generative model, through permutation tests. Additionally, the visualization of
                    voxel-wise and ROI-wise importance maps confirms the neurobiological
                    interpretability of our model.
                </p>
            </div>
        </dd>
        <dt><a name="item486">[486]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03281"
                    title="Abstract">arXiv:2405.03281</a> [<a href="/pdf/2405.03281" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03281" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FDSPC: Fast and Direct Smooth Path Planning via Continuous
                    Curvature Integration
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yiqun Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">In recent decades, global path planning of robot has seen significant
                    advancements. Both heuristic search-based methods and probability
                    sampling-based methods have shown capabilities to find feasible solutions in
                    complex scenarios. However, mainstream global path planning algorithms often
                    produce paths with bends, requiring additional smoothing post-processing. In
                    this work, we propose a fast and direct path planning method based on
                    continuous curvature integration. This method ensures path feasibility while
                    directly generating global smooth paths with constant velocity, thus
                    eliminating the need for post-path-smoothing. Furthermore, we compare the
                    proposed method with existing approaches in terms of solution time, path
                    length, memory usage, and smoothness under multiple scenarios. The proposed
                    method is vastly superior to the average performance of state-of-the-art (SOTA)
                    methods, especially in terms of the self-defined <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-207-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1409"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.04em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1410"><span class="msubsup"
                                                id="MathJax-Span-1411"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1412"><span class="mrow"
                                                                id="MathJax-Span-1413"><span class="mi"
                                                                    id="MathJax-Span-1414"
                                                                    style="font-family: MathJax_Caligraphic;">S<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-1415"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-207">\mathcal{S}_2 </script> smoothness
                    (mean angle of steering). These results demonstrate the effectiveness and
                    superiority of our approach in several representative environments.
                </p>
            </div>
        </dd>
        <dt><a name="item487">[487]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03285"
                    title="Abstract">arXiv:2405.03285</a> [<a href="/pdf/2405.03285" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03285" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A continuous approach for computing the pseudospectra of
                    linear operators
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Deng%2C+K">Kuan Deng</a>,
                    <a href="/search/math?searchtype=author&amp;query=Liu%2C+X">Xiaolin Liu</a>,
                    <a href="/search/math?searchtype=author&amp;query=Xu%2C+K">Kuan Xu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 22 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">We propose a continuous approach for computing the pseudospectra of linear
                    operators following a 'solve-then-discretize' strategy. Instead of taking a
                    finite section approach or using a finite-dimensional matrix to approximate the
                    operator of interest, the new method employs an operator analogue of the
                    Lanczos process to work directly with operators and functions. The method is
                    shown to be free of spectral pollution and spectral invisibility, fully
                    adaptive, nearly optimal in accuracy, and well-conditioned. The advantages of
                    the method are demonstrated by extensive numerical examples and comparison with
                    the traditional method.
                </p>
            </div>
        </dd>
        <dt><a name="item488">[488]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03287"
                    title="Abstract">arXiv:2405.03287</a> [<a href="/pdf/2405.03287" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03287" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Evaluating Eye Movement Biometrics in Virtual Reality: A
                    Comparative Analysis of VR Headset and High-End Eye-Tracker Collected Dataset
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Raju%2C+M+H">Mehedi Hasan Raju</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lohr%2C+D+J">Dillon J Lohr</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Komogortsev%2C+O+V">Oleg V Komogortsev</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">Previous studies have shown that eye movement data recorded at 1000 Hz can be
                    used to authenticate individuals. This study explores the effectiveness of eye
                    movement-based biometrics (EMB) by utilizing data from an eye-tracking
                    (ET)-enabled virtual reality (VR) headset (GazeBaseVR) and compares it to the
                    performance using data from a high-end eye tracker (GazeBase) that has been
                    downsampled to 250 Hz. The research also aims to assess the biometric potential
                    of both binocular and monocular eye movement data. GazeBaseVR dataset achieves
                    an equal error rate (EER) of 1.67% and a false rejection rate (FRR) at 10^-4
                    false acceptance rate (FAR) of 22.73% in a binocular configuration. This study
                    underscores the biometric viability of data obtained from eye-tracking-enabled
                    VR headset.
                </p>
            </div>
        </dd>
        <dt><a name="item489">[489]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03288"
                    title="Abstract">arXiv:2405.03288</a> [<a href="/pdf/2405.03288" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03288" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fundamental Bounds on Unequal Error Protection Codes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+L">Liuquan Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+S">Shuai Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huazi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jun Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+G">Guiying Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Z">Zhiming Ma</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">Unequal error protection (UEP) codes can facilitate the transmission of
                    messages with different protection levels. In this paper, we study the
                    achievability bounds on UEP by the generalization of Gilbert-Varshamov (GV)
                    bound. For the first time, we show that under certain conditions, UEP enhances
                    the code rate comparing with time-sharing (TS) strategies asymptotically.
                </p>
            </div>
        </dd>
        <dt><a name="item490">[490]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03290"
                    title="Abstract">arXiv:2405.03290</a> [<a href="/pdf/2405.03290" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03290" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Coordinating Cooperative Perception in Urban Air Mobility for
                    Enhanced Environmental Awareness
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=H%C3%A4ckel%2C+T">Timo Häckel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=von+Roenn%2C+L">Luca von Roenn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Juchmann%2C+N">Nemo Juchmann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fay%2C+A">Alexander Fay</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Akkermans%2C+R">Rinie Akkermans</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tiedemann%2C+T">Tim Tiedemann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schmidt%2C+T+C">Thomas C. Schmidt</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> If you cite this paper, please use the original reference:
                    Timo H\"ackel, Luca von Roenn, Nemo Juchmann, Alexander Fay, Rinie Akkermans, Tim Tiedemann, and
                    Thomas C. Schmidt. "Coordinating Cooperative Perception in Urban Air Mobility for Enhanced
                    Environmental Awareness,'' In: 2024 International Conference on Unmanned Aircraft Systems (ICUAS).
                    IEEE, June 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>

                </div>
                <p class="mathjax">The trend for Urban Air Mobility (UAM) is growing with prospective air taxis,
                    parcel deliverers, and medical and industrial services. Safe and efficient UAM
                    operation relies on timely communication and reliable data exchange. In this
                    paper, we explore Cooperative Perception (CP) for Unmanned Aircraft Systems
                    (UAS), considering the unique communication needs involving high dynamics and a
                    large number of UAS. We propose a hybrid approach combining local broadcast
                    with a central CP service, inspired by centrally managed U-space and broadcast
                    mechanisms from automotive and aviation domains. In a simulation study, we show
                    that our approach significantly enhances the environmental awareness for UAS
                    compared to fully distributed approaches, with an increased communication
                    channel load, which we also evaluate. These findings prompt a discussion on
                    communication strategies for CP in UAM and the potential of a centralized CP
                    service in future research.
                </p>
            </div>
        </dd>
        <dt><a name="item491">[491]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03296"
                    title="Abstract">arXiv:2405.03296</a> [<a href="/pdf/2405.03296" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03296" title="Download PostScript">ps</a>, <a href="/format/2405.03296"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Coefficient Decomposition for Spectral Graph Convolution
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+F">Feng Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wen Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Spectral graph convolutional network (SGCN) is a kind of graph neural
                    networks (GNN) based on graph signal filters, and has shown compelling
                    expressivity for modeling graph-structured data. Most SGCNs adopt polynomial
                    filters and learn the coefficients from the training data. Many of them focus
                    on which polynomial basis leads to optimal expressive power and models'
                    architecture is little discussed. In this paper, we propose a general form in
                    terms of spectral graph convolution, where the coefficients of polynomial basis
                    are stored in a third-order tensor. Then, we show that the convolution block in
                    existing SGCNs can be derived by performing a certain coefficient decomposition
                    operation on the coefficient tensor. Based on the generalized view, we develop
                    novel spectral graph convolutions CoDeSGC-CP and -Tucker by tensor
                    decomposition CP and Tucker on the coefficient tensor. Extensive experimental
                    results demonstrate that the proposed convolutions achieve favorable
                    performance improvements.
                </p>
            </div>
        </dd>
        <dt><a name="item492">[492]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03298"
                    title="Abstract">arXiv:2405.03298</a> [<a href="/pdf/2405.03298" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03298" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Online Clustering of Known and Emerging Malware Families
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jure%C4%8Dkov%C3%A1%2C+O">Olha Jurečková</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jure%C4%8Dek%2C+M">Martin Jureček</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stamp%2C+M">Mark Stamp</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a
                        href="/abs/2305.00605">arXiv:2305.00605</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Malware attacks have become significantly more frequent and sophisticated in
                    recent years. Therefore, malware detection and classification are critical
                    components of information security. Due to the large amount of malware samples
                    available, it is essential to categorize malware samples according to their
                    malicious characteristics. Clustering algorithms are thus becoming more widely
                    used in computer security to analyze the behavior of malware variants and
                    discover new malware families. Online clustering algorithms help us to
                    understand malware behavior and produce a quicker response to new threats. This
                    paper introduces a novel machine learning-based model for the online clustering
                    of malicious samples into malware families. Streaming data is divided according
                    to the clustering decision rule into samples from known and new emerging
                    malware families. The streaming data is classified using the weighted k-nearest
                    neighbor classifier into known families, and the online k-means algorithm
                    clusters the remaining streaming data and achieves a purity of clusters from
                    90.20% for four clusters to 93.34% for ten clusters. This work is based on
                    static analysis of portable executable files for the Windows operating system.
                    Experimental results indicate that the proposed online clustering model can
                    create high-purity clusters corresponding to malware families. This allows
                    malware analysts to receive similar malware samples, speeding up their
                    analysis.
                </p>
            </div>
        </dd>
        <dt><a name="item493">[493]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03299"
                    title="Abstract">arXiv:2405.03299</a> [<a href="/pdf/2405.03299" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03299" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DarkFed: A Data-Free Backdoor Attack in Federated Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Minghui Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wan%2C+W">Wei Wan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ning%2C+Y">Yuxuan Ning</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+S">Shengshan Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+L">Lulu Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L+Y">Leo Yu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yichen Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper has been accepted by IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">Federated learning (FL) has been demonstrated to be susceptible to backdoor
                    attacks. However, existing academic studies on FL backdoor attacks rely on a
                    high proportion of real clients with main task-related data, which is
                    impractical. In the context of real-world industrial scenarios, even the
                    simplest defense suffices to defend against the state-of-the-art attack, 3DFed.
                    A practical FL backdoor attack remains in a nascent stage of development.
                    <br>To bridge this gap, we present DarkFed. Initially, we emulate a series of
                    fake clients, thereby achieving the attacker proportion typical of academic
                    research scenarios. Given that these emulated fake clients lack genuine
                    training data, we further propose a data-free approach to backdoor FL.
                    Specifically, we delve into the feasibility of injecting a backdoor using a
                    shadow dataset. Our exploration reveals that impressive attack performance can
                    be achieved, even when there is a substantial gap between the shadow dataset
                    and the main task dataset. This holds true even when employing synthetic data
                    devoid of any semantic information as the shadow dataset. Subsequently, we
                    strategically construct a series of covert backdoor updates in an optimized
                    manner, mimicking the properties of benign updates, to evade detection by
                    defenses. A substantial body of empirical evidence validates the tangible
                    effectiveness of DarkFed.
                </p>
            </div>
        </dd>
        <dt><a name="item494">[494]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03300"
                    title="Abstract">arXiv:2405.03300</a> [<a href="/pdf/2405.03300" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03300" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Active RIS-Aided Massive MIMO With Imperfect CSI and Phase
                    Noise
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Z">Zhangjie Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jianchen Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pan%2C+C">Cunhua Pan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zaichen Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=da+Costa%2C+D+B">Daniel Benevides da Costa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Elkashlan%2C+M">Maged Elkashlan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Karagiannidis%2C+G+K">George K. Karagiannidis</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">Active reconfigurable intelligent surface (RIS) has attracted significant
                    attention as a recently proposed RIS architecture. Owing to its capability to
                    amplify the incident signals, active RIS can mitigate the multiplicative fading
                    effect inherent in the passive RIS-aided system. In this paper, we consider an
                    active RIS-aided uplink multi-user massive multiple-input multiple-output
                    (MIMO) system in the presence of phase noise at the active RIS. Specifically,
                    we employ a two-timescale scheme, where the beamforming at the base station
                    (BS) is adjusted based on the instantaneous aggregated channel state
                    information (CSI) and the statistical CSI serves as the basis for designing the
                    phase shifts at the active RIS, so that the feedback overhead and computational
                    complexity can be significantly reduced. The aggregated channel composed of the
                    cascaded and direct channels is estimated by utilizing the linear minimum mean
                    square error (LMMSE) technique. Based on the estimated channel, we derive the
                    analytical closed-form expression of a lower bound of the achievable rate. The
                    power scaling laws in the active RIS-aided system are investigated based on the
                    theoretical expressions. When the transmit power of each user is scaled down by
                    the number of BS antennas M or reflecting elements N, we find that the thermal
                    noise will cause the lower bound of the achievable rate to approach zero, as
                    the number of M or N increases to infinity. Moreover, an optimization approach
                    based on genetic algorithms (GA) is introduced to tackle the phase shift
                    optimization problem. Numerical results reveal that the active RIS can greatly
                    enhance the performance of the considered system under various settings.
                </p>
            </div>
        </dd>
        <dt><a name="item495">[495]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03301"
                    title="Abstract">arXiv:2405.03301</a> [<a href="/pdf/2405.03301" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03301" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Interpretable Network Visualizations: A Human-in-the-Loop
                    Approach for Post-hoc Explainability of CNN-based Image Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bianchi%2C+M">Matteo Bianchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=De+Santis%2C+A">Antonio De Santis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tocchetti%2C+A">Andrea Tocchetti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brambilla%2C+M">Marco Brambilla</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> International Joint Conference on Artificial Intelligence
                    2024 (to be published)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Transparency and explainability in image classification are essential for
                    establishing trust in machine learning models and detecting biases and errors.
                    State-of-the-art explainability methods generate saliency maps to show where a
                    specific class is identified, without providing a detailed explanation of the
                    model's decision process. Striving to address such a need, we introduce a
                    post-hoc method that explains the entire feature extraction process of a
                    Convolutional Neural Network. These explanations include a layer-wise
                    representation of the features the model extracts from the input. Such features
                    are represented as saliency maps generated by clustering and merging similar
                    feature maps, to which we associate a weight derived by generalizing Grad-CAM
                    for the proposed methodology. To further enhance these explanations, we include
                    a set of textual labels collected through a gamified crowdsourcing activity and
                    processed using NLP techniques and Sentence-BERT. Finally, we show an approach
                    to generate global explanations by aggregating labels across multiple images.
                </p>
            </div>
        </dd>
        <dt><a name="item496">[496]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03302"
                    title="Abstract">arXiv:2405.03302</a> [<a href="/pdf/2405.03302" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03302" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The number of random 2-SAT solutions is asymptotically
                    log-normal
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chatterjee%2C+A">Arnab Chatterjee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Coja-Oghlan%2C+A">Amin Coja-Oghlan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+N">Noela Müller</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Riddlesden%2C+C">Connor Riddlesden</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rolvien%2C+M">Maurice Rolvien</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zakharov%2C+P">Pavel Zakharov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+H">Haodong Zhu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics
                        (cs.DM)</span>; Combinatorics (math.CO); Probability (math.PR)

                </div>
                <p class="mathjax">We prove that throughout the satisfiable phase, the logarithm of the number
                    of satisfying assignments of a random 2-SAT formula satisfies a central limit
                    theorem. This implies that the log of the number of satisfying assignments
                    exhibits fluctuations of order <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-208-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1416"
                                style="width: 1.739em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.45em, 1.45em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1417"><span class="msqrt"
                                                id="MathJax-Span-1418"><span
                                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                            class="mrow" id="MathJax-Span-1419"><span class="mi"
                                                                id="MathJax-Span-1420"
                                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1000.64em, 3.938em, -999.997em); top: -4.395em; left: 0.813em;"><span
                                                            style="display: inline-block; position: relative; width: 0.639em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -3.932em; left: 0em;"><span
                                                            style="font-family: MathJax_Main;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-208">\sqrt n</script>, with <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-209-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1421"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1422"><span class="mi" id="MathJax-Span-1423"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-209">n</script> the number of variables. The
                    formula for the variance can be evaluated effectively. By contrast, for
                    numerous other random constraint satisfaction problems the typical fluctuations
                    of the logarithm of the number of solutions are {\em bounded} throughout all or
                    most of the satisfiable regime.
                </p>
            </div>
        </dd>
        <dt><a name="item497">[497]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03303"
                    title="Abstract">arXiv:2405.03303</a> [<a href="/pdf/2405.03303" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03303" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Explainability for Transparent Conversational
                    Information-Seeking
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=%C5%81ajewska%2C+W">Weronika Łajewska</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Spina%2C+D">Damiano Spina</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Trippas%2C+J">Johanne Trippas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Balog%2C+K">Krisztian Balog</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This is the author's version of the work. The definitive
                    version is published in: 47th International ACM SIGIR Conference on Research and Development in
                    Information Retrieval (SIGIR '24), July 14-18, 2024, Washington, DC, USA
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>; Human-Computer Interaction (cs.HC)

                </div>
                <p class="mathjax">The increasing reliance on digital information necessitates advancements in
                    conversational search systems, particularly in terms of information
                    transparency. While prior research in conversational information-seeking has
                    concentrated on improving retrieval techniques, the challenge remains in
                    generating responses useful from a user perspective. This study explores
                    different methods of explaining the responses, hypothesizing that transparency
                    about the source of the information, system confidence, and limitations can
                    enhance users' ability to objectively assess the response. By exploring
                    transparency across explanation type, quality, and presentation mode, this
                    research aims to bridge the gap between system-generated responses and
                    responses verifiable by the user. We design a user study to answer questions
                    concerning the impact of (1) the quality of explanations enhancing the response
                    on its usefulness and (2) ways of presenting explanations to users. The
                    analysis of the collected data reveals lower user ratings for noisy
                    explanations, although these scores seem insensitive to the quality of the
                    response. Inconclusive results on the explanations presentation format suggest
                    that it may not be a critical factor in this setting.
                </p>
            </div>
        </dd>
        <dt><a name="item498">[498]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03305"
                    title="Abstract">arXiv:2405.03305</a> [<a href="/pdf/2405.03305" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03305" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Artificial Intelligence in the Autonomous Navigation of
                    Endovascular Interventions: A Systematic Review
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Robertshaw%2C+H">Harry Robertshaw</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Karstensen%2C+L">Lennart Karstensen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jackson%2C+B">Benjamin Jackson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sadati%2C+H">Hadi Sadati</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rhode%2C+K">Kawal Rhode</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ourselin%2C+S">Sebastien Ourselin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Granados%2C+A">Alejandro Granados</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Booth%2C+T+C">Thomas C Booth</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Abstract shortened for arXiv character limit
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Robertshaw H, Karstensen L, Jackson B, Sadati H, Rhode
                    K, Ourselin
                    S, Granados A and Booth TC (2023) Artificial intelligence in the autonomous
                    navigation of endovascular interventions: a systematic review. Front. Hum.
                    Neurosci. 17:1239374
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Robotics (cs.RO)

                </div>
                <p class="mathjax">Purpose: Autonomous navigation of devices in endovascular interventions can
                    decrease operation times, improve decision-making during surgery, and reduce
                    operator radiation exposure while increasing access to treatment. This
                    systematic review explores recent literature to assess the impact, challenges,
                    and opportunities artificial intelligence (AI) has for the autonomous
                    endovascular intervention navigation.
                    <br>Methods: PubMed and IEEEXplore databases were queried. Eligibility criteria
                    included studies investigating the use of AI in enabling the autonomous
                    navigation of catheters/guidewires in endovascular interventions. Following
                    PRISMA, articles were assessed using QUADAS-2. PROSPERO: CRD42023392259.
                    <br>Results: Among 462 studies, fourteen met inclusion criteria. Reinforcement
                    learning (9/14, 64%) and learning from demonstration (7/14, 50%) were used as
                    data-driven models for autonomous navigation. Studies predominantly utilised
                    physical phantoms (10/14, 71%) and in silico (4/14, 29%) models. Experiments
                    within or around the blood vessels of the heart were reported by the majority
                    of studies (10/14, 71%), while simple non-anatomical vessel platforms were used
                    in three studies (3/14, 21%), and the porcine liver venous system in one study.
                    We observed that risk of bias and poor generalisability were present across
                    studies. No procedures were performed on patients in any of the studies
                    reviewed. Studies lacked patient selection criteria, reference standards, and
                    reproducibility, resulting in low clinical evidence levels.
                    <br>Conclusions: AI's potential in autonomous endovascular navigation is
                    promising, but in an experimental proof-of-concept stage, with a technology
                    readiness level of 3. We highlight that reference standards with
                    well-identified performance metrics are crucial to allow for comparisons of
                    data-driven algorithms proposed in the years to come.
                </p>
            </div>
        </dd>
        <dt><a name="item499">[499]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03307"
                    title="Abstract">arXiv:2405.03307</a> [<a href="/pdf/2405.03307" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03307" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient Symbolic Planning with Views
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hasler%2C+S">Stephan Hasler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tanneberg%2C+D">Daniel Tanneberg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gienger%2C+M">Michael Gienger</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Robotic planning systems model spatial relations in detail as these are
                    needed for manipulation tasks. In contrast to this, other physical attributes
                    of objects and the effect of devices are usually oversimplified and expressed
                    by abstract compound attributes. This limits the ability of planners to find
                    alternative solutions. We propose to break these compound attributes down into
                    a shared set of elementary attributes. This strongly facilitates generalization
                    between different tasks and environments and thus helps to find innovative
                    solutions. On the down-side, this generalization comes with an increased
                    complexity of the solution space. Therefore, as the main contribution of the
                    paper, we propose a method that splits the planning problem into a sequence of
                    views, where in each view only an increasing subset of attributes is
                    considered. We show that this view-based strategy offers a good compromise
                    between planning speed and quality of the found plan, and discuss its general
                    applicability and limitations.
                </p>
            </div>
        </dd>
        <dt><a name="item500">[500]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03309"
                    title="Abstract">arXiv:2405.03309</a> [<a href="/pdf/2405.03309" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03309" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On de Bruijn Rings and Families of Almost Perfect Maps
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Stelldinger%2C+P">Peer Stelldinger</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics
                        (cs.DM)</span>

                </div>
                <p class="mathjax">De Bruijn tori, also called perfect maps, are two-dimensional periodic arrays
                    of letters drawn from a given finite alphabet, such that each possible pattern
                    of a given shape <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-210-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1424"
                                style="width: 3.302em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.723em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.61em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1425"><span class="mo" id="MathJax-Span-1426"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1427"
                                                style="font-family: MathJax_Math-italic;">m</span><span class="mo"
                                                id="MathJax-Span-1428" style="font-family: MathJax_Main;">,</span><span
                                                class="mi" id="MathJax-Span-1429"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="mo" id="MathJax-Span-1430"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-210">(m,n)</script> appears exactly once within one
                    period of the torus.
                    It is still unknown if de Bruijn tori of some certain size exist, like e.g.
                    square shaped de Bruijn Tori with odd <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-211-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1431"
                                style="width: 9.031em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 7.526em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1007.47em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1432"><span class="mi" id="MathJax-Span-1433"
                                                style="font-family: MathJax_Math-italic;">m</span><span class="mo"
                                                id="MathJax-Span-1434"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mi" id="MathJax-Span-1435"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">n</span><span
                                                class="mo" id="MathJax-Span-1436"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∈</span><span
                                                class="mo" id="MathJax-Span-1437"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">{</span><span
                                                class="mn" id="MathJax-Span-1438"
                                                style="font-family: MathJax_Main;">3</span><span class="mo"
                                                id="MathJax-Span-1439" style="font-family: MathJax_Main;">,</span><span
                                                class="mn" id="MathJax-Span-1440"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">5</span><span
                                                class="mo" id="MathJax-Span-1441"
                                                style="font-family: MathJax_Main;">,</span><span class="mn"
                                                id="MathJax-Span-1442"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">7</span><span
                                                class="mo" id="MathJax-Span-1443"
                                                style="font-family: MathJax_Main;">}</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-211">m=n\in\{3,5,7\}</script> and an even alphabet
                    size <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-212-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1444"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1445"><span class="mi" id="MathJax-Span-1446"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-212">k</script>. However, in certain applications like
                    positional coding, sub-perfect
                    maps are sufficient, i.e. one does not need every possible <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-213-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1447"
                                style="width: 3.302em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.723em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.61em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1448"><span class="mo" id="MathJax-Span-1449"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1450"
                                                style="font-family: MathJax_Math-italic;">m</span><span class="mo"
                                                id="MathJax-Span-1451" style="font-family: MathJax_Main;">,</span><span
                                                class="mi" id="MathJax-Span-1452"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="mo" id="MathJax-Span-1453"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-213">(m,n)</script>-pattern to
                    appear, as long as a sufficient large number of such patterns is captured and
                    every pattern occurs at most once. We show, that given any <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-214-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1454"
                                style="width: 3.417em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.839em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1002.84em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1455"><span class="mi" id="MathJax-Span-1456"
                                                style="font-family: MathJax_Math-italic;">m</span><span class="mo"
                                                id="MathJax-Span-1457"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mi" id="MathJax-Span-1458"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-214">m=n</script> and a square
                    alphabet size <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-215-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1459"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.93em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1460"><span class="msubsup"
                                                id="MathJax-Span-1461"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.52em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1462"
                                                            style="font-family: MathJax_Math-italic;">k</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-1463"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-215">k^2</script>, one can efficiently construct a
                    sub-perfect map which is
                    almost perfect, i.e. of almost maximal size. We do this by introducing de
                    Bruijn rings, i.e. sub-perfect maps of minimal height, and providing an
                    efficient construction method for them. We extend our results to non-square
                    torus shapes and arbitrary non-prime alphabet sizes.
                </p>
            </div>
        </dd>
        <dt><a name="item501">[501]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03311"
                    title="Abstract">arXiv:2405.03311</a> [<a href="/pdf/2405.03311" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03311" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Federated Learning for Drowsiness Detection in Connected
                    Vehicles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lindskog%2C+W">William Lindskog</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Spannagl%2C+V">Valentin Spannagl</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Prehofer%2C+C">Christian Prehofer</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 8 figures, 1 table, EAI INTSYS 2023 conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Ensuring driver readiness poses challenges, yet driver monitoring systems can
                    assist in determining the driver's state. By observing visual cues, such
                    systems recognize various behaviors and associate them with specific
                    conditions. For instance, yawning or eye blinking can indicate driver
                    drowsiness. Consequently, an abundance of distributed data is generated for
                    driver monitoring. Employing machine learning techniques, such as driver
                    drowsiness detection, presents a potential solution. However, transmitting the
                    data to a central machine for model training is impractical due to the large
                    data size and privacy concerns. Conversely, training on a single vehicle would
                    limit the available data and likely result in inferior performance. To address
                    these issues, we propose a federated learning framework for drowsiness
                    detection within a vehicular network, leveraging the YawDD dataset. Our
                    approach achieves an accuracy of 99.2%, demonstrating its promise and
                    comparability to conventional deep learning techniques. Lastly, we show how our
                    model scales using various number of federated clients
                </p>
            </div>
        </dd>
        <dt><a name="item502">[502]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03314"
                    title="Abstract">arXiv:2405.03314</a> [<a href="/pdf/2405.03314" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03314" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Learning-based Point Cloud Registration for Augmented
                    Reality-guided Surgery
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Weber%2C+M">Maximilian Weber</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wild%2C+D">Daniel Wild</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kleesiek%2C+J">Jens Kleesiek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Egger%2C+J">Jan Egger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gsaxner%2C+C">Christina Gsaxner</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages, 4 figures; accepted at IEEE ISBI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Point cloud registration aligns 3D point clouds using spatial
                    transformations. It is an important task in computer vision, with applications
                    in areas such as augmented reality (AR) and medical imaging. This work explores
                    the intersection of two research trends: the integration of AR into
                    image-guided surgery and the use of deep learning for point cloud registration.
                    The main objective is to evaluate the feasibility of applying deep
                    learning-based point cloud registration methods for image-to-patient
                    registration in augmented reality-guided surgery. We created a dataset of point
                    clouds from medical imaging and corresponding point clouds captured with a
                    popular AR device, the HoloLens 2. We evaluate three well-established deep
                    learning models in registering these data pairs. While we find that some deep
                    learning methods show promise, we show that a conventional registration
                    pipeline still outperforms them on our challenging dataset.
                </p>
            </div>
        </dd>
        <dt><a name="item503">[503]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03316"
                    title="Abstract">arXiv:2405.03316</a> [<a href="/pdf/2405.03316" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03316" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Provably Unlearnable Examples
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+D">Derui Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+M">Minhui Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bo Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Camtepe%2C+S">Seyit Camtepe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+L">Liming Zhu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Cryptography and Security (cs.CR)

                </div>
                <p class="mathjax">The exploitation of publicly accessible data has led to escalating concerns
                    regarding data privacy and intellectual property (IP) breaches in the age of
                    artificial intelligence. As a strategy to safeguard both data privacy and
                    IP-related domain knowledge, efforts have been undertaken to render shared data
                    unlearnable for unauthorized models in the wild. Existing methods apply
                    empirically optimized perturbations to the data in the hope of disrupting the
                    correlation between the inputs and the corresponding labels such that the data
                    samples are converted into Unlearnable Examples (UEs). Nevertheless, the
                    absence of mechanisms that can verify how robust the UEs are against unknown
                    unauthorized models and train-time techniques engenders several problems.
                    First, the empirically optimized perturbations may suffer from the problem of
                    cross-model generalization, which echoes the fact that the unauthorized models
                    are usually unknown to the defender. Second, UEs can be mitigated by train-time
                    techniques such as data augmentation and adversarial training. Furthermore, we
                    find that a simple recovery attack can restore the clean-task performance of
                    the classifiers trained on UEs by slightly perturbing the learned weights. To
                    mitigate the aforementioned problems, in this paper, we propose a mechanism for
                    certifying the so-called <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-216-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1464"
                                style="width: 2.665em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.202em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.09em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1465"><span class="mo" id="MathJax-Span-1466"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1467" style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1468"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1469"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">η<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1470"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-216">(q, \eta)</script>-Learnability of an unlearnable
                    dataset via
                    parametric smoothing. A lower certified <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-217-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1471"
                                style="width: 2.665em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.202em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.09em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1472"><span class="mo" id="MathJax-Span-1473"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1474" style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1475"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1476"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">η<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1477"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-217">(q, \eta)</script>-Learnability indicates a
                    more robust protection over the dataset. Finally, we try to 1) improve the
                    tightness of certified <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-218-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1478"
                                style="width: 2.665em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.202em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.09em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1479"><span class="mo" id="MathJax-Span-1480"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1481" style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1482"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1483"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">η<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1484"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-218">(q, \eta)</script>-Learnability and 2) design
                    Provably
                    Unlearnable Examples (PUEs) which have reduced <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-219-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1485"
                                style="width: 2.665em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.202em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.09em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1486"><span class="mo" id="MathJax-Span-1487"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1488" style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1489"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1490"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">η<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1491"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-219">(q, \eta)</script>-Learnability.
                    According to experimental results, PUEs demonstrate both decreased certified
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-220-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1492"
                                style="width: 2.665em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.202em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.09em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1493"><span class="mo" id="MathJax-Span-1494"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1495" style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1496"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1497"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">η<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1498"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-220">(q, \eta)</script>-Learnability and enhanced
                    empirical robustness compared to existing
                    UEs.
                </p>
            </div>
        </dd>
        <dt><a name="item504">[504]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03318"
                    title="Abstract">arXiv:2405.03318</a> [<a href="/pdf/2405.03318" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03318" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing DETRs Variants through Improved Content Query and
                    Similar Query Aggregation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yingying Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+C">Chuangji Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+X">Xin Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lao%2C+J">Jiangwei Lao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jian Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jiaotuan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jingdong Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 7 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Multimedia (cs.MM)

                </div>
                <p class="mathjax">The design of the query is crucial for the performance of DETR and its
                    variants. Each query consists of two components: a content part and a
                    positional one. Traditionally, the content query is initialized with a zero or
                    learnable embedding, lacking essential content information and resulting in
                    sub-optimal performance. In this paper, we introduce a novel plug-and-play
                    module, Self-Adaptive Content Query (SACQ), to address this limitation. The
                    SACQ module utilizes features from the transformer encoder to generate content
                    queries via self-attention pooling. This allows candidate queries to adapt to
                    the input image, resulting in a more comprehensive content prior and better
                    focus on target objects. However, this improved concentration poses a challenge
                    for the training process that utilizes the Hungarian matching, which selects
                    only a single candidate and suppresses other similar ones. To overcome this, we
                    propose a query aggregation strategy to cooperate with SACQ. It merges similar
                    predicted candidates from different queries, easing the optimization. Our
                    extensive experiments on the COCO dataset demonstrate the effectiveness of our
                    proposed approaches across six different DETR's variants with multiple
                    configurations, achieving an average improvement of over 1.0 AP.
                </p>
            </div>
        </dd>
        <dt><a name="item505">[505]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03320"
                    title="Abstract">arXiv:2405.03320</a> [<a href="/pdf/2405.03320" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03320" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Denoising of Geodetic Time Series Using Spatiotemporal Graph
                    Neural Networks: Application to Slow Slip Event Extraction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Costantino%2C+G">Giuseppe Costantino</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Giffard-Roisin%2C+S">Sophie Giffard-Roisin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mura%2C+M+D">Mauro Dalla Mura</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Socquet%2C+A">Anne Socquet</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Geophysics
                    (physics.geo-ph)

                </div>
                <p class="mathjax">Geospatial data has been transformative for the monitoring of the Earth, yet,
                    as in the case of (geo)physical monitoring, the measurements can have variable
                    spatial and temporal sampling and may be associated with a significant level of
                    perturbations degrading the signal quality. Denoising geospatial data is,
                    therefore, essential, yet often challenging because the observations may
                    comprise noise coming from different origins, including both environmental
                    signals and instrumental artifacts, which are spatially and temporally
                    correlated, thus hard to disentangle. This study addresses the denoising of
                    multivariate time series acquired by irregularly distributed networks of
                    sensors, requiring specific methods to handle the spatiotemporal correlation of
                    the noise and the signal of interest. Specifically, our method focuses on the
                    denoising of geodetic position time series, used to monitor ground displacement
                    worldwide with centimeter- to-millimeter precision. Among the signals affecting
                    GNSS data, slow slip events (SSEs) are of interest to seismologists. These are
                    transients of deformation that are weakly emerging compared to other signals.
                    Here, we design SSEdenoiser, a multi-station spatiotemporal graph-based
                    attentive denoiser that learns latent characteristics of GNSS noise to reveal
                    SSE-related displacement with sub-millimeter precision. It is based on the key
                    combination of graph recurrent networks and spatiotemporal Transformers. The
                    proposed method is applied to the Cascadia subduction zone, where SSEs occur
                    along with bursts of tectonic tremors, a seismic rumbling identified from
                    independent seismic recordings. The extracted events match the spatiotemporal
                    evolution of tremors. This good space-time correlation of the denoised GNSS
                    signals with the tremors validates the proposed denoising procedure.
                </p>
            </div>
        </dd>
        <dt><a name="item506">[506]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03321"
                    title="Abstract">arXiv:2405.03321</a> [<a href="/pdf/2405.03321" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03321" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Distributed Model Checking on Graphs of Bounded Treedepth
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fomin%2C+F+V">Fedor V. Fomin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fraigniaud%2C+P">Pierre Fraigniaud</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Montealegre%2C+P">Pedro Montealegre</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rapaport%2C+I">Ivan Rapaport</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Todinca%2C+I">Ioan Todinca</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>

                </div>
                <p class="mathjax">We establish that every monadic second-order logic (MSO) formula on graphs
                    with bounded treedepth is decidable in a constant number of rounds within the
                    CONGEST model. To our knowledge, this marks the first meta-theorem regarding
                    distributed model-checking. Various optimization problems on graphs are
                    expressible in MSO. Examples include determining whether a graph <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-221-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1499"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.81em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1500"><span class="mi" id="MathJax-Span-1501"
                                                style="font-family: MathJax_Math-italic;">G</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-221">G</script> has a
                    clique of size <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-222-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1502"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1503"><span class="mi" id="MathJax-Span-1504"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-222">k</script>, whether it admits a coloring with <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-223-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1505"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1506"><span class="mi" id="MathJax-Span-1507"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-223">k</script> colors, whether it
                    contains a graph <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-224-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1508"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1509"><span class="mi" id="MathJax-Span-1510"
                                                style="font-family: MathJax_Math-italic;">H<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-224">H</script> as a subgraph or minor, or whether
                    terminal vertices in
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-225-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1511"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.81em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1512"><span class="mi" id="MathJax-Span-1513"
                                                style="font-family: MathJax_Math-italic;">G</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-225">G</script> could be connected via vertex-disjoint
                    paths. Our meta-theorem
                    significantly enhances the work of Bousquet et al. [PODC 2022], which was
                    focused on distributed certification of MSO on graphs with bounded treedepth.
                    Moreover, our results can be extended to solving optimization and counting
                    problems expressible in MSO, in graphs of bounded treedepth.
                </p>
            </div>
        </dd>
        <dt><a name="item507">[507]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03322"
                    title="Abstract">arXiv:2405.03322</a> [<a href="/pdf/2405.03322" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03322" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing Aeroacoustic Wind Tunnel Studies through Massive
                    Channel Upscaling with MEMS Microphones
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ernst%2C+D">Daniel Ernst</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goudarzi%2C+A">Armin Goudarzi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Geisler%2C+R">Reinhard Geisler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Philipp%2C+F">Florian Philipp</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ahlefeldt%2C+T">Thomas Ahlefeldt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Spehr%2C+C">Carsten Spehr</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 30th AIAA/CEAS Aeroacoustics Conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio
                    and Speech Processing (eess.AS); Instrumentation and Detectors (physics.ins-det)

                </div>
                <p class="mathjax">This paper presents a large 6~m x 3~m aperture 7200 MEMS microphone array.
                    The array is designed so that sub-arrays with optimized point spread functions
                    can be used for beamforming and thus, enable the research of source directivity
                    in wind tunnel facilities. The total array consists of modular 800 microphone
                    panels, each consisting of four unique PCB board designs. This modular
                    architecture allows for the time-synchronized measurement of an arbitrary
                    number of panels and thus, aperture size and total number of sensors. The
                    panels can be installed without a gap so that the array's microphone pattern
                    avoids high sidelobes in the point spread function. The array's capabilities
                    are evaluated on a 1:9.5 airframe half model in an open wind tunnel at DNW-NWB.
                    The total source emission is quantified and the directivity is evaluated with
                    beamforming. Additional far-field microphones are employed to validate the
                    results.
                </p>
            </div>
        </dd>
        <dt><a name="item508">[508]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03326"
                    title="Abstract">arXiv:2405.03326</a> [<a href="/pdf/2405.03326" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03326" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PAFOT: A Position-Based Approach for Finding Optimal Tests of
                    Autonomous Vehicles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Crespo-Rodriguez%2C+V">Victor Crespo-Rodriguez</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Neelofar">Neelofar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Aleti%2C+A">Aldeida Aleti</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Pre-print from AST 2024 conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">Autonomous Vehicles (AVs) are prone to revolutionise the transportation
                    industry. However, they must be thoroughly tested to avoid safety violations.
                    Simulation testing plays a crucial role in finding safety violations of
                    Automated Driving Systems (ADSs). This paper proposes PAFOT, a position-based
                    approach testing framework, which generates adversarial driving scenarios to
                    expose safety violations of ADSs. We introduce a 9-position grid which is
                    virtually drawn around the Ego Vehicle (EV) and modify the driving behaviours
                    of Non-Playable Characters (NPCs) to move within this grid. PAFOT utilises a
                    single-objective genetic algorithm to search for adversarial test scenarios. We
                    demonstrate PAFOT on a well-known high-fidelity simulator, CARLA. The
                    experimental results show that PAFOT can effectively generate safety-critical
                    scenarios to crash ADSs and is able to find collisions in a short simulation
                    time. Furthermore, it outperforms other search-based testing techniques by
                    finding more safety-critical scenarios under the same driving conditions within
                    less effective simulation time.
                </p>
            </div>
        </dd>
        <dt><a name="item509">[509]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03327"
                    title="Abstract">arXiv:2405.03327</a> [<a href="/pdf/2405.03327" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03327" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Clustering of Disease Trajectories with Explainable Machine
                    Learning: A Case Study on Postoperative Delirium Phenotypes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+X">Xiaochen Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sch%C3%BCrch%2C+M">Manuel Schürch</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xingyu Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Komninou%2C+M+A">Maria Angeliki Komninou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sch%C3%BCpbach%2C+R">Reto Schüpbach</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Allam%2C+A">Ahmed Allam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bartussek%2C+J">Jan Bartussek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Krauthammer%2C+M">Michael Krauthammer</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">The identification of phenotypes within complex diseases or syndromes is a
                    fundamental component of precision medicine, which aims to adapt healthcare to
                    individual patient characteristics. Postoperative delirium (POD) is a complex
                    neuropsychiatric condition with significant heterogeneity in its clinical
                    manifestations and underlying pathophysiology. We hypothesize that POD
                    comprises several distinct phenotypes, which cannot be directly observed in
                    clinical practice. Identifying these phenotypes could enhance our understanding
                    of POD pathogenesis and facilitate the development of targeted prevention and
                    treatment strategies. In this paper, we propose an approach that combines
                    supervised machine learning for personalized POD risk prediction with
                    unsupervised clustering techniques to uncover potential POD phenotypes. We
                    first demonstrate our approach using synthetic data, where we simulate patient
                    cohorts with predefined phenotypes based on distinct sets of informative
                    features. We aim to mimic any clinical disease with our synthetic data
                    generation method. By training a predictive model and applying SHAP, we show
                    that clustering patients in the SHAP feature importance space successfully
                    recovers the true underlying phenotypes, outperforming clustering in the raw
                    feature space. We then present a case study using real-world data from a cohort
                    of elderly surgical patients. The results showcase the utility of our approach
                    in uncovering clinically relevant subtypes of complex disorders like POD,
                    paving the way for more precise and personalized treatment strategies.
                </p>
            </div>
        </dd>
        <dt><a name="item510">[510]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03328"
                    title="Abstract">arXiv:2405.03328</a> [<a href="/pdf/2405.03328" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03328" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing Spatiotemporal Disease Progression Models via
                    Latent Diffusion and Prior Knowledge
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Puglisi%2C+L">Lemuel Puglisi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alexander%2C+D+C">Daniel C. Alexander</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rav%C3%AC%2C+D">Daniele Ravì</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">In this work, we introduce Brain Latent Progression (BrLP), a novel
                    spatiotemporal disease progression model based on latent diffusion. BrLP is
                    designed to predict the evolution of diseases at the individual level on 3D
                    brain MRIs. Existing deep generative models developed for this task are
                    primarily data-driven and face challenges in learning disease progressions.
                    BrLP addresses these challenges by incorporating prior knowledge from disease
                    models to enhance the accuracy of predictions. To implement this, we propose to
                    integrate an auxiliary model that infers volumetric changes in various brain
                    regions. Additionally, we introduce Latent Average Stabilization (LAS), a novel
                    technique to improve spatiotemporal consistency of the predicted progression.
                    BrLP is trained and evaluated on a large dataset comprising 11,730 T1-weighted
                    brain MRIs from 2,805 subjects, collected from three publicly available,
                    longitudinal Alzheimer's Disease (AD) studies. In our experiments, we compare
                    the MRI scans generated by BrLP with the actual follow-up MRIs available from
                    the subjects, in both cross-sectional and longitudinal settings. BrLP
                    demonstrates significant improvements over existing methods, with an increase
                    of 22% in volumetric accuracy across AD-related brain regions and 43% in image
                    similarity to the ground-truth scans. The ability of BrLP to generate
                    conditioned 3D scans at the subject level, along with the novelty of
                    integrating prior knowledge to enhance accuracy, represents a significant
                    advancement in disease progression modeling, opening new avenues for precision
                    medicine. The code of BrLP is available at the following link:
                    https://github.com/LemuelPuglisi/BrLP.
                </p>
            </div>
        </dd>
        <dt><a name="item511">[511]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03329"
                    title="Abstract">arXiv:2405.03329</a> [<a href="/pdf/2405.03329" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03329" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Policy Learning for Balancing Short-Term and Long-Term
                    Rewards
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+P">Peng Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Z">Ziyu Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+F">Feng Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhongyao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chunchen Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+Y">Yan Zeng</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
                <p class="mathjax">Empirical researchers and decision-makers spanning various domains frequently
                    seek profound insights into the long-term impacts of interventions. While the
                    significance of long-term outcomes is undeniable, an overemphasis on them may
                    inadvertently overshadow short-term gains. Motivated by this, this paper
                    formalizes a new framework for learning the optimal policy that effectively
                    balances both long-term and short-term rewards, where some long-term outcomes
                    are allowed to be missing. In particular, we first present the identifiability
                    of both rewards under mild assumptions. Next, we deduce the semiparametric
                    efficiency bounds, along with the consistency and asymptotic normality of their
                    estimators. We also reveal that short-term outcomes, if associated, contribute
                    to improving the estimator of the long-term reward. Based on the proposed
                    estimators, we develop a principled policy learning approach and further derive
                    the convergence rates of regret and estimation errors associated with the
                    learned policy. Extensive experiments are conducted to validate the
                    effectiveness of the proposed method, demonstrating its practical
                    applicability.
                </p>
            </div>
        </dd>
        <dt><a name="item512">[512]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03333"
                    title="Abstract">arXiv:2405.03333</a> [<a href="/pdf/2405.03333" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03333" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Light-VQA+: A Video Quality Assessment Model for Exposure
                    Correction with Vision-Language Guidance
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+X">Xunchu Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xiaohong Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+Y">Yunlong Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kou%2C+T">Tengchuan Kou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yixuan Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zicheng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chunyi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Haoning Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+G">Guangtao Zhai</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Recently, User-Generated Content (UGC) videos have gained popularity in our
                    daily lives. However, UGC videos often suffer from poor exposure due to the
                    limitations of photographic equipment and techniques. Therefore, Video Exposure
                    Correction (VEC) algorithms have been proposed, Low-Light Video Enhancement
                    (LLVE) and Over-Exposed Video Recovery (OEVR) included. Equally important to
                    the VEC is the Video Quality Assessment (VQA). Unfortunately, almost all
                    existing VQA models are built generally, measuring the quality of a video from
                    a comprehensive perspective. As a result, Light-VQA, trained on LLVE-QA, is
                    proposed for assessing LLVE. We extend the work of Light-VQA by expanding the
                    LLVE-QA dataset into Video Exposure Correction Quality Assessment (VEC-QA)
                    dataset with over-exposed videos and their corresponding corrected versions. In
                    addition, we propose Light-VQA+, a VQA model specialized in assessing VEC.
                    Light-VQA+ differs from Light-VQA mainly from the usage of the CLIP model and
                    the vision-language guidance during the feature extraction, followed by a new
                    module referring to the Human Visual System (HVS) for more accurate assessment.
                    Extensive experimental results show that our model achieves the best
                    performance against the current State-Of-The-Art (SOTA) VQA models on the
                    VEC-QA dataset and other public datasets.
                </p>
            </div>
        </dd>
        <dt><a name="item513">[513]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03334"
                    title="Abstract">arXiv:2405.03334</a> [<a href="/pdf/2405.03334" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03334" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the constrained feedback linearization control based on
                    the MILP representation of a ReLU-ANN
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Do%2C+H">Huu-Thinh Do</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Prodan%2C+I">Ionela Prodan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">In this work, we explore the efficacy of rectified linear unit artificial
                    neural networks in addressing the intricate challenges of convoluted
                    constraints arising from feedback linearization mapping. Our approach involves
                    a comprehensive procedure, encompassing the approximation of constraints
                    through a regression process. Subsequently, we transform these constraints into
                    an equivalent representation of mixed-integer linear constraints, seamlessly
                    integrating them into other stabilizing control architectures. The advantage
                    resides in the compatibility with the linear control design and the constraint
                    satisfaction in the model predictive control setup, even for forecasted
                    trajectories. Simulations are provided to validate the proposed constraint
                    reformulation.
                </p>
            </div>
        </dd>
        <dt><a name="item514">[514]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03340"
                    title="Abstract">arXiv:2405.03340</a> [<a href="/pdf/2405.03340" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03340" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Functional Equivalence with NARS
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Johansson%2C+R">Robert Johansson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hammer%2C+P">Patrick Hammer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lofthouse%2C+T">Tony Lofthouse</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">This study explores the concept of functional equivalence within the
                    framework of the Non-Axiomatic Reasoning System (NARS), specifically through
                    OpenNARS for Applications (ONA). Functional equivalence allows organisms to
                    categorize and respond to varied stimuli based on their utility rather than
                    perceptual similarity, thus enhancing cognitive efficiency and adaptability. In
                    this study, ONA was modified to allow the derivation of functional equivalence.
                    This paper provides practical examples of the capability of ONA to apply
                    learned knowledge across different functional situations, demonstrating its
                    utility in complex problem-solving and decision-making. An extended example is
                    included, where training of ONA aimed to learn basic human-like language
                    abilities, using a systematic procedure in relating spoken words, objects and
                    written words. The research carried out as part of this study extends the
                    understanding of functional equivalence in AGI systems, and argues for its
                    necessity for level of flexibility in learning and adapting necessary for
                    human-level AGI.
                </p>
            </div>
        </dd>
        <dt><a name="item515">[515]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03341"
                    title="Abstract">arXiv:2405.03341</a> [<a href="/pdf/2405.03341" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03341" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing Q-Learning with Large Language Model Heuristics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xiefeng Wu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a
                        href="/abs/2009.06799">arXiv:2009.06799</a> by other authors
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Q-learning excels in learning from feedback within sequential decision-making
                    tasks but requires extensive sampling for significant improvements. Although
                    reward shaping is a powerful technique for enhancing learning efficiency, it
                    can introduce biases that affect agent performance. Furthermore,
                    potential-based reward shaping is constrained as it does not allow for reward
                    modifications based on actions or terminal states, potentially limiting its
                    effectiveness in complex environments. Additionally, large language models
                    (LLMs) can achieve zero-shot learning, but this is generally limited to simpler
                    tasks. They also exhibit low inference speeds and occasionally produce
                    hallucinations. To address these issues, we propose \textbf{LLM-guided
                    Q-learning} that employs LLMs as heuristic to aid in learning the Q-function
                    for reinforcement learning. It combines the advantages of both technologies
                    without introducing performance bias. Our theoretical analysis demonstrates
                    that the LLM heuristic provides action-level guidance. Additionally, our
                    architecture has the capability to convert the impact of hallucinations into
                    exploration costs. Moreover, the converged Q function corresponds to the MDP
                    optimal Q function. Experiment results demonstrated that our algorithm enables
                    agents to avoid ineffective exploration, enhances sampling efficiency, and is
                    well-suited for complex control tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item516">[516]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03342"
                    title="Abstract">arXiv:2405.03342</a> [<a href="/pdf/2405.03342" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03342" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Doubly Robust Causal Effect Estimation under Networked
                    Interference via Targeted Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+W">Weilin Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+R">Ruichu Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zeqin Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiao%2C+J">Jie Qiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Y">Yuguang Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zijian Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hao%2C+Z">Zhifeng Hao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Causal effect estimation under networked interference is an important but
                    challenging problem. Available parametric methods are limited in their model
                    space, while previous semiparametric methods, e.g., leveraging neural networks
                    to fit only one single nuisance function, may still encounter misspecification
                    problems under networked interference without appropriate assumptions on the
                    data generation process. To mitigate bias stemming from misspecification, we
                    propose a novel doubly robust causal effect estimator under networked
                    interference, by adapting the targeted learning technique to the training of
                    neural networks. Specifically, we generalize the targeted learning technique
                    into the networked interference setting and establish the condition under which
                    an estimator achieves double robustness. Based on the condition, we devise an
                    end-to-end causal effect estimator by transforming the identified theoretical
                    condition into a targeted loss. Moreover, we provide a theoretical analysis of
                    our designed estimator, revealing a faster convergence rate compared to a
                    single nuisance model. Extensive experimental results on two real-world
                    networks with semisynthetic data demonstrate the effectiveness of our proposed
                    estimators.
                </p>
            </div>
        </dd>
        <dt><a name="item517">[517]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03343"
                    title="Abstract">arXiv:2405.03343</a> [<a href="/pdf/2405.03343" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03343" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An efficient hierarchical Bayesian method for the Kuopio
                    tomography challenge 2023
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Pragliola%2C+M">Monica Pragliola</a>,
                    <a href="/search/math?searchtype=author&amp;query=Calvetti%2C+D">Daniela Calvetti</a>,
                    <a href="/search/math?searchtype=author&amp;query=Somersalo%2C+E">Erkki Somersalo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">The aim of Electrical Impedance Tomography (EIT) is to determine the
                    electrical conductivity distribution inside a domain by applying currents and
                    measuring voltages on its boundary. Mathematically, the EIT reconstruction task
                    can be formulated as a non-linear inverse problem. The Bayesian inverse
                    problems framework has been applied expensively to solutions of the EIT inverse
                    problem, in particular in the cases when the unknown conductivity is believed
                    to be blocky. Recently, the Sparsity Promoting Iterative Alternating Sequential
                    (PS-IAS) algorithm, originally proposed for the solution of linear inverse
                    problems, has been adapted for the non linear case of EIT reconstruction in a
                    computationally efficient manner. Here we introduce a hybrid version of the
                    SP-IAS algorithms for the nonlinear EIT inverse problem, providing a detailed
                    description of the implementation details, with a specific focus on parameters
                    selection. The method is applied to the 2023 Kuopio Tomography Challenge
                    dataset, with a comprehensive report of the running times for the different
                    cases and parameter selections.
                </p>
            </div>
        </dd>
        <dt><a name="item518">[518]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03345"
                    title="Abstract">arXiv:2405.03345</a> [<a href="/pdf/2405.03345" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03345" title="Download PostScript">ps</a>, <a href="/format/2405.03345"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FAIR 2.0: Extending the FAIR Guiding Principles to Address
                    Semantic Interoperability
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Vogt%2C+L">Lars Vogt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Str%C3%B6mert%2C+P">Philip Strömert</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matentzoglu%2C+N">Nicolas Matentzoglu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Karam%2C+N">Naouel Karam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Konrad%2C+M">Marcel Konrad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Prinz%2C+M">Manuel Prinz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baum%2C+R">Roman Baum</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

                </div>
                <p class="mathjax">FAIR data presupposes their successful communication between machines and
                    humans while preserving their meaning and reference, requiring all parties
                    involved to share the same background knowledge. Inspired by English as a
                    natural language, we investigate the linguistic structure that ensures reliable
                    communication of information and draw parallels with data structures,
                    understanding both as models of systems of interest. We conceptualize semantic
                    interoperability as comprising terminological and propositional
                    interoperability. The former includes ontological (i.e., same meaning) and
                    referential (i.e., same referent/extension) interoperability and the latter
                    schema (i.e., same data schema) and logical (i.e., same logical framework)
                    interoperability. Since no best ontology and no best data schema exists,
                    establishing semantic interoperability and FAIRness of data and metadata
                    requires the provision of a comprehensive set of relevant ontological and
                    referential entity mappings and schema crosswalks. We therefore propose
                    appropriate additions to the FAIR Guiding Principles, leading to FAIR 2.0.
                    Furthermore, achieving FAIRness of data requires the provision of FAIR services
                    in addition to organizing data into FAIR Digital Objects. FAIR services include
                    a terminology, a schema, and an operations service.
                </p>
            </div>
        </dd>
        <dt><a name="item519">[519]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03348"
                    title="Abstract">arXiv:2405.03348</a> [<a href="/pdf/2405.03348" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03348" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Evolution of the 5G New Radio Two-Step Random Access towards
                    6G Unsourced MAC
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Agostini%2C+P">Patrick Agostini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chamberland%2C+J">Jean-Francois Chamberland</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Clazzer%2C+F">Federico Clazzer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dommel%2C+J">Johannes Dommel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liva%2C+G">Gianluigi Liva</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Munari%2C+A">Andrea Munari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Narayanan%2C+K">Krishna Narayanan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Polyanskiy%2C+Y">Yury Polyanskiy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stanczak%2C+S">Slawomir Stanczak</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Utkovski%2C+Z">Zoran Utkovski</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Version 1.0 of the report
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">This report summarizes some considerations on possible evolutions of
                    grant-free random access in the next generation of the 3GPP wireless cellular
                    standard. The analysis is carried out by mapping the problem to the
                    recently-introduced unsourced multiple access channel (UMAC) setup. By doing
                    so, the performance of existing solutions can be benchmarked with
                    information-theoretic bounds, assessing the potential gains that can be
                    achieved over legacy 3GPP schemes. The study focuses on the two-step random
                    access (2SRA) protocol introduced by Release 16 of the 5G New Radio standard,
                    investigating its applicability to support large MTC / IoT terminal populations
                    in a grant-free fashion. The analysis shows that the existing 2SRA scheme may
                    not succeed in providing energy-efficient support to large user populations.
                    Modifications to the protocol are proposed that enable remarkable gains in both
                    energy and spectral efficiency while retaining a strong resemblance to the
                    legacy protocol.
                </p>
            </div>
        </dd>
        <dt><a name="item520">[520]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03349"
                    title="Abstract">arXiv:2405.03349</a> [<a href="/pdf/2405.03349" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03349" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Retinexmamba: Retinex-based Mamba for Low-light Image
                    Enhancement
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bai%2C+J">Jiesong Bai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yin%2C+Y">Yuhao Yin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+Q">Qiyuan He</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">In the field of low-light image enhancement, both traditional Retinex methods
                    and advanced deep learning techniques such as Retinexformer have shown distinct
                    advantages and limitations. Traditional Retinex methods, designed to mimic the
                    human eye's perception of brightness and color, decompose images into
                    illumination and reflection components but struggle with noise management and
                    detail preservation under low light conditions. Retinexformer enhances
                    illumination estimation through traditional self-attention mechanisms, but
                    faces challenges with insufficient interpretability and suboptimal enhancement
                    effects. To overcome these limitations, this paper introduces the RetinexMamba
                    architecture. RetinexMamba not only captures the physical intuitiveness of
                    traditional Retinex methods but also integrates the deep learning framework of
                    Retinexformer, leveraging the computational efficiency of State Space Models
                    (SSMs) to enhance processing speed. This architecture features innovative
                    illumination estimators and damage restorer mechanisms that maintain image
                    quality during enhancement. Moreover, RetinexMamba replaces the IG-MSA
                    (Illumination-Guided Multi-Head Attention) in Retinexformer with a
                    Fused-Attention mechanism, improving the model's interpretability. Experimental
                    evaluations on the LOL dataset show that RetinexMamba outperforms existing deep
                    learning approaches based on Retinex theory in both quantitative and
                    qualitative metrics, confirming its effectiveness and superiority in enhancing
                    low-light images.
                </p>
            </div>
        </dd>
        <dt><a name="item521">[521]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03351"
                    title="Abstract">arXiv:2405.03351</a> [<a href="/pdf/2405.03351" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03351" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Modality Prompts for Arbitrary Modality Salient Object
                    Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+N">Nianchang Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yang Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qiang Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+J">Jungong Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jin Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages, 7 Figures, 3 Tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">This paper delves into the task of arbitrary modality salient object
                    detection (AM SOD), aiming to detect salient objects from arbitrary modalities,
                    eg RGB images, RGB-D images, and RGB-D-T images. A novel modality-adaptive
                    Transformer (MAT) will be proposed to investigate two fundamental challenges of
                    AM SOD, ie more diverse modality discrepancies caused by varying modality types
                    that need to be processed, and dynamic fusion design caused by an uncertain
                    number of modalities present in the inputs of multimodal fusion strategy.
                    Specifically, inspired by prompt learning's ability of aligning the
                    distributions of pre-trained models to the characteristic of downstream tasks
                    by learning some prompts, MAT will first present a modality-adaptive feature
                    extractor (MAFE) to tackle the diverse modality discrepancies by introducing a
                    modality prompt for each modality. In the training stage, a new modality
                    translation contractive (MTC) loss will be further designed to assist MAFE in
                    learning those modality-distinguishable modality prompts. Accordingly, in the
                    testing stage, MAFE can employ those learned modality prompts to adaptively
                    adjust its feature space according to the characteristics of the input
                    modalities, thus being able to extract discriminative unimodal features. Then,
                    MAFE will present a channel-wise and spatial-wise fusion hybrid (CSFH) strategy
                    to meet the demand for dynamic fusion. For that, CSFH dedicates a channel-wise
                    dynamic fusion module (CDFM) and a novel spatial-wise dynamic fusion module
                    (SDFM) to fuse the unimodal features from varying numbers of modalities and
                    meanwhile effectively capture cross-modal complementary semantic and detail
                    information, respectively. Moreover, CSFH will carefully align CDFM and SDFM to
                    different levels of unimodal features based on their characteristics for more
                    effective complementary information exploitation.
                </p>
            </div>
        </dd>
        <dt><a name="item522">[522]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03352"
                    title="Abstract">arXiv:2405.03352</a> [<a href="/pdf/2405.03352" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03352" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Salient Object Detection From Arbitrary Modalities
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+N">Nianchang Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yang Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xi%2C+R">Ruida Xi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qiang Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+J">Jungong Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jin Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 Pages, 7 Figures, 8 Tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Toward desirable saliency prediction, the types and numbers of inputs for a
                    salient object detection (SOD) algorithm may dynamically change in many
                    real-life applications. However, existing SOD algorithms are mainly designed or
                    trained for one particular type of inputs, failing to be generalized to other
                    types of inputs. Consequentially, more types of SOD algorithms need to be
                    prepared in advance for handling different types of inputs, raising huge
                    hardware and research costs. Differently, in this paper, we propose a new type
                    of SOD task, termed Arbitrary Modality SOD (AM SOD). The most prominent
                    characteristics of AM SOD are that the modality types and modality numbers will
                    be arbitrary or dynamically changed. The former means that the inputs to the AM
                    SOD algorithm may be arbitrary modalities such as RGB, depths, or even any
                    combination of them. While, the latter indicates that the inputs may have
                    arbitrary modality numbers as the input type is changed, e.g. single-modality
                    RGB image, dual-modality RGB-Depth (RGB-D) images or triple-modality
                    RGB-Depth-Thermal (RGB-D-T) images. Accordingly, a preliminary solution to the
                    above challenges, \i.e. a modality switch network (MSN), is proposed in this
                    paper. In particular, a modality switch feature extractor (MSFE) is first
                    designed to extract discriminative features from each modality effectively by
                    introducing some modality indicators, which will generate some weights for
                    modality switching. Subsequently, a dynamic fusion module (DFM) is proposed to
                    adaptively fuse features from a variable number of modalities based on a novel
                    Transformer structure. Finally, a new dataset, named AM-XD, is constructed to
                    facilitate research on AM SOD. Extensive experiments demonstrate that our AM
                    SOD method can effectively cope with changes in the type and number of input
                    modalities for robust salient object detection.
                </p>
            </div>
        </dd>
        <dt><a name="item523">[523]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03353"
                    title="Abstract">arXiv:2405.03353</a> [<a href="/pdf/2405.03353" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03353" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Markov Chain-based Optimization Time Analysis of Bivalent Ant
                    Colony Optimization for Sorting and LeadingOnes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kerga%C3%9Fner%2C+M">Matthias Kergaßner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Keszocze%2C+O">Oliver Keszocze</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wanka%2C+R">Rolf Wanka</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Computational Complexity (cs.CC)

                </div>
                <p class="mathjax">So far, only few bounds on the runtime behavior of Ant Colony Optimization
                    (ACO) have been reported. To alleviate this situation, we investigate the ACO
                    variant we call Bivalent ACO (BACO) that uses exactly two pheromone values. We
                    provide and successfully apply a new Markov chain-based approach to calculate
                    the expected optimization time, i. e., the expected number of iterations until
                    the algorithm terminates. This approach allows to derive exact formulae for the
                    expected optimization time for the problems Sorting and LeadingOnes. It turns
                    out that the ratio of the two pheromone values significantly governs the
                    runtime behavior of BACO. To the best of our knowledge, for the first time, we
                    can present tight bounds for Sorting (<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-226-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1514"
                                style="width: 3.128em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.607em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1002.49em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1515"><span class="mi" id="MathJax-Span-1516"
                                                style="font-family: MathJax_Main;">Θ</span><span class="mo"
                                                id="MathJax-Span-1517" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-1518"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1519"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-1520"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1521"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-226">\Theta(n^3)</script>) with a specifically chosen
                    objective function and prove the missing lower bound <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-227-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1522"
                                style="width: 3.07em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.549em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1002.43em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1523"><span class="mi" id="MathJax-Span-1524"
                                                style="font-family: MathJax_Main;">Ω</span><span class="mo"
                                                id="MathJax-Span-1525" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-1526"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1527"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-1528"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1529"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-227">\Omega(n^2)</script> for
                    LeadingOnes which, thus, is tightly bounded by <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-228-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1530"
                                style="width: 3.128em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.607em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1002.49em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1531"><span class="mi" id="MathJax-Span-1532"
                                                style="font-family: MathJax_Main;">Θ</span><span class="mo"
                                                id="MathJax-Span-1533" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-1534"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1535"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-1536"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1537"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-228">\Theta(n^2)</script>. We show that
                    despite we have a drastically simplified ant algorithm with respect to the
                    influence of the pheromones on the solving process, known bounds on the
                    expected optimization time for the problems OneMax (<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-229-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1538"
                                style="width: 5.327em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.401em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.28em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1539"><span class="mi" id="MathJax-Span-1540"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-1541" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-1542"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mi"
                                                id="MathJax-Span-1543"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">log</span><span
                                                class="mo" id="MathJax-Span-1544"></span><span class="mi"
                                                id="MathJax-Span-1545"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="mo" id="MathJax-Span-1546"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-229">O(n\log n)</script>) and
                    LeadingOnes (<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-230-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1547"
                                style="width: 3.128em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.607em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1002.49em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1548"><span class="mi" id="MathJax-Span-1549"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-1550" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-1551"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1552"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-1553"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1554"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-230">O(n^2)</script>) can be re-produced as a by-product
                    of our approach.
                    Experiments validate our theoretical findings.
                </p>
            </div>
        </dd>
        <dt><a name="item524">[524]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03354"
                    title="Abstract">arXiv:2405.03354</a> [<a href="/pdf/2405.03354" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03354" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> VACO: a Multi-perspective Development of a Therapeutic and
                    Motivational Virtual Robotic Agent for Concentration for children with ADHD
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Richter%2C+B">Birte Richter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Petras%2C+I">Ira-Katharina Petras</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vollmer%2C+A">Anna-Lisa Vollmer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luong%2C+A">Ayla Luong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Siniatchkin%2C+M">Michael Siniatchkin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wrede%2C+B">Britta Wrede</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">In this work, we present (i) a novel approach how artificial intelligence can
                    support in the therapy for better concentration of children with Attention
                    Deficit Hyperactivity Disorder (ADHD) through motivational attention training
                    with a virtual robotic agent and (ii) a development process in which different
                    stakeholders are included with their perspectives. Therefore, we present three
                    participative approaches to include the perspectives of different stakeholders.
                    An online survey (Study I) was conducted with parents in Germany with the aim
                    of ascertaining whether they would use software to promote their children's
                    attention, what influences their attitude towards using it, and what
                    requirements it would have to meet. About half of the parents would be willing
                    to use software to promote attention. To develop the software as close to
                    practice as possible, one of the developers took part in an intensive training
                    for ADHD with the aim of testing which of the elements are technically
                    feasible. Afterward, a first prototype was presented to clinicians (Study II)
                    to make further adjustments. A first feasibility test (Study III) was conducted
                    with the end users to check if the system works and if children and adolescents
                    can use it. Attentional performance software offers multiple opportunities in
                    the treatment of ADHD if the system is adapted to the needs of the practitioner
                    and end user. This development process requires a lot of time and close
                    interdisciplinary collaboration.
                </p>
            </div>
        </dd>
        <dt><a name="item525">[525]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03355"
                    title="Abstract">arXiv:2405.03355</a> [<a href="/pdf/2405.03355" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03355" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the Theory of Cross-Modality Distillation with Contrastive
                    Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+H">Hangyu Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chen Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Chengming Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zhengqi Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yanwei Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yuan Yao</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Cross-modality distillation arises as an important topic for data modalities
                    containing limited knowledge such as depth maps and high-quality sketches. Such
                    techniques are of great importance, especially for memory and
                    privacy-restricted scenarios where labeled training data is generally
                    unavailable. To solve the problem, existing label-free methods leverage a few
                    pairwise unlabeled data to distill the knowledge by aligning features or
                    statistics between the source and target modalities. For instance, one
                    typically aims to minimize the L2 distance or contrastive loss between the
                    learned features of pairs of samples in the source (e.g. image) and the target
                    (e.g. sketch) modalities. However, most algorithms in this domain only focus on
                    the experimental results but lack theoretical insight. To bridge the gap
                    between the theory and practical method of cross-modality distillation, we
                    first formulate a general framework of cross-modality contrastive distillation
                    (CMCD), built upon contrastive learning that leverages both positive and
                    negative correspondence, towards a better distillation of generalizable
                    features. Furthermore, we establish a thorough convergence analysis that
                    reveals that the distance between source and target modalities significantly
                    impacts the test error on downstream tasks within the target modality which is
                    also validated by the empirical results. Extensive experimental results show
                    that our algorithm outperforms existing algorithms consistently by a margin of
                    2-3\% across diverse modalities and tasks, covering modalities of image,
                    sketch, depth map, and audio and tasks of recognition and segmentation.
                </p>
            </div>
        </dd>
        <dt><a name="item526">[526]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03356"
                    title="Abstract">arXiv:2405.03356</a> [<a href="/pdf/2405.03356" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03356" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Overview of Intelligent Meta-surfaces for 6G and Beyond:
                    Opportunities, Trends, and Challenges
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Katwe%2C+M">Mayur Katwe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kaushik%2C+A">Aryan Kaushik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mohjazi%2C+L">Lina Mohjazi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abualhayja%27a%2C+M">Mohammad Abualhayja'a</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dardari%2C+D">Davide Dardari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singh%2C+K">Keshav Singh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Imran%2C+M+A">Muhammad Ali Imran</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Butt%2C+M+M">M. Majid Butt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dobre%2C+O+A">Octavia A. Dobre</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>; Signal Processing (eess.SP)

                </div>
                <p class="mathjax">With the impending arrival of the sixth generation (6G) of wireless
                    communication technology, the telecommunications landscape is poised for
                    another revolutionary transformation. At the forefront of this evolution are
                    intelligent meta-surfaces (IS), emerging as a disruptive physical layer
                    technology with the potential to redefine the capabilities and performance
                    metrics of future wireless networks. As 6G evolves from concept to reality,
                    industry stakeholders, standards organizations, and regulatory bodies are
                    collaborating to define the specifications, protocols, and interoperability
                    standards governing IS deployment. Against this background, this article delves
                    into the ongoing standardization efforts, emerging trends, potential
                    opportunities, and prevailing challenges surrounding the integration of IS into
                    the framework of 6G and beyond networks. Specifically, it provides a
                    tutorial-style overview of recent advancements in IS and explores their
                    potential applications within future networks beyond 6G. Additionally, the
                    article identifies key challenges in the design and implementation of various
                    types of intelligent surfaces, along with considerations for their practical
                    standardization. Finally, it highlights potential future prospects in this
                    evolving field.
                </p>
            </div>
        </dd>
        <dt><a name="item527">[527]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03357"
                    title="Abstract">arXiv:2405.03357</a> [<a href="/pdf/2405.03357" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03357" title="Download PostScript">ps</a>, <a href="/format/2405.03357"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Game Theoretic Analysis of Validator Strategies in Ethereum
                    2.0
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Chien-Chih Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Golab%2C+W">Wojciech Golab</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This work has been accepted for publication in BSCI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>

                </div>
                <p class="mathjax">Ethereum 2.0 is the second-largest cryptocurrency by market capitalization
                    and a widely used smart contract platform. Therefore, examining the reliability
                    of Ethereum 2.0's incentive mechanism is crucial, particularly its
                    effectiveness in encouraging validators to adhere to the Ethereum 2.0's
                    protocol. This paper studies the incentive mechanism of Ethereum 2.0 and
                    evaluates its robustness by analyzing the interaction between block proposers
                    and attesters in a single slot. To this end, we use Bayesian games to model the
                    strategies of block proposers and attesters and calculate their expected
                    utilities. Our results demonstrate that the Ethereum 2.0 incentive mechanism is
                    incentive-compatible and promotes cooperation among validators. We prove that a
                    Bayesian Nash equilibrium and an ex ante dominant strategy exist between the
                    block proposer and attesters in a single slot. Our research provides a solid
                    foundation for further analysis of Ethereum 2.0's incentive mechanism and
                    insights for individuals considering participation as a validator in Ethereum
                    2.0.
                </p>
            </div>
        </dd>
        <dt><a name="item528">[528]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03358"
                    title="Abstract">arXiv:2405.03358</a> [<a href="/pdf/2405.03358" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03358" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Pinching Tactile Display: A Cloth that Changes Tactile
                    Sensation by Electrostatic Adsorption
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kitagishi%2C+T">Takekazu Kitagishi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hiraki%2C+H">Hirotaka Hiraki</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nakamura%2C+H">Hiromi Nakamura</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ishiguro%2C+Y">Yoshio Ishiguro</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rekimoto%2C+J">Jun Rekimoto</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 7 figures, International Conference on Advanced
                    Visual Interfaces 2024 (AVI 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Hardware Architecture (cs.AR)

                </div>
                <p class="mathjax">Haptic displays play an important role in enhancing the sense of presence in
                    VR and telepresence. Displaying the tactile properties of fabrics has potential
                    in the fashion industry, but there are difficulties in dynamically displaying
                    different types of tactile sensations while maintaining their flexible
                    properties. The vibrotactile stimulation of fabrics is an important element in
                    the tactile properties of fabrics, as it greatly affects the way a garment
                    feels when rubbed against the skin. To dynamically change the vibrotactile
                    stimuli, many studies have used mechanical actuators. However, when combined
                    with fabric, the soft properties of the fabric are compromised by the stiffness
                    of the actuator. In addition, because the vibration generated by such actuators
                    is applied to a single point, it is not possible to provide a uniform tactile
                    sensation over the entire surface of the fabric, resulting in an uneven tactile
                    sensation. In this study, we propose a Pinching Tactile Display: a conductive
                    cloth that changes the tactile sensation by controlling electrostatic
                    adsorption. By controlling the voltage and frequency applied to the conductive
                    cloth, different tactile sensations can be dynamically generated. This makes it
                    possible to create a tactile device in which tactile sensations are applied to
                    the entire fabric while maintaining the thin and soft characteristics of the
                    fabric. As a result, users could experiment with tactile sensations by picking
                    up and rubbing the fabric in the same way they normally touch it. This
                    mechanism has the potential for dynamic tactile transformation of soft
                    materials.
                </p>
            </div>
        </dd>
        <dt><a name="item529">[529]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03359"
                    title="Abstract">arXiv:2405.03359</a> [<a href="/pdf/2405.03359" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03359" title="Download PostScript">ps</a>, <a href="/format/2405.03359"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MedDoc-Bot: A Chat Tool for Comparative Analysis of Large
                    Language Models in the Context of the Pediatric Hypertension Guideline
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jabarulla%2C+M+Y">Mohamed Yaseen Jabarulla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Oeltze-Jafra%2C+S">Steffen Oeltze-Jafra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Beerbaum%2C+P">Philipp Beerbaum</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Uden%2C+T">Theodor Uden</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> {copyright} 2024 IEEE. This work has been accepted for
                    publication and presentation at the 46th Annual International Conference of the IEEE Engineering in
                    Medicine and Biology Society, to be held in Orlando, Florida, USA, July 15-19, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

                </div>
                <p class="mathjax">This research focuses on evaluating the non-commercial open-source large
                    language models (LLMs) Meditron, MedAlpaca, Mistral, and Llama-2 for their
                    efficacy in interpreting medical guidelines saved in PDF format. As a specific
                    test scenario, we applied these models to the guidelines for hypertension in
                    children and adolescents provided by the European Society of Cardiology (ESC).
                    Leveraging Streamlit, a Python library, we developed a user-friendly medical
                    document chatbot tool (MedDoc-Bot). This tool enables authorized users to
                    upload PDF files and pose questions, generating interpretive responses from
                    four locally stored LLMs. A pediatric expert provides a benchmark for
                    evaluation by formulating questions and responses extracted from the ESC
                    guidelines. The expert rates the model-generated responses based on their
                    fidelity and relevance. Additionally, we evaluated the METEOR and chrF metric
                    scores to assess the similarity of model responses to reference answers. Our
                    study found that Llama-2 and Mistral performed well in metrics evaluation.
                    However, Llama-2 was slower when dealing with text and tabular data. In our
                    human evaluation, we observed that responses created by Mistral, Meditron, and
                    Llama-2 exhibited reasonable fidelity and relevance. This study provides
                    valuable insights into the strengths and limitations of LLMs for future
                    developments in medical document interpretation. Open-Source Code:
                    https://github.com/yaseen28/MedDoc-Bot
                </p>
            </div>
        </dd>
        <dt><a name="item530">[530]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03360"
                    title="Abstract">arXiv:2405.03360</a> [<a href="/pdf/2405.03360" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03360" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Embedded Distributed Inference of Deep Neural Networks: A
                    Systematic Review
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Peccia%2C+F+N">Federico Nicolás Peccia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bringmann%2C+O">Oliver Bringmann</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 32 pages, 12 tables, 11 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>

                </div>
                <p class="mathjax">Embedded distributed inference of Neural Networks has emerged as a promising
                    approach for deploying machine-learning models on resource-constrained devices
                    in an efficient and scalable manner. The inference task is distributed across a
                    network of embedded devices, with each device contributing to the overall
                    computation by performing a portion of the workload. In some cases, more
                    powerful devices such as edge or cloud servers can be part of the system to be
                    responsible of the most demanding layers of the network. As the demand for
                    intelligent systems and the complexity of the deployed neural network models
                    increases, this approach is becoming more relevant in a variety of applications
                    such as robotics, autonomous vehicles, smart cities, Industry 4.0 and smart
                    health. We present a systematic review of papers published during the last six
                    years which describe techniques and methods to distribute Neural Networks
                    across these kind of systems. We provide an overview of the current
                    state-of-the-art by analysing more than 100 papers, present a new taxonomy to
                    characterize them, and discuss trends and challenges in the field.
                </p>
            </div>
        </dd>
        <dt><a name="item531">[531]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03361"
                    title="Abstract">arXiv:2405.03361</a> [<a href="/pdf/2405.03361" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03361" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Secure Semantic Communication over Wiretap Channel
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kozlov%2C+D">Denis Kozlov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mirmohseni%2C+M">Mahtab Mirmohseni</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tafazolli%2C+R">Rahim Tafazolli</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">Semantic communication, an emerging feature for future networks like 6G,
                    emphasizes message meaning. Yet, the open nature of a wireless channel poses
                    security risks for semantic communications. In this paper we derive
                    information-theoretic limits, considering the semantic source model within a
                    wiretap channel framework. Under separate equivocation and distortion
                    conditions for semantics and observed data, we present the general outer and
                    inner bounds of the region. We also reduce the general region to a case of
                    Gaussian source and channel and provide numerical evaluation.
                </p>
            </div>
        </dd>
        <dt><a name="item532">[532]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03363"
                    title="Abstract">arXiv:2405.03363</a> [<a href="/pdf/2405.03363" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03363" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Telextiles: End-to-end Remote Transmission of Fabric Tactile
                    Sensation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kitagishi%2C+T">Takekazu Kitagishi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hiroi%2C+Y">Yuichi Hiroi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Watanabe%2C+Y">Yuna Watanabe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Itoh%2C+Y">Yuta Itoh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rekimoto%2C+J">Jun Rekimoto</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 8 figures, Proceedings of the 36th Annual ACM
                    Symposium on User Interface Software and Technology
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Proceedings of the 36th Annual ACM Symposium on User
                    Interface
                    Software and Technology (2023)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">The tactile sensation of textiles is critical in determining the comfort of
                    clothing. For remote use, such as online shopping, users cannot physically
                    touch the textile of clothes, making it difficult to evaluate its tactile
                    sensation. Tactile sensing and actuation devices are required to transmit the
                    tactile sensation of textiles. The sensing device needs to recognize different
                    garments, even with hand-held sensors. In addition, the existing actuation
                    device can only present a limited number of known patterns and cannot transmit
                    unknown tactile sensations of textiles. To address these issues, we propose
                    Telextiles, an interface that can remotely transmit tactile sensations of
                    textiles by creating a latent space that reflects the proximity of textiles
                    through contrastive self-supervised learning. We confirm that textiles with
                    similar tactile features are located close to each other in the latent space
                    through a two-dimensional plot. We then compress the latent features for known
                    textile samples into the 1D distance and apply the 16 textile samples to the
                    rollers in the order of the distance. The roller is rotated to select the
                    textile with the closest feature if an unknown textile is detected.
                </p>
            </div>
        </dd>
        <dt><a name="item533">[533]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03367"
                    title="Abstract">arXiv:2405.03367</a> [<a href="/pdf/2405.03367" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03367" title="Download PostScript">ps</a>, <a href="/format/2405.03367"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the (In-)Completeness of Destructive Equality Resolution
                    in the Superposition Calculus
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Waldmann%2C+U">Uwe Waldmann</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 22 pages; shortened version to appear in Proc. IJCAR 2024,
                    Springer
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>

                </div>
                <p class="mathjax">Bachmair's and Ganzinger's abstract redundancy concept for the Superposition
                    Calculus justifies almost all operations that are used in superposition provers
                    to delete or simplify clauses, and thus to keep the clause set manageable.
                    Typical examples are tautology deletion, subsumption deletion, and
                    demodulation, and with a more refined definition of redundancy joinability and
                    connectedness can be covered as well. The notable exception is Destructive
                    Equality Resolution, that is, the replacement of a clause <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-231-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1555"
                                style="width: 5.095em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.227em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1004.23em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1556"><span class="mi" id="MathJax-Span-1557"
                                                style="font-family: MathJax_Math-italic;">x</span><span class="mo"
                                                id="MathJax-Span-1558"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≉</span><span
                                                class="mi" id="MathJax-Span-1559"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">t</span><span
                                                class="mo" id="MathJax-Span-1560"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">∨</span><span
                                                class="mi" id="MathJax-Span-1561"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">C<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-231">x \not\approx t \lor
    C</script> with <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-232-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1562"
                                style="width: 5.79em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.806em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1004.69em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1563"><span class="mi" id="MathJax-Span-1564"
                                                style="font-family: MathJax_Math-italic;">x</span><span class="mo"
                                                id="MathJax-Span-1565"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∉</span><span
                                                class="texatom" id="MathJax-Span-1566"
                                                style="padding-left: 0.292em;"><span class="mrow"
                                                    id="MathJax-Span-1567"><span class="mi" id="MathJax-Span-1568"
                                                        style="font-family: MathJax_Main;">v</span><span class="mi"
                                                        id="MathJax-Span-1569"
                                                        style="font-family: MathJax_Main;">a</span><span class="mi"
                                                        id="MathJax-Span-1570"
                                                        style="font-family: MathJax_Main;">r</span><span class="mi"
                                                        id="MathJax-Span-1571"
                                                        style="font-family: MathJax_Main;">s</span></span></span><span
                                                class="mo" id="MathJax-Span-1572"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-1573"
                                                style="font-family: MathJax_Math-italic;">t</span><span class="mo"
                                                id="MathJax-Span-1574"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-232">x \notin \mathrm{vars}(t)</script> by <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-233-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1575"
                                style="width: 5.153em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.285em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.23em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1576"><span class="mi" id="MathJax-Span-1577"
                                                style="font-family: MathJax_Math-italic;">C<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="mo" id="MathJax-Span-1578"
                                                style="font-family: MathJax_Main;">{</span><span class="mi"
                                                id="MathJax-Span-1579"
                                                style="font-family: MathJax_Math-italic;">x</span><span class="mo"
                                                id="MathJax-Span-1580"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">↦</span><span
                                                class="mi" id="MathJax-Span-1581"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">t</span><span
                                                class="mo" id="MathJax-Span-1582"
                                                style="font-family: MathJax_Main;">}</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-233">C\{x \mapsto t\}</script>. This operation is
                    implemented in state-of-the-art provers, and it is clearly useful in practice,
                    but little is known about how it affects refutational completeness. We
                    demonstrate on the one hand that the naive addition of Destructive Equality
                    Resolution to the standard abstract redundancy concept renders the calculus
                    refutationally incomplete. On the other hand, we present several restricted
                    variants of the Superposition Calculus that are refutationally complete even
                    with Destructive Equality Resolution.
                </p>
            </div>
        </dd>
        <dt><a name="item534">[534]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03371"
                    title="Abstract">arXiv:2405.03371</a> [<a href="/pdf/2405.03371" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03371" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Explainable Fake News Detection With Large Language Model via
                    Defense Among Competing Wisdom
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bo Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+J">Jing Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+H">Hongzhan Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhiwei Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+R">Ruichao Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yuan Tian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+Y">Yi Chang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, WWW'2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Most fake news detection methods learn latent feature representations based
                    on neural networks, which makes them black boxes to classify a piece of news
                    without giving any justification. Existing explainable systems generate
                    veracity justifications from investigative journalism, which suffer from
                    debunking delayed and low efficiency. Recent studies simply assume that the
                    justification is equivalent to the majority opinions expressed in the wisdom of
                    crowds. However, the opinions typically contain some inaccurate or biased
                    information since the wisdom of crowds is uncensored. To detect fake news from
                    a sea of diverse, crowded and even competing narratives, in this paper, we
                    propose a novel defense-based explainable fake news detection framework.
                    Specifically, we first propose an evidence extraction module to split the
                    wisdom of crowds into two competing parties and respectively detect salient
                    evidences. To gain concise insights from evidences, we then design a
                    prompt-based module that utilizes a large language model to generate
                    justifications by inferring reasons towards two possible veracities. Finally,
                    we propose a defense-based inference module to determine veracity via modeling
                    the defense among these justifications. Extensive experiments conducted on two
                    real-world benchmarks demonstrate that our proposed method outperforms
                    state-of-the-art baselines in terms of fake news detection and provides
                    high-quality justifications.
                </p>
            </div>
        </dd>
        <dt><a name="item535">[535]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03372"
                    title="Abstract">arXiv:2405.03372</a> [<a href="/pdf/2405.03372" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03372" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Snake Learning: A Communication- and Computation-Efficient
                    Distributed Learning Framework for 6G
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+X">Xiaoxue Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yi%2C+X">Xingfu Yi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Rongpeng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+F">Fei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+C">Chenghui Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhifeng Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Honggang Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">In the evolution towards 6G, integrating Artificial Intelligence (AI) with
                    advanced network infrastructure emerges as a pivotal strategy for enhancing
                    network intelligence and resource utilization. Existing distributed learning
                    frameworks like Federated Learning and Split Learning often struggle with
                    significant challenges in dynamic network environments including high
                    synchronization demands, costly communication overheads, severe computing
                    resource consumption, and data heterogeneity across network nodes. These
                    obstacles hinder the applications of ubiquitous computing capabilities of 6G
                    networks, especially in light of the trend of escalating model parameters and
                    training data volumes. To address these challenges effectively, this paper
                    introduces "Snake Learning", a cost-effective distributed learning framework.
                    Specifically, Snake Learning respects the heterogeneity of inter-node computing
                    capability and local data distribution in 6G networks, and sequentially trains
                    the designated part of model layers on individual nodes. This layer-by-layer
                    serpentine update mechanism contributes to significantly reducing the
                    requirements for storage, memory and communication during the model training
                    phase, and demonstrates superior adaptability and efficiency for both Computer
                    Vision (CV) training and Large Language Model (LLM) fine-tuning tasks across
                    homogeneous and heterogeneous data distributions.
                </p>
            </div>
        </dd>
        <dt><a name="item536">[536]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03373"
                    title="Abstract">arXiv:2405.03373</a> [<a href="/pdf/2405.03373" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03373" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Knowledge-aware Text-Image Retrieval for Remote Sensing
                    Images
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mi%2C+L">Li Mi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+X">Xianjie Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Castillo-Navarro%2C+J">Javiera Castillo-Navarro</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tuia%2C+D">Devis Tuia</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Under review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Image-based retrieval in large Earth observation archives is challenging
                    because one needs to navigate across thousands of candidate matches only with
                    the query image as a guide. By using text as information supporting the visual
                    query, the retrieval system gains in usability, but at the same time faces
                    difficulties due to the diversity of visual signals that cannot be summarized
                    by a short caption only. For this reason, as a matching-based task, cross-modal
                    text-image retrieval often suffers from information asymmetry between texts and
                    images. To address this challenge, we propose a Knowledge-aware Text-Image
                    Retrieval (KTIR) method for remote sensing images. By mining relevant
                    information from an external knowledge graph, KTIR enriches the text scope
                    available in the search query and alleviates the information gaps between texts
                    and images for better matching. Moreover, by integrating domain-specific
                    knowledge, KTIR also enhances the adaptation of pre-trained vision-language
                    models to remote sensing applications. Experimental results on three commonly
                    used remote sensing text-image retrieval benchmarks show that the proposed
                    knowledge-aware method leads to varied and consistent retrievals, outperforming
                    state-of-the-art retrieval methods.
                </p>
            </div>
        </dd>
        <dt><a name="item537">[537]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03376"
                    title="Abstract">arXiv:2405.03376</a> [<a href="/pdf/2405.03376" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03376" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CRA5: Extreme Compression of ERA5 for Portable Global Climate
                    and Weather Research via an Efficient Variational Transformer
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+T">Tao Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+z">zhenghao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+S">Song Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+W">Wanghan Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bai%2C+L">Lei Bai</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Main text and supplementary, 22 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">The advent of data-driven weather forecasting models, which learn from
                    hundreds of terabytes (TB) of reanalysis data, has significantly advanced
                    forecasting capabilities. However, the substantial costs associated with data
                    storage and transmission present a major challenge for data providers and
                    users, affecting resource-constrained researchers and limiting their
                    accessibility to participate in AI-based meteorological research. To mitigate
                    this issue, we introduce an efficient neural codec, the Variational Autoencoder
                    Transformer (VAEformer), for extreme compression of climate data to
                    significantly reduce data storage cost, making AI-based meteorological research
                    portable to researchers. Our approach diverges from recent complex neural
                    codecs by utilizing a low-complexity Auto-Encoder transformer. This encoder
                    produces a quantized latent representation through variance inference, which
                    reparameterizes the latent space as a Gaussian distribution. This method
                    improves the estimation of distributions for cross-entropy coding. Extensive
                    experiments demonstrate that our VAEformer outperforms existing
                    state-of-the-art compression methods in the context of climate data. By
                    applying our VAEformer, we compressed the most popular ERA5 climate dataset
                    (226 TB) into a new dataset, CRA5 (0.7 TB). This translates to a compression
                    ratio of over 300 while retaining the dataset's utility for accurate scientific
                    analysis. Further, downstream experiments show that global weather forecasting
                    models trained on the compact CRA5 dataset achieve forecasting accuracy
                    comparable to the model trained on the original dataset. Code, the CRA5
                    dataset, and the pre-trained model are available at
                    https://github.com/taohan10200/CRA5.
                </p>
            </div>
        </dd>
        <dt><a name="item538">[538]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03379"
                    title="Abstract">arXiv:2405.03379</a> [<a href="/pdf/2405.03379" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03379" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Reverse Forward Curriculum Learning for Extreme Sample and
                    Demonstration Efficiency in Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tao%2C+S">Stone Tao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shukla%2C+A">Arth Shukla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+T">Tse-kai Chan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+H">Hao Su</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at The Twelfth International Conference on
                    Learning Representations (ICLR 2024). Website: <a href="https://reverseforward-cl.github.io/">this
                        https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

                </div>
                <p class="mathjax">Reinforcement learning (RL) presents a promising framework to learn policies
                    through environment interaction, but often requires an infeasible amount of
                    interaction data to solve complex tasks from sparse rewards. One direction
                    includes augmenting RL with offline data demonstrating desired tasks, but past
                    work often require a lot of high-quality demonstration data that is difficult
                    to obtain, especially for domains such as robotics. Our approach consists of a
                    reverse curriculum followed by a forward curriculum. Unique to our approach
                    compared to past work is the ability to efficiently leverage more than one
                    demonstration via a per-demonstration reverse curriculum generated via state
                    resets. The result of our reverse curriculum is an initial policy that performs
                    well on a narrow initial state distribution and helps overcome difficult
                    exploration problems. A forward curriculum is then used to accelerate the
                    training of the initial policy to perform well on the full initial state
                    distribution of the task and improve demonstration and sample efficiency. We
                    show how the combination of a reverse curriculum and forward curriculum in our
                    method, RFCL, enables significant improvements in demonstration and sample
                    efficiency compared against various state-of-the-art
                    learning-from-demonstration baselines, even solving previously unsolvable tasks
                    that require high precision and control.
                </p>
            </div>
        </dd>
        <dt><a name="item539">[539]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03381"
                    title="Abstract">arXiv:2405.03381</a> [<a href="/pdf/2405.03381" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03381" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Statistical Edge Detection And UDF Learning For Shape
                    Representation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Foy%2C+V">Virgile Foy</a> (IMT),
                    <a href="/search/cs?searchtype=author&amp;query=Gamboa%2C+F">Fabrice Gamboa</a> (IMT),
                    <a href="/search/cs?searchtype=author&amp;query=Chhaibi%2C+R">Reda Chhaibi</a> (IMT)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG); Applications (stat.AP)

                </div>
                <p class="mathjax">In the field of computer vision, the numerical encoding of 3D surfaces is
                    crucial. It is classical to represent surfaces with their Signed Distance
                    Functions (SDFs) or Unsigned Distance Functions (UDFs). For tasks like
                    representation learning, surface classification, or surface reconstruction,
                    this function can be learned by a neural network, called Neural Distance
                    Function. This network, and in particular its weights, may serve as a
                    parametric and implicit representation for the surface. The network must
                    represent the surface as accurately as possible. In this paper, we propose a
                    method for learning UDFs that improves the fidelity of the obtained Neural UDF
                    to the original 3D surface. The key idea of our method is to concentrate the
                    learning effort of the Neural UDF on surface edges. More precisely, we show
                    that sampling more training points around surface edges allows better local
                    accuracy of the trained Neural UDF, and thus improves the global expressiveness
                    of the Neural UDF in terms of Hausdorff distance. To detect surface edges, we
                    propose a new statistical method based on the calculation of a <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-234-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1583"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.52em, 2.26em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1584"><span class="mi" id="MathJax-Span-1585"
                                                style="font-family: MathJax_Math-italic;">p</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-234">p</script>-value at
                    each point on the surface. Our method is shown to detect surface edges more
                    accurately than a commonly used local geometric descriptor.
                </p>
            </div>
        </dd>
        <dt><a name="item540">[540]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03382"
                    title="Abstract">arXiv:2405.03382</a> [<a href="/pdf/2405.03382" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03382" title="Download PostScript">ps</a>, <a href="/format/2405.03382"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improving (Re-)Usability of Musical Datasets: An Overview of
                    the DOREMUS Project
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lisena%2C+P">Pasquale Lisena</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Achichi%2C+M">Manel Achichi</a> (WEB3),
                    <a href="/search/cs?searchtype=author&amp;query=Choff%C3%A9%2C+P">Pierre Choffé</a> (BnF),
                    <a href="/search/cs?searchtype=author&amp;query=Cecconi%2C+C">Cécile Cecconi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Todorov%2C+K">Konstantin Todorov</a> (WEB3),
                    <a href="/search/cs?searchtype=author&amp;query=Jacquemin%2C+B">Bernard Jacquemin</a> (GERIICO),
                    <a href="/search/cs?searchtype=author&amp;query=Troncy%2C+R">Raphaël Troncy</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Bibliothek Forschung und Praxis, 2018, 42 (2),
                    pp.194-205.
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">DOREMUS works on a better description of music by building new tools to link
                    and explore the data of three French institutions. This paper gives an overview
                    of the data model based on FRBRoo, explains the conversion and linking
                    processes using linked data technologies and presents the prototypes created to
                    consume the data according to the web users' needs.
                </p>
            </div>
        </dd>
        <dt><a name="item541">[541]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03384"
                    title="Abstract">arXiv:2405.03384</a> [<a href="/pdf/2405.03384" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03384" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GLIP: Electromagnetic Field Exposure Map Completion by Deep
                    Generative Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mallik%2C+M">Mohammed Mallik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gaillot%2C+D+P">Davy P. Gaillot</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Clavier%2C+L">Laurent Clavier</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">In Spectrum cartography (SC), the generation of exposure maps for radio
                    frequency electromagnetic fields (RF-EMF) spans dimensions of frequency, space,
                    and time, which relies on a sparse collection of sensor data, posing a
                    challenging ill-posed inverse problem. Cartography methods based on models
                    integrate designed priors, such as sparsity and low-rank structures, to refine
                    the solution of this inverse problem. In our previous work, EMF exposure map
                    reconstruction was achieved by Generative Adversarial Networks (GANs) where
                    physical laws or structural constraints were employed as a prior, but they
                    require a large amount of labeled data or simulated full maps for training to
                    produce efficient results. In this paper, we present a method to reconstruct
                    EMF exposure maps using only the generator network in GANs which does not
                    require explicit training, thus overcoming the limitations of GANs, such as
                    using reference full exposure maps. This approach uses a prior from sensor data
                    as Local Image Prior (LIP) captured by deep convolutional generative networks
                    independent of learning the network parameters from images in an urban
                    environment. Experimental results show that, even when only sparse sensor data
                    are available, our method can produce accurate estimates.
                </p>
            </div>
        </dd>
        <dt><a name="item542">[542]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03385"
                    title="Abstract">arXiv:2405.03385</a> [<a href="/pdf/2405.03385" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03385" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fully Reversing the Shoebox Image Source Method: From Impulse
                    Responses to Room Parameters
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sprunck%2C+T">Tom Sprunck</a> (IRMA),
                    <a href="/search/cs?searchtype=author&amp;query=Deleforge%2C+A">Antoine Deleforge</a> (IRMA),
                    <a href="/search/cs?searchtype=author&amp;query=Privat%2C+Y">Yannick Privat</a> (IECL, SPHINX, IUF),
                    <a href="/search/cs?searchtype=author&amp;query=Foy%2C+C">Cédric Foy</a> (UMRAE, Cerema Direction
                    Est)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio
                    and Speech Processing (eess.AS); Signal Processing (eess.SP); Classical Physics (physics.class-ph)

                </div>
                <p class="mathjax">We present an algorithm that fully reverses the shoebox image source method
                    (ISM), a popular and widely used room impulse response (RIR) simulator for
                    cuboid rooms introduced by Allen and Berkley in 1979. More precisely, given a
                    discrete multichannel RIR generated by the shoebox ISM for a microphone array
                    of known geometry, the algorithm reliably recovers the 18 input parameters.
                    These are the 3D source position, the 3 dimensions of the room, the
                    6-degrees-of-freedom room translation and orientation, and an absorption
                    coefficient for each of the 6 room boundaries. The approach builds on a
                    recently proposed gridless image source localization technique combined with
                    new procedures for room axes recovery and first-order-reflection
                    identification. Extensive simulated experiments reveal that near-exact recovery
                    of all parameters is achieved for a 32-element, 8.4-cm-wide spherical
                    microphone array and a sampling rate of 16~kHz using fully randomized input
                    parameters within rooms of size 2X2X2 to 10X10X5 meters. Estimation errors
                    decay towards zero when increasing the array size and sampling rate. The method
                    is also shown to strongly outperform a known baseline, and its ability to
                    extrapolate RIRs at new positions is demonstrated. Crucially, the approach is
                    strictly limited to low-passed discrete RIRs simulated using the vanilla
                    shoebox ISM. Nonetheless, it represents to our knowledge the first algorithmic
                    demonstration that this difficult inverse problem is in-principle fully
                    solvable over a wide range of configurations.
                </p>
            </div>
        </dd>
        <dt><a name="item543">[543]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03386"
                    title="Abstract">arXiv:2405.03386</a> [<a href="/pdf/2405.03386" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03386" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Annot-Mix: Learning with Noisy Class Labels from Multiple
                    Annotators via a Mixup Extension
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Herde%2C+M">Marek Herde</a>,
                    <a href="/search/cs?searchtype=author&amp;query=L%C3%BChrs%2C+L">Lukas Lührs</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huseljic%2C+D">Denis Huseljic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sick%2C+B">Bernhard Sick</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Under review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Training with noisy class labels impairs neural networks' generalization
                    performance. In this context, mixup is a popular regularization technique to
                    improve training robustness by making memorizing false class labels more
                    difficult. However, mixup neglects that, typically, multiple annotators, e.g.,
                    crowdworkers, provide class labels. Therefore, we propose an extension of
                    mixup, which handles multiple class labels per instance while considering which
                    class label originates from which annotator. Integrated into our
                    multi-annotator classification framework annot-mix, it performs superiorly to
                    eight state-of-the-art approaches on eleven datasets with noisy class labels
                    provided either by human or simulated annotators. Our code is publicly
                    available through our repository at https://github.com/ies-research/annot-mix.
                </p>
            </div>
        </dd>
        <dt><a name="item544">[544]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03387"
                    title="Abstract">arXiv:2405.03387</a> [<a href="/pdf/2405.03387" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03387" title="Download PostScript">ps</a>, <a href="/format/2405.03387"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The high dimensional psychological profile and cultural bias
                    of ChatGPT
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+H">Hang Yuan</a> (1),
                    <a href="/search/cs?searchtype=author&amp;query=Che%2C+Z">Zhongyue Che</a> (1),
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shao Li</a> (1),
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yue Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xiaomeng Hu</a> (2),
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+S">Siyang Luo</a> (1) ((1) Sun Yat-Sen
                    University, (2) Renmin University of China)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Given the rapid advancement of large-scale language models, artificial
                    intelligence (AI) models, like ChatGPT, are playing an increasingly prominent
                    role in human society. However, to ensure that artificial intelligence models
                    benefit human society, we must first fully understand the similarities and
                    differences between the human-like characteristics exhibited by artificial
                    intelligence models and real humans, as well as the cultural stereotypes and
                    biases that artificial intelligence models may exhibit in the process of
                    interacting with humans. This study first measured ChatGPT in 84 dimensions of
                    psychological characteristics, revealing differences between ChatGPT and human
                    norms in most dimensions as well as in high-dimensional psychological
                    representations. Additionally, through the measurement of ChatGPT in 13
                    dimensions of cultural values, it was revealed that ChatGPT's cultural value
                    patterns are dissimilar to those of various countries/regions worldwide.
                    Finally, an analysis of ChatGPT's performance in eight decision-making tasks
                    involving interactions with humans from different countries/regions revealed
                    that ChatGPT exhibits clear cultural stereotypes in most decision-making tasks
                    and shows significant cultural bias in third-party punishment and ultimatum
                    games. The findings indicate that, compared to humans, ChatGPT exhibits a
                    distinct psychological profile and cultural value orientation, and it also
                    shows cultural biases and stereotypes in interpersonal decision-making. Future
                    research endeavors should emphasize enhanced technical oversight and augmented
                    transparency in the database and algorithmic training procedures to foster more
                    efficient cross-cultural communication and mitigate social disparities.
                </p>
            </div>
        </dd>
        <dt><a name="item545">[545]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03388"
                    title="Abstract">arXiv:2405.03388</a> [<a href="/pdf/2405.03388" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03388" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> 3D LiDAR Mapping in Dynamic Environments Using a 4D Implicit
                    Neural Representation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+X">Xingguang Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pan%2C+Y">Yue Pan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stachniss%2C+C">Cyrill Stachniss</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Behley%2C+J">Jens Behley</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, CVPR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Robotics (cs.RO)

                </div>
                <p class="mathjax">Building accurate maps is a key building block to enable reliable
                    localization, planning, and navigation of autonomous vehicles. We propose a
                    novel approach for building accurate maps of dynamic environments utilizing a
                    sequence of LiDAR scans. To this end, we propose encoding the 4D scene into a
                    novel spatio-temporal implicit neural map representation by fitting a
                    time-dependent truncated signed distance function to each point. Using our
                    representation, we extract the static map by filtering the dynamic parts. Our
                    neural representation is based on sparse feature grids, a globally shared
                    decoder, and time-dependent basis functions, which we jointly optimize in an
                    unsupervised fashion. To learn this representation from a sequence of LiDAR
                    scans, we design a simple yet efficient loss function to supervise the map
                    optimization in a piecewise way. We evaluate our approach on various scenes
                    containing moving objects in terms of the reconstruction quality of static maps
                    and the segmentation of dynamic point clouds. The experimental results
                    demonstrate that our method is capable of removing the dynamic part of the
                    input point clouds while reconstructing accurate and complete 3D maps,
                    outperforming several state-of-the-art methods. Codes are available at:
                    https://github.com/PRBonn/4dNDF
                </p>
            </div>
        </dd>
        <dt><a name="item546">[546]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03389"
                    title="Abstract">arXiv:2405.03389</a> [<a href="/pdf/2405.03389" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03389" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Don't Waste Your Time: Early Stopping Cross-Validation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bergman%2C+E">Edward Bergman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Purucker%2C+L">Lennart Purucker</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hutter%2C+F">Frank Hutter</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at Third International Conference on Automated
                    Machine Learning (AutoML 2024); for code, see <a
                        href="https://github.com/automl/DontWasteYourTime-early-stopping">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">State-of-the-art automated machine learning systems for tabular data often
                    employ cross-validation; ensuring that measured performances generalize to
                    unseen data, or that subsequent ensembling does not overfit. However, using
                    k-fold cross-validation instead of holdout validation drastically increases the
                    computational cost of validating a single configuration. While ensuring better
                    generalization and, by extension, better performance, the additional cost is
                    often prohibitive for effective model selection within a time budget. We aim to
                    make model selection with cross-validation more effective. Therefore, we study
                    early stopping the process of cross-validation during model selection. We
                    investigate the impact of early stopping on random search for two algorithms,
                    MLP and random forest, across 36 classification datasets. We further analyze
                    the impact of the number of folds by considering 3-, 5-, and 10-folds. In
                    addition, we investigate the impact of early stopping with Bayesian
                    optimization instead of random search and also repeated cross-validation. Our
                    exploratory study shows that even a simple-to-understand and easy-to-implement
                    method consistently allows model selection to converge faster; in ~94% of all
                    datasets, on average by ~214%. Moreover, stopping cross-validation enables
                    model selection to explore the search space more exhaustively by considering
                    +167% configurations on average within one hour, while also obtaining better
                    overall performance.
                </p>
            </div>
        </dd>
        <dt><a name="item547">[547]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03393"
                    title="Abstract">arXiv:2405.03393</a> [<a href="/pdf/2405.03393" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03393" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On-site scale factor linearity calibration of MEMS triaxial
                    gyroscopes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yaqi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Li Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhitao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiangqing Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jiaojiao Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+S+w">Steven weidong Su</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Systems and Control (eess.SY)

                </div>
                <p class="mathjax">The calibration of MEMS triaxial gyroscopes is crucial for achieving precise
                    attitude estimation for various wearable health monitoring applications.
                    However, gyroscope calibration poses greater challenges compared to
                    accelerometers and magnetometers. This paper introduces an efficient method for
                    calibrating MEMS triaxial gyroscopes via only a servo motor, making it
                    well-suited for field environments. The core strategy of the method involves
                    utilizing the fact that the dot product of the measured gravity and the
                    rotational speed in a fixed frame remains constant. To eliminate the influence
                    of rotating centrifugal force on the accelerometer, the accelerometer data is
                    measured while stationary. The proposed calibration experiment scheme, which
                    allows gyroscopic measurements when operating each axis at a specific rotation
                    speed, making it easier to evaluate the linearity across a related speed range
                    constituted by a series of rotation speeds. Moreover, solely the classical
                    least squares algorithm proves adequate for estimating the scale factor,
                    notably streamlining the analysis of the calibration process. Extensive
                    numerical simulations were conducted to analyze the proposed method's
                    performance in calibrating a triaxial gyroscope model. Experimental validation
                    was also carried out using a commercially available MEMS inertial measurement
                    unit (LSM9DS1 from Arduino nano 33 BLE SENSE) and a servo motor capable of
                    controlling precise speed. The experimental results effectively demonstrate the
                    efficacy of the proposed calibration approach.
                </p>
            </div>
        </dd>
        <dt><a name="item548">[548]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03401"
                    title="Abstract">arXiv:2405.03401</a> [<a href="/pdf/2405.03401" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03401" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> E2GNN: Efficient Graph Neural Network Ensembles for
                    Semi-Supervised Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xin Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zha%2C+D">Daochen Zha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tan%2C+Q">Qiaoyu Tan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">This work studies ensemble learning for graph neural networks (GNNs) under
                    the popular semi-supervised setting. Ensemble learning has shown superiority in
                    improving the accuracy and robustness of traditional machine learning by
                    combining the outputs of multiple weak learners. However, adopting a similar
                    idea to integrate different GNN models is challenging because of two reasons.
                    First, GNN is notorious for its poor inference ability, so naively assembling
                    multiple GNN models would deteriorate the inference efficiency. Second, when
                    GNN models are trained with few labeled nodes, their performance are limited.
                    In this case, the vanilla ensemble approach, e.g., majority vote, may be
                    sub-optimal since most base models, i.e., GNNs, may make the wrong predictions.
                    To this end, in this paper, we propose an efficient ensemble learner--E2GNN to
                    assemble multiple GNNs in a learnable way by leveraging both labeled and
                    unlabeled nodes. Specifically, we first pre-train different GNN models on a
                    given data scenario according to the labeled nodes. Next, instead of directly
                    combing their outputs for label inference, we train a simple multi-layer
                    perceptron--MLP model to mimic their predictions on both labeled and unlabeled
                    nodes. Then the unified MLP model is deployed to infer labels for unlabeled or
                    new nodes. Since the predictions of unlabeled nodes from different GNN models
                    may be incorrect, we develop a reinforced discriminator to effectively filter
                    out those wrongly predicted nodes to boost the performance of MLP. By doing
                    this, we suggest a principled approach to tackle the inference issues of GNN
                    ensembles and maintain the merit of ensemble learning: improved performance.
                    Comprehensive experiments over both transductive and inductive settings, across
                    different GNN backbones and 8 benchmark datasets, demonstrate the superiority
                    of E2GNN.
                </p>
            </div>
        </dd>
        <dt><a name="item549">[549]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03403"
                    title="Abstract">arXiv:2405.03403</a> [<a href="/pdf/2405.03403" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03403" title="Download PostScript">ps</a>, <a href="/format/2405.03403"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improved scalar auxiliary variable schemes for original
                    energy stability of gradient flows
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Chen%2C+R">RUi Chen</a>,
                    <a href="/search/math?searchtype=author&amp;query=Wang%2C+T">Tingfeng Wang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Zhao%2C+X">Xiaofei Zhao</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">Scalar auxiliary variable (SAV) methods are a class of linear schemes for
                    solving gradient flows that are known for the stability of a `modified' energy.
                    In this paper, we propose an improved SAV (iSAV) scheme that not only retains
                    the complete linearity but also ensures rigorously the stability of the
                    original energy. The convergence and optimal error bound are rigorously
                    established for the iSAV scheme and discussions are made for its high-order
                    extension. Extensive numerical experiments are done to validate the
                    convergence, robustness and energy stability of iSAV, and some comparisons are
                    made.
                </p>
            </div>
        </dd>
        <dt><a name="item550">[550]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03406"
                    title="Abstract">arXiv:2405.03406</a> [<a href="/pdf/2405.03406" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03406" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Automated Computation of Therapies Using Failure Mode and
                    Effects Analysis in the Medical Domain
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Luttermann%2C+M">Malte Luttermann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baake%2C+E">Edgar Baake</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bouchagiar%2C+J">Juljan Bouchagiar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gebel%2C+B">Benjamin Gebel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gr%C3%BCning%2C+P">Philipp Grüning</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Manikwadura%2C+D">Dilini Manikwadura</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schollemann%2C+F">Franziska Schollemann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Teifke%2C+E">Elisa Teifke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rostalski%2C+P">Philipp Rostalski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=M%C3%B6ller%2C+R">Ralf Möller</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to the German Journal of Artificial Intelligence
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">Failure mode and effects analysis (FMEA) is a systematic approach to identify
                    and analyse potential failures and their effects in a system or process. The
                    FMEA approach, however, requires domain experts to manually analyse the FMEA
                    model to derive risk-reducing actions that should be applied. In this paper, we
                    provide a formal framework to allow for automatic planning and acting in FMEA
                    models. More specifically, we cast the FMEA model into a Markov decision
                    process which can then be solved by existing solvers. We show that the FMEA
                    approach can not only be used to support medical experts during the modelling
                    process but also to automatically derive optimal therapies for the treatment of
                    patients.
                </p>
            </div>
        </dd>
        <dt><a name="item551">[551]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03409"
                    title="Abstract">arXiv:2405.03409</a> [<a href="/pdf/2405.03409" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03409" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LightTR: A Lightweight Framework for Federated Trajectory
                    Recovery
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziqiao Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Miao%2C+H">Hao Miao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Y">Yan Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+C">Chenxi Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+K">Kai Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Huan Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> The paper was accepted by ICDE 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">With the proliferation of GPS-equipped edge devices, huge trajectory data is
                    generated and accumulated in various domains, motivating a variety of urban
                    applications. Due to the limited acquisition capabilities of edge devices, a
                    lot of trajectories are recorded at a low sampling rate, which may lead to the
                    effectiveness drop of urban applications. We aim to recover a high-sampled
                    trajectory based on the low-sampled trajectory in free space, i.e., without
                    road network information, to enhance the usability of trajectory data and
                    support urban applications more effectively. Recent proposals targeting
                    trajectory recovery often assume that trajectories are available at a central
                    location, which fail to handle the decentralized trajectories and hurt privacy.
                    To bridge the gap between decentralized training and trajectory recovery, we
                    propose a lightweight framework, LightTR, for federated trajectory recovery
                    based on a client-server architecture, while keeping the data decentralized and
                    private in each client/platform center (e.g., each data center of a company).
                    Specifically, considering the limited processing capabilities of edge devices,
                    LightTR encompasses a light local trajectory embedding module that offers
                    improved computational efficiency without compromising its feature extraction
                    capabilities. LightTR also features a meta-knowledge enhanced local-global
                    training scheme to reduce communication costs between the server and clients
                    and thus further offer efficiency improvement. Extensive experiments
                    demonstrate the effectiveness and efficiency of the proposed framework.
                </p>
            </div>
        </dd>
        <dt><a name="item552">[552]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03411"
                    title="Abstract">arXiv:2405.03411</a> [<a href="/pdf/2405.03411" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03411" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Greedy Heuristics for Sampling-based Motion Planning in
                    High-Dimensional State Spaces
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kyaw%2C+P+T">Phone Thiha Kyaw</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Le%2C+A+V">Anh Vu Le</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yi%2C+L">Lim Yi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Veerajagadheswar%2C+P">Prabakaran
                        Veerajagadheswar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Elara%2C+M+R">Mohan Rajesh Elara</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vo%2C+D+T">Dinh Tung Vo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vu%2C+M+B">Minh Bui Vu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To be published at the International Journal of Robotics
                    Research (IJRR)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Sampling-based motion planning algorithms are very effective at finding
                    solutions in high-dimensional continuous state spaces as they do not require
                    prior approximations of the problem domain compared to traditional discrete
                    graph-based searches. The anytime version of the Rapidly-exploring Random Trees
                    (RRT) algorithm, denoted as RRT*, often finds high-quality solutions by
                    incrementally approximating and searching the problem domain through random
                    sampling. However, due to its low sampling efficiency and slow convergence
                    rate, research has proposed many variants of RRT*, incorporating different
                    heuristics and sampling strategies to overcome the constraints in complex
                    planning problems. Yet, these approaches address specific convergence aspects
                    of RRT* limitations, leaving a need for a sampling-based algorithm that can
                    quickly find better solutions in complex high-dimensional state spaces with a
                    faster convergence rate for practical motion planning applications. This
                    article unifies and leverages the greedy search and heuristic techniques used
                    in various RRT* variants to develop a greedy version of the anytime
                    Rapidly-exploring Random Trees algorithm, denoted as Greedy RRT* (G-RRT*). It
                    improves the initial solution-finding time of RRT* by maintaining two trees
                    rooted at both the start and goal ends, advancing toward each other using
                    greedy connection heuristics. It also accelerates the convergence rate of RRT*
                    by introducing a greedy version of direct informed sampling procedure, which
                    guides the sampling towards the promising region of the problem domain based on
                    heuristics. We validate our approach on simulated planning problems,
                    manipulation problems on Barrett WAM Arms, and on a self-reconfigurable robot,
                    Panthera. Results show that G-RRT* produces asymptotically optimal solution
                    paths and outperforms state-of-the-art RRT* variants, especially in
                    high-dimensional planning problems.
                </p>
            </div>
        </dd>
        <dt><a name="item553">[553]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03413"
                    title="Abstract">arXiv:2405.03413</a> [<a href="/pdf/2405.03413" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03413" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SL-SLAM: A robust visual-inertial SLAM based deep feature
                    extraction and matching
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+Z">Zhang Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shuaixin Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">This paper explores how deep learning techniques can improve visual-based
                    SLAM performance in challenging environments. By combining deep feature
                    extraction and deep matching methods, we introduce a versatile hybrid visual
                    SLAM system designed to enhance adaptability in challenging scenarios, such as
                    low-light conditions, dynamic lighting, weak-texture areas, and severe jitter.
                    Our system supports multiple modes, including monocular, stereo,
                    monocular-inertial, and stereo-inertial configurations. We also perform
                    analysis how to combine visual SLAM with deep learning methods to enlighten
                    other researches. Through extensive experiments on both public datasets and
                    self-sampled data, we demonstrate the superiority of the SL-SLAM system over
                    traditional approaches. The experimental results show that SL-SLAM outperforms
                    state-of-the-art SLAM algorithms in terms of localization accuracy and tracking
                    robustness. For the benefit of community, we make public the source code at
                    https://github.com/zzzzxxxx111/SLslam.
                </p>
            </div>
        </dd>
        <dt><a name="item554">[554]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03415"
                    title="Abstract">arXiv:2405.03415</a> [<a href="/pdf/2405.03415" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03415" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unique solvability and error analysis of the Lagrange
                    multiplier approach for gradient flows
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Cheng%2C+Q">Qing Cheng</a>,
                    <a href="/search/math?searchtype=author&amp;query=Shen%2C+J">Jie Shen</a>,
                    <a href="/search/math?searchtype=author&amp;query=Wang%2C+C">Cheng Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>; Analysis of PDEs (math.AP)

                </div>
                <p class="mathjax">The unique solvability and error analysis of the original Lagrange multiplier
                    approach proposed in [8] for gradient flows is studied in this paper. We
                    identify a necessary and sufficient condition that must be satisfied for the
                    nonlinear algebraic equation arising from the original Lagrange multiplier
                    approach to admit a unique solution in the neighborhood of its exact solution,
                    and propose a modified Lagrange multiplier approach so that the computation can
                    continue even if the aforementioned condition is not satisfied. Using
                    Cahn-Hilliard equation as an example, we prove rigorously the unique
                    solvability and establish optimal error estimates of a second-order Lagrange
                    multiplier scheme assuming this condition and that the time step is sufficient
                    small. We also present numerical results to demonstrate that the modified
                    Lagrange multiplier approach is much more robust and can use much larger time
                    step than the original Lagrange multiplier approach.
                </p>
            </div>
        </dd>
        <dt><a name="item555">[555]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03416"
                    title="Abstract">arXiv:2405.03416</a> [<a href="/pdf/2405.03416" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03416" title="Download PostScript">ps</a>, <a href="/format/2405.03416"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mental health of computing professionals and students: A
                    systematic literature review
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Takaoka%2C+A+J+W">Alicia Julia Wilson Takaoka</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sharma%2C+K">Kshitij Sharma</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages, 7 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>

                </div>
                <p class="mathjax">The intersections of mental health and computing education is under-examined.
                    In this systematic literature review, we evaluate the state-of-the-art of
                    research in mental health and well-being interventions, assessments, and
                    concerns like anxiety and depression in computer science and computing
                    education. The studies evaluated occurred across the computing education
                    pipeline from introductory to PhD courses and found some commonalities
                    contributing to high reporting of anxiety and depression in those studied. In
                    addition, interventions that were designed to address mental health topics
                    often revolved around self-guidance. Based on our review of the literature, we
                    recommend increasing sample sizes and focusing on the design and development of
                    tools and interventions specifically designed for computing professionals and
                    students.
                </p>
            </div>
        </dd>
        <dt><a name="item556">[556]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03417"
                    title="Abstract">arXiv:2405.03417</a> [<a href="/pdf/2405.03417" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03417" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Gaussian Splatting: 3D Reconstruction and Novel View
                    Synthesis, a Review
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dalal%2C+A">Anurag Dalal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hagen%2C+D">Daniel Hagen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Robbersmyr%2C+K+G">Kjell G. Robbersmyr</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Knausg%C3%A5rd%2C+K+M">Kristian Muri Knausgård</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 24 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
                <p class="mathjax">Image-based 3D reconstruction is a challenging task that involves inferring
                    the 3D shape of an object or scene from a set of input images. Learning-based
                    methods have gained attention for their ability to directly estimate 3D shapes.
                    This review paper focuses on state-of-the-art techniques for 3D reconstruction,
                    including the generation of novel, unseen views. An overview of recent
                    developments in the Gaussian Splatting method is provided, covering input
                    types, model structures, output representations, and training strategies.
                    Unresolved challenges and future directions are also discussed. Given the rapid
                    progress in this domain and the numerous opportunities for enhancing 3D
                    reconstruction methods, a comprehensive examination of algorithms appears
                    essential. Consequently, this study offers a thorough overview of the latest
                    advancements in Gaussian Splatting.
                </p>
            </div>
        </dd>
        <dt><a name="item557">[557]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03419"
                    title="Abstract">arXiv:2405.03419</a> [<a href="/pdf/2405.03419" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03419" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Automated Metaheuristic Algorithm Design with Autoregressive
                    Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Q">Qi Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Tengfei Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+B">Bai Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Duan%2C+Q">Qiqi Duan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jian Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuhui Shi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Automated design of metaheuristic algorithms offers an attractive avenue to
                    reduce human effort and gain enhanced performance beyond human intuition.
                    Current automated methods design algorithms within a fixed structure and
                    operate from scratch. This poses a clear gap towards fully discovering
                    potentials over the metaheuristic family and fertilizing from prior design
                    experience. To bridge the gap, this paper proposes an autoregressive
                    learning-based designer for automated design of metaheuristic algorithms. Our
                    designer formulates metaheuristic algorithm design as a sequence generation
                    task, and harnesses an autoregressive generative network to handle the task.
                    This offers two advances. First, through autoregressive inference, the designer
                    generates algorithms with diverse lengths and structures, enabling to fully
                    discover potentials over the metaheuristic family. Second, prior design
                    knowledge learned and accumulated in neurons of the designer can be retrieved
                    for designing algorithms for future problems, paving the way to continual
                    design of algorithms for open-ended problem-solving. Extensive experiments on
                    numeral benchmarks and real-world problems reveal that the proposed designer
                    generates algorithms that outperform all human-created baselines on 24 out of
                    25 test problems. The generated algorithms display various structures and
                    behaviors, reasonably fitting for different problem-solving contexts. Code will
                    be released after paper publication.
                </p>
            </div>
        </dd>
        <dt><a name="item558">[558]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03420"
                    title="Abstract">arXiv:2405.03420</a> [<a href="/pdf/2405.03420" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03420" title="Download PostScript">ps</a>, <a href="/format/2405.03420"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Implantable Adaptive Cells: differentiable architecture
                    search to improve the performance of any trained U-shaped network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Benedykciuk%2C+E">Emil Benedykciuk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Denkowski%2C+M">Marcin Denkowski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=W%C3%B3jcik%2C+G">Grzegorz Wójcik</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">This paper introduces a novel approach to enhance the performance of
                    pre-trained neural networks in medical image segmentation using Neural
                    Architecture Search (NAS) methods, specifically Differentiable Architecture
                    Search (DARTS). We present the concept of Implantable Adaptive Cell (IAC),
                    small but powerful modules identified through Partially-Connected DARTS,
                    designed to be injected into the skip connections of an existing and already
                    trained U-shaped model. Our strategy allows for the seamless integration of the
                    IAC into the pre-existing architecture, thereby enhancing its performance
                    without necessitating a complete retraining from scratch. The empirical
                    studies, focusing on medical image segmentation tasks, demonstrate the efficacy
                    of this method. The integration of specialized IAC cells into various
                    configurations of the U-Net model increases segmentation accuracy by almost 2\%
                    points on average for the validation dataset and over 3\% points for the
                    training dataset. The findings of this study not only offer a cost-effective
                    alternative to the complete overhaul of complex models for performance upgrades
                    but also indicate the potential applicability of our method to other
                    architectures and problem domains.
                </p>
            </div>
        </dd>
        <dt><a name="item559">[559]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03421"
                    title="Abstract">arXiv:2405.03421</a> [<a href="/pdf/2405.03421" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03421" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Homotopy methods for higher order shape optimization: A
                    globalized shape-Newton method and Pareto-front tracing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Cesarano%2C+A">A. Cesarano</a>,
                    <a href="/search/math?searchtype=author&amp;query=Endtmayer%2C+B">B. Endtmayer</a>,
                    <a href="/search/math?searchtype=author&amp;query=Gangl%2C+P">P. Gangl</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">First order shape optimization methods, in general, require a large number of
                    iterations until they reach a locally optimal design. While higher order
                    methods can significantly reduce the number of iterations, they exhibit only
                    local convergence properties, necessitating a sufficiently close initial guess.
                    In this work, we present an unregularized shape-Newton method and combine shape
                    optimization with homotopy (or continuation) methods in order to allow for the
                    use of higher order methods even if the initial design is far from a solution.
                    The idea of homotopy methods is to continuously connect the problem of interest
                    with a simpler problem and to follow the corresponding solution path by a
                    predictor-corrector scheme. We use a shape-Newton method as a corrector and
                    arbitrary order shape derivatives for the predictor. Moreover, we apply
                    homotopy methods also to the case of multi-objective shape optimization to
                    efficiently obtain well-distributed points on a Pareto front. Finally, our
                    results are substantiated with a set of numerical experiments.
                </p>
            </div>
        </dd>
        <dt><a name="item560">[560]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03425"
                    title="Abstract">arXiv:2405.03425</a> [<a href="/pdf/2405.03425" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03425" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Gaussian Stochastic Weight Averaging for Bayesian Low-Rank
                    Adaptation of Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Onal%2C+E">Emre Onal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fl%C3%B6ge%2C+K">Klemens Flöge</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Caldwell%2C+E">Emma Caldwell</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sheverdin%2C+A">Arsen Sheverdin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fortuin%2C+V">Vincent Fortuin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 1 figure, 2 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Fine-tuned Large Language Models (LLMs) often suffer from overconfidence and
                    poor calibration, particularly when fine-tuned on small datasets. To address
                    these challenges, we propose a simple combination of Low-Rank Adaptation (LoRA)
                    with Gaussian Stochastic Weight Averaging (SWAG), facilitating approximate
                    Bayesian inference in LLMs. Through extensive testing across several Natural
                    Language Processing (NLP) benchmarks, we demonstrate that our straightforward
                    and computationally efficient approach improves model generalization and
                    calibration. We further show that our method exhibits greater robustness
                    against distribution shift, as reflected in its performance on
                    out-of-distribution tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item561">[561]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03426"
                    title="Abstract">arXiv:2405.03426</a> [<a href="/pdf/2405.03426" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03426" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> EdgeAlpha: Bringing Process Discovery to the Data Sources
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Rossow%2C+J">Julia Rossow</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rathje%2C+P">Patrick Rathje</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Landsiedel%2C+O">Olaf Landsiedel</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>;
                    Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">Process Mining is moving beyond mining traditional event logs and nowadays
                    includes, for example, data sourced from sensors in the Internet of Things
                    (IoT). The volume and velocity of data generated by such sensors makes it
                    increasingly challenging for traditional process discovery algorithms to store
                    and mine such data in traditional event logs. Further, privacy considerations
                    often prevent data collection at a central location in the first place. To
                    address this challenge, this paper introduces EdgeAlpha, a distributed
                    algorithm for process discovery operating directly on sensor nodes and edge
                    devices on a stream of real-time event data. Based on the Alpha Miner,
                    EdgeAlpha tracks each event and its predecessor and successor events directly
                    on the sensor node where the event is sensed and recorded. From this local
                    view, each node in EdgeAlpha derives a partial footprint matrix, which we then
                    merge at a central location, whenever we query the system to compute a process
                    model. EdgeAlpha enables (a) scalable mining, as a node, for each event, only
                    interacts with its predecessors and, when queried, only exchanges aggregates,
                    i.e., partial footprint matrices, with the central location and (b) privacy
                    preserving process mining, as nodes only store their own as well as predecessor
                    and successor events. On the Sepsis Cases event log, for example, a node
                    queries on average 18.7% of all nodes. For the Hospital Log, we can even reduce
                    the overall querying to 3.87% of the nodes.
                </p>
            </div>
        </dd>
        <dt><a name="item562">[562]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03427"
                    title="Abstract">arXiv:2405.03427</a> [<a href="/pdf/2405.03427" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03427" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Geometry-aware framework for deep energy method: an
                    application to structural mechanics with hyperelastic materials
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+T+N+K">Thi Nguyen Khoa Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dairay%2C+T">Thibault Dairay</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Meunier%2C+R">Raphaël Meunier</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Millet%2C+C">Christophe Millet</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mougeot%2C+M">Mathilde Mougeot</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 28 pages, 26 figures, 4 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Physics-Informed Neural Networks (PINNs) have gained considerable interest in
                    diverse engineering domains thanks to their capacity to integrate physical laws
                    into deep learning models. Recently, geometry-aware PINN-based approaches that
                    employ the strong form of underlying physical system equations have been
                    developed with the aim of integrating geometric information into PINNs. Despite
                    ongoing research, the assessment of PINNs in problems with various geometries
                    remains an active area of investigation. In this work, we introduce a novel
                    physics-informed framework named the Geometry-Aware Deep Energy Method (GADEM)
                    for solving structural mechanics problems on different geometries. As the weak
                    form of the physical system equation (or the energy-based approach) has
                    demonstrated clear advantages compared to the strong form for solving solid
                    mechanics problems, GADEM employs the weak form and aims to infer the solution
                    on multiple shapes of geometries. Integrating a geometry-aware framework into
                    an energy-based method results in an effective physics-informed deep learning
                    model in terms of accuracy and computational cost. Different ways to represent
                    the geometric information and to encode the geometric latent vectors are
                    investigated in this work. We introduce a loss function of GADEM which is
                    minimized based on the potential energy of all considered geometries. An
                    adaptive learning method is also employed for the sampling of collocation
                    points to enhance the performance of GADEM. We present some applications of
                    GADEM to solve solid mechanics problems, including a loading simulation of a
                    toy tire involving contact mechanics and large deformation hyperelasticity. The
                    numerical results of this work demonstrate the remarkable capability of GADEM
                    to infer the solution on various and new shapes of geometries using only one
                    trained model.
                </p>
            </div>
        </dd>
        <dt><a name="item563">[563]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03429"
                    title="Abstract">arXiv:2405.03429</a> [<a href="/pdf/2405.03429" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03429" title="Download PostScript">ps</a>, <a href="/format/2405.03429"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ReCycle: Fast and Efficient Long Time Series Forecasting with
                    Residual Cyclic Transformers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Weyrauch%2C+A">Arvid Weyrauch</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Steens%2C+T">Thomas Steens</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Taubert%2C+O">Oskar Taubert</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hanke%2C+B">Benedikt Hanke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eqbal%2C+A">Aslan Eqbal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=G%C3%B6tz%2C+E">Ewa Götz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Streit%2C+A">Achim Streit</a>,
                    <a href="/search/cs?searchtype=author&amp;query=G%C3%B6tz%2C+M">Markus Götz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Debus%2C+C">Charlotte Debus</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 3 figures, to be published at IEEE CAI 2024,
                    Associated code available at <a href="https://github.com/Helmholtz-AI-Energy/ReCycle">this https
                        URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Transformers have recently gained prominence in long time series forecasting
                    by elevating accuracies in a variety of use cases. Regrettably, in the race for
                    better predictive performance the overhead of model architectures has grown
                    onerous, leading to models with computational demand infeasible for most
                    practical applications. To bridge the gap between high method complexity and
                    realistic computational resources, we introduce the Residual Cyclic
                    Transformer, ReCycle. ReCycle utilizes primary cycle compression to address the
                    computational complexity of the attention mechanism in long time series. By
                    learning residuals from refined smoothing average techniques, ReCycle surpasses
                    state-of-the-art accuracy in a variety of application use cases. The reliable
                    and explainable fallback behavior ensured by simple, yet robust, smoothing
                    average techniques additionally lowers the barrier for user acceptance. At the
                    same time, our approach reduces the run time and energy consumption by more
                    than an order of magnitude, making both training and inference feasible on
                    low-performance, low-power and edge computing devices. Code is available at
                    https://github.com/Helmholtz-AI-Energy/ReCycle
                </p>
            </div>
        </dd>
        <dt><a name="item564">[564]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03432"
                    title="Abstract">arXiv:2405.03432</a> [<a href="/pdf/2405.03432" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03432" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improved Forward-Forward Contrastive Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=R%2C+G">Gananath R</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

                </div>
                <p class="mathjax">The backpropagation algorithm, or backprop, is a widely utilized optimization
                    technique in deep learning. While there's growing evidence suggesting that
                    models trained with backprop can accurately explain neuronal data, no
                    backprop-like method has yet been discovered in the biological brain for
                    learning. Moreover, employing a naive implementation of backprop in the brain
                    has several drawbacks. In 2022, Geoffrey Hinton proposed a biologically
                    plausible learning method known as the Forward-Forward (FF) algorithm. Shortly
                    after this paper, a modified version called FFCL was introduced. However, FFCL
                    had limitations, notably being a three-stage learning system where the final
                    stage still relied on regular backpropagation. In our approach, we address
                    these drawbacks by eliminating the last two stages of FFCL and completely
                    removing regular backpropagation. Instead, we rely solely on local updates,
                    offering a more biologically plausible alternative.
                </p>
            </div>
        </dd>
        <dt><a name="item565">[565]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03433"
                    title="Abstract">arXiv:2405.03433</a> [<a href="/pdf/2405.03433" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03433" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Annealed adaptive importance sampling method in PINNs for
                    solving high dimensional partial differential equations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Zhang%2C+Z">Zhengqi Zhang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Li%2C+J">Jing Li</a>,
                    <a href="/search/math?searchtype=author&amp;query=Liu%2C+B">Bin Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">Physics-informed neural networks (PINNs) have emerged as powerful tools for
                    solving a wide range of partial differential equations (PDEs). However, despite
                    their user-friendly interface and broad applicability, PINNs encounter
                    challenges in accurately resolving PDEs, especially when dealing with singular
                    cases that may lead to unsatisfactory local minima. To address these challenges
                    and improve solution accuracy, we propose an innovative approach called
                    Annealed Adaptive Importance Sampling (AAIS) for computing the discretized PDE
                    residuals of the cost functions, inspired by the Expectation Maximization
                    algorithm used in finite mixtures to mimic target density. Our objective is to
                    approximate discretized PDE residuals by strategically sampling additional
                    points in regions with elevated residuals, thus enhancing the effectiveness and
                    accuracy of PINNs. Implemented together with a straightforward resampling
                    strategy within PINNs, our AAIS algorithm demonstrates significant improvements
                    in efficiency across a range of tested PDEs, even with limited training
                    datasets. Moreover, our proposed AAIS-PINN method shows promising capabilities
                    in solving high-dimensional singular PDEs. The adaptive sampling framework
                    introduced here can be integrated into various PINN frameworks.
                </p>
            </div>
        </dd>
        <dt><a name="item566">[566]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03436"
                    title="Abstract">arXiv:2405.03436</a> [<a href="/pdf/2405.03436" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03436" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DBDH: A Dual-Branch Dual-Head Neural Network for Invisible
                    Embedded Regions Localization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chengxin Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ling%2C+H">Hefei Ling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+S">Sijing Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+N">Nan Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zongyi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuxuan Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiazhong Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 6 figures (Have been accepted by IJCNN 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Multimedia (cs.MM)

                </div>
                <p class="mathjax">Embedding invisible hyperlinks or hidden codes in images to replace QR codes
                    has become a hot topic recently. This technology requires first localizing the
                    embedded region in the captured photos before decoding. Existing methods that
                    train models to find the invisible embedded region struggle to obtain accurate
                    localization results, leading to degraded decoding accuracy. This limitation is
                    primarily because the CNN network is sensitive to low-frequency signals, while
                    the embedded signal is typically in the high-frequency form. Based on this,
                    this paper proposes a Dual-Branch Dual-Head (DBDH) neural network tailored for
                    the precise localization of invisible embedded regions. Specifically, DBDH uses
                    a low-level texture branch containing 62 high-pass filters to capture the
                    high-frequency signals induced by embedding. A high-level context branch is
                    used to extract discriminative features between the embedded and normal
                    regions. DBDH employs a detection head to directly detect the four vertices of
                    the embedding region. In addition, we introduce an extra segmentation head to
                    segment the mask of the embedding region during training. The segmentation head
                    provides pixel-level supervision for model learning, facilitating better
                    learning of the embedded signals. Based on two state-of-the-art invisible
                    offline-to-online messaging methods, we construct two datasets and augmentation
                    strategies for training and testing localization models. Extensive experiments
                    demonstrate the superior performance of the proposed DBDH over existing
                    methods.
                </p>
            </div>
        </dd>
        <dt><a name="item567">[567]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03437"
                    title="Abstract">arXiv:2405.03437</a> [<a href="/pdf/2405.03437" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03437" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> pyCFS-data: Data Processing Framework in Python for openCFS
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wurzinger%2C+A">Andreas Wurzinger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schoder%2C+S">Stefan Schoder</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">Many numerical simulation tools have been developed and are on the market,
                    but there is still a strong need for appropriate tools capable of simulating
                    multi-field problems, especially in aeroacoustics. Therefore, openCFS provides
                    an open-source framework for implementing partial differential equations using
                    the finite element method. Since 2000, the software has been developed
                    continuously. The result is openCFS (before 2020, known as CFS++ Coupled Field
                    Simulations written in C++). In this paper, we present pyCFS-data, a data
                    processing framework written in Python to provide a flexible and easy-to-use
                    toolbox to access and manipulate, pre- and postprocess data generated by or for
                    usage with openCFS.
                </p>
            </div>
        </dd>
        <dt><a name="item568">[568]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03440"
                    title="Abstract">arXiv:2405.03440</a> [<a href="/pdf/2405.03440" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03440" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Robotic Constrained Imitation Learning for the Peg Transfer
                    Task in Fundamentals of Laparoscopic Surgery
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Okada%2C+K">Kei Okada</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Inaba%2C+M">Masayuki Inaba</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at ICRA2024, website - <a
                        href="https://haraduka.github.io/fls-imitation">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In this study, we present an implementation strategy for a robot that
                    performs peg transfer tasks in Fundamentals of Laparoscopic Surgery (FLS) via
                    imitation learning, aimed at the development of an autonomous robot for
                    laparoscopic surgery. Robotic laparoscopic surgery presents two main
                    challenges: (1) the need to manipulate forceps using ports established on the
                    body surface as fulcrums, and (2) difficulty in perceiving depth information
                    when working with a monocular camera that displays its images on a monitor.
                    Especially, regarding issue (2), most prior research has assumed the
                    availability of depth images or models of a target to be operated on.
                    Therefore, in this study, we achieve more accurate imitation learning with only
                    monocular images by extracting motion constraints from one exemplary motion of
                    skilled operators, collecting data based on these constraints, and conducting
                    imitation learning based on the collected data. We implemented an overall
                    system using two Franka Emika Panda Robot Arms and validated its effectiveness.
                </p>
            </div>
        </dd>
        <dt><a name="item569">[569]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03442"
                    title="Abstract">arXiv:2405.03442</a> [<a href="/pdf/2405.03442" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03442" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Behavioral analysis in immersive learning environments: A
                    systematic literature review and research agenda
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yu Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yue%2C+K">Kang Yue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yue Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 29 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">The rapid growth of immersive technologies in educational areas has increased
                    research interest in analyzing the specific behavioral patterns of learners in
                    immersive learning environments. Considering the fact that research on the
                    technical affordances of immersive technologies and the pedagogical affordances
                    of behavioral analysis remains fragmented, this study first contributes by
                    developing a conceptual framework that amalgamates learning requirements,
                    specification, evaluation, and iteration into an integrated model to identify
                    learning benefits and potential hurdles of behavioral analysis in immersive
                    learning environments. Then, a systematic review was conducted underpinning the
                    proposed conceptual framework to retrieve valuable empirical evidence from the
                    40 eligible articles during the last decade. The review findings suggest that
                    (1) there is an essential need to sufficiently prepare the salient pedagogical
                    requirements to define the specific learning stage, envisage intended cognitive
                    objectives, and specify an appropriate set of learning activities, when
                    developing comprehensive plans on behavioral analysis in immersive learning
                    environments. (2) Researchers could customize the unique immersive experimental
                    implementation by considering factors from four dimensions: learner, pedagogy,
                    context, and representation. (3) The behavioral patterns constructed in
                    immersive learning environments vary by considering the influence of behavioral
                    analysis techniques, research themes, and immersive technical features. (4) The
                    use of behavioral analysis in immersive learning environments faces several
                    challenges from technical, implementation, and data processing perspectives.
                    This study also articulates critical research agenda that could drive future
                    investigation on behavioral analysis in immersive learning environments.
                </p>
            </div>
        </dd>
        <dt><a name="item570">[570]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03446"
                    title="Abstract">arXiv:2405.03446</a> [<a href="/pdf/2405.03446" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03446" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SEvenLLM: Benchmarking, Eliciting, and Enhancing Abilities of
                    Large Language Models in Cyber Threat Intelligence
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+H">Hangyuan Ji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jian Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chai%2C+L">Linzheng Chai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+C">Chaoren Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L">Liqun Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Duan%2C+Y">Yunlong Duan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yunli Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+T">Tianzhen Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+H">Hongcheng Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+T">Tongliang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+C">Changyu Ren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhoujun Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">To address the increasing complexity and frequency of cybersecurity incidents
                    emphasized by the recent cybersecurity threat reports with over 10 billion
                    instances, cyber threat intelligence (CTI) plays a critical role in the modern
                    cybersecurity landscape by offering the insights required to understand and
                    combat the constantly evolving nature of cyber threats. Inspired by the
                    powerful capability of large language models (LLMs) in handling complex tasks,
                    in this paper, we introduce a framework to benchmark, elicit, and improve
                    cybersecurity incident analysis and response abilities in LLMs for Security
                    Events (SEvenLLM). Specifically, we create a high-quality bilingual instruction
                    corpus by crawling cybersecurity raw text from cybersecurity websites to
                    overcome the lack of effective data for information extraction. Then, we design
                    a pipeline to auto-select tasks from the tasks pool and convert the raw text
                    into supervised corpora comprised of question and response. The instruction
                    dataset SEvenLLM-Instruct is used to train cybersecurity LLMs with the
                    multi-task learning objective (27 well-designed tasks) for augmenting the
                    analysis of cybersecurity events. Extensive experiments in our curated
                    benchmark (SEvenLLM-bench) demonstrate that SEvenLLM performs more
                    sophisticated threat analysis and fortifies defenses against the evolving
                    landscape of cyber threats.
                </p>
            </div>
        </dd>
        <dt><a name="item571">[571]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03449"
                    title="Abstract">arXiv:2405.03449</a> [<a href="/pdf/2405.03449" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03449" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Byzantine-Robust Gossip: Insights from a Dual Approach
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gaucher%2C+R">Renaud Gaucher</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hendrikx%2C+H">Hadrien Hendrikx</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dieuleveut%2C+A">Aymeric Dieuleveut</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 1 figure
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
                <p class="mathjax">Distributed approaches have many computational benefits, but they are
                    vulnerable to attacks from a subset of devices transmitting incorrect
                    information. This paper investigates Byzantine-resilient algorithms in a
                    decentralized setting, where devices communicate directly with one another. We
                    leverage the so-called dual approach to design a general robust decentralized
                    optimization method. We provide both global and local clipping rules in the
                    special case of average consensus, with tight convergence guarantees. These
                    clipping rules are practical, and yield results that finely characterize the
                    impact of Byzantine nodes, highlighting for instance a qualitative difference
                    in convergence between global and local clipping thresholds. Lastly, we
                    demonstrate that they can serve as a basis for designing efficient attacks.
                </p>
            </div>
        </dd>
        <dt><a name="item572">[572]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03452"
                    title="Abstract">arXiv:2405.03452</a> [<a href="/pdf/2405.03452" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03452" title="Download PostScript">ps</a>, <a href="/format/2405.03452"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Large Language Models (LLMs) as Agents for Augmented
                    Democracy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gudi%C3%B1o-Rosero%2C+J">Jairo Gudiño-Rosero</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Grandi%2C+U">Umberto Grandi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hidalgo%2C+C+A">César A. Hidalgo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages main manuscript with 3 figures. 12 pages of
                    supplementary material
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
                <p class="mathjax">We explore the capabilities of an augmented democracy system built on
                    off-the-shelf LLMs fine-tuned on data summarizing individual preferences across
                    67 policy proposals collected during the 2022 Brazilian presidential elections.
                    We use a train-test cross-validation setup to estimate the accuracy with which
                    the LLMs predict both: a subject's individual political choices and the
                    aggregate preferences of the full sample of participants. At the individual
                    level, the accuracy of the out of sample predictions lie in the range 69%-76%
                    and are significantly better at predicting the preferences of liberal and
                    college educated participants. At the population level, we aggregate
                    preferences using an adaptation of the Borda score and compare the ranking of
                    policy proposals obtained from a probabilistic sample of participants and from
                    data augmented using LLMs. We find that the augmented data predicts the
                    preferences of the full population of participants better than probabilistic
                    samples alone when these represent less than 30% to 40% of the total
                    population. These results indicate that LLMs are potentially useful for the
                    construction of systems of augmented democracy.
                </p>
            </div>
        </dd>
        <dt><a name="item573">[573]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03456"
                    title="Abstract">arXiv:2405.03456</a> [<a href="/pdf/2405.03456" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03456" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Performance of H-Matrix-Vector Multiplication with Floating
                    Point Compression
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kriemann%2C+R">Ronald Kriemann</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Mathematical Software (cs.MS)

                </div>
                <p class="mathjax">Matrix-vector multiplication forms the basis of many iterative solution
                    algorithms and as such is an important algorithm also for hierarchical
                    matrices. However, due to its low computational intensity, its performance is
                    typically limited by the available memory bandwidth. By optimizing the storage
                    representation of the data within such matrices, this limitation can be lifted
                    and the performance increased. This applies not only to hierarchical matrices
                    but for also for other low-rank approximation schemes, e.g. block low-rank
                    matrices.
                </p>
            </div>
        </dd>
        <dt><a name="item574">[574]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03458"
                    title="Abstract">arXiv:2405.03458</a> [<a href="/pdf/2405.03458" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03458" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SSyncOA: Self-synchronizing Object-aligned Watermarking to
                    Resist Cropping-paste Attacks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chengxin Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ling%2C+H">Hefei Ling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+S">Sijing Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+H">Han Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yaokun Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+N">Nan Sun</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 5 figures (Have been accepted by ICME 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Modern image processing tools have made it easy for attackers to crop the
                    region or object of interest in images and paste it into other images. The
                    challenge this cropping-paste attack poses to the watermarking technology is
                    that it breaks the synchronization of the image watermark, introducing multiple
                    superimposed desynchronization distortions, such as rotation, scaling, and
                    translation. However, current watermarking methods can only resist a single
                    type of desynchronization and cannot be applied to protect the object's
                    copyright under the cropping-paste attack. With the finding that the key to
                    resisting the cropping-paste attack lies in robust features of the object to
                    protect, this paper proposes a self-synchronizing object-aligned watermarking
                    method, called SSyncOA. Specifically, we first constrain the watermarked region
                    to be aligned with the protected object, and then synchronize the watermark's
                    translation, rotation, and scaling distortions by normalizing the object
                    invariant features, i.e., its centroid, principal orientation, and minimum
                    bounding square, respectively. To make the watermark embedded in the protected
                    object, we introduce the object-aligned watermarking model, which incorporates
                    the real cropping-paste attack into the encoder-noise layer-decoder pipeline
                    and is optimized end-to-end. Besides, we illustrate the effect of different
                    desynchronization distortions on the watermark training, which confirms the
                    necessity of the self-synchronization process. Extensive experiments
                    demonstrate the superiority of our method over other SOTAs.
                </p>
            </div>
        </dd>
        <dt><a name="item575">[575]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03462"
                    title="Abstract">arXiv:2405.03462</a> [<a href="/pdf/2405.03462" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03462" title="Download PostScript">ps</a>, <a href="/format/2405.03462"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Lightweight Neural Architecture Search Model for Medical
                    Image Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+L">Lunchen Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lomurno%2C+E">Eugenio Lomurno</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gambella%2C+M">Matteo Gambella</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ardagna%2C+D">Danilo Ardagna</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roveri%2C+M">Manuel Roveri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matteucci%2C+M">Matteo Matteucci</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Q">Qingjiang Shi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Accurate classification of medical images is essential for modern
                    diagnostics. Deep learning advancements led clinicians to increasingly use
                    sophisticated models to make faster and more accurate decisions, sometimes
                    replacing human judgment. However, model development is costly and repetitive.
                    Neural Architecture Search (NAS) provides solutions by automating the design of
                    deep learning architectures. This paper presents ZO-DARTS+, a differentiable
                    NAS algorithm that improves search efficiency through a novel method of
                    generating sparse probabilities by bi-level optimization. Experiments on five
                    public medical datasets show that ZO-DARTS+ matches the accuracy of
                    state-of-the-art solutions while reducing search times by up to three times.
                </p>
            </div>
        </dd>
        <dt><a name="item576">[576]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03467"
                    title="Abstract">arXiv:2405.03467</a> [<a href="/pdf/2405.03467" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03467" title="Download PostScript">ps</a>, <a href="/format/2405.03467"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Welfare Loss in Connected Resource Allocation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bei%2C+X">Xiaohui Bei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lam%2C+A">Alexander Lam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+X">Xinhang Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Suksompong%2C+W">Warut Suksompong</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Appears in the 33rd International Joint Conference on
                    Artificial Intelligence (IJCAI), 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>

                </div>
                <p class="mathjax">We study the allocation of indivisible goods that form an undirected graph
                    and investigate the worst-case welfare loss when requiring that each agent must
                    receive a connected subgraph. Our focus is on both egalitarian and utilitarian
                    welfare. Specifically, we introduce the concept of egalitarian (resp.,
                    utilitarian) price of connectivity, which captures the worst-case ratio between
                    the optimal egalitarian (resp., utilitarian) welfare among all allocations and
                    that among the connected allocations. We provide tight or asymptotically tight
                    bounds on the price of connectivity for various large classes of graphs when
                    there are two agents as well as for paths, stars and cycles in the general
                    case. Many of our results are supplemented with algorithms which find connected
                    allocations with a welfare guarantee corresponding to the price of
                    connectivity.
                </p>
            </div>
        </dd>
        <dt><a name="item577">[577]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03470"
                    title="Abstract">arXiv:2405.03470</a> [<a href="/pdf/2405.03470" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03470" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Motion Planning under Uncertainty: Integrating Learning-Based
                    Multi-Modal Predictors into Branch Model Predictive Control
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bouzidi%2C+M">Mohamed-Khalil Bouzidi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Derajic%2C+B">Bojan Derajic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goehring%2C+D">Daniel Goehring</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reichardt%2C+J">Joerg Reichardt</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Systems and Control (eess.SY)

                </div>
                <p class="mathjax">In complex traffic environments, autonomous vehicles face multi-modal
                    uncertainty about other agents' future behavior. To address this, recent
                    advancements in learningbased motion predictors output multi-modal predictions.
                    We present our novel framework that leverages Branch Model Predictive
                    Control(BMPC) to account for these predictions. The framework includes an
                    online scenario-selection process guided by topology and collision risk
                    criteria. This efficiently selects a minimal set of predictions, rendering the
                    BMPC realtime capable. Additionally, we introduce an adaptive decision
                    postponing strategy that delays the planner's commitment to a single scenario
                    until the uncertainty is resolved. Our comprehensive evaluations in traffic
                    intersection and random highway merging scenarios demonstrate enhanced comfort
                    and safety through our method.
                </p>
            </div>
        </dd>
        <dt><a name="item578">[578]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03473"
                    title="Abstract">arXiv:2405.03473</a> [<a href="/pdf/2405.03473" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03473" title="Download PostScript">ps</a>, <a href="/format/2405.03473"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Minimum-Jerk Approach to Handle Singularities in Virtual
                    Fixtures
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Braglia%2C+G">Giovanni Braglia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Calinon%2C+S">Sylvain Calinon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Biagiotti%2C+L">Luigi Biagiotti</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Implementing virtual fixtures in guiding tasks constrains the movement of the
                    robot's end effector to specific curves within its workspace. However,
                    incorporating guiding frameworks may encounter discontinuities when optimizing
                    the reference target position to the nearest point relative to the current
                    robot position. This article aims to give a geometric interpretation of such
                    discontinuities, with specific reference to the commonly adopted Gauss-Newton
                    algorithm. The effect of such discontinuities, defined as Euclidean Distance
                    Singularities, is experimentally proved. We then propose a solution that is
                    based on a Linear Quadratic Tracking problem with minimum jerk command, then
                    compare and validate the performances of the proposed framework in two
                    different human-robot interaction scenarios.
                </p>
            </div>
        </dd>
        <dt><a name="item579">[579]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03474"
                    title="Abstract">arXiv:2405.03474</a> [<a href="/pdf/2405.03474" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03474" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fast Approximate Determinants Using Rational Functions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Colthurst%2C+T">Thomas Colthurst</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vasudevan%2C+S">Srinivas Vasudevan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lottes%2C+J">James Lottes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Patton%2C+B">Brian Patton</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 22 pages, 17 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">We show how rational function approximations to the logarithm, such as <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-235-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1586"
                                style="width: 15.512em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 12.908em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1012.79em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1587"><span class="mi" id="MathJax-Span-1588"
                                                style="font-family: MathJax_Main;">log</span><span class="mo"
                                                id="MathJax-Span-1589"></span><span class="mi" id="MathJax-Span-1590"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">z<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1591"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≈</span><span
                                                class="mo" id="MathJax-Span-1592"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">(</span><span
                                                class="msubsup" id="MathJax-Span-1593"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.47em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1594"
                                                            style="font-family: MathJax_Math-italic;">z<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-1595"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1596"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mn" id="MathJax-Span-1597"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">1</span><span
                                                class="mo" id="MathJax-Span-1598"
                                                style="font-family: MathJax_Main;">)</span><span class="texatom"
                                                id="MathJax-Span-1599"><span class="mrow" id="MathJax-Span-1600"><span
                                                        class="mo" id="MathJax-Span-1601"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="mo" id="MathJax-Span-1602"
                                                style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                id="MathJax-Span-1603"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.47em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1604"
                                                            style="font-family: MathJax_Math-italic;">z<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-1605"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1606"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mn" id="MathJax-Span-1607"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">6</span><span
                                                class="mi" id="MathJax-Span-1608"
                                                style="font-family: MathJax_Math-italic;">z<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1609"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mn" id="MathJax-Span-1610"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">1</span><span
                                                class="mo" id="MathJax-Span-1611"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-235">\log
    z \approx (z^2 - 1)/(z^2 + 6z + 1)</script>, can be turned into fast algorithms for
                    approximating the determinant of a very large matrix. We empirically
                    demonstrate that when combined with a good preconditioner, the third order
                    rational function approximation offers a very good trade-off between speed and
                    accuracy when measured on matrices coming from Mat\'ern-<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-236-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1612"
                                style="width: 1.855em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.508em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.45em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1613"><span class="mn" id="MathJax-Span-1614"
                                                style="font-family: MathJax_Main;">5</span><span class="texatom"
                                                id="MathJax-Span-1615"><span class="mrow" id="MathJax-Span-1616"><span
                                                        class="mo" id="MathJax-Span-1617"
                                                        style="font-family: MathJax_Main;">/</span></span></span><span
                                                class="mn" id="MathJax-Span-1618"
                                                style="font-family: MathJax_Main;">2</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-236">5/2</script> and radial basis
                    function Gaussian process kernels. In particular, it is significantly more
                    accurate on those matrices than the state-of-the-art stochastic Lanczos
                    quadrature method for approximating determinants while running at about the
                    same speed.
                </p>
            </div>
        </dd>
        <dt><a name="item580">[580]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03476"
                    title="Abstract">arXiv:2405.03476</a> [<a href="/pdf/2405.03476" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03476" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DexSkills: Skill Segmentation Using Haptic Data for Learning
                    Autonomous Long-Horizon Robotic Manipulation Tasks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mao%2C+X">Xiaofeng Mao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Giudici%2C+G">Gabriele Giudici</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Coppola%2C+C">Claudio Coppola</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Althoefer%2C+K">Kaspar Althoefer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Farkhatdinov%2C+I">Ildar Farkhatdinov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhibin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jamone%2C+L">Lorenzo Jamone</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Effective execution of long-horizon tasks with dexterous robotic hands
                    remains a significant challenge in real-world problems. While learning from
                    human demonstrations have shown encouraging results, they require extensive
                    data collection for training. Hence, decomposing long-horizon tasks into
                    reusable primitive skills is a more efficient approach. To achieve so, we
                    developed DexSkills, a novel supervised learning framework that addresses
                    long-horizon dexterous manipulation tasks using primitive skills. DexSkills is
                    trained to recognize and replicate a select set of skills using human
                    demonstration data, which can then segment a demonstrated long-horizon
                    dexterous manipulation task into a sequence of primitive skills to achieve
                    one-shot execution by the robot directly. Significantly, DexSkills operates
                    solely on proprioceptive and tactile data, i.e., haptic data. Our real-world
                    robotic experiments show that DexSkills can accurately segment skills, thereby
                    enabling autonomous robot execution of a diverse range of tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item581">[581]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03478"
                    title="Abstract">arXiv:2405.03478</a> [<a href="/pdf/2405.03478" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03478" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Synthetic Datasets for Program Similarity Research
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Interrante-Grant%2C+A">Alexander
                        Interrante-Grant</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Michael Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baer%2C+L">Lisa Baer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Whelan%2C+R">Ryan Whelan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Leek%2C+T">Tim Leek</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Program similarity has become an increasingly popular area of research with
                    various security applications such as plagiarism detection, author
                    identification, and malware analysis. However, program similarity research
                    faces a few unique dataset quality problems in evaluating the effectiveness of
                    novel approaches. First, few high-quality datasets for binary program
                    similarity exist and are widely used in this domain. Second, there are
                    potentially many different, disparate definitions of what makes one program
                    similar to another and in many cases there is often a large semantic gap
                    between the labels provided by a dataset and any useful notion of behavioral or
                    semantic similarity. In this paper, we present HELIX - a framework for
                    generating large, synthetic program similarity datasets. We also introduce
                    Blind HELIX, a tool built on top of HELIX for extracting HELIX components from
                    library code automatically using program slicing. We evaluate HELIX and Blind
                    HELIX by comparing the performance of program similarity tools on a HELIX
                    dataset to a hand-crafted dataset built from multiple, disparate notions of
                    program similarity. Using Blind HELIX, we show that HELIX can generate
                    realistic and useful datasets of virtually infinite size for program similarity
                    research with ground truth labels that embody practical notions of program
                    similarity. Finally, we discuss the results and reason about relative tool
                    ranking.
                </p>
            </div>
        </dd>
        <dt><a name="item582">[582]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03480"
                    title="Abstract">arXiv:2405.03480</a> [<a href="/pdf/2405.03480" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03480" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Doing Personal LAPS: LLM-Augmented Dialogue Construction for
                    Personalized Multi-Session Conversational Search
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Joko%2C+H">Hideaki Joko</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chatterjee%2C+S">Shubham Chatterjee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ramsay%2C+A">Andrew Ramsay</a>,
                    <a href="/search/cs?searchtype=author&amp;query=de+Vries%2C+A+P">Arjen P. de Vries</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dalton%2C+J">Jeff Dalton</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hasibi%2C+F">Faegheh Hasibi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at SIGIR 2024 (Full Paper)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">The future of conversational agents will provide users with personalized
                    information responses. However, a significant challenge in developing models is
                    the lack of large-scale dialogue datasets that span multiple sessions and
                    reflect real-world user preferences. Previous approaches rely on experts in a
                    wizard-of-oz setup that is difficult to scale, particularly for personalized
                    tasks. Our method, LAPS, addresses this by using large language models (LLMs)
                    to guide a single human worker in generating personalized dialogues. This
                    method has proven to speed up the creation process and improve quality. LAPS
                    can collect large-scale, human-written, multi-session, and multi-domain
                    conversations, including extracting user preferences. When compared to existing
                    datasets, LAPS-produced conversations are as natural and diverse as
                    expert-created ones, which stays in contrast with fully synthetic methods. The
                    collected dataset is suited to train preference extraction and personalized
                    response generation. Our results show that responses generated explicitly using
                    extracted preferences better match user's actual preferences, highlighting the
                    value of using extracted preferences over simple dialogue history. Overall,
                    LAPS introduces a new method to leverage LLMs to create realistic personalized
                    conversational data more efficiently and effectively than previous methods.
                </p>
            </div>
        </dd>
        <dt><a name="item583">[583]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03481"
                    title="Abstract">arXiv:2405.03481</a> [<a href="/pdf/2405.03481" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03481" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AnchorGT: Efficient and Flexible Attention Architecture for
                    Scalable Graph Transformers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+W">Wenhao Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+G">Guojie Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Liang Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shaoguo Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Graph Transformers (GTs) have significantly advanced the field of graph
                    representation learning by overcoming the limitations of message-passing graph
                    neural networks (GNNs) and demonstrating promising performance and expressive
                    power. However, the quadratic complexity of self-attention mechanism in GTs has
                    limited their scalability, and previous approaches to address this issue often
                    suffer from expressiveness degradation or lack of versatility. To address this
                    issue, we propose AnchorGT, a novel attention architecture for GTs with global
                    receptive field and almost linear complexity, which serves as a flexible
                    building block to improve the scalability of a wide range of GT models.
                    Inspired by anchor-based GNNs, we employ structurally important <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-237-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1619"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1620"><span class="mi" id="MathJax-Span-1621"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-237">k</script>-dominating
                    node set as anchors and design an attention mechanism that focuses on the
                    relationship between individual nodes and anchors, while retaining the global
                    receptive field for all nodes. With its intuitive design, AnchorGT can easily
                    replace the attention module in various GT models with different network
                    architectures and structural encodings, resulting in reduced computational
                    overhead without sacrificing performance. In addition, we theoretically prove
                    that AnchorGT attention can be strictly more expressive than Weisfeiler-Lehman
                    test, showing its superiority in representing graph structures. Our experiments
                    on three state-of-the-art GT models demonstrate that their AnchorGT variants
                    can achieve better results while being faster and significantly more memory
                    efficient.
                </p>
            </div>
        </dd>
        <dt><a name="item584">[584]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03482"
                    title="Abstract">arXiv:2405.03482</a> [<a href="/pdf/2405.03482" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03482" title="Download PostScript">ps</a>, <a href="/format/2405.03482"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Managing Renewable Energy Resources Using Equity-Market Risk
                    Tools - the Efficient Frontiers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Grebel%2C+H">Haim Grebel</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Vikas%2C+D">Divya Vikas</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Shi%2C+J">Jim Shi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 3 figures, 10 ref
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">The energy market, and specifically the renewable sector carries volatility
                    and risks, similar to the financial market. Here, we leverage on a
                    well-established, return-risk approach, commonly used by equity
                    portfolio-managers and apply it to energy resources. We visualize the
                    relationship between the resources' costs and their risks in terms of efficient
                    frontiers. We apply this analysis to publically available data for various US
                    regions: Central, Eastern and Western coasts. Since risk management is
                    contingent on costs, this approach sheds useful light in assessing dynamic
                    pricing in modern electrical grids. By integrating geographical and temporal
                    dimensions into our research, we aim at providing more nuanced and
                    context-specific recommendations for energy resource allocation. This approach
                    may help decision-makers in the renewable energy sector to make informed
                    choices that account for regional variations, climatic conditions, and
                    long-term performance trends.
                </p>
            </div>
        </dd>
        <dt><a name="item585">[585]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03483"
                    title="Abstract">arXiv:2405.03483</a> [<a href="/pdf/2405.03483" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03483" title="Download PostScript">ps</a>, <a href="/format/2405.03483"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On certain matrix algebras related to quasi-Toeplitz matrices
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Bini%2C+D">Dario Bini</a>,
                    <a href="/search/math?searchtype=author&amp;query=Meini%2C+B">Beatrice Meini</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">Let <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-238-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1622"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.28em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1623"><span class="msubsup"
                                                id="MathJax-Span-1624"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1625"
                                                            style="font-family: MathJax_Math-italic;">A</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.755em;"><span
                                                            class="mi" id="MathJax-Span-1626"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-238">A_\alpha</script> be the semi-infinite tridiagonal
                    matrix having subdiagonal and
                    superdiagonal unit entries, <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-239-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1627"
                                style="width: 5.79em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.806em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.75em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1628"><span class="mo" id="MathJax-Span-1629"
                                                style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                id="MathJax-Span-1630"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1631"
                                                            style="font-family: MathJax_Math-italic;">A</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.755em;"><span
                                                            class="mi" id="MathJax-Span-1632"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-1633"><span
                                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.07em, 1000.29em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mo" id="MathJax-Span-1634"
                                                            style="font-family: MathJax_Main;">)</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.408em;"><span
                                                            class="texatom" id="MathJax-Span-1635"><span class="mrow"
                                                                id="MathJax-Span-1636"><span class="mn"
                                                                    id="MathJax-Span-1637"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">11</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1638"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mi" id="MathJax-Span-1639"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">α</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-239">(A_\alpha)_{11}=\alpha</script>, where <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-240-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1640"
                                style="width: 3.128em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.607em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.623em, 1002.55em, 2.723em, -999.997em); top: -2.486em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1641"><span class="mi" id="MathJax-Span-1642"
                                                style="font-family: MathJax_Math-italic;">α</span><span class="mo"
                                                id="MathJax-Span-1643"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∈</span><span
                                                class="texatom" id="MathJax-Span-1644"
                                                style="padding-left: 0.292em;"><span class="mrow"
                                                    id="MathJax-Span-1645"><span class="mi" id="MathJax-Span-1646"
                                                        style="font-family: MathJax_AMS;">C</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.491em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-240">\alpha\in\mathbb
    C</script>, and zero elsewhere. A basis <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-241-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1647"
                                style="width: 7.989em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.658em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1006.6em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1648"><span class="mo" id="MathJax-Span-1649"
                                                style="font-family: MathJax_Main;">{</span><span class="msubsup"
                                                id="MathJax-Span-1650"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1651"
                                                            style="font-family: MathJax_Math-italic;">P<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.639em;"><span
                                                            class="mn" id="MathJax-Span-1652"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">0</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1653"
                                                style="font-family: MathJax_Main;">,</span><span class="msubsup"
                                                id="MathJax-Span-1654" style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1655"
                                                            style="font-family: MathJax_Math-italic;">P<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.639em;"><span
                                                            class="mn" id="MathJax-Span-1656"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1657"
                                                style="font-family: MathJax_Main;">,</span><span class="msubsup"
                                                id="MathJax-Span-1658" style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1659"
                                                            style="font-family: MathJax_Math-italic;">P<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.639em;"><span
                                                            class="mn" id="MathJax-Span-1660"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1661"
                                                style="font-family: MathJax_Main;">,</span><span class="mo"
                                                id="MathJax-Span-1662"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">…</span><span
                                                class="mo" id="MathJax-Span-1663"
                                                style="font-family: MathJax_Main;">}</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-241">\{P_0,P_1,P_2,\ldots\}</script> of the linear space
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-242-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1664"
                                style="width: 1.508em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.22em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1665"><span class="msubsup"
                                                id="MathJax-Span-1666"><span
                                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.227em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1667"><span class="mrow"
                                                                id="MathJax-Span-1668"><span class="mi"
                                                                    id="MathJax-Span-1669"
                                                                    style="font-family: MathJax_Caligraphic;">P<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mi" id="MathJax-Span-1670"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-242">\mathcal P_\alpha</script> spanned by the powers of
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-243-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1671"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.28em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1672"><span class="msubsup"
                                                id="MathJax-Span-1673"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1674"
                                                            style="font-family: MathJax_Math-italic;">A</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.755em;"><span
                                                            class="mi" id="MathJax-Span-1675"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-243">A_\alpha</script> is determined, where
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-244-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1676"
                                style="width: 3.475em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.896em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.9em, 2.491em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1677"><span class="msubsup"
                                                id="MathJax-Span-1678"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1679"
                                                            style="font-family: MathJax_Math-italic;">P<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.639em;"><span
                                                            class="mn" id="MathJax-Span-1680"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">0</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1681"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mi" id="MathJax-Span-1682"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">I<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-244">P_0=I</script>, <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-245-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1683"
                                style="width: 7.468em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.195em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1006.2em, 2.549em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1684"><span class="msubsup"
                                                id="MathJax-Span-1685"><span
                                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1686"
                                                            style="font-family: MathJax_Math-italic;">P<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.639em;"><span
                                                            class="mi" id="MathJax-Span-1687"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1688"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="msubsup" id="MathJax-Span-1689"
                                                style="padding-left: 0.292em;"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.7em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1690"
                                                            style="font-family: MathJax_Math-italic;">T<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.582em;"><span
                                                            class="mi" id="MathJax-Span-1691"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1692"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="msubsup" id="MathJax-Span-1693"
                                                style="padding-left: 0.234em;"><span
                                                    style="display: inline-block; position: relative; width: 1.334em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1694"
                                                            style="font-family: MathJax_Math-italic;">H<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-1695"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-245">P_n=T_n+H_n</script>, <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-246-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1696"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.1em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1697"><span class="msubsup"
                                                id="MathJax-Span-1698"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.7em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1699"
                                                            style="font-family: MathJax_Math-italic;">T<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.582em;"><span
                                                            class="mi" id="MathJax-Span-1700"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-246">T_n</script> is the symmetric Toeplitz matrix
                    having ones in
                    the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-247-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1701"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1702"><span class="mi" id="MathJax-Span-1703"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-247">n</script>th super- and sub-diagonal, zeros
                    elsewhere, and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-248-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1704"
                                style="width: 1.623em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.334em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.33em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1705"><span class="msubsup"
                                                id="MathJax-Span-1706"><span
                                                    style="display: inline-block; position: relative; width: 1.334em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1707"
                                                            style="font-family: MathJax_Math-italic;">H<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-1708"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-248">H_n</script> is the Hankel
                    matrix with first row <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-249-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1709"
                                style="width: 14.933em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 12.445em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1012.33em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1710"><span class="mo" id="MathJax-Span-1711"
                                                style="font-family: MathJax_Main;">[</span><span class="mi"
                                                id="MathJax-Span-1712"
                                                style="font-family: MathJax_Math-italic;">θ</span><span class="msubsup"
                                                id="MathJax-Span-1713"><span
                                                    style="display: inline-block; position: relative; width: 2.028em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1714"
                                                            style="font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.639em;"><span
                                                            class="texatom" id="MathJax-Span-1715"><span class="mrow"
                                                                id="MathJax-Span-1716"><span class="mi"
                                                                    id="MathJax-Span-1717"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                                    class="mo" id="MathJax-Span-1718"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-1719"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">2</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1720"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1721"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">θ</span><span
                                                class="msubsup" id="MathJax-Span-1722"><span
                                                    style="display: inline-block; position: relative; width: 2.028em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1723"
                                                            style="font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.639em;"><span
                                                            class="texatom" id="MathJax-Span-1724"><span class="mrow"
                                                                id="MathJax-Span-1725"><span class="mi"
                                                                    id="MathJax-Span-1726"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                                    class="mo" id="MathJax-Span-1727"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-1728"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">3</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1729"
                                                style="font-family: MathJax_Main;">,</span><span class="mo"
                                                id="MathJax-Span-1730"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">…</span><span
                                                class="mo" id="MathJax-Span-1731"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">,</span><span
                                                class="mi" id="MathJax-Span-1732"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">θ</span><span
                                                class="mo" id="MathJax-Span-1733"
                                                style="font-family: MathJax_Main;">,</span><span class="mi"
                                                id="MathJax-Span-1734"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">α</span><span
                                                class="mo" id="MathJax-Span-1735"
                                                style="font-family: MathJax_Main;">,</span><span class="mn"
                                                id="MathJax-Span-1736"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">0</span><span
                                                class="mo" id="MathJax-Span-1737"
                                                style="font-family: MathJax_Main;">,</span><span class="mo"
                                                id="MathJax-Span-1738"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">…</span><span
                                                class="mo" id="MathJax-Span-1739"
                                                style="font-family: MathJax_Main;">]</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-249">[\theta\alpha^{n-2}, \theta\alpha^{n-3}, \ldots, \theta,
    \alpha, 0, \ldots]</script>, where <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-250-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1740"
                                style="width: 5.558em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.633em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.58em, 2.433em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1741"><span class="mi" id="MathJax-Span-1742"
                                                style="font-family: MathJax_Math-italic;">θ</span><span class="mo"
                                                id="MathJax-Span-1743"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="msubsup" id="MathJax-Span-1744"
                                                style="padding-left: 0.292em;"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1745"
                                                            style="font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.639em;"><span
                                                            class="mn" id="MathJax-Span-1746"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1747"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">−</span><span
                                                class="mn" id="MathJax-Span-1748"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-250">\theta=\alpha^2-1</script>. The set <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-251-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1749"
                                style="width: 1.508em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.22em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1750"><span class="msubsup"
                                                id="MathJax-Span-1751"><span
                                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.227em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1752"><span class="mrow"
                                                                id="MathJax-Span-1753"><span class="mi"
                                                                    id="MathJax-Span-1754"
                                                                    style="font-family: MathJax_Caligraphic;">P<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mi" id="MathJax-Span-1755"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-251">\mathcal P_\alpha</script> is
                    an algebra, and for <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-252-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1756"
                                style="width: 7.295em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.079em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1006.02em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1757"><span class="mi" id="MathJax-Span-1758"
                                                style="font-family: MathJax_Math-italic;">α</span><span class="mo"
                                                id="MathJax-Span-1759"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∈</span><span
                                                class="mo" id="MathJax-Span-1760"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">{</span><span
                                                class="mo" id="MathJax-Span-1761"
                                                style="font-family: MathJax_Main;">−</span><span class="mn"
                                                id="MathJax-Span-1762" style="font-family: MathJax_Main;">1</span><span
                                                class="mo" id="MathJax-Span-1763"
                                                style="font-family: MathJax_Main;">,</span><span class="mn"
                                                id="MathJax-Span-1764"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">0</span><span
                                                class="mo" id="MathJax-Span-1765"
                                                style="font-family: MathJax_Main;">,</span><span class="mn"
                                                id="MathJax-Span-1766"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">1</span><span
                                                class="mo" id="MathJax-Span-1767"
                                                style="font-family: MathJax_Main;">}</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-252">\alpha\in\{-1,0,1\}</script>, <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-253-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1768"
                                style="width: 1.623em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.334em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.33em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1769"><span class="msubsup"
                                                id="MathJax-Span-1770"><span
                                                    style="display: inline-block; position: relative; width: 1.334em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1771"
                                                            style="font-family: MathJax_Math-italic;">H<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-1772"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-253">H_n</script> has only one nonzero
                    anti-diagonal. This fact is exploited to provide a better representation of
                    symmetric quasi-Toeplitz matrices <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-254-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1773"
                                style="width: 2.318em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.913em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.91em, 1.334em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1774"><span class="msubsup"
                                                id="MathJax-Span-1775"><span
                                                    style="display: inline-block; position: relative; width: 1.913em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.68em, 4.285em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1776"><span class="mrow"
                                                                id="MathJax-Span-1777"><span class="mi"
                                                                    id="MathJax-Span-1778"
                                                                    style="font-family: MathJax_Caligraphic;">Q</span><span
                                                                    class="mi" id="MathJax-Span-1779"
                                                                    style="font-family: MathJax_Caligraphic;">T<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.292em;"></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 1.392em;"><span
                                                            class="mi" id="MathJax-Span-1780"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">S<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-254">\mathcal {QT}_S</script>, where, instead of
                    representing a generic matrix <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-255-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1781"
                                style="width: 4.748em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.938em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1003.94em, 2.549em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1782"><span class="mi" id="MathJax-Span-1783"
                                                style="font-family: MathJax_Math-italic;">A</span><span class="mo"
                                                id="MathJax-Span-1784"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∈</span><span
                                                class="msubsup" id="MathJax-Span-1785"
                                                style="padding-left: 0.292em;"><span
                                                    style="display: inline-block; position: relative; width: 1.913em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.68em, 4.285em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1786"><span class="mrow"
                                                                id="MathJax-Span-1787"><span class="mi"
                                                                    id="MathJax-Span-1788"
                                                                    style="font-family: MathJax_Caligraphic;">Q</span><span
                                                                    class="mi" id="MathJax-Span-1789"
                                                                    style="font-family: MathJax_Caligraphic;">T<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.292em;"></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 1.392em;"><span
                                                            class="mi" id="MathJax-Span-1790"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">S<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-255">A\in\mathcal{QT}_S</script> as <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-256-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1791"
                                style="width: 6.021em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.98em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1004.98em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1792"><span class="mi" id="MathJax-Span-1793"
                                                style="font-family: MathJax_Math-italic;">A</span><span class="mo"
                                                id="MathJax-Span-1794"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mi" id="MathJax-Span-1795"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-1796"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mi" id="MathJax-Span-1797"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-256">A=T+K</script>, where <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-257-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1798"
                                style="width: 0.871em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.7em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1799"><span class="mi" id="MathJax-Span-1800"
                                                style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-257">T</script> is
                    Toeplitz and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-258-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1801"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1802"><span class="mi" id="MathJax-Span-1803"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-258">K</script> is compact, it is represented as <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-259-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1804"
                                style="width: 6.079em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.038em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1005.04em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1805"><span class="mi" id="MathJax-Span-1806"
                                                style="font-family: MathJax_Math-italic;">A</span><span class="mo"
                                                id="MathJax-Span-1807"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mi" id="MathJax-Span-1808"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.292em;">P<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-1809"
                                                style="font-family: MathJax_Main; padding-left: 0.234em;">+</span><span
                                                class="mi" id="MathJax-Span-1810"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.234em;">H<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-259">A=P+H</script>, where <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-260-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1811"
                                style="width: 3.938em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.244em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1003.24em, 2.549em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1812"><span class="mi" id="MathJax-Span-1813"
                                                style="font-family: MathJax_Math-italic;">P<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span><span
                                                class="mo" id="MathJax-Span-1814"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∈</span><span
                                                class="msubsup" id="MathJax-Span-1815"
                                                style="padding-left: 0.292em;"><span
                                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.75em, 4.227em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-1816"><span class="mrow"
                                                                id="MathJax-Span-1817"><span class="mi"
                                                                    id="MathJax-Span-1818"
                                                                    style="font-family: MathJax_Caligraphic;">P<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mi" id="MathJax-Span-1819"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">α</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-260">P\in\mathcal
    P_\alpha</script> and <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-261-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1820"
                                style="width: 1.045em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.871em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.87em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1821"><span class="mi" id="MathJax-Span-1822"
                                                style="font-family: MathJax_Math-italic;">H<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-261">H</script> is compact. It is shown experimentally
                    that the matrix
                    arithmetic obtained this way is much more effective than that implemented in
                    the CQT-Toolbox of Numer.~Algo. 81(2):741--769, 2019.
                </p>
            </div>
        </dd>
        <dt><a name="item586">[586]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03484"
                    title="Abstract">arXiv:2405.03484</a> [<a href="/pdf/2405.03484" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03484" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Whispy: Adapting STT Whisper Models to Real-Time Environments
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bevilacqua%2C+A">Antonio Bevilacqua</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saviano%2C+P">Paolo Saviano</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Amirante%2C+A">Alessandro Amirante</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Romano%2C+S+P">Simon Pietro Romano</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">Large general-purpose transformer models have recently become the mainstay in
                    the realm of speech analysis. In particular, Whisper achieves state-of-the-art
                    results in relevant tasks such as speech recognition, translation, language
                    identification, and voice activity detection. However, Whisper models are not
                    designed to be used in real-time conditions, and this limitation makes them
                    unsuitable for a vast plethora of practical applications. In this paper, we
                    introduce Whispy, a system intended to bring live capabilities to the Whisper
                    pretrained models. As a result of a number of architectural optimisations,
                    Whispy is able to consume live audio streams and generate high level, coherent
                    voice transcriptions, while still maintaining a low computational cost. We
                    evaluate the performance of our system on a large repository of publicly
                    available speech datasets, investigating how the transcription mechanism
                    introduced by Whispy impacts on the Whisper output. Experimental results show
                    how Whispy excels in robustness, promptness, and accuracy.
                </p>
            </div>
        </dd>
        <dt><a name="item587">[587]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03485"
                    title="Abstract">arXiv:2405.03485</a> [<a href="/pdf/2405.03485" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03485" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LGTM: Local-to-Global Text-Driven Human Motion Diffusion
                    Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+H">Haowen Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+R">Ruikun Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Haibin Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+C">Chongyang Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Hui Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+R">Ruizhen Hu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages,7 figures, SIGGRAPH 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
                <p class="mathjax">In this paper, we introduce LGTM, a novel Local-to-Global pipeline for
                    Text-to-Motion generation. LGTM utilizes a diffusion-based architecture and
                    aims to address the challenge of accurately translating textual descriptions
                    into semantically coherent human motion in computer animation. Specifically,
                    traditional methods often struggle with semantic discrepancies, particularly in
                    aligning specific motions to the correct body parts. To address this issue, we
                    propose a two-stage pipeline to overcome this challenge: it first employs large
                    language models (LLMs) to decompose global motion descriptions into
                    part-specific narratives, which are then processed by independent body-part
                    motion encoders to ensure precise local semantic alignment. Finally, an
                    attention-based full-body optimizer refines the motion generation results and
                    guarantees the overall coherence. Our experiments demonstrate that LGTM gains
                    significant improvements in generating locally accurate, semantically-aligned
                    human motion, marking a notable advancement in text-to-motion applications.
                    Code and data for this paper are available at https://github.com/L-Sun/LGTM
                </p>
            </div>
        </dd>
        <dt><a name="item588">[588]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03486"
                    title="Abstract">arXiv:2405.03486</a> [<a href="/pdf/2405.03486" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03486" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> UnsafeBench: Benchmarking Image Safety Classifiers on
                    Real-World and AI-Generated Images
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Qu%2C+Y">Yiting Qu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+X">Xinyue Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yixin Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Backes%2C+M">Michael Backes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zannettou%2C+S">Savvas Zannettou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yang Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Social and Information Networks
                    (cs.SI)

                </div>
                <p class="mathjax">Image safety classifiers play an important role in identifying and mitigating
                    the spread of unsafe images online (e.g., images including violence, hateful
                    rhetoric, etc.). At the same time, with the advent of text-to-image models and
                    increasing concerns about the safety of AI models, developers are increasingly
                    relying on image safety classifiers to safeguard their models. Yet, the
                    performance of current image safety classifiers remains unknown for real-world
                    and AI-generated images. To bridge this research gap, in this work, we propose
                    UnsafeBench, a benchmarking framework that evaluates the effectiveness and
                    robustness of image safety classifiers. First, we curate a large dataset of 10K
                    real-world and AI-generated images that are annotated as safe or unsafe based
                    on a set of 11 unsafe categories of images (sexual, violent, hateful, etc.).
                    Then, we evaluate the effectiveness and robustness of five popular image safety
                    classifiers, as well as three classifiers that are powered by general-purpose
                    visual language models. Our assessment indicates that existing image safety
                    classifiers are not comprehensive and effective enough in mitigating the
                    multifaceted problem of unsafe images. Also, we find that classifiers trained
                    only on real-world images tend to have degraded performance when applied to
                    AI-generated images. Motivated by these findings, we design and implement a
                    comprehensive image moderation tool called PerspectiveVision, which effectively
                    identifies 11 categories of real-world and AI-generated unsafe images. The best
                    PerspectiveVision model achieves an overall F1-Score of 0.810 on six evaluation
                    datasets, which is comparable with closed-source and expensive state-of-the-art
                    models like GPT-4V. UnsafeBench and PerspectiveVision can aid the research
                    community in better understanding the landscape of image safety classification
                    in the era of generative AI.
                </p>
            </div>
        </dd>
        <dt><a name="item589">[589]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03488"
                    title="Abstract">arXiv:2405.03488</a> [<a href="/pdf/2405.03488" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03488" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Accurate and Fast Approximate Graph Pattern Mining at Scale
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Arpaci-Dusseau%2C+A">Anna Arpaci-Dusseau</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zixiang Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xuhao Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 12 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>;
                    Data Structures and Algorithms (cs.DS)

                </div>
                <p class="mathjax">Approximate graph pattern mining (A-GPM) is an important data analysis tool
                    for many graph-based applications. There exist sampling-based A-GPM systems to
                    provide automation and generalization over a wide variety of use cases.
                    However, there are two major obstacles that prevent existing A-GPM systems
                    being adopted in practice. First, the termination mechanism that decides when
                    to end sampling lacks theoretical backup on confidence, and is unstable and
                    slow in practice. Second, they suffer poor performance when dealing with the
                    "needle-in-the-hay" cases, because a huge number of samples are required to
                    converge, given the extremely low hit rate of their fixed sampling schemes. We
                    build ScaleGPM, an accurate and fast A-GPM system that removes the two
                    obstacles. First, we propose a novel on-the-fly convergence detection mechanism
                    to achieve stable termination and provide theoretical guarantee on the
                    confidence, with negligible overhead. Second, we propose two techniques to deal
                    with the "needle-in-the-hay" problem, eager-verify and hybrid sampling. Our
                    eager-verify method improves sampling hit rate by pruning unpromising
                    candidates as early as possible. Hybrid sampling improves performance by
                    automatically choosing the better scheme between fine-grained and
                    coarse-grained sampling schemes. Experiments show that our online convergence
                    detection mechanism can detect convergence and results in stable and rapid
                    termination with theoretically guaranteed confidence. We show the effectiveness
                    of eager-verify in improving the hit rate, and the scheme-selection mechanism
                    in correctly choosing the better scheme for various cases. Overall, ScaleGPM
                    achieves a geomean average of 565x (up to 610169x) speedup over the
                    state-of-the-art A-GPM system, Arya. In particular, ScaleGPM handles
                    billion-scale graphs in seconds, where existing systems either run out of
                    memory or fail to complete in hours.
                </p>
            </div>
        </dd>
        <dt><a name="item590">[590]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03489"
                    title="Abstract">arXiv:2405.03489</a> [<a href="/pdf/2405.03489" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03489" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the Influence of Data Resampling for Deep Learning-Based
                    Log Anomaly Detection: Insights and Recommendations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+X">Xiaoxue Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zou%2C+H">Huiqi Zou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Keung%2C+J">Jacky Keung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+P">Pinjia He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yishu Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+X">Xiao Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sarro%2C+F">Federica Sarro</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 2 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">Numerous DL-based approaches have garnered considerable attention in the
                    field of software Log Anomaly Detection. However, a practical challenge
                    persists: the class imbalance in the public data commonly used to train the DL
                    models. This imbalance is characterized by a substantial disparity in the
                    number of abnormal log sequences compared to normal ones, for example,
                    anomalies represent less than 1% of one of the most popular datasets. Previous
                    research has indicated that existing DLLAD approaches may exhibit
                    unsatisfactory performance, particularly when confronted with datasets
                    featuring severe class imbalances. Mitigating class imbalance through data
                    resampling has proven effective for other software engineering tasks, however,
                    it has been unexplored for LAD thus far. This study aims to fill this gap by
                    providing an in-depth analysis of the impact of diverse data resampling methods
                    on existing DLLAD approaches from two distinct perspectives. Firstly, we assess
                    the performance of these DLLAD approaches across three datasets and explore the
                    impact of resampling ratios of normal to abnormal data on ten data resampling
                    methods. Secondly, we evaluate the effectiveness of the data resampling methods
                    when utilizing optimal resampling ratios of normal to abnormal data. Our
                    findings indicate that oversampling methods generally outperform undersampling
                    and hybrid methods. Data resampling on raw data yields superior results
                    compared to data resampling in the feature space. In most cases, certain
                    undersampling and hybrid methods show limited effectiveness. Additionally, by
                    exploring the resampling ratio of normal to abnormal data, we suggest
                    generating more data for minority classes through oversampling while removing
                    less data from majority classes through undersampling. In conclusion, our study
                    provides valuable insights into the intricate relationship between data
                    resampling methods and DLLAD.
                </p>
            </div>
        </dd>
        <dt><a name="item591">[591]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03491"
                    title="Abstract">arXiv:2405.03491</a> [<a href="/pdf/2405.03491" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03491" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Jointly Learning Cost and Constraints from Demonstrations for
                    Safe Trajectory Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chaubey%2C+S">Shivam Chaubey</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Verdoja%2C+F">Francesco Verdoja</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kyrki%2C+V">Ville Kyrki</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to 2024 IEEE/RSJ International Conference on
                    Intelligent Robots and Systems (IROS)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Learning from Demonstration allows robots to mimic human actions. However,
                    these methods do not model constraints crucial to ensure safety of the learned
                    skill. Moreover, even when explicitly modelling constraints, they rely on the
                    assumption of a known cost function, which limits their practical usability for
                    task with unknown cost. In this work we propose a two-step optimization process
                    that allow to estimate cost and constraints by decoupling the learning of cost
                    functions from the identification of unknown constraints within the
                    demonstrated trajectories. Initially, we identify the cost function by
                    isolating the effect of constraints on parts of the demonstrations.
                    Subsequently, a constraint leaning method is used to identify the unknown
                    constraints. Our approach is validated both on simulated trajectories and a
                    real robotic manipulation task. Our experiments show the impact that incorrect
                    cost estimation has on the learned constraints and illustrate how the proposed
                    method is able to infer unknown constraints, such as obstacles, from
                    demonstrated trajectories without any initial knowledge of the cost.
                </p>
            </div>
        </dd>
        <dt><a name="item592">[592]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03500"
                    title="Abstract">arXiv:2405.03500</a> [<a href="/pdf/2405.03500" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03500" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Rate-Distortion-Classification Approach for Lossy Image
                    Compression
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuefeng Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Digital Signal Processing Volume 141, September 2023,
                    104163
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>;
                    Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Information Theory
                    (cs.IT)

                </div>
                <p class="mathjax">In lossy image compression, the objective is to achieve minimal signal
                    distortion while compressing images to a specified bit rate. The increasing
                    demand for visual analysis applications, particularly in classification tasks,
                    has emphasized the significance of considering semantic distortion in
                    compressed images. To bridge the gap between image compression and visual
                    analysis, we propose a Rate-Distortion-Classification (RDC) model for lossy
                    image compression, offering a unified framework to optimize the trade-off
                    between rate, distortion, and classification accuracy. The RDC model is
                    extensively analyzed both statistically on a multi-distribution source and
                    experimentally on the widely used MNIST dataset. The findings reveal that the
                    RDC model exhibits desirable properties, including monotonic non-increasing and
                    convex functions, under certain conditions. This work provides insights into
                    the development of human-machine friendly compression methods and Video Coding
                    for Machine (VCM) approaches, paving the way for end-to-end image compression
                    techniques in real-world applications.
                </p>
            </div>
        </dd>
        <dt><a name="item593">[593]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03501"
                    title="Abstract">arXiv:2405.03501</a> [<a href="/pdf/2405.03501" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03501" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Boosting Single Positive Multi-label Classification with
                    Generalized Robust Loss
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yanxi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chunxiao Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+X">Xinyang Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jinhuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+W">Weiyu Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yiming Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Renyuan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tinghe Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bo Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 5 figures, 6 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Multi-label learning (MLL) requires comprehensive multi-semantic annotations
                    that is hard to fully obtain, thus often resulting in missing labels scenarios.
                    In this paper, we investigate Single Positive Multi-label Learning (SPML),
                    where each image is associated with merely one positive label. Existing SPML
                    methods only focus on designing losses using mechanisms such as hard
                    pseudo-labeling and robust losses, mostly leading to unacceptable false
                    negatives. To address this issue, we first propose a generalized loss framework
                    based on expected risk minimization to provide soft pseudo labels, and point
                    out that the former losses can be seamlessly converted into our framework. In
                    particular, we design a novel robust loss based on our framework, which enjoys
                    flexible coordination between false positives and false negatives, and can
                    additionally deal with the imbalance between positive and negative samples.
                    Extensive experiments show that our approach can significantly improve SPML
                    performance and outperform the vast majority of state-of-the-art methods on all
                    the four benchmarks.
                </p>
            </div>
        </dd>
        <dt><a name="item594">[594]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03502"
                    title="Abstract">arXiv:2405.03502</a> [<a href="/pdf/2405.03502" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03502" title="Download PostScript">ps</a>, <a href="/format/2405.03502"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Human-Variability-Respecting Optimal Control for Physical
                    Human-Machine Interaction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Kille%2C+S">Sean Kille</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Leibold%2C+P">Paul Leibold</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Karg%2C+P">Philipp Karg</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Varga%2C+B">Balint Varga</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Hohmann%2C+S">Sören Hohmann</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">Physical Human-Machine Interaction plays a pivotal role in facilitating
                    collaboration across various domains. When designing appropriate model-based
                    controllers to assist a human in the interaction, the accuracy of the human
                    model is crucial for the resulting overall behavior of the coupled system. When
                    looking at state-of-the-art control approaches, most methods rely on a
                    deterministic model or no model at all of the human behavior. This poses a gap
                    to the current neuroscientific standard regarding human movement modeling,
                    which uses stochastic optimal control models that include signal-dependent
                    noise processes and therefore describe the human behavior much more accurate
                    than the deterministic counterparts. To close this gap by including these
                    stochastic human models in the control design, we introduce a novel design
                    methodology resulting in a Human-Variability-Respecting Optimal Control that
                    explicitly incorporates the human noise processes and their influence on the
                    mean and variability behavior of a physically coupled human-machine system. Our
                    approach results in an improved overall system performance, i.e. higher
                    accuracy and lower variability in target point reaching, while allowing to
                    shape the joint variability, for example to preserve human natural variability
                    patterns.
                </p>
            </div>
        </dd>
        <dt><a name="item595">[595]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03506"
                    title="Abstract">arXiv:2405.03506</a> [<a href="/pdf/2405.03506" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03506" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spin-Wave Voices: Sonification of Nanoscale Spin Waves as an
                    Engagement and Research Tool
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pile%2C+S">Santa Pile</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lesota%2C+O">Oleg Lesota</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peter%2C+S+D">Silvan David Peter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Humer%2C+C">Christina Humer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gasser%2C+M">Martin Gasser</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to ICAD2024 conference proceedings
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">Magnonics is an emerging research field that addresses the use of spin waves
                    (magnons), purely magnetic waves, for information transport and processing.
                    Spin waves are a potential replacement for electric current in modern
                    computational devices that would make them more compact and energy efficient.
                    The field is yet little known, even among physicists. Additionally, with the
                    development of new measuring techniques and computational physics, the obtained
                    magnetic data becomes more complex, in some cases including 3D vector fields
                    and time-resolution. This work presents an approach to the audio-visual
                    representation of the spin waves and discusses its use as a tool for science
                    communication exhibits and possible data analysis tool. The work also details
                    an instance of such an exhibit presented at the annual international digital
                    art exhibition Ars Electronica Festival in 2022.
                </p>
            </div>
        </dd>
        <dt><a name="item596">[596]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03509"
                    title="Abstract">arXiv:2405.03509</a> [<a href="/pdf/2405.03509" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03509" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Are Human Rules Necessary? Generating Reusable APIs with CoT
                    Reasoning and In-Context Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mai%2C+Y">Yubo Mai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zhipeng Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xing Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bao%2C+L">Lingfeng Bao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yu Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jianling Sun</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">Inspired by the great potential of Large Language Models (LLMs) for solving
                    complex coding tasks, in this paper, we propose a novel approach, named
                    Code2API, to automatically perform APIzation for Stack Overflow code snippets.
                    Code2API does not require additional model training or any manual crafting
                    rules and can be easily deployed on personal computers without relying on other
                    external tools. Specifically, Code2API guides the LLMs through well-designed
                    prompts to generate well-formed APIs for given code snippets. To elicit
                    knowledge and logical reasoning from LLMs, we used chain-of-thought (CoT)
                    reasoning and few-shot in-context learning, which can help the LLMs fully
                    understand the APIzation task and solve it step by step in a manner similar to
                    a developer. Our evaluations show that Code2API achieves a remarkable accuracy
                    in identifying method parameters (65%) and return statements (66%) equivalent
                    to human-generated ones, surpassing the current state-of-the-art approach,
                    APIzator, by 15.0% and 16.5% respectively. Moreover, compared with APIzator,
                    our user study demonstrates that Code2API exhibits superior performance in
                    generating meaningful method names, even surpassing the human-level
                    performance, and developers are more willing to use APIs generated by our
                    approach, highlighting the applicability of our tool in practice. Finally, we
                    successfully extend our framework to the Python dataset, achieving a comparable
                    performance with Java, which verifies the generalizability of our tool.
                </p>
            </div>
        </dd>
        <dt><a name="item597">[597]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03511"
                    title="Abstract">arXiv:2405.03511</a> [<a href="/pdf/2405.03511" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03511" title="Download PostScript">ps</a>, <a href="/format/2405.03511"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Extremal Separation Problems for Temporal Instance Queries
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jung%2C+J+C">Jean Christoph Jung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ryzhikov%2C+V">Vladislav Ryzhikov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wolter%2C+F">Frank Wolter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zakharyaschev%2C+M">Michael Zakharyaschev</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>;
                    Logic in Computer Science (cs.LO)

                </div>
                <p class="mathjax">The separation problem for a class Q of database queries is to find a query
                    in Q that distinguishes between a given set of `positive' and `negative' data
                    examples. Separation provides explanations of examples and underpins the
                    query-by-example paradigm to support database users in constructing and
                    refining queries. As the space of all separating queries can be large, it is
                    helpful to succinctly represent this space by means of its most specific
                    (logically strongest) and general (weakest) members. We investigate this
                    extremal separation problem for classes of instance queries formulated in
                    linear temporal logic LTL with the operators conjunction, next, and eventually.
                    Our results range from tight complexity bounds for verifying and counting
                    extremal separators to algorithms computing them.
                </p>
            </div>
        </dd>
        <dt><a name="item598">[598]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03513"
                    title="Abstract">arXiv:2405.03513</a> [<a href="/pdf/2405.03513" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03513" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> QBER: Quantifying Cyber Risks for Strategic Decisions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Franco%2C+M+F">Muriel Figueredo Franco</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mullick%2C+A+R">Aiatur Rahaman Mullick</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jha%2C+S">Santosh Jha</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 9 equations, 3 tables, 2 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Computational Engineering, Finance, and Science (cs.CE)

                </div>
                <p class="mathjax">Quantifying cyber risks is essential for organizations to grasp their
                    vulnerability to threats and make informed decisions. However, current
                    approaches still need to work on blending economic viewpoints to provide
                    insightful analysis. To bridge this gap, we introduce QBER approach to offer
                    decision-makers measurable risk metrics. The QBER evaluates losses from
                    cyberattacks, performs detailed risk analyses based on existing cybersecurity
                    measures, and provides thorough cost assessments. Our contributions involve
                    outlining cyberattack probabilities and risks, identifying Technical, Economic,
                    and Legal (TEL) impacts, creating a model to gauge impacts, suggesting risk
                    mitigation strategies, and examining trends and challenges in implementing
                    widespread Cyber Risk Quantification (CRQ). The QBER approach serves as a
                    guided approach for organizations to assess risks and strategically invest in
                    cybersecurity.
                </p>
            </div>
        </dd>
        <dt><a name="item599">[599]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03514"
                    title="Abstract">arXiv:2405.03514</a> [<a href="/pdf/2405.03514" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03514" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Development of Ultra-Portable 3D Mapping Systems for
                    Emergency Services
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hamesse%2C+C">Charles Hamesse</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fr%C3%A9ville%2C+T">Timothée Fréville</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saarinen%2C+J">Juha Saarinen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vlaminck%2C+M">Michiel Vlaminck</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luong%2C+H">Hiep Luong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Haelterman%2C+R">Rob Haelterman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages, 20 figures, accepted to the IEEE ICRA Workshop on
                    Field Robotics 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">Miniaturization of cameras and LiDAR sensors has enabled the development of
                    wearable 3D mapping systems for emergency responders. These systems have the
                    potential to revolutionize response capabilities by providing real-time,
                    high-fidelity maps of dynamic and hazardous environments. We present our recent
                    efforts towards the development of such ultra-portable 3D mapping systems. We
                    review four different sensor configurations, either helmet-mounted or
                    body-worn, with two different mapping algorithms that were implemented and
                    evaluated during field trials. The paper discusses the experimental results
                    with the aim to stimulate further discussion within the portable 3D mapping
                    research community.
                </p>
            </div>
        </dd>
        <dt><a name="item600">[600]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03516"
                    title="Abstract">arXiv:2405.03516</a> [<a href="/pdf/2405.03516" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03516" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GI-SMN: Gradient Inversion Attack against Federated Learning
                    without Prior Knowledge
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Qian%2C+J">Jin Qian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+K">Kaimin Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yongdong Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jilian Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jipeng Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bao%2C+H">Huan Bao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages, 10 figures, conference
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Federated learning (FL) has emerged as a privacy-preserving machine learning
                    approach where multiple parties share gradient information rather than original
                    user data. Recent work has demonstrated that gradient inversion attacks can
                    exploit the gradients of FL to recreate the original user data, posing
                    significant privacy risks. However, these attacks make strong assumptions about
                    the attacker, such as altering the model structure or parameters, gaining batch
                    normalization statistics, or acquiring prior knowledge of the original training
                    set, etc. Consequently, these attacks are not possible in real-world scenarios.
                    To end it, we propose a novel Gradient Inversion attack based on Style
                    Migration Network (GI-SMN), which breaks through the strong assumptions made by
                    previous gradient inversion attacks. The optimization space is reduced by the
                    refinement of the latent code and the use of regular terms to facilitate
                    gradient matching. GI-SMN enables the reconstruction of user data with high
                    similarity in batches. Experimental results have demonstrated that GI-SMN
                    outperforms state-of-the-art gradient inversion attacks in both visual effect
                    and similarity metrics. Additionally, it also can overcome gradient pruning and
                    differential privacy defenses.
                </p>
            </div>
        </dd>
        <dt><a name="item601">[601]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03518"
                    title="Abstract">arXiv:2405.03518</a> [<a href="/pdf/2405.03518" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03518" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Reinforcement Nash Equilibrium Solver
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xinrun Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+C">Chang Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Shuxin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+P">Pengdeng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiao Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+H">Hau Chan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=An%2C+B">Bo An</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>

                </div>
                <p class="mathjax">Nash Equilibrium (NE) is the canonical solution concept of game theory, which
                    provides an elegant tool to understand the rationalities. Though mixed strategy
                    NE exists in any game with finite players and actions, computing NE in two- or
                    multi-player general-sum games is PPAD-Complete. Various alternative solutions,
                    e.g., Correlated Equilibrium (CE), and learning methods, e.g., fictitious play
                    (FP), are proposed to approximate NE. For convenience, we call these methods as
                    "inexact solvers", or "solvers" for short. However, the alternative solutions
                    differ from NE and the learning methods generally fail to converge to NE.
                    Therefore, in this work, we propose REinforcement Nash Equilibrium Solver
                    (RENES), which trains a single policy to modify the games with different sizes
                    and applies the solvers on the modified games where the obtained solution is
                    evaluated on the original games. Specifically, our contributions are threefold.
                    i) We represent the games as <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-262-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1823"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1824"><span class="mi" id="MathJax-Span-1825"
                                                style="font-family: MathJax_Math-italic;">α</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-262">\alpha</script>-rank response graphs and leverage
                    graph
                    neural network (GNN) to handle the games with different sizes as inputs; ii) We
                    use tensor decomposition, e.g., canonical polyadic (CP), to make the dimension
                    of modifying actions fixed for games with different sizes; iii) We train the
                    modifying strategy for games with the widely-used proximal policy optimization
                    (PPO) and apply the solvers to solve the modified games, where the obtained
                    solution is evaluated on original games. Extensive experiments on large-scale
                    normal-form games show that our method can further improve the approximation of
                    NE of different solvers, i.e., <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-263-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1826"
                                style="width: 0.813em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.639em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1827"><span class="mi" id="MathJax-Span-1828"
                                                style="font-family: MathJax_Math-italic;">α</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-263">\alpha</script>-rank, CE, FP and PRD, and can be
                    generalized to unseen games.
                </p>
            </div>
        </dd>
        <dt><a name="item602">[602]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03519"
                    title="Abstract">arXiv:2405.03519</a> [<a href="/pdf/2405.03519" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03519" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Low-light Object Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+P">Pengpeng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+H">Haowei Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yang Yang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">In this competition we employed a model fusion approach to achieve object
                    detection results close to those of real images. Our method is based on the
                    CO-DETR model, which was trained on two sets of data: one containing images
                    under dark conditions and another containing images enhanced with low-light
                    conditions. We used various enhancement techniques on the test data to generate
                    multiple sets of prediction results. Finally, we applied a clustering
                    aggregation method guided by IoU thresholds to select the optimal results.
                </p>
            </div>
        </dd>
        <dt><a name="item603">[603]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03520"
                    title="Abstract">arXiv:2405.03520</a> [<a href="/pdf/2405.03520" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03520" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Is Sora a World Simulator? A Comprehensive Survey on General
                    World Models and Beyond
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zheng Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaofeng Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+W">Wangbo Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Min%2C+C">Chen Min</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+N">Nianchen Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dou%2C+M">Min Dou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuqi Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+B">Botian Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+K">Kai Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=You%2C+Y">Yang You</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoxiang Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+D">Dawei Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+L">Liang Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+J">Jian Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+J">Jiwen Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+G">Guan Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This survey will be regularly updated at: <a
                        href="https://github.com/GigaAI-research/General-World-Models-Survey">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">General world models represent a crucial pathway toward achieving Artificial
                    General Intelligence (AGI), serving as the cornerstone for various applications
                    ranging from virtual environments to decision-making systems. Recently, the
                    emergence of the Sora model has attained significant attention due to its
                    remarkable simulation capabilities, which exhibits an incipient comprehension
                    of physical laws. In this survey, we embark on a comprehensive exploration of
                    the latest advancements in world models. Our analysis navigates through the
                    forefront of generative methodologies in video generation, where world models
                    stand as pivotal constructs facilitating the synthesis of highly realistic
                    visual content. Additionally, we scrutinize the burgeoning field of
                    autonomous-driving world models, meticulously delineating their indispensable
                    role in reshaping transportation and urban mobility. Furthermore, we delve into
                    the intricacies inherent in world models deployed within autonomous agents,
                    shedding light on their profound significance in enabling intelligent
                    interactions within dynamic environmental contexts. At last, we examine
                    challenges and limitations of world models, and discuss their potential future
                    directions. We hope this survey can serve as a foundational reference for the
                    research community and inspire continued innovation. This survey will be
                    regularly updated at:
                    https://github.com/GigaAI-research/General-World-Models-Survey.
                </p>
            </div>
        </dd>
        <dt><a name="item604">[604]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03523"
                    title="Abstract">arXiv:2405.03523</a> [<a href="/pdf/2405.03523" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03523" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Basilisk: Achieving Competitive Performance with Open EDA
                    Tools on an Open-Source Linux-Capable RISC-V SoC
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sauter%2C+P">Phillippe Sauter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Benz%2C+T">Thomas Benz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Scheffler%2C+P">Paul Scheffler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zerun Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Muheim%2C+B">Beat Muheim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=G%C3%BCrkaynak%2C+F+K">Frank K. Gürkaynak</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Benini%2C+L">Luca Benini</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 2 pages, 1 figure, accepted as a poster at the RISC-V
                    Summit Europe 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture
                        (cs.AR)</span>

                </div>
                <p class="mathjax">We introduce Basilisk, an optimized application-specific integrated circuit
                    (ASIC) implementation and design flow building on the end-to-end open-source
                    Iguana system-on-chip (SoC). We present enhancements to synthesis tools and
                    logic optimization scripts improving quality of results (QoR), as well as an
                    optimized physical design with an improved power grid and cell placement
                    integration enabling a higher core utilization. The tapeout-ready version of
                    Basilisk implemented in IHP's open 130 nm technology achieves an operation
                    frequency of 77 MHz (51 logic levels) under typical conditions, a 2.3x
                    improvement compared to the baseline open-source EDA design flow presented in
                    Iguana, and a higher 55 % core utilization compared to 50 % in the baseline
                    design. Through collaboration with EDA tool developers and domain experts,
                    Basilisk exemplifies a synergistic effort towards competitive open-source
                    electronic design automation (EDA) tools for research and industry
                    applications.
                </p>
            </div>
        </dd>
        <dt><a name="item605">[605]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03524"
                    title="Abstract">arXiv:2405.03524</a> [<a href="/pdf/2405.03524" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03524" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring knowledge graph-based neural-symbolic system from
                    application perspective
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+S">Shenzhe Zhu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
                <p class="mathjax">The rapid advancement in artificial intelligence (AI), particularly through
                    deep neural networks, has catalyzed significant progress in fields such as
                    vision and text processing. Nonetheless, the pursuit of AI systems that exhibit
                    human-like reasoning and interpretability continues to pose a substantial
                    challenge. The Neural-Symbolic paradigm, which integrates the deep learning
                    prowess of neural networks with the reasoning capabilities of symbolic systems,
                    presents a promising pathway toward developing more transparent and
                    comprehensible AI systems. Within this paradigm, the Knowledge Graph (KG)
                    emerges as a crucial element, offering a structured and dynamic method for
                    representing knowledge through interconnected entities and relationships,
                    predominantly utilizing the triple (subject, predicate, object). This paper
                    explores recent advancements in neural-symbolic integration based on KG,
                    elucidating how KG underpins this integration across three key categories:
                    enhancing the reasoning and interpretability of neural networks through the
                    incorporation of symbolic knowledge (Symbol for Neural), refining the
                    completeness and accuracy of symbolic systems via neural network methodologies
                    (Neural for Symbol), and facilitating their combined application in Hybrid
                    Neural-Symbolic Integration. It highlights current trends and proposes
                    directions for future research in the domain of Neural-Symbolic AI.
                </p>
            </div>
        </dd>
        <dt><a name="item606">[606]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03526"
                    title="Abstract">arXiv:2405.03526</a> [<a href="/pdf/2405.03526" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03526" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ReinWiFi: A Reinforcement-Learning-Based Framework for the
                    Application-Layer QoS Optimization of WiFi Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qianren Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lv%2C+B">Bojie Lv</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hong%2C+Y">Yuncong Hong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+R">Rui Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In this paper, a reinforcement-learning-based scheduling framework is
                    proposed and implemented to optimize the application-layer quality-of-service
                    (QoS) of a practical wireless local area network (WLAN) suffering from unknown
                    interference. Particularly, application-layer tasks of file delivery and
                    delay-sensitive communication, e.g., screen projection, in a WLAN with enhanced
                    distributed channel access (EDCA) mechanism, are jointly scheduled by adjusting
                    the contention window sizes and application-layer throughput limitation, such
                    that their QoS, including the throughput of file delivery and the round trip
                    time of the delay-sensitive communication, can be optimized. Due to the unknown
                    interference and vendor-dependent implementation of the network interface card,
                    the relation between the scheduling policy and the system QoS is unknown.
                    Hence, a reinforcement learning method is proposed, in which a novel Q-network
                    is trained to map from the historical scheduling parameters and QoS
                    observations to the current scheduling action. It is demonstrated on a testbed
                    that the proposed framework can achieve a significantly better QoS than the
                    conventional EDCA mechanism.
                </p>
            </div>
        </dd>
        <dt><a name="item607">[607]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03529"
                    title="Abstract">arXiv:2405.03529</a> [<a href="/pdf/2405.03529" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03529" title="Download PostScript">ps</a>, <a href="/format/2405.03529"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Quasi-Monte Carlo for Bayesian design of experiment problems
                    governed by parametric PDEs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Kaarnioja%2C+V">Vesa Kaarnioja</a>,
                    <a href="/search/math?searchtype=author&amp;query=Schillings%2C+C">Claudia Schillings</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 43 pages, 3 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
                <p class="mathjax">This paper contributes to the study of optimal experimental design for
                    Bayesian inverse problems governed by partial differential equations (PDEs). We
                    derive estimates for the parametric regularity of multivariate double
                    integration problems over high-dimensional parameter and data domains arising
                    in Bayesian optimal design problems. We provide a detailed analysis for these
                    double integration problems using two approaches: a full tensor product and a
                    sparse tensor product combination of quasi-Monte Carlo (QMC) cubature rules
                    over the parameter and data domains. Specifically, we show that the latter
                    approach significantly improves the convergence rate, exhibiting performance
                    comparable to that of QMC integration of a single high-dimensional integral.
                    Furthermore, we numerically verify the predicted convergence rates for an
                    elliptic PDE problem with an unknown diffusion coefficient in two spatial
                    dimensions, offering empirical evidence supporting the theoretical results and
                    highlighting practical applicability.
                </p>
            </div>
        </dd>
        <dt><a name="item608">[608]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03530"
                    title="Abstract">arXiv:2405.03530</a> [<a href="/pdf/2405.03530" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03530" title="Download PostScript">ps</a>, <a href="/format/2405.03530"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Semi-autonomous Robotic Disassembly Enhanced by Mixed Reality
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Rastegarpanah%2C+A">Alireza Rastegarpanah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Contreras%2C+C+A">Cesar Alan Contreras</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stolkin%2C+R">Rustam Stolkin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">In this study, we introduce "SARDiM," a modular semi-autonomous platform
                    enhanced with mixed reality for industrial disassembly tasks. Through a case
                    study focused on EV battery disassembly, SARDiM integrates Mixed Reality,
                    object segmentation, teleoperation, force feedback, and variable autonomy.
                    Utilising the ROS, Unity, and MATLAB platforms, alongside a joint impedance
                    controller, SARDiM facilitates teleoperated disassembly. The approach combines
                    FastSAM for real-time object segmentation, generating data which is
                    subsequently processed through a cluster analysis algorithm to determine the
                    centroid and orientation of the components, categorizing them by size and
                    disassembly priority. This data guides the MoveIt platform in trajectory
                    planning for the Franka Robot arm. SARDiM provides the capability to switch
                    between two teleoperation modes: manual and semi-autonomous with variable
                    autonomy. Each was evaluated using four different Interface Methods (IM):
                    direct view, monitor feed, mixed reality with monitor feed, and point cloud
                    mixed reality. Evaluations across the eight IMs demonstrated a 40.61% decrease
                    in joint limit violations using Mode 2. Moreover, Mode 2-IM4 outperformed Mode
                    1-IM1 by achieving a 2.33%-time reduction while considerably increasing safety,
                    making it optimal for operating in hazardous environments at a safe distance,
                    with the same ease of use as teleoperation with a direct view of the
                    environment.
                </p>
            </div>
        </dd>
        <dt><a name="item609">[609]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03534"
                    title="Abstract">arXiv:2405.03534</a> [<a href="/pdf/2405.03534" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03534" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Meta-Evolve: Continuous Robot Evolution for One-to-many
                    Policy Transfer
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xingyu Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pathak%2C+D">Deepak Pathak</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+D">Ding Zhao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

                </div>
                <p class="mathjax">We investigate the problem of transferring an expert policy from a source
                    robot to multiple different robots. To solve this problem, we propose a method
                    named <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-264-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1829"
                                style="width: 2.896em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.376em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1002.38em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1830"><span class="mi" id="MathJax-Span-1831"
                                                style="font-family: MathJax_Math-italic;">M<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="mi" id="MathJax-Span-1832"
                                                style="font-family: MathJax_Math-italic;">e</span><span class="mi"
                                                id="MathJax-Span-1833"
                                                style="font-family: MathJax_Math-italic;">t</span><span class="mi"
                                                id="MathJax-Span-1834"
                                                style="font-family: MathJax_Math-italic;">a</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-264">Meta</script>-<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-265-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1835"
                                style="width: 3.591em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.954em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1002.9em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1836"><span class="mi" id="MathJax-Span-1837"
                                                style="font-family: MathJax_Math-italic;">E<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mi" id="MathJax-Span-1838"
                                                style="font-family: MathJax_Math-italic;">v</span><span class="mi"
                                                id="MathJax-Span-1839"
                                                style="font-family: MathJax_Math-italic;">o</span><span class="mi"
                                                id="MathJax-Span-1840"
                                                style="font-family: MathJax_Math-italic;">l</span><span class="mi"
                                                id="MathJax-Span-1841"
                                                style="font-family: MathJax_Math-italic;">v</span><span class="mi"
                                                id="MathJax-Span-1842"
                                                style="font-family: MathJax_Math-italic;">e</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-265">Evolve</script> that uses continuous robot
                    evolution to efficiently
                    transfer the policy to each target robot through a set of tree-structured
                    evolutionary robot sequences. The robot evolution tree allows the robot
                    evolution paths to be shared, so our approach can significantly outperform
                    naive one-to-one policy transfer. We present a heuristic approach to determine
                    an optimized robot evolution tree. Experiments have shown that our method is
                    able to improve the efficiency of one-to-three transfer of manipulation policy
                    by up to 3.2<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-266-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1843"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1844"><span class="mo" id="MathJax-Span-1845"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-266">\times</script> and one-to-six transfer of agile
                    locomotion policy by
                    2.4<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-267-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1846"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1847"><span class="mo" id="MathJax-Span-1848"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-267">\times</script> in terms of simulation cost over
                    the baseline of launching multiple
                    independent one-to-one policy transfers.
                </p>
            </div>
        </dd>
        <dt><a name="item610">[610]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03535"
                    title="Abstract">arXiv:2405.03535</a> [<a href="/pdf/2405.03535" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03535" title="Download PostScript">ps</a>, <a href="/format/2405.03535"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Asymptotic-preserving hybridizable discontinuous Galerkin
                    method for the Westervelt quasilinear wave equation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=G%C3%B3mez%2C+S">Sergio Gómez</a>,
                    <a href="/search/math?searchtype=author&amp;query=Meliani%2C+M">Mostafa Meliani</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>; Analysis of PDEs (math.AP)

                </div>
                <p class="mathjax">We discuss the asymptotic-preserving properties of a hybridizable
                    discontinuous Galerkin method for the Westervelt model of ultrasound waves.
                    More precisely, we show that the proposed method is robust with respect to
                    small values of the sound diffusivity damping parameter~<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-268-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1849"
                                style="width: 0.582em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.466em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.47em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1850"><span class="mi" id="MathJax-Span-1851"
                                                style="font-family: MathJax_Math-italic;">δ<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-268">\delta</script> by deriving
                    low- and high-order energy stability estimates, and \emph{a priori} error
                    bounds that are independent of~<span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-269-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1852"
                                style="width: 0.582em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.466em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.47em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1853"><span class="mi" id="MathJax-Span-1854"
                                                style="font-family: MathJax_Math-italic;">δ<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-269">\delta</script>. Such bounds are then used to show
                    that, when~<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-270-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1855"
                                style="width: 3.764em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.128em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1003.13em, 2.376em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1856"><span class="mi" id="MathJax-Span-1857"
                                                style="font-family: MathJax_Math-italic;">δ<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-1858"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">→</span><span
                                                class="msubsup" id="MathJax-Span-1859"
                                                style="padding-left: 0.292em;"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.47em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-1860"
                                                            style="font-family: MathJax_Main;">0</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.524em;"><span
                                                            class="mo" id="MathJax-Span-1861"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-270">\delta \rightarrow 0^+</script>, the method remains
                    stable and the discrete
                    acoustic velocity potential~<span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-271-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1862"
                                style="width: 1.97em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.229em, 1001.62em, 1.508em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1863"><span class="msubsup"
                                                id="MathJax-Span-1864"><span
                                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1865"
                                                            style="font-family: MathJax_Math-italic;">ψ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.302em, 1000.93em, 4.343em, -999.997em); top: -4.511em; left: 0.639em;"><span
                                                            class="texatom" id="MathJax-Span-1866"><span class="mrow"
                                                                id="MathJax-Span-1867"><span class="mo"
                                                                    id="MathJax-Span-1868"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span
                                                                    class="mi" id="MathJax-Span-1869"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">δ<span
                                                                        style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                                    class="mo" id="MathJax-Span-1870"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 0.639em;"><span
                                                            class="mi" id="MathJax-Span-1871"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.809em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-271">\psi_h^{(\delta)}</script> converges to~<span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-272-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1872"
                                style="width: 1.97em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.229em, 1001.62em, 1.508em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1873"><span class="msubsup"
                                                id="MathJax-Span-1874"><span
                                                    style="display: inline-block; position: relative; width: 1.623em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1875"
                                                            style="font-family: MathJax_Math-italic;">ψ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.302em, 1000.99em, 4.343em, -999.997em); top: -4.511em; left: 0.639em;"><span
                                                            class="texatom" id="MathJax-Span-1876"><span class="mrow"
                                                                id="MathJax-Span-1877"><span class="mo"
                                                                    id="MathJax-Span-1878"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span
                                                                    class="mn" id="MathJax-Span-1879"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">0</span><span
                                                                    class="mo" id="MathJax-Span-1880"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.47em, 4.17em, -999.997em); top: -3.643em; left: 0.639em;"><span
                                                            class="mi" id="MathJax-Span-1881"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">h</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.809em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-272">\psi_h^{(0)}</script>,
                    where the latter is the singular vanishing dissipation limit. Moreover, we
                    prove optimal convergence for the approximation of the acoustic particle
                    velocity variable~<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-273-Frame" tabindex="0" style=""><span class="math" id="MathJax-Span-1882"
                            style=""><span class="noError" id="MathJax-Span-1883">$\bv = \nabla
                                \psi$</span></span></span>
                    <script type="math/tex" id="MathJax-Element-273">\bv = \nabla \psi</script>. The established
                    theoretical results are
                    illustrated with some numerical experiments.
                </p>
            </div>
        </dd>
        <dt><a name="item611">[611]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03536"
                    title="Abstract">arXiv:2405.03536</a> [<a href="/pdf/2405.03536" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03536" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Extensional and Non-extensional Functions as Processes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sakayori%2C+K">Ken Sakayori</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sangiorgi%2C+D">Davide Sangiorgi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>; Programming Languages (cs.PL)

                </div>
                <p class="mathjax">Following Milner's seminal paper, the representation of functions as
                    processes has received considerable attention. For pure <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-274-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1884"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1885"><span class="mi" id="MathJax-Span-1886"
                                                style="font-family: MathJax_Math-italic;">λ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-274">\lambda</script>-calculus, the
                    process representations yield (at best) non-extensional <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-275-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1887"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1888"><span class="mi" id="MathJax-Span-1889"
                                                style="font-family: MathJax_Math-italic;">λ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-275">\lambda </script>-theories
                    (i.e., <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-276-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1890"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.26em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1891"><span class="mi" id="MathJax-Span-1892"
                                                style="font-family: MathJax_Math-italic;">β<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-276">\beta</script> rule holds, whereas <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-277-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1893"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.52em, 2.318em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1894"><span class="mi" id="MathJax-Span-1895"
                                                style="font-family: MathJax_Math-italic;">η<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-277">\eta</script> does not).
                    <br>In the paper, we study how to obtain extensional representations, and how to
                    move between extensional and non-extensional representations. Using Internal
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-278-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1896"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1897"><span class="mi" id="MathJax-Span-1898"
                                                style="font-family: MathJax_Math-italic;">π<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-278">\pi</script>, <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-279-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1899"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.93em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1900"><span class="texatom"
                                                id="MathJax-Span-1901"><span class="mrow" id="MathJax-Span-1902"><span
                                                        class="mi" id="MathJax-Span-1903"
                                                        style="font-family: MathJax_Main;">I</span></span></span><span
                                                class="mi" id="MathJax-Span-1904"
                                                style="font-family: MathJax_Math-italic;">π<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-279">\mathrm{I}\pi</script> (a subset of the <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-280-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1905"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1906"><span class="mi" id="MathJax-Span-1907"
                                                style="font-family: MathJax_Math-italic;">π<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-280">\pi</script>-calculus in which all outputs are
                    bound), we develop a refinement of Milner's original encoding of functions as
                    processes that is parametric on certain abstract components called wires. These
                    are, intuitively, processes whose task is to connect two end-point channels. We
                    show that when a few algebraic properties of wires hold, the encoding yields a
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-281-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1908"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1909"><span class="mi" id="MathJax-Span-1910"
                                                style="font-family: MathJax_Math-italic;">λ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-281">\lambda</script>-theory. Exploiting the symmetries
                    and dualities of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-282-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1911"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.93em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1912"><span class="texatom"
                                                id="MathJax-Span-1913"><span class="mrow" id="MathJax-Span-1914"><span
                                                        class="mi" id="MathJax-Span-1915"
                                                        style="font-family: MathJax_Main;">I</span></span></span><span
                                                class="mi" id="MathJax-Span-1916"
                                                style="font-family: MathJax_Math-italic;">π<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-282">\mathrm{I}\pi</script>,
                    we isolate three main classes of wires. The first two have a sequential
                    behaviour and are dual of each other; the third has a parallel behaviour and is
                    the dual of itself. We show the adoption of the parallel wires yields an
                    extensional <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-283-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1917"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1918"><span class="mi" id="MathJax-Span-1919"
                                                style="font-family: MathJax_Math-italic;">λ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-283">\lambda</script>-theory; in fact, it yields an
                    equality that coincides
                    with that of B\"ohm trees with infinite <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-284-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1920"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.52em, 2.318em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1921"><span class="mi" id="MathJax-Span-1922"
                                                style="font-family: MathJax_Math-italic;">η<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-284">\eta</script>. In contrast, the other two
                    classes of wires yield non-extensional <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-285-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1923"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1924"><span class="mi" id="MathJax-Span-1925"
                                                style="font-family: MathJax_Math-italic;">λ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-285">\lambda</script>-theories whose equalities are
                    those of the L\'evy-Longo and B\"ohm trees.
                </p>
            </div>
        </dd>
        <dt><a name="item612">[612]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03537"
                    title="Abstract">arXiv:2405.03537</a> [<a href="/pdf/2405.03537" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03537" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring the Efficacy of Federated-Continual Learning Nodes
                    with Attention-Based Classifier for Robust Web Phishing Detection: An Empirical Investigation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=M%2C+J+J">Jesher Joshua M</a>,
                    <a href="/search/cs?searchtype=author&amp;query=R%2C+A">Adhithya R</a>,
                    <a href="/search/cs?searchtype=author&amp;query=S%2C+S+D">Sree Dananjay S</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Revathi%2C+M">M Revathi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Web phishing poses a dynamic threat, requiring detection systems to quickly
                    adapt to the latest tactics. Traditional approaches of accumulating data and
                    periodically retraining models are outpaced. We propose a novel paradigm
                    combining federated learning and continual learning, enabling distributed nodes
                    to continually update models on streams of new phishing data, without
                    accumulating data. These locally adapted models are then aggregated at a
                    central server via federated learning. To enhance detection, we introduce a
                    custom attention-based classifier model with residual connections, tailored for
                    web phishing, leveraging attention mechanisms to capture intricate phishing
                    patterns. We evaluate our hybrid learning paradigm across continual learning
                    strategies (cumulative, replay, MIR, LwF) and model architectures through an
                    empirical investigation. Our main contributions are: (1) a new hybrid
                    federated-continual learning paradigm for robust web phishing detection, and
                    (2) a novel attention + residual connections based model explicitly designed
                    for this task, attaining 0.93 accuracy, 0.90 precision, 0.96 recall and 0.93
                    f1-score with the LwF strategy, outperforming traditional approaches in
                    detecting emerging phishing threats while retaining past knowledge.
                </p>
            </div>
        </dd>
        <dt><a name="item613">[613]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03541"
                    title="Abstract">arXiv:2405.03541</a> [<a href="/pdf/2405.03541" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03541" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> RepVGG-GELAN: Enhanced GELAN with VGG-STYLE ConvNets for
                    Brain Tumour Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Balakrishnan%2C+T">Thennarasi Balakrishnan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sengar%2C+S+S">Sandeep Singh Sengar</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Object detection algorithms particularly those based on YOLO have
                    demonstrated remarkable efficiency in balancing speed and accuracy. However,
                    their application in brain tumour detection remains underexplored. This study
                    proposes RepVGG-GELAN, a novel YOLO architecture enhanced with RepVGG, a
                    reparameterized convolutional approach for object detection tasks particularly
                    focusing on brain tumour detection within medical images. RepVGG-GELAN
                    leverages the RepVGG architecture to improve both speed and accuracy in
                    detecting brain tumours. Integrating RepVGG into the YOLO framework aims to
                    achieve a balance between computational efficiency and detection performance.
                    This study includes a spatial pyramid pooling-based Generalized Efficient Layer
                    Aggregation Network (GELAN) architecture which further enhances the capability
                    of RepVGG. Experimental evaluation conducted on a brain tumour dataset
                    demonstrates the effectiveness of RepVGG-GELAN surpassing existing RCS-YOLO in
                    terms of precision and speed. Specifically, RepVGG-GELAN achieves an increased
                    precision of 4.91% and an increased AP50 of 2.54% over the latest existing
                    approach while operating at 240.7 GFLOPs. The proposed RepVGG-GELAN with GELAN
                    architecture presents promising results establishing itself as a
                    state-of-the-art solution for accurate and efficient brain tumour detection in
                    medical images. The implementation code is publicly available at
                    https://github.com/ThensiB/RepVGG-GELAN.
                </p>
            </div>
        </dd>
        <dt><a name="item614">[614]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03544"
                    title="Abstract">arXiv:2405.03544</a> [<a href="/pdf/2405.03544" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03544" title="Download PostScript">ps</a>, <a href="/format/2405.03544"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Formal Model of Security Controls' Capabilities and Its
                    Applications to Policy Refinement and Incident Management
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Basile%2C+C">Cataldo Basile</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gatti%2C+G">Gabriele Gatti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Settanni%2C+F">Francesco Settanni</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">Enforcing security requirements in networked information systems relies on
                    security controls to mitigate the risks from increasingly dangerous threats.
                    Configuring security controls is challenging; even nowadays, administrators
                    must perform it without adequate tool support. Hence, this process is plagued
                    by errors that translate to insecure postures, security incidents, and a lack
                    of promptness in answering threats. This paper presents the Security Capability
                    Model (SCM), a formal model that abstracts the features that security controls
                    offer for enforcing security policies, which includes an Information Model that
                    depicts the basic concepts related to rules (i.e., conditions, actions, events)
                    and policies (i.e., conditions' evaluation, resolution strategies, default
                    actions), and a Data Model that covers the capabilities needed to describe
                    different types of filtering and channel protection controls. Following
                    state-of-the-art design patterns, the model allows for generating abstract
                    versions of the security controls' languages and a model-driven approach for
                    translating abstract policies into device-specific configuration settings. By
                    validating its effectiveness in real-world scenarios, we show that SCM enables
                    the automation of different and complex security tasks, i.e., accurate and
                    granular security control comparison, policy refinement, and incident response.
                    Lastly, we present opportunities for extensions and integration with other
                    frameworks and models.
                </p>
            </div>
        </dd>
        <dt><a name="item615">[615]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03545"
                    title="Abstract">arXiv:2405.03545</a> [<a href="/pdf/2405.03545" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03545" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Optimizing Hand Region Detection in MediaPipe Holistic
                    Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Moryossef%2C+A">Amit Moryossef</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">This paper addresses a critical flaw in MediaPipe Holistic's hand Region of
                    Interest (ROI) prediction, which struggles with non-ideal hand orientations,
                    affecting sign language recognition accuracy. We propose a data-driven approach
                    to enhance ROI estimation, leveraging an enriched feature set including
                    additional hand keypoints and the z-dimension. Our results demonstrate better
                    estimates, with higher Intersection-over-Union compared to the current method.
                    Our code and optimizations are available at
                    https://github.com/sign-language-processing/mediapipe-hand-crop-fix.
                </p>
            </div>
        </dd>
        <dt><a name="item616">[616]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03546"
                    title="Abstract">arXiv:2405.03546</a> [<a href="/pdf/2405.03546" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03546" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CCDM: Continuous Conditional Diffusion Models for Image
                    Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+X">Xin Ding</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yongwei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kao Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z+J">Z. Jane Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Continuous Conditional Generative Modeling (CCGM) aims to estimate the
                    distribution of high-dimensional data, typically images, conditioned on scalar
                    continuous variables known as regression labels. While Continuous conditional
                    Generative Adversarial Networks (CcGANs) were initially designed for this task,
                    their adversarial training mechanism remains vulnerable to extremely sparse or
                    imbalanced data, resulting in suboptimal outcomes. To enhance the quality of
                    generated images, a promising alternative is to replace CcGANs with Conditional
                    Diffusion Models (CDMs), renowned for their stable training process and ability
                    to produce more realistic images. However, existing CDMs encounter challenges
                    when applied to CCGM tasks due to several limitations such as inadequate U-Net
                    architectures and deficient model fitting mechanisms for handling regression
                    labels. In this paper, we introduce Continuous Conditional Diffusion Models
                    (CCDMs), the first CDM designed specifically for the CCGM task. CCDMs address
                    the limitations of existing CDMs by introducing specially designed conditional
                    diffusion processes, a modified denoising U-Net with a custom-made conditioning
                    mechanism, a novel hard vicinal loss for model fitting, and an efficient
                    conditional sampling procedure. With comprehensive experiments on four datasets
                    with varying resolutions ranging from 64x64 to 192x192, we demonstrate the
                    superiority of the proposed CCDM over state-of-the-art CCGM models,
                    establishing new benchmarks in CCGM. Extensive ablation studies validate the
                    model design and implementation configuration of the proposed CCDM. Our code is
                    publicly available at https://github.com/UBCDingXin/CCDM.
                </p>
            </div>
        </dd>
        <dt><a name="item617">[617]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03547"
                    title="Abstract">arXiv:2405.03547</a> [<a href="/pdf/2405.03547" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03547" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Position Paper: Leveraging Foundational Models for Black-Box
                    Optimization: Benefits, Challenges, and Future Directions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+X">Xingyou Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yingtao Tian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lange%2C+R+T">Robert Tjarko Lange</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+C">Chansoo Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yujin Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yutian Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to International Conference on Machine Learning
                    (ICML) 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

                </div>
                <p class="mathjax">Undeniably, Large Language Models (LLMs) have stirred an extraordinary wave
                    of innovation in the machine learning research domain, resulting in substantial
                    impact across diverse fields such as reinforcement learning, robotics, and
                    computer vision. Their incorporation has been rapid and transformative, marking
                    a significant paradigm shift in the field of machine learning research.
                    <br>However, the field of experimental design, grounded on black-box
                    optimization, has been much less affected by such a paradigm shift, even though
                    integrating LLMs with optimization presents a unique landscape ripe for
                    exploration. In this position paper, we frame the field of black-box
                    optimization around sequence-based foundation models and organize their
                    relationship with previous literature. We discuss the most promising ways
                    foundational language models can revolutionize optimization, which include
                    harnessing the vast wealth of information encapsulated in free-form text to
                    enrich task comprehension, utilizing highly flexible sequence models such as
                    Transformers to engineer superior optimization strategies, and enhancing
                    performance prediction over previously unseen search spaces.
                </p>
            </div>
        </dd>
        <dt><a name="item618">[618]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03548"
                    title="Abstract">arXiv:2405.03548</a> [<a href="/pdf/2405.03548" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03548" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MAmmoTH2: Scaling Instructions from the Web
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yue%2C+X">Xiang Yue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+T">Tuney Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Ge Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+W">Wenhu Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Work in Progress
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">Instruction tuning improves the reasoning abilities of large language models
                    (LLMs), with data quality and scalability being the crucial factors. Most
                    instruction tuning data come from human crowd-sourcing or GPT-4 distillation.
                    We propose a paradigm to efficiently harvest 10 million naturally existing
                    instruction data from the pre-training web corpus to enhance LLM reasoning. Our
                    approach involves (1) recalling relevant documents, (2) extracting
                    instruction-response pairs, and (3) refining the extracted pairs using
                    open-source LLMs. Fine-tuning base LLMs on this dataset, we build MAmmoTH2
                    models, which significantly boost performance on reasoning benchmarks. Notably,
                    MAmmoTH2-7B's (Mistral) performance increases from 11% to 34% on MATH and from
                    36% to 67% on GSM8K without training on any in-domain data. Further training
                    MAmmoTH2 on public instruction tuning datasets yields MAmmoTH2-Plus, achieving
                    state-of-the-art performance on several reasoning and chatbot benchmarks. Our
                    work demonstrates how to harvest large-scale, high-quality instruction data
                    without costly human annotation or GPT-4 distillation, providing a new paradigm
                    for building better instruction tuning data.
                </p>
            </div>
        </dd>
        <dt><a name="item619">[619]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03553"
                    title="Abstract">arXiv:2405.03553</a> [<a href="/pdf/2405.03553" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03553" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AlphaMath Almost Zero: process Supervision without process
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+G">Guoxin Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liao%2C+M">Minpeng Liao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chengxi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+K">Kai Fan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Work in progress
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Recent advancements in large language models (LLMs) have substantially
                    enhanced their mathematical reasoning abilities. However, these models still
                    struggle with complex problems that require multiple reasoning steps,
                    frequently leading to logical or numerical errors. While numerical mistakes can
                    largely be addressed by integrating a code interpreter, identifying logical
                    errors within intermediate steps is more challenging. Moreover, manually
                    annotating these steps for training is not only expensive but also demands
                    specialized expertise. In this study, we introduce an innovative approach that
                    eliminates the need for manual annotation by leveraging the Monte Carlo Tree
                    Search (MCTS) framework to generate both the process supervision and evaluation
                    signals automatically. Essentially, when a LLM is well pre-trained, only the
                    mathematical questions and their final answers are required to generate our
                    training data, without requiring the solutions. We proceed to train a
                    step-level value model designed to improve the LLM's inference process in
                    mathematical domains. Our experiments indicate that using automatically
                    generated solutions by LLMs enhanced with MCTS significantly improves the
                    model's proficiency in dealing with intricate mathematical reasoning tasks.
                </p>
            </div>
        </dd>
        <dt><a name="item620">[620]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03555"
                    title="Abstract">arXiv:2405.03555</a> [<a href="/pdf/2405.03555" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03555" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Comprehensive Overview and Survey of O-RAN: Exploring
                    Slicing-aware Architecture, Deployment Options, and Use Cases
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Alam%2C+K">Khurshid Alam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Habibi%2C+M+A">Mohammad Asif Habibi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tammen%2C+M">Matthias Tammen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Krummacker%2C+D">Dennis Krummacker</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saad%2C+W">Walid Saad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Di+Renzo%2C+M">Marco Di Renzo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Melodia%2C+T">Tommaso Melodia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Costa-P%C3%A9rez%2C+X">Xavier Costa-Pérez</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Debbah%2C+M">Mérouane Debbah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dutta%2C+A">Ashutosh Dutta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schotten%2C+H+D">Hans D. Schotten</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 45 pages, 12 figures, 4 tables, and 190 references
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>

                </div>
                <p class="mathjax">Open-radio access network (O-RAN) seeks to establish principles of openness,
                    programmability, automation, intelligence, and hardware-software disaggregation
                    with interoperable interfaces. It advocates for multi-vendorism and
                    multi-stakeholderism within a cloudified and virtualized wireless
                    infrastructure, aimed at enhancing the deployment, operation, and maintenance
                    of RAN architecture. This enhancement promises increased flexibility,
                    performance optimization, service innovation, energy efficiency, and cost
                    efficiency in fifth-generation (5G), sixth-generation (6G), and future
                    networks. One of the key features of the O-RAN architecture is its support for
                    network slicing, which entails interaction with other slicing domains within a
                    mobile network, notably the transport network (TN) domain and the core network
                    (CN) domain, to realize end-to-end (E2E) network slicing. The study of this
                    feature requires exploring the stances and contributions of diverse standards
                    development organizations (SDOs). In this context, we note that despite the
                    ongoing industrial deployments and standardization efforts, the research and
                    standardization communities have yet to comprehensively address network slicing
                    in O-RAN. To address this gap, this survey paper provides a comprehensive
                    exploration of network slicing in O-RAN through an in-depth review of
                    specification documents from O-RAN Alliance and research papers from leading
                    industry and academic institutions. The paper commences with an overview of the
                    ongoing standardization efforts and open-source contributions associated with
                    O-RAN, subsequently delving into the latest O-RAN architecture with an emphasis
                    on its slicing aspects. Further, the paper explores deployment scenarios for
                    network slicing within O-RAN, examining options for the deployment and
                    orchestration of O-RAN and TN network slice subnets...
                </p>
            </div>
        </dd>
        <dt><a name="item621">[621]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03561"
                    title="Abstract">arXiv:2405.03561</a> [<a href="/pdf/2405.03561" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03561" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Model- and Data-Based Control of Self-Balancing Robots:
                    Practical Educational Approach with LabVIEW and Arduino
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Abdelgawad%2C+A">Abdelrahman Abdelgawad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shohdy%2C+T">Tarek Shohdy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nada%2C+A">Ayman Nada</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Systems and Control (eess.SY)

                </div>
                <p class="mathjax">A two-wheeled self-balancing robot (TWSBR) is non-linear and unstable system.
                    This study compares the performance of model-based and data-based control
                    strategies for TWSBRs, with an explicit practical educational approach.
                    Model-based control (MBC) algorithms such as Lead-Lag and PID control require a
                    proficient dynamic modeling and mathematical manipulation to drive the
                    linearized equations of motions and develop the appropriate controller. On the
                    other side, data-based control (DBC) methods, like fuzzy control, provide a
                    simpler and quicker approach to designing effective controllers without needing
                    in-depth understanding of the system model. In this paper, the advantages and
                    disadvantages of both MBC and DBC using a TWSBR are illustrated. All
                    controllers were implemented and tested on the OSOYOO self-balancing kit,
                    including an Arduino microcontroller, MPU-6050 sensor, and DC motors. The
                    control law and the user interface are constructed using the LabVIEW-LINX
                    toolkit. A real-time hardware-in-loop experiment validates the results,
                    highlighting controllers that can be implemented on a cost-effective platform.
                </p>
            </div>
        </dd>
        <dt><a name="item622">[622]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03562"
                    title="Abstract">arXiv:2405.03562</a> [<a href="/pdf/2405.03562" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03562" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ID-centric Pre-training for Recommendation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yiqing Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+R">Ruobing Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhao Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+F">Fuzhen Zhuang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+L">Leyu Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kang%2C+Z">Zhanhui Kang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yongjun Xu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
                <p class="mathjax">Classical sequential recommendation models generally adopt ID embeddings to
                    store knowledge learned from user historical behaviors and represent items.
                    However, these unique IDs are challenging to be transferred to new domains.
                    With the thriving of pre-trained language model (PLM), some pioneer works adopt
                    PLM for pre-trained recommendation, where modality information (e.g., text) is
                    considered universal across domains via PLM. Unfortunately, the behavioral
                    information in ID embeddings is still verified to be dominating in PLM-based
                    recommendation models compared to modality information and thus limits these
                    models' performance. In this work, we propose a novel ID-centric recommendation
                    pre-training paradigm (IDP), which directly transfers informative ID embeddings
                    learned in pre-training domains to item representations in new domains.
                    Specifically, in pre-training stage, besides the ID-based sequential model for
                    recommendation, we also build a Cross-domain ID-matcher (CDIM) learned by both
                    behavioral and modality information. In the tuning stage, modality information
                    of new domain items is regarded as a cross-domain bridge built by CDIM. We
                    first leverage the textual information of downstream domain items to retrieve
                    behaviorally and semantically similar items from pre-training domains using
                    CDIM. Next, these retrieved pre-trained ID embeddings, rather than certain
                    textual embeddings, are directly adopted to generate downstream new items'
                    embeddings. Through extensive experiments on real-world datasets, both in cold
                    and warm settings, we demonstrate that our proposed model significantly
                    outperforms all baselines. Codes will be released upon acceptance.
                </p>
            </div>
        </dd>
        <dt><a name="item623">[623]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03565"
                    title="Abstract">arXiv:2405.03565</a> [<a href="/pdf/2405.03565" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03565" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text
                    Classification via Anchor Generation and Classification Reframing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Han Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+S">Siyang Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaotong Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+F">Feng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+F">Fenglong Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hongyang Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+H">Hong Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xianchao Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to AAAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Few-shot and zero-shot text classification aim to recognize samples from
                    novel classes with limited labeled samples or no labeled samples at all. While
                    prevailing methods have shown promising performance via transferring knowledge
                    from seen classes to unseen classes, they are still limited by (1) Inherent
                    dissimilarities among classes make the transformation of features learned from
                    seen classes to unseen classes both difficult and inefficient. (2) Rare labeled
                    novel samples usually cannot provide enough supervision signals to enable the
                    model to adjust from the source distribution to the target distribution,
                    especially for complicated scenarios. To alleviate the above issues, we propose
                    a simple and effective strategy for few-shot and zero-shot text classification.
                    We aim to liberate the model from the confines of seen classes, thereby
                    enabling it to predict unseen categories without the necessity of training on
                    seen classes. Specifically, for mining more related unseen category knowledge,
                    we utilize a large pre-trained language model to generate pseudo novel samples,
                    and select the most representative ones as category anchors. After that, we
                    convert the multi-class classification task into a binary classification task
                    and use the similarities of query-anchor pairs for prediction to fully leverage
                    the limited supervision signals. Extensive experiments on six widely used
                    public datasets show that our proposed method can outperform other strong
                    baselines significantly in few-shot and zero-shot tasks, even without using any
                    seen class samples.
                </p>
            </div>
        </dd>
        <dt><a name="item624">[624]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03567"
                    title="Abstract">arXiv:2405.03567</a> [<a href="/pdf/2405.03567" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03567" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Space Separable Distillation for Lightweight Acoustic
                    Scene Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+S">ShuQi Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yuan Tian</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

                </div>
                <p class="mathjax">Acoustic scene classification (ASC) is highly important in the real world.
                    Recently, deep learning-based methods have been widely employed for acoustic
                    scene classification. However, these methods are currently not lightweight
                    enough as well as their performance is not satisfactory. To solve these
                    problems, we propose a deep space separable distillation network. Firstly, the
                    network performs high-low frequency decomposition on the log-mel spectrogram,
                    significantly reducing computational complexity while maintaining model
                    performance. Secondly, we specially design three lightweight operators for ASC,
                    including Separable Convolution (SC), Orthonormal Separable Convolution (OSC),
                    and Separable Partial Convolution (SPC). These operators exhibit highly
                    efficient feature extraction capabilities in acoustic scene classification
                    tasks. The experimental results demonstrate that the proposed method achieves a
                    performance gain of 9.8% compared to the currently popular deep learning
                    methods, while also having smaller parameter count and computational
                    complexity.
                </p>
            </div>
        </dd>
        <dt><a name="item625">[625]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03568"
                    title="Abstract">arXiv:2405.03568</a> [<a href="/pdf/2405.03568" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03568" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Majority consensus thresholds in competitive Lotka--Volterra
                    populations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=F%C3%BCgger%2C+M">Matthias Függer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nowak%2C+T">Thomas Nowak</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rybicki%2C+J">Joel Rybicki</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 32 pages, to appear in PODC 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>

                </div>
                <p class="mathjax">One of the key challenges in synthetic biology is devising robust signaling
                    primitives for engineered microbial consortia. In such systems, a fundamental
                    signal amplification problem is the majority consensus problem: given a system
                    with two input species with initial difference of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-286-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1926"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.75em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1927"><span class="mi" id="MathJax-Span-1928"
                                                style="font-family: MathJax_Main;">Δ</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-286">\Delta</script> in population sizes,
                    what is the probability that the system reaches a state in which only the
                    initial majority species is present?
                    <br>In this work, we consider a discrete and stochastic version of competitive
                    Lotka--Volterra dynamics, a standard model of microbial community dynamics. We
                    identify new threshold properties for majority consensus under different types
                    of interference competition:
                    <br>- We show that under so-called self-destructive interference competition
                    between the two input species, majority consensus can be reached with high
                    probability if the initial difference satisfies <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-287-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1929"
                                style="width: 7.237em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.021em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1005.91em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1930"><span class="mi" id="MathJax-Span-1931"
                                                style="font-family: MathJax_Main;">Δ</span><span class="mo"
                                                id="MathJax-Span-1932"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∈</span><span
                                                class="mi" id="MathJax-Span-1933"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">Ω</span><span
                                                class="mo" id="MathJax-Span-1934"
                                                style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                id="MathJax-Span-1935"><span
                                                    style="display: inline-block; position: relative; width: 1.681em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.28em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-1936"
                                                            style="font-family: MathJax_Main;">log</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 1.276em;"><span
                                                            class="mn" id="MathJax-Span-1937"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1938"></span><span class="mi"
                                                id="MathJax-Span-1939"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span><span
                                                class="mo" id="MathJax-Span-1940"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.531em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-287">\Delta \in \Omega(\log^2 n)</script>,
                    where <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-288-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1941"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1942"><span class="mi" id="MathJax-Span-1943"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-288">n</script> is the initial population size. This
                    gives an exponential improvement
                    compared to the previously known bound of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-289-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1944"
                                style="width: 6.427em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.327em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1005.21em, 2.665em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1945"><span class="mi" id="MathJax-Span-1946"
                                                style="font-family: MathJax_Main;">Ω</span><span class="mo"
                                                id="MathJax-Span-1947" style="font-family: MathJax_Main;">(</span><span
                                                class="msqrt" id="MathJax-Span-1948"><span
                                                    style="display: inline-block; position: relative; width: 3.822em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1002.84em, 4.401em, -999.997em); top: -3.99em; left: 0.987em;"><span
                                                            class="mrow" id="MathJax-Span-1949"><span class="mi"
                                                                id="MathJax-Span-1950"
                                                                style="font-family: MathJax_Math-italic;">n</span><span
                                                                class="mi" id="MathJax-Span-1951"
                                                                style="font-family: MathJax_Main; padding-left: 0.177em;">log</span><span
                                                                class="mo" id="MathJax-Span-1952"></span><span
                                                                class="mi" id="MathJax-Span-1953"
                                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1002.78em, 3.938em, -999.997em); top: -4.569em; left: 0.987em;"><span
                                                            style="display: inline-block; position: relative; width: 2.781em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: 2.086em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 0.466em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 1.045em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 1.623em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(2.954em, 1001.04em, 4.517em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            style="font-family: MathJax_Size1;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1954"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.601em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-289">\Omega(\sqrt{n \log n})</script> by Cho et
                    al. [Distributed Computing, 2021] given for a special case of the competitive
                    Lotka--Volterra model. In contrast, we show that an initial gap of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-290-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-1955"
                                style="width: 7.989em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 6.658em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1006.54em, 2.665em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1956"><span class="mi" id="MathJax-Span-1957"
                                                style="font-family: MathJax_Main;">Δ</span><span class="mo"
                                                id="MathJax-Span-1958"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∈</span><span
                                                class="mi" id="MathJax-Span-1959"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">Ω</span><span
                                                class="mo" id="MathJax-Span-1960"
                                                style="font-family: MathJax_Main;">(</span><span class="msqrt"
                                                id="MathJax-Span-1961"><span
                                                    style="display: inline-block; position: relative; width: 3.07em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1002.03em, 4.401em, -999.997em); top: -3.99em; left: 0.987em;"><span
                                                            class="mrow" id="MathJax-Span-1962"><span class="mi"
                                                                id="MathJax-Span-1963"
                                                                style="font-family: MathJax_Main;">log</span><span
                                                                class="mo" id="MathJax-Span-1964"></span><span
                                                                class="mi" id="MathJax-Span-1965"
                                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1001.97em, 3.938em, -999.997em); top: -4.569em; left: 0.987em;"><span
                                                            style="display: inline-block; position: relative; width: 1.97em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: 1.276em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 0.408em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 0.871em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(2.954em, 1001.04em, 4.517em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            style="font-family: MathJax_Size1;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1966"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.601em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-290">\Delta \in
    \Omega(\sqrt{\log n})</script> is necessary.
                    <br>- On the other hand, we prove that under non-self-destructive interference
                    competition, an initial gap of <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-291-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1967"
                                style="width: 3.591em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.954em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.84em, 2.607em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1968"><span class="mi" id="MathJax-Span-1969"
                                                style="font-family: MathJax_Main;">Ω</span><span class="mo"
                                                id="MathJax-Span-1970" style="font-family: MathJax_Main;">(</span><span
                                                class="msqrt" id="MathJax-Span-1971"><span
                                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                            class="mrow" id="MathJax-Span-1972"><span class="mi"
                                                                id="MathJax-Span-1973"
                                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1000.64em, 3.938em, -999.997em); top: -4.395em; left: 0.813em;"><span
                                                            style="display: inline-block; position: relative; width: 0.639em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -3.932em; left: 0em;"><span
                                                            style="font-family: MathJax_Main;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1974"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-291">\Omega(\sqrt{n})</script> is necessary to succeed
                    with
                    high probability and that a <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-292-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1975"
                                style="width: 6.427em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 5.327em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1005.21em, 2.665em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1976"><span class="mi" id="MathJax-Span-1977"
                                                style="font-family: MathJax_Main;">Ω</span><span class="mo"
                                                id="MathJax-Span-1978" style="font-family: MathJax_Main;">(</span><span
                                                class="msqrt" id="MathJax-Span-1979"><span
                                                    style="display: inline-block; position: relative; width: 3.822em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1002.84em, 4.401em, -999.997em); top: -3.99em; left: 0.987em;"><span
                                                            class="mrow" id="MathJax-Span-1980"><span class="mi"
                                                                id="MathJax-Span-1981"
                                                                style="font-family: MathJax_Math-italic;">n</span><span
                                                                class="mi" id="MathJax-Span-1982"
                                                                style="font-family: MathJax_Main; padding-left: 0.177em;">log</span><span
                                                                class="mo" id="MathJax-Span-1983"></span><span
                                                                class="mi" id="MathJax-Span-1984"
                                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">n</span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1002.78em, 3.938em, -999.997em); top: -4.569em; left: 0.987em;"><span
                                                            style="display: inline-block; position: relative; width: 2.781em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: 2.086em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 0.466em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 1.045em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="font-family: MathJax_Main; position: absolute; top: -3.99em; left: 1.623em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(2.954em, 1001.04em, 4.517em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            style="font-family: MathJax_Size1;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-1985"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.601em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-292">\Omega(\sqrt{n \log n})</script> gap is sufficient.
                    <br>This shows a strong qualitative gap between the performance of
                    self-destructive and non-self-destructive interference competition. Moreover,
                    we show that if in addition the populations exhibit interference competition
                    between the individuals of the same species, then majority consensus cannot
                    always be solved with high probability, no matter what the difference in the
                    initial population counts.
                </p>
            </div>
        </dd>
        <dt><a name="item626">[626]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03572"
                    title="Abstract">arXiv:2405.03572</a> [<a href="/pdf/2405.03572" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03572" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> RoboCar: A Rapidly Deployable Open-Source Platform for
                    Autonomous Driving Research
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Testouri%2C+M">Mehdi Testouri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Elghazaly%2C+G">Gamal Elghazaly</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Frank%2C+R">Raphael Frank</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
                <p class="mathjax">This paper introduces RoboCar, an open-source research platform for
                    autonomous driving developed at the University of Luxembourg. RoboCar provides
                    a modular, cost-effective framework for the development of experimental
                    Autonomous Driving Systems (ADS), utilizing the 2018 KIA Soul EV. The platform
                    integrates a robust hardware and software architecture that aligns with the
                    vehicle's existing systems, minimizing the need for extensive modifications. It
                    supports various autonomous driving functions and has undergone real-world
                    testing on public roads in Luxembourg City. This paper outlines the platform's
                    architecture, integration challenges, and initial test results, offering
                    insights into its application in advancing autonomous driving research. RoboCar
                    is available to anyone at https://github.com/sntubix/robocar and is released
                    under an open-source MIT license.
                </p>
            </div>
        </dd>
        <dt><a name="item627">[627]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03573"
                    title="Abstract">arXiv:2405.03573</a> [<a href="/pdf/2405.03573" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03573" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Demystifying Anonymity: Uncovering the Structure Underlying
                    "Read-Write Wait-Free Covering"
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Losa%2C+G">Giuliano Losa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gafni%2C+E">Eli Gafni</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>

                </div>
                <p class="mathjax">The study of particular synchronization problems in anonymous shared-memory
                    models -- be it processor anonymity, memory anonymity, or full anonymity -- has
                    produced ad hoc, so-called covering arguments in which processors overwrite
                    each other's writes. Those arguments give us proverbial fish, but they do not
                    teach us how to fish. In this paper, we take a step back to ask more general
                    questions.
                    <br>First, what does it mean to solve a task under processor anonymity? With
                    tasks such as renaming, the traditional notion obviously does not apply.
                    Instead of restricting ourselves to colorless tasks, we propose using the
                    notion of group solvability, which allows transferring any task to
                    processor-anonymous models.
                    <br>Second, we consider solving tasks read-write wait-free under full anonymity,
                    and we ask what we call the eventual-pattern question: if anonymous processors
                    forever read and write in anonymous shared-memory, learning about inputs of
                    other processors, what is the structure of the eventually-stable sets of inputs
                    that processors learn? Solving the eventual-pattern question leads us to a
                    group solution to the snapshot task and to M(M-1)/2-renaming, where M is the
                    number of distinct inputs. Finally, using the snapshot solution, we easily
                    obtain a solution to obstruction-free consensus.
                </p>
            </div>
        </dd>
        <dt><a name="item628">[628]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03574"
                    title="Abstract">arXiv:2405.03574</a> [<a href="/pdf/2405.03574" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03574" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ILILT: Implicit Learning of Inverse Lithography Technologies
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H">Haoyu Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+H">Haoxing Ren</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 10 figures, accepted by International Conference
                    on Machine Learning (ICML24)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Lithography, transferring chip design masks to the silicon wafer, is the most
                    important phase in modern semiconductor manufacturing flow. Due to the
                    limitations of lithography systems, Extensive design optimizations are required
                    to tackle the design and silicon mismatch. Inverse lithography technology (ILT)
                    is one of the promising solutions to perform pre-fabrication optimization,
                    termed mask optimization. Because of mask optimization problems' constrained
                    non-convexity, numerical ILT solvers rely heavily on good initialization to
                    avoid getting stuck on sub-optimal solutions. Machine learning (ML) techniques
                    are hence proposed to generate mask initialization for ILT solvers with
                    one-shot inference, targeting faster and better convergence during ILT. This
                    paper addresses the question of \textit{whether ML models can directly generate
                    high-quality optimized masks without engaging ILT solvers in the loop}. We
                    propose an implicit learning ILT framework: ILILT, which leverages the implicit
                    layer learning method and lithography-conditioned inputs to ground the model.
                    Trained to understand the ILT optimization procedure, ILILT can outperform the
                    state-of-the-art machine learning solutions, significantly improving efficiency
                    and quality.
                </p>
            </div>
        </dd>
        <dt><a name="item629">[629]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03575"
                    title="Abstract">arXiv:2405.03575</a> [<a href="/pdf/2405.03575" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03575" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Valuation Framework for Customers Impacted by Extreme
                    Temperature-Related Outages
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Yu%2C+M+G">Min Gyung Yu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Mukherjee%2C+M">Monish Mukherjee</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Poudela%2C+S">Shiva Poudela</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Bender%2C+S+R">Sadie R. Bender</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Hanif%2C+S">Sarmad Hanif</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Hardy%2C+T+D">Trevor D. Hardy</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Reeve%2C+H+M">Hayden M. Reeve</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
                <p class="mathjax">Extreme temperature outages can lead to not just economic losses but also
                    various non-energy impacts (NEI) due to significant degradation of indoor
                    operating conditions caused by service disruptions. However, existing
                    resilience assessment approaches lack specificity for extreme temperature
                    conditions. They often overlook temperature-related mortality and neglect the
                    customer characteristics and grid response in the calculation, despite the
                    significant influence of these factors on NEI-related economic losses. This
                    paper aims to address these gaps by introducing a comprehensive framework to
                    estimate the impact of resilience enhancement not only on the direct economic
                    losses incurred by customers but also on potential NEI, including mortality and
                    the value of statistical life during extreme temperature-related outages. The
                    proposed resilience valuation integrates customer characteristics and grid
                    response variables based on a scalable grid simulation environment. This study
                    adopts a holistic approach to quantify customer-oriented economic impacts,
                    utilizing probabilistic loss scenarios that incorporate health-related factors
                    and damage/loss models as a function of exposure for valuation. The proposed
                    methodology is demonstrated through comparative resilient outage planning,
                    using grid response models emulating a Texas weather zone during the 2021
                    winter storm Uri. The case study results show that enhanced outage planning
                    with hardened infrastructure can improve the system resilience and thereby
                    reduce the relative risk of mortality by 16% and save the total costs related
                    to non-energy impacts by 74%. These findings underscore the efficacy of the
                    framework by assessing the financial implications of each case, providing
                    valuable insights for decision-makers and stakeholders involved in
                    extreme-weather related resilience planning for risk management and mitigation
                    strategies.
                </p>
            </div>
        </dd>
        <dt><a name="item630">[630]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03582"
                    title="Abstract">arXiv:2405.03582</a> [<a href="/pdf/2405.03582" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03582" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Functional Latent Dynamics for Irregularly Sampled Time
                    Series Forecasting
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kl%C3%B6tergens%2C+C">Christian Klötergens</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yalavarthi%2C+V+K">Vijaya Krishna Yalavarthi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stubbemann%2C+M">Maximilian Stubbemann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Irregularly sampled time series with missing values are often observed in
                    multiple real-world applications such as healthcare, climate and astronomy.
                    They pose a significant challenge to standard deep learn- ing models that
                    operate only on fully observed and regularly sampled time series. In order to
                    capture the continuous dynamics of the irreg- ular time series, many models
                    rely on solving an Ordinary Differential Equation (ODE) in the hidden state.
                    These ODE-based models tend to perform slow and require large memory due to
                    sequential operations and a complex ODE solver. As an alternative to complex
                    ODE-based mod- els, we propose a family of models called Functional Latent
                    Dynamics (FLD). Instead of solving the ODE, we use simple curves which exist at
                    all time points to specify the continuous latent state in the model. The
                    coefficients of these curves are learned only from the observed values in the
                    time series ignoring the missing values. Through extensive experi- ments, we
                    demonstrate that FLD achieves better performance compared to the best ODE-based
                    model while reducing the runtime and memory overhead. Specifically, FLD
                    requires an order of magnitude less time to infer the forecasts compared to the
                    best performing forecasting model.
                </p>
            </div>
        </dd>
        <dt><a name="item631">[631]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03585"
                    title="Abstract">arXiv:2405.03585</a> [<a href="/pdf/2405.03585" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03585" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Sociotechnical Stack: Opportunities for Social Computing
                    Research in Non-consensual Intimate Media
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Qiwei%2C+L">Li Qiwei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McDonald%2C+A">Allison McDonald</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Haimson%2C+O+L">Oliver L. Haimson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schoenebeck%2C+S">Sarita Schoenebeck</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gilbert%2C+E">Eric Gilbert</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>; Human-Computer Interaction (cs.HC)

                </div>
                <p class="mathjax">Non-consensual intimate media (NCIM) involves sharing intimate content
                    without the depicted person's consent, including "revenge porn" and sexually
                    explicit deepfakes. While NCIM has received attention in legal, psychological,
                    and communication fields over the past decade, it is not sufficiently addressed
                    in computing scholarship. This paper addresses this gap by linking NCIM harms
                    to the specific technological components that facilitate them. We introduce the
                    sociotechnical stack, a conceptual framework designed to map the technical
                    stack to its corresponding social impacts. The sociotechnical stack allows us
                    to analyze sociotechnical problems like NCIM, and points toward opportunities
                    for computing research. We propose a research roadmap for computing and social
                    computing communities to deter NCIM perpetration and support victim-survivors
                    through building and rebuilding technologies.
                </p>
            </div>
        </dd>
        <dt><a name="item632">[632]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03588"
                    title="Abstract">arXiv:2405.03588</a> [<a href="/pdf/2405.03588" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03588" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Effective Quadratic Error Bounds for Floating-Point
                    Algorithms Computing the Hypotenuse Function
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Muller%2C+J">Jean-Michel Muller</a>,
                    <a href="/search/math?searchtype=author&amp;query=Salvy%2C+B">Bruno Salvy</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>; Symbolic Computation (cs.SC)

                </div>
                <p class="mathjax">We provide tools to help automate the error analysis of algorithms that
                    evaluate simple functions over the floating-point numbers. The aim is to obtain
                    tight relative error bounds for these algorithms, expressed as a function of
                    the unit round-off. Due to the discrete nature of the set of floating-point
                    numbers, the largest errors are often intrinsically "arithmetic" in the sense
                    that their appearance may depend on specific bit patterns in the binary
                    representations of intermediate variables, which may be present only for some
                    precisions. We focus on generic (i.e., parameterized by the precision) and
                    analytic over-estimations that still capture the correlations between the
                    errors made at each step of the algorithms. Using methods from computer
                    algebra, which we adapt to the particular structure of the polynomial systems
                    that encode the errors, we obtain bounds with a linear term in the unit
                    round-off that is sharp in manycases. An explicit quadratic bound is given,
                    rather than the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-293-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1986"
                                style="width: 1.913em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.565em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.45em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1987"><span class="mi" id="MathJax-Span-1988"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-1989" style="font-family: MathJax_Main;">(</span><span
                                                class="mo" id="MathJax-Span-1990"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-293">O()</script>-estimate that is more common in this
                    area. This is
                    particularly important when using low precision formats, which are increasingly
                    common in modern processors. Using this approach, we compare five algorithms
                    for computing the hypotenuse function, ranging from elementary to quite
                    challenging.
                </p>
            </div>
        </dd>
        <dt><a name="item633">[633]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03590"
                    title="Abstract">arXiv:2405.03590</a> [<a href="/pdf/2405.03590" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03590" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Clustering with Self-Supervision using Pairwise
                    Similarities
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sadeghi%2C+M">Mohammadreza Sadeghi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Armanfard%2C+N">Narges Armanfard</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Deep clustering incorporates embedding into clustering to find a
                    lower-dimensional space appropriate for clustering. In this paper, we propose a
                    novel deep clustering framework with self-supervision using pairwise
                    similarities (DCSS). The proposed method consists of two successive phases. In
                    the first phase, we propose to form hypersphere-like groups of similar data
                    points, i.e. one hypersphere per cluster, employing an autoencoder that is
                    trained using cluster-specific losses. The hyper-spheres are formed in the
                    autoencoder's latent space. In the second phase, we propose to employ pairwise
                    similarities to create a <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-294-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1991"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1992"><span class="mi" id="MathJax-Span-1993"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-294">K</script>-dimensional space that is capable of
                    accommodating
                    more complex cluster distributions, hence providing more accurate clustering
                    performance. <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-295-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1994"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1995"><span class="mi" id="MathJax-Span-1996"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-295">K</script> is the number of clusters. The
                    autoencoder's latent space
                    obtained in the first phase is used as the input of the second phase. The
                    effectiveness of both phases is demonstrated on seven benchmark datasets by
                    conducting a rigorous set of experiments.
                </p>
            </div>
        </dd>
        <dt><a name="item634">[634]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03594"
                    title="Abstract">arXiv:2405.03594</a> [<a href="/pdf/2405.03594" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03594" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enabling High-Sparsity Foundational Llama Models with
                    Efficient Pretraining and Deployment
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Agarwalla%2C+A">Abhinav Agarwalla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+A">Abhay Gupta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Marques%2C+A">Alexandre Marques</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pandit%2C+S">Shubhra Pandit</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goin%2C+M">Michael Goin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kurtic%2C+E">Eldar Kurtic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Leong%2C+K">Kevin Leong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+T">Tuan Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Salem%2C+M">Mahmoud Salem</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alistarh%2C+D">Dan Alistarh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lie%2C+S">Sean Lie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kurtz%2C+M">Mark Kurtz</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Large language models (LLMs) have revolutionized Natural Language Processing
                    (NLP), but their size creates computational bottlenecks. We introduce a novel
                    approach to create accurate, sparse foundational versions of performant LLMs
                    that achieve full accuracy recovery for fine-tuning tasks at up to 70%
                    sparsity. We achieve this for the LLaMA-2 7B model by combining the SparseGPT
                    one-shot pruning method and sparse pretraining of those models on a subset of
                    the SlimPajama dataset mixed with a Python subset of The Stack dataset. We
                    exhibit training acceleration due to sparsity on Cerebras CS-3 chips that
                    closely matches theoretical scaling. In addition, we establish inference
                    acceleration of up to 3x on CPUs by utilizing Neural Magic's DeepSparse engine
                    and 1.7x on GPUs through Neural Magic's nm-vllm engine. The above gains are
                    realized via sparsity alone, thus enabling further gains through additional use
                    of quantization. Specifically, we show a total speedup on CPUs for
                    sparse-quantized LLaMA models of up to 8.6x. We demonstrate these results
                    across diverse, challenging tasks, including chat, instruction following, code
                    generation, arithmetic reasoning, and summarization to prove their generality.
                    This work paves the way for rapidly creating smaller and faster LLMs without
                    sacrificing accuracy.
                </p>
            </div>
        </dd>
        <dt><a name="item635">[635]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03595"
                    title="Abstract">arXiv:2405.03595</a> [<a href="/pdf/2405.03595" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03595" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GREEN: Generative Radiology Report Evaluation and Error
                    Notation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ostmeier%2C+S">Sophie Ostmeier</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Justin Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhihong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Varma%2C+M">Maya Varma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Blankemeier%2C+L">Louis Blankemeier</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bluethgen%2C+C">Christian Bluethgen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Michalson%2C+A+E">Arne Edward Michalson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Moseley%2C+M">Michael Moseley</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Langlotz%2C+C">Curtis Langlotz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chaudhari%2C+A+S">Akshay S Chaudhari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Delbrouck%2C+J">Jean-Benoit Delbrouck</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Evaluating radiology reports is a challenging problem as factual correctness
                    is extremely important due to the need for accurate medical communication about
                    medical images. Existing automatic evaluation metrics either suffer from
                    failing to consider factual correctness (e.g., BLEU and ROUGE) or are limited
                    in their interpretability (e.g., F1CheXpert and F1RadGraph). In this paper, we
                    introduce GREEN (Generative Radiology Report Evaluation and Error Notation), a
                    radiology report generation metric that leverages the natural language
                    understanding of language models to identify and explain clinically significant
                    errors in candidate reports, both quantitatively and qualitatively. Compared to
                    current metrics, GREEN offers: 1) a score aligned with expert preferences, 2)
                    human interpretable explanations of clinically significant errors, enabling
                    feedback loops with end-users, and 3) a lightweight open-source method that
                    reaches the performance of commercial counterparts. We validate our GREEN
                    metric by comparing it to GPT-4, as well as to error counts of 6 experts and
                    preferences of 2 experts. Our method demonstrates not only higher correlation
                    with expert error counts, but simultaneously higher alignment with expert
                    preferences when compared to previous approaches."
                </p>
            </div>
        </dd>
        <dt><a name="item636">[636]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03605"
                    title="Abstract">arXiv:2405.03605</a> [<a href="/pdf/2405.03605" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03605" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Trackable Island-model Genetic Algorithms at Wafer Scale
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Moreno%2C+M+A">Matthew Andres Moreno</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+C">Connor Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dolson%2C+E">Emily Dolson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zaman%2C+L">Luis Zaman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a
                        href="/abs/2404.10861">arXiv:2404.10861</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">Emerging ML/AI hardware accelerators, like the 850,000 processor Cerebras
                    Wafer-Scale Engine (WSE), hold great promise to scale up the capabilities of
                    evolutionary computation. However, challenges remain in maintaining visibility
                    into underlying evolutionary processes while efficiently utilizing these
                    platforms' large processor counts. Here, we focus on the problem of extracting
                    phylogenetic information from digital evolution on the WSE platform. We present
                    a tracking-enabled asynchronous island-based genetic algorithm (GA) framework
                    for WSE hardware. Emulated and on-hardware GA benchmarks with a simple
                    tracking-enabled agent model clock upwards of 1 million generations a minute
                    for population sizes reaching 16 million. This pace enables quadrillions of
                    evaluations a day. We validate phylogenetic reconstructions from these trials
                    and demonstrate their suitability for inference of underlying evolutionary
                    conditions. In particular, we demonstrate extraction of clear phylometric
                    signals that differentiate wafer-scale runs with adaptive dynamics enabled
                    versus disabled. Together, these benchmark and validation trials reflect strong
                    potential for highly scalable evolutionary computation that is both efficient
                    and observable. Kernel code implementing the island-model GA supports drop-in
                    customization to support any fixed-length genome content and fitness criteria,
                    allowing it to be leveraged to advance research interests across the community.
                </p>
            </div>
        </dd>
        <dt><a name="item637">[637]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03609"
                    title="Abstract">arXiv:2405.03609</a> [<a href="/pdf/2405.03609" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03609" title="Download PostScript">ps</a>, <a href="/format/2405.03609"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Decision algorithms for reversibility of one-dimensional
                    non-linear cellular automata under null boundary conditions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Junchi%2C+M">Ma Junchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Weilin%2C+C">Chen Weilin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+W">Wang Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Defu%2C+L">Lin Defu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chao%2C+W">Wang Chao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> in Chinese language
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity
                        (cs.CC)</span>

                </div>
                <p class="mathjax">The property of reversibility is quite meaningful for the classic theoretical
                    computer science model, cellular automata. For the reversibility problem for a
                    CA under null boundary conditions, while linear rules have been studied a lot,
                    the non-linear rules remain unexplored at present. The paper investigates the
                    reversibility problem of general one-dimensional CA on a finite field
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-296-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-1997"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.1em, 1.45em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-1998"><span class="msubsup"
                                                id="MathJax-Span-1999"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-2000"><span class="mrow"
                                                                id="MathJax-Span-2001"><span class="mi"
                                                                    id="MathJax-Span-2002"
                                                                    style="font-family: MathJax_AMS;">Z</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.697em;"><span
                                                            class="mi" id="MathJax-Span-2003"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-296">\mathbb{Z}_p</script>, and proposes an approach to
                    optimize the Amoroso's infinite CA
                    surjectivity detection algorithm. This paper proposes algorithms for deciding
                    the reversibility of one-dimensional CA under null boundary conditions. We
                    propose a method to decide the strict reversibility of one-dimensional CA under
                    null boundary conditions. We also provide a bucket chain based algorithm for
                    calculating the reversibility function of one-dimensional CA under null
                    boundary conditions. These decision algorithms work for not only linear rules
                    but also non-linear rules. In addition, it has been confirmed that the
                    reversibility function always has a period, and its periodicity is related to
                    the periodicity of the corresponding bucket chain. Some of our experiment
                    results of reversible CA are presented in the paper, complementing and
                    validating the theoretical aspects, and thereby further supporting the research
                    conclusions of this paper.
                </p>
            </div>
        </dd>
        <dt><a name="item638">[638]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03613"
                    title="Abstract">arXiv:2405.03613</a> [<a href="/pdf/2405.03613" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03613" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Dual Relation Mining Network for Zero-Shot Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+J">Jinwei Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yingguo Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Z">Zhiwen Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+K">Ke Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+S">Shouhong Ding</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Y">Yuan Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+G">Gui-Song Xia</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Zero-shot learning (ZSL) aims to recognize novel classes through transferring
                    shared semantic knowledge (e.g., attributes) from seen classes to unseen
                    classes. Recently, attention-based methods have exhibited significant progress
                    which align visual features and attributes via a spatial attention mechanism.
                    However, these methods only explore visual-semantic relationship in the spatial
                    dimension, which can lead to classification ambiguity when different attributes
                    share similar attention regions, and semantic relationship between attributes
                    is rarely discussed. To alleviate the above problems, we propose a Dual
                    Relation Mining Network (DRMN) to enable more effective visual-semantic
                    interactions and learn semantic relationship among attributes for knowledge
                    transfer. Specifically, we introduce a Dual Attention Block (DAB) for
                    visual-semantic relationship mining, which enriches visual information by
                    multi-level feature fusion and conducts spatial attention for visual to
                    semantic embedding. Moreover, an attribute-guided channel attention is utilized
                    to decouple entangled semantic features. For semantic relationship modeling, we
                    utilize a Semantic Interaction Transformer (SIT) to enhance the generalization
                    of attribute representations among images. Additionally, a global
                    classification branch is introduced as a complement to human-defined semantic
                    attributes, and we then combine the results with attribute-based
                    classification. Extensive experiments demonstrate that the proposed DRMN leads
                    to new state-of-the-art performances on three standard ZSL benchmarks, i.e.,
                    CUB, SUN, and AwA2.
                </p>
            </div>
        </dd>
        <dt><a name="item639">[639]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03614"
                    title="Abstract">arXiv:2405.03614</a> [<a href="/pdf/2405.03614" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03614" title="Download PostScript">ps</a>, <a href="/format/2405.03614"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Repairing with Zero Skip Cost
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenqin Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chee%2C+Y+M">Yeow Meng Chee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dau%2C+S+H">Son Hoang Dau</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Etzion%2C+T">Tuvi Etzion</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kiah%2C+H+M">Han Mao Kiah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Y">Yuan Luo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">To measure repair latency at helper nodes, we introduce a new metric called
                    skip cost that quantifies the number of contiguous sections accessed on a disk.
                    We provide explicit constructions of zigzag codes and fractional repetition
                    codes that incur zero skip cost
                </p>
            </div>
        </dd>
        <dt><a name="item640">[640]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03615"
                    title="Abstract">arXiv:2405.03615</a> [<a href="/pdf/2405.03615" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03615" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Nonnegative Matrix Factorization in Dimensionality Reduction:
                    A Survey
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Saberi-Movahed%2C+F">Farid Saberi-Movahed</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Berahman%2C+K">Kamal Berahman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sheikhpour%2C+R">Razieh Sheikhpour</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuefeng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pan%2C+S">Shirui Pan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 Paes, 2 figures, to be appear in acm computing survey
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Dimensionality Reduction plays a pivotal role in improving feature learning
                    accuracy and reducing training time by eliminating redundant features, noise,
                    and irrelevant data. Nonnegative Matrix Factorization (NMF) has emerged as a
                    popular and powerful method for dimensionality reduction. Despite its extensive
                    use, there remains a need for a comprehensive analysis of NMF in the context of
                    dimensionality reduction. To address this gap, this paper presents a
                    comprehensive survey of NMF, focusing on its applications in both feature
                    extraction and feature selection. We introduce a classification of
                    dimensionality reduction, enhancing understanding of the underlying concepts.
                    Subsequently, we delve into a thorough summary of diverse NMF approaches used
                    for feature extraction and selection. Furthermore, we discuss the latest
                    research trends and potential future directions of NMF in dimensionality
                    reduction, aiming to highlight areas that need further exploration and
                    development.
                </p>
            </div>
        </dd>
        <dt><a name="item641">[641]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03616"
                    title="Abstract">arXiv:2405.03616</a> [<a href="/pdf/2405.03616" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03616" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Controlled Experiment on the Energy Efficiency of the
                    Source Code Generated by Code Llama
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cursaru%2C+V">Vlad-Andrei Cursaru</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Duits%2C+L">Laura Duits</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Milligan%2C+J">Joel Milligan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ural%2C+D">Damla Ural</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sanchez%2C+B+R">Berta Rodriguez Sanchez</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stoico%2C+V">Vincenzo Stoico</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Malavolta%2C+I">Ivano Malavolta</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Context. Nowadays, 83% of software developers use Large Language Models
                    (LLMs) to generate code. LLMs recently became essential to increase the
                    productivity of software developers and decrease the time and cost of software
                    development. Developers ranging from novices to experts use LLM tools not only
                    to detect and patch bugs, but also to integrate generated code into their
                    software. However, as of today there is no objective assessment of the energy
                    efficiency of the source code generated by LLM tools. Released in August 2023,
                    Code Llama is one of the most recent LLM tools.
                    <br>Goal. In this paper, we present an empirical study that assesses the energy
                    efficiency of Code Llama with respect to human-written source code.
                    <br>Method. We design an experiment involving three human-written benchmarks
                    implemented in C++, JavaScript, and Python. We ask Code Llama to generate the
                    code of the benchmarks using different prompts and temperatures. Therefore, we
                    execute both implementations and profile their energy efficiency.
                    <br>Results. Our study shows that the energy efficiency of code generated by Code
                    Llama is heavily-dependent on the chosen programming language and the specific
                    code problem at hand. Also, human implementations tend to be more energy
                    efficient overall, with generated JavaScript code outperforming its human
                    counterpart. Moreover, explicitly asking Code Llama to generate
                    energy-efficient code results in an equal or worse energy efficiency, as well
                    as using different temperatures seems not to affect the energy efficiency of
                    generated code.
                    <br>Conclusions. According to our results, code generated using Code Llama does
                    not guarantee energy efficiency, even when prompted to do so. Therefore,
                    software developers should evaluate the energy efficiency of generated code
                    before integrating it into the software system under development.
                </p>
            </div>
        </dd>
        <dt><a name="item642">[642]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03619"
                    title="Abstract">arXiv:2405.03619</a> [<a href="/pdf/2405.03619" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03619" title="Download PostScript">ps</a>, <a href="/format/2405.03619"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The trade-offs between Monolithic vs. Distributed
                    Architectures
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Felisberto%2C+M">Matheus Felisberto</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
                <p class="mathjax">Software architects frequently engage in trade-off analysis, often
                    confronting sub-optimal solutions due to unforeseen or overlooked
                    disadvantages. Such outcomes can detrimentally affect a company's business
                    operations and resource allocation. This article conducts a critical review of
                    archi- tectural styles, particularly focusing on the strengths and weaknesses
                    of both monolithic and distributed architectures, and their relationship to
                    architectural characteristics. It also explores the role of cloud computing in
                    transitioning from monolithic to distributed-based applications. Utilizing a
                    broad range of sources, including papers and books from both industry and
                    academia, this research provides an overview from theoretical foundations to
                    practical applications. A notable trend observed is a shift back from
                    distributed to monolithic architectures, possibly due to factors such as cost,
                    complexity, and performance.
                </p>
            </div>
        </dd>
        <dt><a name="item643">[643]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03620"
                    title="Abstract">arXiv:2405.03620</a> [<a href="/pdf/2405.03620" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03620" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Detecting Android Malware: From Neural Embeddings to Hands-On
                    Validation with BERTroid
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chaieb%2C+M">Meryam Chaieb</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghorab%2C+M+A">Mostafa Anouar Ghorab</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saied%2C+M+A">Mohamed Aymen Saied</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">As cyber threats and malware attacks increasingly alarm both individuals and
                    businesses, the urgency for proactive malware countermeasures intensifies. This
                    has driven a rising interest in automated machine learning solutions.
                    Transformers, a cutting-edge category of attention-based deep learning methods,
                    have demonstrated remarkable success. In this paper, we present BERTroid, an
                    innovative malware detection model built on the BERT architecture. Overall,
                    BERTroid emerged as a promising solution for combating Android malware. Its
                    ability to outperform state-of-the-art solutions demonstrates its potential as
                    a proactive defense mechanism against malicious software attacks. Additionally,
                    we evaluate BERTroid on multiple datasets to assess its performance across
                    diverse scenarios. In the dynamic landscape of cybersecurity, our approach has
                    demonstrated promising resilience against the rapid evolution of malware on
                    Android systems. While the machine learning model captures broad patterns, we
                    emphasize the role of manual validation for deeper comprehension and insight
                    into these behaviors. This human intervention is critical for discerning
                    intricate and context-specific behaviors, thereby validating and reinforcing
                    the model's findings.
                </p>
            </div>
        </dd>
        <dt><a name="item644">[644]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03624"
                    title="Abstract">arXiv:2405.03624</a> [<a href="/pdf/2405.03624" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03624" title="Download PostScript">ps</a>, <a href="/format/2405.03624"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-297-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2004"
                                style="width: 0.558em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.465em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.345em, 1000.42em, 2.086em, -999.998em); top: -1.942em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2005"><span class="texatom"
                                                id="MathJax-Span-2006"><span class="mrow" id="MathJax-Span-2007"><span
                                                        class="mo" id="MathJax-Span-2008"
                                                        style="font-family: MathJax_Math-italic;">ε</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.947em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.669em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-297">ε</script>-Policy Gradient for Online Pricing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Szpruch%2C+L">Lukasz Szpruch</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Treetanthiploet%2C+T">Tanut Treetanthiploet</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yufei Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Optimization and Control (math.OC); Statistical Finance (q-fin.ST); Machine
                    Learning (stat.ML)

                </div>
                <p class="mathjax">Combining model-based and model-free reinforcement learning approaches, this
                    paper proposes and analyzes an <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-298-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2009"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.41em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2010"><span class="mi" id="MathJax-Span-2011"
                                                style="font-family: MathJax_Math-italic;">ϵ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-298">\epsilon</script>-policy gradient algorithm for the
                    online pricing learning task. The algorithm extends <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-299-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2012"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.41em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2013"><span class="mi" id="MathJax-Span-2014"
                                                style="font-family: MathJax_Math-italic;">ϵ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-299">\epsilon</script>-greedy algorithm
                    by replacing greedy exploitation with gradient descent step and facilitates
                    learning via model inference. We optimize the regret of the proposed algorithm
                    by quantifying the exploration cost in terms of the exploration probability
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-300-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2015"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.41em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2016"><span class="mi" id="MathJax-Span-2017"
                                                style="font-family: MathJax_Math-italic;">ϵ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-300">\epsilon</script> and the exploitation cost in
                    terms of the gradient descent
                    optimization and gradient estimation errors. The algorithm achieves an expected
                    regret of order <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-301-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2018"
                                style="width: 3.764em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.128em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1003.01em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2019"><span class="texatom"
                                                id="MathJax-Span-2020"><span class="mrow" id="MathJax-Span-2021"><span
                                                        class="mi" id="MathJax-Span-2022"
                                                        style="font-family: MathJax_Caligraphic;">O</span></span></span><span
                                                class="mo" id="MathJax-Span-2023"
                                                style="font-family: MathJax_Main;">(</span><span class="msqrt"
                                                id="MathJax-Span-2024"><span
                                                    style="display: inline-block; position: relative; width: 1.565em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.7em, 4.17em, -999.997em); top: -3.99em; left: 0.813em;"><span
                                                            class="mrow" id="MathJax-Span-2025"><span class="mi"
                                                                id="MathJax-Span-2026"
                                                                style="font-family: MathJax_Math-italic;">T<span
                                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.533em, 1000.75em, 3.938em, -999.997em); top: -4.569em; left: 0.813em;"><span
                                                            style="display: inline-block; position: relative; width: 0.755em; height: 0px;"><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: -0.055em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                                style="position: absolute; font-family: MathJax_Main; top: -3.99em; left: 0.061em;">−<span
                                                                    style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; clip: rect(3.012em, 1000.87em, 4.343em, -999.997em); top: -4.048em; left: 0em;"><span
                                                            style="font-family: MathJax_Main;">√</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-2027"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.462em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-301">\mathcal{O}(\sqrt{T})</script> (up to a logarithmic
                    factor) over <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-302-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2028"
                                style="width: 0.871em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.7em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2029"><span class="mi" id="MathJax-Span-2030"
                                                style="font-family: MathJax_Math-italic;">T<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.119em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-302">T</script>
                    trials.
                </p>
            </div>
        </dd>
        <dt><a name="item645">[645]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03628"
                    title="Abstract">arXiv:2405.03628</a> [<a href="/pdf/2405.03628" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03628" title="Download PostScript">ps</a>, <a href="/format/2405.03628"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> State-Aware Timeliness in Energy Harvesting IoT Systems
                    Monitoring a Markovian Source
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Delfani%2C+E">Erfan Delfani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stamatakis%2C+G+J">George J. Stamatakis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pappas%2C+N">Nikolaos Pappas</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted for journal publication. arXiv admin note: text
                    overlap with <a href="/abs/1907.03826">arXiv:1907.03826</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

                </div>
                <p class="mathjax">In this study, we investigate the optimal transmission policies within an
                    energy harvesting status update system, where the demand for status updates
                    depends on the state of the source. The system monitors a two-state Markovian
                    source that characterizes a stochastic process, which can be in either a normal
                    state or an alarm state, with a higher demand for fresh updates when the source
                    is in the alarm state. We propose a metric to capture the freshness of status
                    updates for each state of the stochastic process by introducing two Age of
                    Information (AoI) variables, extending the definition of AoI to account for the
                    state changes of the stochastic process. We formulate the problem as a Markov
                    Decision Process (MDP), utilizing a transition cost function that applies
                    linear and non-linear penalties based on AoI and the state of the stochastic
                    process. Through analytical investigation, we delve into the structure of the
                    optimal transmission policy for the resulting MDP problem. Furthermore, we
                    evaluate the derived policies via numerical results and demonstrate their
                    effectiveness in reserving energy in anticipation of forthcoming alarm states.
                </p>
            </div>
        </dd>
        <dt><a name="item646">[646]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03629"
                    title="Abstract">arXiv:2405.03629</a> [<a href="/pdf/2405.03629" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03629" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Configuration-Constrained Tube MPC for Tracking
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Badalamenti%2C+F">Filippo Badalamenti</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Mulagaleti%2C+S+K">Sampath Kumar Mulagaleti</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Bemporad%2C+A">Alberto Bemporad</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Houska%2C+B">Boris Houska</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Villanueva%2C+M+E">Mario Eduardo Villanueva</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, paper presented to the L-CSS/CDC combined
                    submission
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>; Optimization and Control (math.OC)

                </div>
                <p class="mathjax">This paper proposes a novel tube-based Model Predictive Control (MPC)
                    framework for tracking varying setpoint references with linear systems subject
                    to additive and multiplicative uncertainties. The MPC controllers designed
                    using this framework exhibit recursively feasible for changing references, and
                    robust asymptotic stability for piecewise constant references. The framework
                    leverages configuration-constrained polytopes to parameterize the tubes,
                    offering flexibility to optimize their shape. The efficacy of the approach is
                    demonstrated through two numerical examples. The first example illustrates the
                    theoretical results, and the second uses the framework to design a lane-change
                    controller for an autonomous vehicle.
                </p>
            </div>
        </dd>
        <dt><a name="item647">[647]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03632"
                    title="Abstract">arXiv:2405.03632</a> [<a href="/pdf/2405.03632" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03632" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LaserEscape: Detecting and Mitigating Optical Probing Attacks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Monfared%2C+S+K">Saleh Khalaj Monfared</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mitard%2C+K">Kyle Mitard</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cannon%2C+A">Andrew Cannon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Forte%2C+D">Domenic Forte</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tajik%2C+S">Shahin Tajik</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
                <p class="mathjax">The security of integrated circuits (ICs) can be broken by sophisticated
                    physical attacks relying on failure analysis methods. Optical probing is one of
                    the most prominent examples of such attacks, which can be accomplished in a
                    matter of days, even with limited knowledge of the IC under attack.
                    Unfortunately, few countermeasures are proposed in the literature, and none has
                    been fabricated and tested in practice. These countermeasures usually require
                    changing the standard cell libraries and, thus, are incompatible with digital
                    and programmable platforms, such as field programmable gate arrays (FPGAs). In
                    this work, we shift our attention from preventing the attack to detecting and
                    responding to it. We introduce LaserEscape, the first fully digital and
                    FPGA-compatible countermeasure to detect and mitigate optical probing attacks.
                    LaserEscape incorporates digital delay-based sensors to reliably detect the
                    physical alteration on the fabric caused by laser beam irradiations in real
                    time. Furthermore, as a response to the attack, LaserEscape deploys real-time
                    hiding approaches using randomized hardware reconfigurability. It realizes 1)
                    moving target defense (MTD) to physically move the sensitive circuity under
                    attack out of the probing field of focus to protect secret keys and 2)
                    polymorphism to logically obfuscate the functionality of the targeted circuit
                    to counter function extraction and reverse engineering attempts. We demonstrate
                    the effectiveness and resiliency of our approach by performing optical probing
                    attacks on protected and unprotected designs on a 28-nm FPGA. Our results show
                    that optical probing attacks can be reliably detected and mitigated without
                    interrupting the chip's operation.
                </p>
            </div>
        </dd>
        <dt><a name="item648">[648]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03633"
                    title="Abstract">arXiv:2405.03633</a> [<a href="/pdf/2405.03633" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03633" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Neural Graph Mapping for Dense SLAM with Efficient Loop
                    Closure
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bruns%2C+L">Leonard Bruns</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jun Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jensfelt%2C+P">Patric Jensfelt</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Project page: <a
                        href="https://kth-rpl.github.io/neural_graph_mapping/">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Robotics (cs.RO)

                </div>
                <p class="mathjax">Existing neural field-based SLAM methods typically employ a single monolithic
                    field as their scene representation. This prevents efficient incorporation of
                    loop closure constraints and limits scalability. To address these shortcomings,
                    we propose a neural mapping framework which anchors lightweight neural fields
                    to the pose graph of a sparse visual SLAM system. Our approach shows the
                    ability to integrate large-scale loop closures, while limiting necessary
                    reintegration. Furthermore, we verify the scalability of our approach by
                    demonstrating successful building-scale mapping taking multiple loop closures
                    into account during the optimization, and show that our method outperforms
                    existing state-of-the-art approaches on large scenes in terms of quality and
                    runtime. Our code is available at
                    https://kth-rpl.github.io/neural_graph_mapping/.
                </p>
            </div>
        </dd>
        <dt><a name="item649">[649]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03636"
                    title="Abstract">arXiv:2405.03636</a> [<a href="/pdf/2405.03636" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03636" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Federated Learning Privacy: Attacks, Defenses, Applications,
                    and Policy Landscape - A Survey
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+J+C">Joshua C. Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bagchi%2C+S">Saurabh Bagchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Avestimehr%2C+S">Salman Avestimehr</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+K+S">Kevin S. Chan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chaterji%2C+S">Somali Chaterji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dimitriadis%2C+D">Dimitris Dimitriadis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jiacheng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+N">Ninghui Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nourian%2C+A">Arash Nourian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roth%2C+H+R">Holger R. Roth</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to ACM Computing Surveys
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Deep learning has shown incredible potential across a vast array of tasks and
                    accompanying this growth has been an insatiable appetite for data. However, a
                    large amount of data needed for enabling deep learning is stored on personal
                    devices and recent concerns on privacy have further highlighted challenges for
                    accessing such data. As a result, federated learning (FL) has emerged as an
                    important privacy-preserving technology enabling collaborative training of
                    machine learning models without the need to send the raw, potentially
                    sensitive, data to a central server. However, the fundamental premise that
                    sending model updates to a server is privacy-preserving only holds if the
                    updates cannot be "reverse engineered" to infer information about the private
                    training data. It has been shown under a wide variety of settings that this
                    premise for privacy does {\em not} hold.
                    <br>In this survey paper, we provide a comprehensive literature review of the
                    different privacy attacks and defense methods in FL. We identify the current
                    limitations of these attacks and highlight the settings in which FL client
                    privacy can be broken. We dissect some of the successful industry applications
                    of FL and draw lessons for future successful adoption. We survey the emerging
                    landscape of privacy regulation for FL. We conclude with future directions for
                    taking FL toward the cherished goal of generating accurate models while
                    preserving the privacy of the data from its participants.
                </p>
            </div>
        </dd>
        <dt><a name="item650">[650]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03637"
                    title="Abstract">arXiv:2405.03637</a> [<a href="/pdf/2405.03637" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03637" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Collage: Light-Weight Low-Precision Strategy for LLM Training
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+T">Tao Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+G">Gaurav Gupta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gopalswamy%2C+K">Karthick Gopalswamy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mamidala%2C+A">Amith Mamidala</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hao Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huynh%2C+J">Jeffrey Huynh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+Y">Youngsuk Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Diamant%2C+R">Ron Diamant</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deoras%2C+A">Anoop Deoras</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huan%2C+L">Luke Huan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Large models training is plagued by the intense compute cost and limited
                    hardware memory. A practical solution is low-precision representation but is
                    troubled by loss in numerical accuracy and unstable training rendering the
                    model less useful. We argue that low-precision floating points can perform well
                    provided the error is properly compensated at the critical locations in the
                    training process. We propose Collage which utilizes multi-component float
                    representation in low-precision to accurately perform operations with numerical
                    errors accounted. To understand the impact of imprecision to training, we
                    propose a simple and novel metric which tracks the lost information during
                    training as well as differentiates various precision strategies. Our method
                    works with commonly used low-precision such as half-precision (<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-303-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2031"
                                style="width: 1.218em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.987em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.93em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2032"><span class="mn" id="MathJax-Span-2033"
                                                style="font-family: MathJax_Main;">16</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-303">16</script>-bit
                    floating points) and can be naturally extended to work with even lower
                    precision such as <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-304-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2034"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2035"><span class="mn" id="MathJax-Span-2036"
                                                style="font-family: MathJax_Main;">8</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-304">8</script>-bit. Experimental results show that
                    pre-training using
                    Collage removes the requirement of using <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-305-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2037"
                                style="width: 1.218em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.987em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.93em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2038"><span class="mn" id="MathJax-Span-2039"
                                                style="font-family: MathJax_Main;">32</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-305">32</script>-bit floating-point copies of the
                    model and attains similar/better training performance compared to <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-306-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2040"
                                style="width: 3.938em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.244em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1003.13em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2041"><span class="mo" id="MathJax-Span-2042"
                                                style="font-family: MathJax_Main;">(</span><span class="mn"
                                                id="MathJax-Span-2043" style="font-family: MathJax_Main;">16</span><span
                                                class="mo" id="MathJax-Span-2044"
                                                style="font-family: MathJax_Main;">,</span><span class="mn"
                                                id="MathJax-Span-2045"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">32</span><span
                                                class="mo" id="MathJax-Span-2046"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-306">(16,
    32)</script>-bit mixed-precision strategy, with up to <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-307-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2047"
                                style="width: 2.549em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.91em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2048"><span class="mn" id="MathJax-Span-2049"
                                                style="font-family: MathJax_Main;">3.7</span><span class="mo"
                                                id="MathJax-Span-2050"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-307">3.7\times</script> speedup and <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-308-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2051"
                                style="width: 3.475em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.896em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1002.84em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2052"><span class="mo" id="MathJax-Span-2053"
                                                style="font-family: MathJax_Main;">∼</span><span class="mn"
                                                id="MathJax-Span-2054"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">15</span><span
                                                class="mi" id="MathJax-Span-2055"
                                                style="font-family: MathJax_Main;">%</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-308">\sim
    15\%</script> to <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-309-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2056"
                                style="width: 2.26em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.855em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.8em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2057"><span class="mn" id="MathJax-Span-2058"
                                                style="font-family: MathJax_Main;">23</span><span class="mi"
                                                id="MathJax-Span-2059"
                                                style="font-family: MathJax_Main;">%</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-309">23\%</script> less memory usage in practice.
                </p>
            </div>
        </dd>
        <dt><a name="item651">[651]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03638"
                    title="Abstract">arXiv:2405.03638</a> [<a href="/pdf/2405.03638" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03638" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Cosine Annealing Optimized Denoising Diffusion Error
                    Correction Codes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ou%2C+C">Congyang Ou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaojing Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+W">Wan Jiang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
                <p class="mathjax">To address the issue of increased bit error rates during the later stages of
                    linear search in denoising diffusion error correction codes, we propose a novel
                    method that optimizes denoising diffusion error correction codes (ECC) using
                    cosine annealing. In response to the challenge of decoding long codewords, the
                    proposed method employs a variance adjustment strategy during the reverse
                    diffusion process, rather than maintaining a constant variance. By leveraging
                    cosine annealing, this method effectively lowers the bit error rate and
                    enhances decoding effciency. This letter extensively validates the approach
                    through experiments and demonstrates signifcant improvements in bit error rate
                    reduction and iteration effciency compared to existing methods. This
                    advancement offers a promising solution for improving ECC decoding performance,
                    potentially impacting secure digital communication practices.
                </p>
            </div>
        </dd>
        <dt><a name="item652">[652]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03642"
                    title="Abstract">arXiv:2405.03642</a> [<a href="/pdf/2405.03642" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03642" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Classification of Breast Cancer Histopathology Images using a
                    Modified Supervised Contrastive Learning Method
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sani%2C+M+M">Matina Mahdizadeh Sani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Royat%2C+A">Ali Royat</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baghshah%2C+M+S">Mahdieh Soleymani Baghshah</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages, 3 figures, 4 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Deep neural networks have reached remarkable achievements in medical image
                    processing tasks, specifically classifying and detecting various diseases.
                    However, when confronted with limited data, these networks face a critical
                    vulnerability, often succumbing to overfitting by excessively memorizing the
                    limited information available. This work addresses the challenge mentioned
                    above by improving the supervised contrastive learning method to reduce the
                    impact of false positives. Unlike most existing methods that rely predominantly
                    on fully supervised learning, our approach leverages the advantages of
                    self-supervised learning in conjunction with employing the available labeled
                    data. We evaluate our method on the BreakHis dataset, which consists of breast
                    cancer histopathology images, and demonstrate an increase in classification
                    accuracy by 1.45% at the image level and 1.42% at the patient level compared to
                    the state-of-the-art method. This improvement corresponds to 93.63% absolute
                    accuracy, highlighting our approach's effectiveness in leveraging data
                    properties to learn more appropriate representation space.
                </p>
            </div>
        </dd>
        <dt><a name="item653">[653]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03643"
                    title="Abstract">arXiv:2405.03643</a> [<a href="/pdf/2405.03643" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03643" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Collecting Consistently High Quality Object Tracks with
                    Minimal Human Involvement by Using Self-Supervised Learning to Detect Tracker Errors
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Anjum%2C+S">Samreen Anjum</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jain%2C+S">Suyog Jain</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gurari%2C+D">Danna Gurari</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">We propose a hybrid framework for consistently producing high-quality object
                    tracks by combining an automated object tracker with little human input. The
                    key idea is to tailor a module for each dataset to intelligently decide when an
                    object tracker is failing and so humans should be brought in to re-localize an
                    object for continued tracking. Our approach leverages self-supervised learning
                    on unlabeled videos to learn a tailored representation for a target object that
                    is then used to actively monitor its tracked region and decide when the tracker
                    fails. Since labeled data is not needed, our approach can be applied to novel
                    object categories. Experiments on three datasets demonstrate our method
                    outperforms existing approaches, especially for small, fast moving, or occluded
                    objects.
                </p>
            </div>
        </dd>
        <dt><a name="item654">[654]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03644"
                    title="Abstract">arXiv:2405.03644</a> [<a href="/pdf/2405.03644" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03644" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> When LLMs Meet Cybersecurity: A Systematic Literature Review
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jie Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bu%2C+H">Haoyu Bu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wen%2C+H">Hui Wen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yu Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Lun Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+H">Hongsong Zhu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 36 pages, 7 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">The rapid advancements in large language models (LLMs) have opened new
                    avenues across various fields, including cybersecurity, which faces an
                    ever-evolving threat landscape and need for innovative technologies. Despite
                    initial explorations into the application of LLMs in cybersecurity, there is a
                    lack of a comprehensive overview of this research area. This paper bridge this
                    gap by providing a systematic literature review, encompassing an analysis of
                    over 180 works, spanning across 25 LLMs and more than 10 downstream scenarios.
                    Our comprehensive overview addresses three critical research questions: the
                    construction of cybersecurity-oriented LLMs, LLMs' applications in various
                    cybersecurity tasks, and the existing challenges and further research in this
                    area. This study aims to shed light on the extensive potential of LLMs in
                    enhancing cybersecurity practices, and serve as a valuable resource for
                    applying LLMs in this doamin. We also maintain and regularly updated list of
                    practical guides on LLMs for cybersecurity at
                    https://github.com/tmylla/Awesome-LLM4Cybersecurity.
                </p>
            </div>
        </dd>
        <dt><a name="item655">[655]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03646"
                    title="Abstract">arXiv:2405.03646</a> [<a href="/pdf/2405.03646" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03646" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Content-Oblivious Leader Election on Rings
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Frei%2C+F">Fabian Frei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gelles%2C+R">Ran Gelles</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghazy%2C+A">Ahmed Ghazy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nolin%2C+A">Alexandre Nolin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">In content-oblivious computation, n nodes wish to compute a given task over
                    an asynchronous network that suffers from an extremely harsh type of noise,
                    which corrupts the content of all messages across all channels. In a recent
                    work, Censor-Hillel, Cohen, Gelles, and Sela (Distributed Computing, 2023)
                    showed how to perform arbitrary computations in a content-oblivious way in
                    2-edge connected networks but only if the network has a distinguished node
                    (called root) to initiate the computation.
                    <br>Our goal is to remove this assumption, which was conjectured to be necessary.
                    Achieving this goal essentially reduces to performing a content-oblivious
                    leader election since an elected leader can then serve as the root required to
                    perform arbitrary content-oblivious computations. We focus on ring networks,
                    which are the simplest 2-edge connected graphs. On oriented rings, we obtain a
                    leader election algorithm with message complexity O(n*ID_max), where ID_max is
                    the maximal assigned ID. As it turns out, this dependency on <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-310-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2060"
                                style="width: 3.764em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.128em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1003.07em, 2.26em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2061"><span class="mi" id="MathJax-Span-2062"
                                                style="font-family: MathJax_Math-italic;">I<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                class="msubsup" id="MathJax-Span-2063"><span
                                                    style="display: inline-block; position: relative; width: 1.508em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.81em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2064"
                                                            style="font-family: MathJax_Math-italic;">D</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.813em;"><span
                                                            class="mi" id="MathJax-Span-2065"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mi" id="MathJax-Span-2066"
                                                style="font-family: MathJax_Math-italic;">a</span><span class="mi"
                                                id="MathJax-Span-2067"
                                                style="font-family: MathJax_Math-italic;">x</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-310">ID_max</script> is
                    inherent: we show a lower bound of Omega(n*log(ID_max/n)) messages for
                    content-oblivious leader election algorithms. We also extend our results to
                    non-oriented rings, where nodes cannot tell which channel leads to which
                    neighbor. In this case, however, the algorithm does not terminate but only
                    reaches quiescence.
                </p>
            </div>
        </dd>
        <dt><a name="item656">[656]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03649"
                    title="Abstract">arXiv:2405.03649</a> [<a href="/pdf/2405.03649" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03649" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Learning Robust Classifiers with Self-Guided Spurious
                    Correlation Mitigation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+G">Guangtao Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+W">Wenqian Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+A">Aidong Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Deep neural classifiers tend to rely on spurious correlations between
                    spurious attributes of inputs and targets to make predictions, which could
                    jeopardize their generalization capability. Training classifiers robust to
                    spurious correlations typically relies on annotations of spurious correlations
                    in data, which are often expensive to get. In this paper, we tackle an
                    annotation-free setting and propose a self-guided spurious correlation
                    mitigation framework. Our framework automatically constructs fine-grained
                    training labels tailored for a classifier obtained with empirical risk
                    minimization to improve its robustness against spurious correlations. The
                    fine-grained training labels are formulated with different prediction behaviors
                    of the classifier identified in a novel spuriousness embedding space. We
                    construct the space with automatically detected conceptual attributes and a
                    novel spuriousness metric which measures how likely a class-attribute
                    correlation is exploited for predictions. We demonstrate that training the
                    classifier to distinguish different prediction behaviors reduces its reliance
                    on spurious correlations without knowing them a priori and outperforms prior
                    methods on five real-world datasets.
                </p>
            </div>
        </dd>
        <dt><a name="item657">[657]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03650"
                    title="Abstract">arXiv:2405.03650</a> [<a href="/pdf/2405.03650" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03650" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Generated Contents Enrichment
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Naseri%2C+M">Mahdi Naseri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+J">Jiayan Qiu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhou Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">In this paper, we investigate a novel artificial intelligence generation
                    task, termed as generated contents enrichment (GCE). Different from
                    conventional artificial intelligence contents generation task that enriches the
                    given textual description implicitly with limited semantics for generating
                    visually real content, our proposed GCE strives to perform content enrichment
                    explicitly on both the visual and textual domain, from which the enriched
                    contents are visually real, structurally reasonable, and semantically abundant.
                    Towards to solve GCE, we propose a deep end-to-end method that explicitly
                    explores the semantics and inter-semantic relationships during the enrichment.
                    Specifically, we first model the input description as a semantic graph, wherein
                    each node represents an object and each edge corresponds to the inter-object
                    relationship. We then adopt Graph Convolutional Networks on top of the input
                    scene description to predict the enriching objects and their relationships with
                    the input objects. Finally, the enriched graph is fed into an image synthesis
                    model to carry out the visual contents generation. Our experiments conducted on
                    the Visual Genome dataset exhibit promising and visually plausible results.
                </p>
            </div>
        </dd>
        <dt><a name="item658">[658]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03651"
                    title="Abstract">arXiv:2405.03651</a> [<a href="/pdf/2405.03651" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03651" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adaptive Retrieval and Scalable Indexing for k-NN Search with
                    Cross-Encoders
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yadav%2C+N">Nishant Yadav</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Monath%2C+N">Nicholas Monath</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zaheer%2C+M">Manzil Zaheer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fergus%2C+R">Rob Fergus</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McCallum%2C+A">Andrew McCallum</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Cross-encoder (CE) models which compute similarity by jointly encoding a
                    query-item pair perform better than embedding-based models (dual-encoders) at
                    estimating query-item relevance. Existing approaches perform k-NN search with
                    CE by approximating the CE similarity with a vector embedding space fit either
                    with dual-encoders (DE) or CUR matrix factorization. DE-based
                    retrieve-and-rerank approaches suffer from poor recall on new domains and the
                    retrieval with DE is decoupled from the CE. While CUR-based approaches can be
                    more accurate than the DE-based approach, they require a prohibitively large
                    number of CE calls to compute item embeddings, thus making it impractical for
                    deployment at scale. In this paper, we address these shortcomings with our
                    proposed sparse-matrix factorization based method that efficiently computes
                    latent query and item embeddings to approximate CE scores and performs k-NN
                    search with the approximate CE similarity. We compute item embeddings offline
                    by factorizing a sparse matrix containing query-item CE scores for a set of
                    train queries. Our method produces a high-quality approximation while requiring
                    only a fraction of CE calls as compared to CUR-based methods, and allows for
                    leveraging DE to initialize the embedding space while avoiding compute- and
                    resource-intensive finetuning of DE via distillation. At test time, the item
                    embeddings remain fixed and retrieval occurs over rounds, alternating between
                    a) estimating the test query embedding by minimizing error in approximating CE
                    scores of items retrieved thus far, and b) using the updated test query
                    embedding for retrieving more items. Our k-NN search method improves recall by
                    up to 5% (k=1) and 54% (k=100) over DE-based approaches. Additionally, our
                    indexing approach achieves a speedup of up to 100x over CUR-based and 5x over
                    DE distillation methods, while matching or improving k-NN search recall over
                    baselines.
                </p>
            </div>
        </dd>
        <dt><a name="item659">[659]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03652"
                    title="Abstract">arXiv:2405.03652</a> [<a href="/pdf/2405.03652" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03652" title="Download PostScript">ps</a>, <a href="/format/2405.03652"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Field-of-View Extension for Diffusion MRI via Deep Generative
                    Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+C">Chenyu Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bao%2C+S">Shunxing Bao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+M">Michael Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Newlin%2C+N">Nancy Newlin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kanakaraj%2C+P">Praitayini Kanakaraj</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+T">Tianyuan Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rudravaram%2C+G">Gaurav Rudravaram</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huo%2C+Y">Yuankai Huo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Moyer%2C+D">Daniel Moyer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schilling%2C+K">Kurt Schilling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kukull%2C+W">Walter Kukull</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Toga%2C+A">Arthur Toga</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Archer%2C+D">Derek Archer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hohman%2C+T">Timothy Hohman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Landman%2C+B">Bennett Landman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhiyuan Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 20 pages, 11 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Purpose: In diffusion MRI (dMRI), the volumetric and bundle analyses of
                    whole-brain tissue microstructure and connectivity can be severely impeded by
                    an incomplete field-of-view (FOV). This work aims to develop a method for
                    imputing the missing slices directly from existing dMRI scans with an
                    incomplete FOV. We hypothesize that the imputed image with complete FOV can
                    improve the whole-brain tractography for corrupted data with incomplete FOV.
                    Therefore, our approach provides a desirable alternative to discarding the
                    valuable dMRI data, enabling subsequent tractography analyses that would
                    otherwise be challenging or unattainable with corrupted data. Approach: We
                    propose a framework based on a deep generative model that estimates the absent
                    brain regions in dMRI scans with incomplete FOV. The model is capable of
                    learning both the diffusion characteristics in diffusion-weighted images (DWI)
                    and the anatomical features evident in the corresponding structural images for
                    efficiently imputing missing slices of DWI outside of incomplete FOV. Results:
                    For evaluating the imputed slices, on the WRAP dataset the proposed framework
                    achieved PSNRb0=22.397, SSIMb0=0.905, PSNRb1300=22.479, SSIMb1300=0.893; on the
                    NACC dataset it achieved PSNRb0=21.304, SSIMb0=0.892, PSNRb1300=21.599,
                    SSIMb1300= 0.877. The proposed framework improved the tractography accuracy, as
                    demonstrated by an increased average Dice score for 72 tracts (p &lt; 0.001) on
                    both the WRAP and NACC datasets. Conclusions: Results suggest that the proposed
                    framework achieved sufficient imputation performance in dMRI data with
                    incomplete FOV for improving whole-brain tractography, thereby repairing the
                    corrupted data. Our approach achieved more accurate whole-brain tractography
                    results with extended and complete FOV and reduced the uncertainty when
                    analyzing bundles associated with Alzheimer's Disease.
                </p>
            </div>
        </dd>
        <dt><a name="item660">[660]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03654"
                    title="Abstract">arXiv:2405.03654</a> [<a href="/pdf/2405.03654" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03654" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Can LLMs Deeply Detect Complex Malicious Queries? A Framework
                    for Jailbreaking via Obfuscating Intent
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shang%2C+S">Shang Shang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xinqiang Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Z">Zhongjiang Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yepeng Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+L">Liya Su</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+Z">Zijing Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+X">Xiaodan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Zhengwei Jiang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">To demonstrate and address the underlying maliciousness, we propose a
                    theoretical hypothesis and analytical approach, and introduce a new black-box
                    jailbreak attack methodology named IntentObfuscator, exploiting this identified
                    flaw by obfuscating the true intentions behind user prompts.This approach
                    compels LLMs to inadvertently generate restricted content, bypassing their
                    built-in content security measures. We detail two implementations under this
                    framework: "Obscure Intention" and "Create Ambiguity", which manipulate query
                    complexity and ambiguity to evade malicious intent detection effectively. We
                    empirically validate the effectiveness of the IntentObfuscator method across
                    several models, including ChatGPT-3.5, ChatGPT-4, Qwen and Baichuan, achieving
                    an average jailbreak success rate of 69.21\%. Notably, our tests on
                    ChatGPT-3.5, which claims 100 million weekly active users, achieved a
                    remarkable success rate of 83.65\%. We also extend our validation to diverse
                    types of sensitive content like graphic violence, racism, sexism, political
                    sensitivity, cybersecurity threats, and criminal skills, further proving the
                    substantial impact of our findings on enhancing 'Red Team' strategies against
                    LLM content security frameworks.
                </p>
            </div>
        </dd>
        <dt><a name="item661">[661]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03658"
                    title="Abstract">arXiv:2405.03658</a> [<a href="/pdf/2405.03658" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03658" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A review on data-driven constitutive laws for solids
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fuhg%2C+J+N">Jan Niklas Fuhg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Padmanabha%2C+G+A">Govinda Anantha Padmanabha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bouklas%2C+N">Nikolaos Bouklas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bahmani%2C+B">Bahador Bahmani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+W">WaiChing Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vlassis%2C+N+N">Nikolaos N. Vlassis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Flaschel%2C+M">Moritz Flaschel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Carrara%2C+P">Pietro Carrara</a>,
                    <a href="/search/cs?searchtype=author&amp;query=De+Lorenzis%2C+L">Laura De Lorenzis</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 57 pages, 7 Figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Applied Physics (physics.app-ph)

                </div>
                <p class="mathjax">This review article highlights state-of-the-art data-driven techniques to
                    discover, encode, surrogate, or emulate constitutive laws that describe the
                    path-independent and path-dependent response of solids. Our objective is to
                    provide an organized taxonomy to a large spectrum of methodologies developed in
                    the past decades and to discuss the benefits and drawbacks of the various
                    techniques for interpreting and forecasting mechanics behavior across different
                    scales. Distinguishing between machine-learning-based and model-free methods,
                    we further categorize approaches based on their interpretability and on their
                    learning process/type of required data, while discussing the key problems of
                    generalization and trustworthiness. We attempt to provide a road map of how
                    these can be reconciled in a data-availability-aware context. We also touch
                    upon relevant aspects such as data sampling techniques, design of experiments,
                    verification, and validation.
                </p>
            </div>
        </dd>
        <dt><a name="item662">[662]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03659"
                    title="Abstract">arXiv:2405.03659</a> [<a href="/pdf/2405.03659" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03659" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Construct-Optimize Approach to Sparse View Synthesis
                    without Camera Pose
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+K">Kaiwen Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+Y">Yang Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=T%2C+M+V">Mukund Varma T</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Belhe%2C+Y">Yash Belhe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaolong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+H">Hao Su</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ramamoorthi%2C+R">Ravi Ramamoorthi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
                <p class="mathjax">Novel view synthesis from a sparse set of input images is a challenging
                    problem of great practical interest, especially when camera poses are absent or
                    inaccurate. Direct optimization of camera poses and usage of estimated depths
                    in neural radiance field algorithms usually do not produce good results because
                    of the coupling between poses and depths, and inaccuracies in monocular depth
                    estimation. In this paper, we leverage the recent 3D Gaussian splatting method
                    to develop a novel construct-and-optimize method for sparse view synthesis
                    without camera poses. Specifically, we construct a solution progressively by
                    using monocular depth and projecting pixels back into the 3D world. During
                    construction, we optimize the solution by detecting 2D correspondences between
                    training views and the corresponding rendered images. We develop a unified
                    differentiable pipeline for camera registration and adjustment of both camera
                    poses and depths, followed by back-projection. We also introduce a novel notion
                    of an expected surface in Gaussian splatting, which is critical to our
                    optimization. These steps enable a coarse solution, which can then be low-pass
                    filtered and refined using standard optimization methods. We demonstrate
                    results on the Tanks and Temples and Static Hikes datasets with as few as three
                    widely-spaced views, showing significantly better quality than competing
                    methods, including those with approximate camera pose information. Moreover,
                    our results improve with more views and outperform previous InstantNGP and
                    Gaussian Splatting algorithms even when using half the dataset.
                </p>
            </div>
        </dd>
        <dt><a name="item663">[663]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03660"
                    title="Abstract">arXiv:2405.03660</a> [<a href="/pdf/2405.03660" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03660" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CICA: Content-Injected Contrastive Alignment for Zero-Shot
                    Document Image Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sinha%2C+S">Sankalp Sinha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+M+S+U">Muhammad Saif Ullah Khan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sheikh%2C+T+U">Talha Uddin Sheikh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stricker%2C+D">Didier Stricker</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Afzal%2C+M+Z">Muhammad Zeshan Afzal</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 Pages, 4 Figures and Accepted in ICDAR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Zero-shot learning has been extensively investigated in the broader field of
                    visual recognition, attracting significant interest recently. However, the
                    current work on zero-shot learning in document image classification remains
                    scarce. The existing studies either focus exclusively on zero-shot inference,
                    or their evaluation does not align with the established criteria of zero-shot
                    evaluation in the visual recognition domain. We provide a comprehensive
                    document image classification analysis in Zero-Shot Learning (ZSL) and
                    Generalized Zero-Shot Learning (GZSL) settings to address this gap. Our
                    methodology and evaluation align with the established practices of this domain.
                    Additionally, we propose zero-shot splits for the RVL-CDIP dataset.
                    Furthermore, we introduce CICA (pronounced 'ki-ka'), a framework that enhances
                    the zero-shot learning capabilities of CLIP. CICA consists of a novel 'content
                    module' designed to leverage any generic document-related textual information.
                    The discriminative features extracted by this module are aligned with CLIP's
                    text and image features using a novel 'coupled-contrastive' loss. Our module
                    improves CLIP's ZSL top-1 accuracy by 6.7% and GZSL harmonic mean by 24% on the
                    RVL-CDIP dataset. Our module is lightweight and adds only 3.3% more parameters
                    to CLIP. Our work sets the direction for future research in zero-shot document
                    classification.
                </p>
            </div>
        </dd>
        <dt><a name="item664">[664]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03661"
                    title="Abstract">arXiv:2405.03661</a> [<a href="/pdf/2405.03661" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03661" title="Download PostScript">ps</a>, <a href="/format/2405.03661"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Competitive strategies to use "warm start" algorithms with
                    predictions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Srinivas%2C+V">Vaidehi Srinivas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Blum%2C+A">Avrim Blum</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">We consider the problem of learning and using predictions for warm start
                    algorithms with predictions. In this setting, an algorithm is given an instance
                    of a problem, and a prediction of the solution. The runtime of the algorithm is
                    bounded by the distance from the predicted solution to the true solution of the
                    instance. Previous work has shown that when instances are drawn iid from some
                    distribution, it is possible to learn an approximately optimal fixed prediction
                    (Dinitz et al, NeurIPS 2021), and in the adversarial online case, it is
                    possible to compete with the best fixed prediction in hindsight (Khodak et al,
                    NeurIPS 2022).
                    <br>In this work we give competitive guarantees against stronger benchmarks that
                    consider a set of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-311-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2068"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2069"><span class="mi" id="MathJax-Span-2070"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-311">k</script> predictions <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-312-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2071"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.392em, 1000.75em, 2.433em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2072"><span class="texatom"
                                                id="MathJax-Span-2073"><span class="mrow" id="MathJax-Span-2074"><span
                                                        class="mi" id="MathJax-Span-2075"
                                                        style="font-family: MathJax_Main-bold;">P</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-312">\mathbf{P}</script>. That is, the "optimal offline
                    cost" to solve an instance with respect to <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-313-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2076"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.392em, 1000.75em, 2.433em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2077"><span class="texatom"
                                                id="MathJax-Span-2078"><span class="mrow" id="MathJax-Span-2079"><span
                                                        class="mi" id="MathJax-Span-2080"
                                                        style="font-family: MathJax_Main-bold;">P</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-313">\mathbf{P}</script> is the distance from
                    the true solution to the closest member of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-314-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2081"
                                style="width: 0.987em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.813em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.392em, 1000.75em, 2.433em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2082"><span class="texatom"
                                                id="MathJax-Span-2083"><span class="mrow" id="MathJax-Span-2084"><span
                                                        class="mi" id="MathJax-Span-2085"
                                                        style="font-family: MathJax_Main-bold;">P</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-314">\mathbf{P}</script>. This is analogous to
                    the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-315-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2086"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2087"><span class="mi" id="MathJax-Span-2088"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-315">k</script>-medians objective function. In the
                    distributional setting, we show a
                    simple strategy that incurs cost that is at most an <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-316-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2089"
                                style="width: 2.549em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.97em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2090"><span class="mi" id="MathJax-Span-2091"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-2092" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-2093"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mo"
                                                id="MathJax-Span-2094"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-316">O(k)</script> factor worse than
                    the optimal offline cost. We then show a way to leverage learnable coarse
                    information, in the form of partitions of the instance space into groups of
                    "similar" instances, that allows us to potentially avoid this <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-317-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2095"
                                style="width: 2.549em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.086em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.97em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2096"><span class="mi" id="MathJax-Span-2097"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-2098" style="font-family: MathJax_Main;">(</span><span
                                                class="mi" id="MathJax-Span-2099"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mo"
                                                id="MathJax-Span-2100"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-317">O(k)</script> factor.
                    <br>Finally, we consider an online version of the problem, where we compete
                    against offline strategies that are allowed to maintain a moving set of <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-318-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2101"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2102"><span class="mi" id="MathJax-Span-2103"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-318">k</script>
                    predictions or "trajectories," and are charged for how much the predictions
                    move. We give an algorithm that does at most <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-319-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2104"
                                style="width: 5.558em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.633em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.16em, 1004.52em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2105"><span class="mi" id="MathJax-Span-2106"
                                                style="font-family: MathJax_Math-italic;">O</span><span class="mo"
                                                id="MathJax-Span-2107" style="font-family: MathJax_Main;">(</span><span
                                                class="msubsup" id="MathJax-Span-2108"><span
                                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.52em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2109"
                                                            style="font-family: MathJax_Math-italic;">k</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.524em;"><span
                                                            class="mn" id="MathJax-Span-2110"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">4</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="msubsup" id="MathJax-Span-2111"
                                                style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.81em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2112"
                                                            style="font-family: MathJax_Main;">ln</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.813em;"><span
                                                            class="mn" id="MathJax-Span-2113"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-2114"></span><span class="mi"
                                                id="MathJax-Span-2115"
                                                style="font-family: MathJax_Math-italic; padding-left: 0.177em;">k</span><span
                                                class="mo" id="MathJax-Span-2116"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.531em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-319">O(k^4 \ln^2 k)</script> times as much
                    work as any offline strategy of <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-320-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2117"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2118"><span class="mi" id="MathJax-Span-2119"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-320">k</script> trajectories. This algorithm is
                    deterministic (robust to an adaptive adversary), and oblivious to the setting
                    of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-321-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2120"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2121"><span class="mi" id="MathJax-Span-2122"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-321">k</script>. Thus the guarantee holds for all <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-322-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2123"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2124"><span class="mi" id="MathJax-Span-2125"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-322">k</script> simultaneously.
                </p>
            </div>
        </dd>
        <dt><a name="item665">[665]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03662"
                    title="Abstract">arXiv:2405.03662</a> [<a href="/pdf/2405.03662" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03662" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Diffeomorphic Template Registration for Atmospheric
                    Turbulence Mitigation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lao%2C+D">Dong Lao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Congli Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wong%2C+A">Alex Wong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Soatto%2C+S">Stefano Soatto</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">We describe a method for recovering the irradiance underlying a collection of
                    images corrupted by atmospheric turbulence. Since supervised data is often
                    technically impossible to obtain, assumptions and biases have to be imposed to
                    solve this inverse problem, and we choose to model them explicitly. Rather than
                    initializing a latent irradiance ("template") by heuristics to estimate
                    deformation, we select one of the images as a reference, and model the
                    deformation in this image by the aggregation of the optical flow from it to
                    other images, exploiting a prior imposed by Central Limit Theorem. Then with a
                    novel flow inversion module, the model registers each image TO the template but
                    WITHOUT the template, avoiding artifacts related to poor template
                    initialization. To illustrate the robustness of the method, we simply (i)
                    select the first frame as the reference and (ii) use the simplest optical flow
                    to estimate the warpings, yet the improvement in registration is decisive in
                    the final reconstruction, as we achieve state-of-the-art performance despite
                    its simplicity. The method establishes a strong baseline that can be further
                    improved by integrating it seamlessly into more sophisticated pipelines, or
                    with domain-specific methods if so desired.
                </p>
            </div>
        </dd>
        <dt><a name="item666">[666]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03664"
                    title="Abstract">arXiv:2405.03664</a> [<a href="/pdf/2405.03664" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03664" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A New Robust Partial <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-323-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2126"
                                style="width: 0.604em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.512em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.345em, 1000.51em, 2.271em, -999.998em); top: -1.942em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2127"><span class="mi" id="MathJax-Span-2128"
                                                style="font-family: MathJax_Math-italic;">p</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.947em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.275em; border-left: 0px solid; width: 0px; height: 0.892em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-323">p</script>-Wasserstein-Based Metric for Comparing
                    Distributions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Raghvendra%2C+S">Sharath Raghvendra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shirzadian%2C+P">Pouyan Shirzadian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+K">Kaiyi Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
                <p class="mathjax">The <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-324-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2129"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2130"><span class="mn" id="MathJax-Span-2131"
                                                style="font-family: MathJax_Main;">2</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-324">2</script>-Wasserstein distance is sensitive to
                    minor geometric differences
                    between distributions, making it a very powerful dissimilarity metric. However,
                    due to this sensitivity, a small outlier mass can also cause a significant
                    increase in the <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-325-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2132"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2133"><span class="mn" id="MathJax-Span-2134"
                                                style="font-family: MathJax_Main;">2</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-325">2</script>-Wasserstein distance between two similar
                    distributions.
                    Similarly, sampling discrepancy can cause the empirical <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-326-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2135"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2136"><span class="mn" id="MathJax-Span-2137"
                                                style="font-family: MathJax_Main;">2</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-326">2</script>-Wasserstein
                    distance on <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-327-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2138"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2139"><span class="mi" id="MathJax-Span-2140"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-327">n</script> samples in <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-328-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2141"
                                style="width: 1.392em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1001.16em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2142"><span class="msubsup"
                                                id="MathJax-Span-2143"><span
                                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.7em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-2144"><span class="mrow"
                                                                id="MathJax-Span-2145"><span class="mi"
                                                                    id="MathJax-Span-2146"
                                                                    style="font-family: MathJax_AMS;">R</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-2147"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-328">\mathbb{R}^2</script> to converge to the true
                    distance at a
                    rate of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-329-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2148"
                                style="width: 2.723em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1002.26em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2149"><span class="msubsup"
                                                id="MathJax-Span-2150"><span
                                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2151"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="texatom" id="MathJax-Span-2152"><span class="mrow"
                                                                id="MathJax-Span-2153"><span class="mo"
                                                                    id="MathJax-Span-2154"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-2155"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                    class="texatom" id="MathJax-Span-2156"><span
                                                                        class="mrow" id="MathJax-Span-2157"><span
                                                                            class="mo" id="MathJax-Span-2158"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="mn" id="MathJax-Span-2159"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">4</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-329">n^{-1/4}</script>, which is significantly slower
                    than the rate of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-330-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2160"
                                style="width: 2.723em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1002.26em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2161"><span class="msubsup"
                                                id="MathJax-Span-2162"><span
                                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2163"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="texatom" id="MathJax-Span-2164"><span class="mrow"
                                                                id="MathJax-Span-2165"><span class="mo"
                                                                    id="MathJax-Span-2166"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-2167"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                    class="texatom" id="MathJax-Span-2168"><span
                                                                        class="mrow" id="MathJax-Span-2169"><span
                                                                            class="mo" id="MathJax-Span-2170"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="mn" id="MathJax-Span-2171"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">2</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-330">n^{-1/2}</script>
                    for <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-331-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2172"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2173"><span class="mn" id="MathJax-Span-2174"
                                                style="font-family: MathJax_Main;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-331">1</script>-Wasserstein distance.
                    <br>We introduce a new family of distances parameterized by <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-332-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2175"
                                style="width: 2.896em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.376em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.32em, 2.433em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2176"><span class="mi" id="MathJax-Span-2177"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mo"
                                                id="MathJax-Span-2178"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≥</span><span
                                                class="mn" id="MathJax-Span-2179"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">0</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-332">k \ge 0</script>, called
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-333-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2180"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2181"><span class="mi" id="MathJax-Span-2182"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-333">k</script>-RPW, that is based on computing the
                    partial <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-334-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2183"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2184"><span class="mn" id="MathJax-Span-2185"
                                                style="font-family: MathJax_Main;">2</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-334">2</script>-Wasserstein distance. We
                    show that (1) <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-335-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2186"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2187"><span class="mi" id="MathJax-Span-2188"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-335">k</script>-RPW satisfies the metric properties, (2)
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-336-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2189"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2190"><span class="mi" id="MathJax-Span-2191"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-336">k</script>-RPW is robust to
                    small outlier mass while retaining the sensitivity of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-337-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2192"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2193"><span class="mn" id="MathJax-Span-2194"
                                                style="font-family: MathJax_Main;">2</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-337">2</script>-Wasserstein distance
                    to minor geometric differences, and (3) when <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-338-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2195"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2196"><span class="mi" id="MathJax-Span-2197"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-338">k</script> is a constant, <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-339-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2198"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2199"><span class="mi" id="MathJax-Span-2200"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-339">k</script>-RPW
                    distance between empirical distributions on <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-340-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2201"
                                style="width: 0.697em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.582em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.58em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2202"><span class="mi" id="MathJax-Span-2203"
                                                style="font-family: MathJax_Math-italic;">n</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-340">n</script> samples in <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-341-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2204"
                                style="width: 1.392em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1001.16em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2205"><span class="msubsup"
                                                id="MathJax-Span-2206"><span
                                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.7em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-2207"><span class="mrow"
                                                                id="MathJax-Span-2208"><span class="mi"
                                                                    id="MathJax-Span-2209"
                                                                    style="font-family: MathJax_AMS;">R</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.697em;"><span
                                                            class="mn" id="MathJax-Span-2210"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-341">\mathbb{R}^2</script>
                    converges to the true distance at a rate of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-342-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2211"
                                style="width: 2.723em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1002.26em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2212"><span class="msubsup"
                                                id="MathJax-Span-2213"><span
                                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2214"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="texatom" id="MathJax-Span-2215"><span class="mrow"
                                                                id="MathJax-Span-2216"><span class="mo"
                                                                    id="MathJax-Span-2217"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-2218"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                    class="texatom" id="MathJax-Span-2219"><span
                                                                        class="mrow" id="MathJax-Span-2220"><span
                                                                            class="mo" id="MathJax-Span-2221"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="mn" id="MathJax-Span-2222"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">3</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-342">n^{-1/3}</script>, which is faster than
                    the convergence rate of <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-343-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2223"
                                style="width: 2.723em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1002.26em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2224"><span class="msubsup"
                                                id="MathJax-Span-2225"><span
                                                    style="display: inline-block; position: relative; width: 2.26em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2226"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.582em;"><span
                                                            class="texatom" id="MathJax-Span-2227"><span class="mrow"
                                                                id="MathJax-Span-2228"><span class="mo"
                                                                    id="MathJax-Span-2229"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-2230"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                    class="texatom" id="MathJax-Span-2231"><span
                                                                        class="mrow" id="MathJax-Span-2232"><span
                                                                            class="mo" id="MathJax-Span-2233"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="mn" id="MathJax-Span-2234"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">4</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-343">n^{-1/4}</script> for the <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-344-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2235"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2236"><span class="mn" id="MathJax-Span-2237"
                                                style="font-family: MathJax_Main;">2</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-344">2</script>-Wasserstein distance.
                    <br>Using the partial <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-345-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2238"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.52em, 2.26em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2239"><span class="mi" id="MathJax-Span-2240"
                                                style="font-family: MathJax_Math-italic;">p</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-345">p</script>-Wasserstein distance, we extend our
                    distance to any <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-346-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2241"
                                style="width: 5.153em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.285em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.17em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2242"><span class="mi" id="MathJax-Span-2243"
                                                style="font-family: MathJax_Math-italic;">p</span><span class="mo"
                                                id="MathJax-Span-2244"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">∈</span><span
                                                class="mo" id="MathJax-Span-2245"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">[</span><span
                                                class="mn" id="MathJax-Span-2246"
                                                style="font-family: MathJax_Main;">1</span><span class="mo"
                                                id="MathJax-Span-2247" style="font-family: MathJax_Main;">,</span><span
                                                class="mi" id="MathJax-Span-2248"
                                                style="font-family: MathJax_Main; padding-left: 0.177em;">∞</span><span
                                                class="mo" id="MathJax-Span-2249"
                                                style="font-family: MathJax_Main;">]</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-346">p
    \in [1,\infty]</script>. By setting parameters <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-347-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2250"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2251"><span class="mi" id="MathJax-Span-2252"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-347">k</script> or <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-348-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2253"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.52em, 2.26em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2254"><span class="mi" id="MathJax-Span-2255"
                                                style="font-family: MathJax_Math-italic;">p</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-348">p</script> appropriately, we can reduce
                    our distance to the total variation, <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-349-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2256"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.52em, 2.26em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2257"><span class="mi" id="MathJax-Span-2258"
                                                style="font-family: MathJax_Math-italic;">p</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-349">p</script>-Wasserstein, and the L\'evy-Prokhorov
                    distances. Experiments show that our distance function achieves higher accuracy
                    in comparison to the <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-350-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2259"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2260"><span class="mn" id="MathJax-Span-2261"
                                                style="font-family: MathJax_Main;">1</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-350">1</script>-Wasserstein, <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-351-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2262"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2263"><span class="mn" id="MathJax-Span-2264"
                                                style="font-family: MathJax_Main;">2</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-351">2</script>-Wasserstein, and TV distances for
                    image retrieval tasks on noisy real-world data sets.
                </p>
            </div>
        </dd>
        <dt><a name="item667">[667]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03666"
                    title="Abstract">arXiv:2405.03666</a> [<a href="/pdf/2405.03666" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03666" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ScrewMimic: Bimanual Imitation from Human Videos with Screw
                    Space Projection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bahety%2C+A">Arpit Bahety</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mandikal%2C+P">Priyanka Mandikal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abbatematteo%2C+B">Ben Abbatematteo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mart%C3%ADn-Mart%C3%ADn%2C+R">Roberto
                        Martín-Martín</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Bimanual manipulation is a longstanding challenge in robotics due to the
                    large number of degrees of freedom and the strict spatial and temporal
                    synchronization required to generate meaningful behavior. Humans learn bimanual
                    manipulation skills by watching other humans and by refining their abilities
                    through play. In this work, we aim to enable robots to learn bimanual
                    manipulation behaviors from human video demonstrations and fine-tune them
                    through interaction. Inspired by seminal work in psychology and biomechanics,
                    we propose modeling the interaction between two hands as a serial kinematic
                    linkage -- as a screw motion, in particular, that we use to define a new action
                    space for bimanual manipulation: screw actions. We introduce ScrewMimic, a
                    framework that leverages this novel action representation to facilitate
                    learning from human demonstration and self-supervised policy fine-tuning. Our
                    experiments demonstrate that ScrewMimic is able to learn several complex
                    bimanual behaviors from a single human video demonstration, and that it
                    outperforms baselines that interpret demonstrations and fine-tune directly in
                    the original space of motion of both arms. For more information and video
                    results, https://robin-lab.cs.utexas.edu/ScrewMimic/
                </p>
            </div>
        </dd>
        <dt><a name="item668">[668]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03669"
                    title="Abstract">arXiv:2405.03669</a> [<a href="/pdf/2405.03669" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03669" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> IMELL Cut Elimination with Linear Overhead
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Accattoli%2C+B">Beniamino Accattoli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Coen%2C+C+S">Claudio Sacerdoti Coen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Version with proofs of the FSCD 2024 paper with the same
                    title
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>

                </div>
                <p class="mathjax">Recently, Accattoli introduced the Exponential Substitution Calculus (ESC)
                    given by untyped proof terms for Intuitionistic Multiplicative Exponential
                    Linear Logic (IMELL), endowed with rewriting rules at-a-distance for cut
                    elimination. He also introduced a new cut elimination strategy, dubbed the good
                    strategy, and showed that its number of steps is a time cost model with
                    polynomial overhead for the ESC/IMELL, and the first such one.
                    <br>Here, we refine Accattoli's result by introducing an abstract machine for ESC
                    and proving that it implements the good strategy and computes cut-free
                    terms/proofs within a linear overhead.
                </p>
            </div>
        </dd>
        <dt><a name="item669">[669]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03671"
                    title="Abstract">arXiv:2405.03671</a> [<a href="/pdf/2405.03671" title="Download PDF">pdf</a>, <a
                    href="/ps/2405.03671" title="Download PostScript">ps</a>, <a href="/format/2405.03671"
                    title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Prompting Task Trees using Gemini: Methodologies and Insights
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tandra%2C+P">Pallavi Tandra</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">Robots are the future of every technology where every advanced technology
                    eventually will be used to make robots which are more efficient. The major
                    challenge today is to train the robots exactly and empathetically using
                    knowledge representation. This paper gives you insights of how we can use
                    unstructured knowledge representation and convert them to meaningful structured
                    representation with the help of prompt engineering which can be eventually used
                    in the robots to make help them understand how human brain can make wonders
                    with the minimal data or objects can providing to them.
                </p>
            </div>
        </dd>
        <dt><a name="item670">[670]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03672"
                    title="Abstract">arXiv:2405.03672</a> [<a href="/pdf/2405.03672" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03672" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Cutting through buggy adversarial example defenses: fixing 1
                    line of code breaks Sabre
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Carlini%2C+N">Nicholas Carlini</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Sabre is a defense to adversarial examples that was accepted at IEEE S&amp;P
                    2024. We first reveal significant flaws in the evaluation that point to clear
                    signs of gradient masking. We then show the cause of this gradient masking: a
                    bug in the original evaluation code. By fixing a single line of code in the
                    original repository, we reduce Sabre's robust accuracy to 0%. In response to
                    this, the authors modify the defense and introduce a new defense component not
                    described in the original paper. But this fix contains a second bug; modifying
                    one more line of code reduces robust accuracy to below baseline levels.
                </p>
            </div>
        </dd>
        <dt><a name="item671">[671]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03673"
                    title="Abstract">arXiv:2405.03673</a> [<a href="/pdf/2405.03673" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03673" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MemoryMamba: Memory-Augmented State Space Model for Defect
                    Recognition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qianning Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">He Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yucheng Zhou</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 7 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">As automation advances in manufacturing, the demand for precise and
                    sophisticated defect detection technologies grows. Existing vision models for
                    defect recognition methods are insufficient for handling the complexities and
                    variations of defects in contemporary manufacturing settings. These models
                    especially struggle in scenarios involving limited or imbalanced defect data.
                    In this work, we introduce MemoryMamba, a novel memory-augmented state space
                    model (SSM), designed to overcome the limitations of existing defect
                    recognition models. MemoryMamba integrates the state space model with the
                    memory augmentation mechanism, enabling the system to maintain and retrieve
                    essential defect-specific information in training. Its architecture is designed
                    to capture dependencies and intricate defect characteristics, which are crucial
                    for effective defect detection. In the experiments, MemoryMamba was evaluated
                    across four industrial datasets with diverse defect types and complexities. The
                    model consistently outperformed other methods, demonstrating its capability to
                    adapt to various defect recognition scenarios.
                </p>
            </div>
        </dd>
        <dt><a name="item672">[672]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03674"
                    title="Abstract">arXiv:2405.03674</a> [<a href="/pdf/2405.03674" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03674" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Anti-Heroes: An Ethics-focused Method for Responsible
                    Designer Intentions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mehta%2C+S">Shikha Mehta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chivukula%2C+S+S">Shruthi Sai Chivukula</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gray%2C+C+M">Colin M. Gray</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gairola%2C+R">Ritika Gairola</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
                <p class="mathjax">HCI and design researchers have designed, adopted, and customized a range of
                    ethics-focused methods to inscribe values and support ethical decision making
                    in a design process. In this work-in-progress, we add to this body of
                    resources, constructing a method that surfaces the designer's intentions in an
                    action-focused way, encouraging consideration of both manipulative and
                    value-centered roles. Anti-Heroes is a card deck that allows a designer to
                    playfully take on pairs of manipulative (Anti-Hero) and value-centered (Hero)
                    roles during design ideation/conceptualization, evaluation, and ethical
                    dialogue. The card deck includes twelve cards with Anti-Hero and Hero faces,
                    along with three action cards that include reflective questions for different
                    play modes. Alongside the creation of the Anti-Hero card deck, we describe the
                    evaluation and iteration of the card deck through playtesting sessions with
                    four groups of three design students. We propose implications of Anti-Heros for
                    technology and design education and practice.
                </p>
            </div>
        </dd>
        <dt><a name="item673">[673]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03676"
                    title="Abstract">arXiv:2405.03676</a> [<a href="/pdf/2405.03676" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03676" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Why is SAM Robust to Label Noise?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Baek%2C+C">Christina Baek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kolter%2C+Z">Zico Kolter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Raghunathan%2C+A">Aditi Raghunathan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
                <p class="mathjax">Sharpness-Aware Minimization (SAM) is most known for achieving state-of
                    the-art performances on natural image and language tasks. However, its most
                    pronounced improvements (of tens of percent) is rather in the presence of label
                    noise. Understanding SAM's label noise robustness requires a departure from
                    characterizing the robustness of minimas lying in "flatter" regions of the loss
                    landscape. In particular, the peak performance under label noise occurs with
                    early stopping, far before the loss converges. We decompose SAM's robustness
                    into two effects: one induced by changes to the logit term and the other
                    induced by changes to the network Jacobian. The first can be observed in linear
                    logistic regression where SAM provably up-weights the gradient contribution
                    from clean examples. Although this explicit up-weighting is also observable in
                    neural networks, when we intervene and modify SAM to remove this effect,
                    surprisingly, we see no visible degradation in performance. We infer that SAM's
                    effect in deeper networks is instead explained entirely by the effect SAM has
                    on the network Jacobian. We theoretically derive the implicit regularization
                    induced by this Jacobian effect in two layer linear networks. Motivated by our
                    analysis, we see that cheaper alternatives to SAM that explicitly induce these
                    regularization effects largely recover the benefits in deep networks trained on
                    real-world datasets.
                </p>
            </div>
        </dd>
        <dt><a name="item674">[674]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03677"
                    title="Abstract">arXiv:2405.03677</a> [<a href="/pdf/2405.03677" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03677" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards A Human-in-the-Loop LLM Approach to Collaborative
                    Discourse Analysis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cohn%2C+C">Clayton Cohn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Snyder%2C+C">Caitlin Snyder</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Montenegro%2C+J">Justin Montenegro</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Biswas%2C+G">Gautam Biswas</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> In press at the 25th international conference on
                    Artificial Intelligence in Education (AIED) Late-Breaking Results (LBR) track
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
                <p class="mathjax">LLMs have demonstrated proficiency in contextualizing their outputs using
                    human input, often matching or beating human-level performance on a variety of
                    tasks. However, LLMs have not yet been used to characterize synergistic
                    learning in students' collaborative discourse. In this exploratory work, we
                    take a first step towards adopting a human-in-the-loop prompt engineering
                    approach with GPT-4-Turbo to summarize and categorize students' synergistic
                    learning during collaborative discourse. Our preliminary findings suggest
                    GPT-4-Turbo may be able to characterize students' synergistic learning in a
                    manner comparable to humans and that our approach warrants further
                    investigation.
                </p>
            </div>
        </dd>
        <dt><a name="item675">[675]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03682"
                    title="Abstract">arXiv:2405.03682</a> [<a href="/pdf/2405.03682" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03682" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Empty Room is All We Want: Automatic Defurnishing of
                    Indoor Panoramas
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Slavcheva%2C+M">Mira Slavcheva</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gausebeck%2C+D">Dave Gausebeck</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K">Kevin Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Buchhofer%2C+D">David Buchhofer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sabik%2C+A">Azwad Sabik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+C">Chen Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dhillon%2C+S">Sachal Dhillon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brandt%2C+O">Olaf Brandt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dolhasz%2C+A">Alan Dolhasz</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at CVPR 2024 workshops. Project page: <a
                        href="https://matterport.github.io/automatic-defurnishing-of-indoor-panoramas/">this https
                        URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">We propose a pipeline that leverages Stable Diffusion to improve inpainting
                    results in the context of defurnishing -- the removal of furniture items from
                    indoor panorama images. Specifically, we illustrate how increased context,
                    domain-specific model fine-tuning, and improved image blending can produce
                    high-fidelity inpaints that are geometrically plausible without needing to rely
                    on room layout estimation. We demonstrate qualitative and quantitative
                    improvements over other furniture removal techniques.
                </p>
            </div>
        </dd>
        <dt><a name="item676">[676]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03685"
                    title="Abstract">arXiv:2405.03685</a> [<a href="/pdf/2405.03685" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03685" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Language-Image Models with 3D Understanding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cho%2C+J+H">Jang Hyun Cho</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ivanovic%2C+B">Boris Ivanovic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+Y">Yulong Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schmerling%2C+E">Edward Schmerling</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yue Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Weng%2C+X">Xinshuo Weng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Boyi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=You%2C+Y">Yurong You</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kr%C3%A4henb%C3%BChl%2C+P">Philipp Krähenbühl</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pavone%2C+M">Marco Pavone</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Project page: <a
                        href="https://janghyuncho.github.io/Cube-LLM">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL);
                    Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Multi-modal large language models (MLLMs) have shown incredible capabilities
                    in a variety of 2D vision and language tasks. We extend MLLMs' perceptual
                    capabilities to ground and reason about images in 3-dimensional space. To that
                    end, we first develop a large-scale pre-training dataset for 2D and 3D called
                    LV3D by combining multiple existing 2D and 3D recognition datasets under a
                    common task formulation: as multi-turn question-answering. Next, we introduce a
                    new MLLM named Cube-LLM and pre-train it on LV3D. We show that pure data
                    scaling makes a strong 3D perception capability without 3D specific
                    architectural design or training objective. Cube-LLM exhibits intriguing
                    properties similar to LLMs: (1) Cube-LLM can apply chain-of-thought prompting
                    to improve 3D understanding from 2D context information. (2) Cube-LLM can
                    follow complex and diverse instructions and adapt to versatile input and output
                    formats. (3) Cube-LLM can be visually prompted such as 2D box or a set of
                    candidate 3D boxes from specialists. Our experiments on outdoor benchmarks
                    demonstrate that Cube-LLM significantly outperforms existing baselines by 21.3
                    points of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7
                    points on the DriveLM dataset for complex reasoning about driving scenarios,
                    respectively. Cube-LLM also shows competitive results in general MLLM
                    benchmarks such as refCOCO for 2D grounding with (87.0) average score, as well
                    as visual question answering benchmarks such as VQAv2, GQA, SQA, POPE, etc. for
                    complex reasoning. Our project is available at
                    https://janghyuncho.github.io/Cube-LLM.
                </p>
            </div>
        </dd>
        <dt><a name="item677">[677]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03687"
                    title="Abstract">arXiv:2405.03687</a> [<a href="/pdf/2405.03687" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03687" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Monotone Randomized Apportionment
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Correa%2C+J">José Correa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=G%C3%B6lz%2C+P">Paul Gölz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schmidt-Kraepelin%2C+U">Ulrike
                        Schmidt-Kraepelin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tucker-Foltz%2C+J">Jamie Tucker-Foltz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Verdugo%2C+V">Victor Verdugo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

                </div>
                <p class="mathjax">Apportionment is the act of distributing the seats of a legislature among
                    political parties (or states) in proportion to their vote shares (or
                    populations). A famous impossibility by Balinski and Young (2001) shows that no
                    apportionment method can be proportional up to one seat (quota) while also
                    responding monotonically to changes in the votes (population monotonicity).
                    Grimmett (2004) proposed to overcome this impossibility by randomizing the
                    apportionment, which can achieve quota as well as perfect proportionality and
                    monotonicity -- at least in terms of the expected number of seats awarded to
                    each party. Still, the correlations between the seats awarded to different
                    parties may exhibit bizarre non-monotonicities. When parties or voters care
                    about joint events, such as whether a coalition of parties reaches a majority,
                    these non-monotonicities can cause paradoxes, including incentives for
                    strategic voting.
                    <br>In this paper, we propose monotonicity axioms ruling out these paradoxes, and
                    study which of them can be satisfied jointly with Grimmett's axioms.
                    Essentially, we require that, if a set of parties all receive more votes, the
                    probability of those parties jointly receiving more seats should increase. Our
                    work draws on a rich literature on unequal probability sampling in statistics
                    (studied as dependent randomized rounding in computer science). Our main result
                    shows that a sampling scheme due to Sampford (1967) satisfies Grimmett's axioms
                    and a notion of higher-order correlation monotonicity.
                </p>
            </div>
        </dd>
        <dt><a name="item678">[678]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03688"
                    title="Abstract">arXiv:2405.03688</a> [<a href="/pdf/2405.03688" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03688" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Large Language Models Reveal Information Operation Goals,
                    Tactics, and Narrative Frames
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Burghardt%2C+K">Keith Burghardt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K">Kai Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lerman%2C+K">Kristina Lerman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Adversarial information operations can destabilize societies by undermining
                    fair elections, manipulating public opinions on policies, and promoting scams.
                    Despite their widespread occurrence and potential impacts, our understanding of
                    influence campaigns is limited by manual analysis of messages and subjective
                    interpretation of their observable behavior. In this paper, we explore whether
                    these limitations can be mitigated with large language models (LLMs), using
                    GPT-3.5 as a case-study for coordinated campaign annotation. We first use
                    GPT-3.5 to scrutinize 126 identified information operations spanning over a
                    decade. We utilize a number of metrics to quantify the close (if imperfect)
                    agreement between LLM and ground truth descriptions. We next extract
                    coordinated campaigns from two large multilingual datasets from X (formerly
                    Twitter) that respectively discuss the 2022 French election and 2023 Balikaran
                    Philippine-U.S. military exercise in 2023. For each coordinated campaign, we
                    use GPT-3.5 to analyze posts related to a specific concern and extract goals,
                    tactics, and narrative frames, both before and after critical events (such as
                    the date of an election). While the GPT-3.5 sometimes disagrees with subjective
                    interpretation, its ability to summarize and interpret demonstrates LLMs'
                    potential to extract higher-order indicators from text to provide a more
                    complete picture of the information campaigns compared to previous methods.
                </p>
            </div>
        </dd>
        <dt><a name="item679">[679]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03689"
                    title="Abstract">arXiv:2405.03689</a> [<a href="/pdf/2405.03689" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03689" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Pose Priors from Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Subramanian%2C+S">Sanjay Subramanian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ng%2C+E">Evonne Ng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=M%C3%BCller%2C+L">Lea Müller</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Klein%2C+D">Dan Klein</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ginosar%2C+S">Shiry Ginosar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Darrell%2C+T">Trevor Darrell</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL)

                </div>
                <p class="mathjax">We present a zero-shot pose optimization method that enforces accurate
                    physical contact constraints when estimating the 3D pose of humans. Our central
                    insight is that since language is often used to describe physical interaction,
                    large pretrained text-based models can act as priors on pose estimation.
                    <br>We can thus leverage this insight to improve pose estimation by converting
                    natural language descriptors, generated by a large multimodal model (LMM), into
                    tractable losses to constrain the 3D pose optimization. Despite its simplicity,
                    our method produces surprisingly compelling pose reconstructions of people in
                    close contact, correctly capturing the semantics of the social and physical
                    interactions. We demonstrate that our method rivals more complex
                    state-of-the-art approaches that require expensive human annotation of contact
                    points and training specialized models. Moreover, unlike previous approaches,
                    our method provides a unified framework for resolving self-contact and
                    person-to-person contact.
                </p>
            </div>
        </dd>
        <dt><a name="item680">[680]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03690"
                    title="Abstract">arXiv:2405.03690</a> [<a href="/pdf/2405.03690" title="Download PDF">pdf</a>, <a
                    href="/format/2405.03690" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Complex Video Reasoning and Robustness Evaluation Suite for
                    Video-LMMs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Khattak%2C+M+U">Muhammad Uzair Khattak</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Naeem%2C+M+F">Muhammad Ferjad Naeem</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hassan%2C+J">Jameel Hassan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Naseer%2C+M">Muzammal Naseer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tombari%2C+F">Federico Tombari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+F+S">Fahad Shahbaz Khan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+S">Salman Khan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Technical report
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
                <p class="mathjax">Recent advancements in Large Language Models (LLMs) have led to the
                    development of Video Large Multi-modal Models (Video-LMMs) that can handle a
                    wide range of video understanding tasks. These models have the potential to be
                    deployed in real-world applications such as robotics, AI assistants, medical
                    imaging, and autonomous vehicles. The widespread adoption of Video-LMMs in our
                    daily lives underscores the importance of ensuring and evaluating their robust
                    performance in mirroring human-like reasoning and interaction capabilities in
                    complex, real-world contexts. However, existing benchmarks for Video-LMMs
                    primarily focus on general video comprehension abilities and neglect assessing
                    their reasoning capabilities over complex videos in the real-world context, and
                    robustness of these models through the lens of user prompts as text queries. In
                    this paper, we present the Complex Video Reasoning and Robustness Evaluation
                    Suite (CVRR-ES), a novel benchmark that comprehensively assesses the
                    performance of Video-LMMs across 11 diverse real-world video dimensions. We
                    evaluate 9 recent models, including both open-source and closed-source
                    variants, and find that most of the Video-LMMs, {especially open-source ones,}
                    struggle with robustness and reasoning when dealing with complex videos. Based
                    on our analysis, we develop a training-free Dual-Step Contextual Prompting
                    (DSCP) technique to enhance the performance of existing Video-LMMs. Our
                    findings provide valuable insights for building the next generation of
                    human-centric AI systems with advanced robustness and reasoning capabilities.
                    Our dataset and code are publicly available at:
                    https://mbzuai-oryx.github.io/CVRR-Evaluation-Suite/.
                </p>
            </div>
        </dd>
    </dl>
    <h3>Cross-lists for Tue, 7 May 24</h3>
    <dl>
        <dt><a name="item681">[681]</a>&nbsp; <span class="list-identifier"><a href="/abs/2003.05708"
                    title="Abstract">arXiv:2003.05708</a> (cross-list from q-fin.CP) [<a href="/pdf/2003.05708"
                    title="Download PDF">pdf</a>, <a href="/ps/2003.05708" title="Download PostScript">ps</a>, <a
                    href="/format/2003.05708" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multilevel Monte Carlo with Numerical Smoothing for Robust
                    and Efficient Computation of Probabilities and Densities
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/q-fin?searchtype=author&amp;query=Bayer%2C+C">Christian Bayer</a>,
                    <a href="/search/q-fin?searchtype=author&amp;query=Hammouda%2C+C+B">Chiheb Ben Hammouda</a>,
                    <a href="/search/q-fin?searchtype=author&amp;query=Tempone%2C+R">Raul Tempone</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance
                        (q-fin.CP)</span>; Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">The multilevel Monte Carlo (MLMC) method is highly efficient for estimating
                    expectations of a functional of a solution to a stochastic differential
                    equation (SDE). However, MLMC estimators may be unstable and have a poor
                    (noncanonical) complexity in the case of low regularity of the functional. To
                    overcome this issue, we extend our previously introduced idea of numerical
                    smoothing in (Quantitative Finance, 23(2), 209-227, 2023), in the context of
                    deterministic quadrature methods to the MLMC setting. The numerical smoothing
                    technique is based on root-finding methods combined with one-dimensional
                    numerical integration with respect to a single well-chosen variable. This study
                    is motivated by the computation of probabilities of events, pricing options
                    with a discontinuous payoff, and density estimation problems for dynamics where
                    the discretization of the underlying stochastic processes is necessary. The
                    analysis and numerical experiments reveal that the numerical smoothing
                    significantly improves the strong convergence, and consequently, the complexity
                    and robustness (by making the kurtosis at deep levels bounded) of the MLMC
                    method. In particular, we show that numerical smoothing enables recovering the
                    MLMC complexities obtained for Lipschitz functionals due to the optimal
                    variance decay rate when using the Euler--Maruyama scheme. For the Milstein
                    scheme, numerical smoothing recovers the canonical MLMC complexity even for the
                    nonsmooth integrand mentioned above. Finally, our approach efficiently
                    estimates univariate and multivariate density functions.
                </p>
            </div>
        </dd>
        <dt><a name="item682">[682]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02339"
                    title="Abstract">arXiv:2405.02339</a> (cross-list from astro-ph.IM) [<a href="/pdf/2405.02339"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.02339" title="Download PostScript">ps</a>, <a
                    href="/format/2405.02339" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Noise Models in the LISA Mission
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/astro-ph?searchtype=author&amp;query=Pagone%2C+M">Michele Pagone</a>,
                    <a href="/search/astro-ph?searchtype=author&amp;query=Novara%2C+C">Carlo Novara</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods
                        for Astrophysics (astro-ph.IM)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">This document briefly describes the noise models and shapes used for the
                    synthesis of the Drag-Free and Attitude Control System in the LISA space
                    mission. LISA (Laser Interferometer Space Antenna) is one of the next
                    large-class missions from the European Space Agency (ESA), expected to be
                    launched in 2034. The main goal of the mission is to detect the gravitational
                    waves, which are undulatory perturbations of the space-time fabric, extremely
                    important to collect experimental proofs for the General Relativity Theory. In
                    the 90s, different international collaborations of institutes laid the
                    foundations for the first ground-based interferometers (see, e.g., LIGO and
                    Virgo). However, ground-based interferometers have a limited bandwidth due to
                    the Earth's environmental noises and short arm-length of few kilometers.
                    Therefore, they cannot observe gravitational waves belonging to the portion of
                    the spectrum below 1 Hz. This issue can be overcome by means of space-based
                    interferometers, that can have arm-lengths up to millions of kilometers and
                    exploit a quieter environment than the Earth's surface. The LISA system is
                    affected by actuation, sensing and environmental disturbances and noises. Among
                    the actuation noises we have those given by the Micro Propulsion System (MPS),
                    the Gravitational Reference Sensor (GRS) and the Optical Assembly (OA) motor.
                    Among the sensing noises we consider the interferometer, the Differential
                    Wavefront Sensor (DWS) and the GRS. The environmental disturbances are given by
                    the solar radiation pressure, the test-mass stiffness and self-gravity, and the
                    environmental noises acting directly on the test-mass.
                </p>
            </div>
        </dd>
        <dt><a name="item683">[683]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02340"
                    title="Abstract">arXiv:2405.02340</a> (cross-list from stat.AP) [<a href="/pdf/2405.02340"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02340" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Comprehensive Approach to Carbon Dioxide Emission Analysis
                    in High Human Development Index Countries using Statistical and Machine Learning Techniques
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Khosravi%2C+H">Hamed Khosravi</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Raihan%2C+A+S">Ahmed Shoyeb Raihan</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Islam%2C+F">Farzana Islam</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Nimbarte%2C+A">Ashish Nimbarte</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Ahmed%2C+I">Imtiaz Ahmed</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Applications
                        (stat.AP)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Reducing Carbon dioxide (CO2) emission is vital at both global and national
                    levels, given their significant role in exacerbating climate change. CO2
                    emission, stemming from a variety of industrial and economic activities, are
                    major contributors to the greenhouse effect and global warming, posing
                    substantial obstacles in addressing climate issues. It's imperative to forecast
                    CO2 emission trends and classify countries based on their emission patterns to
                    effectively mitigate worldwide carbon emission. This paper presents an in-depth
                    comparative study on the determinants of CO2 emission in twenty countries with
                    high Human Development Index (HDI), exploring factors related to economy,
                    environment, energy use, and renewable resources over a span of 25 years. The
                    study unfolds in two distinct phases: initially, statistical techniques such as
                    Ordinary Least Squares (OLS), fixed effects, and random effects models are
                    applied to pinpoint significant determinants of CO2 emission. Following this,
                    the study leverages supervised and unsupervised machine learning (ML) methods
                    to further scrutinize and understand the factors influencing CO2 emission.
                    Seasonal AutoRegressive Integrated Moving Average with eXogenous variables
                    (SARIMAX), a supervised ML model, is first used to predict emission trends from
                    historical data, offering practical insights for policy formulation.
                    Subsequently, Dynamic Time Warping (DTW), an unsupervised learning approach, is
                    used to group countries by similar emission patterns. The dual-phase approach
                    utilized in this study significantly improves the accuracy of CO2 emission
                    predictions while also providing a deeper insight into global emission trends.
                    By adopting this thorough analytical framework, nations can develop more
                    focused and effective carbon reduction policies, playing a vital role in the
                    global initiative to combat climate change.
                </p>
            </div>
        </dd>
        <dt><a name="item684">[684]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02366"
                    title="Abstract">arXiv:2405.02366</a> (cross-list from astro-ph.IM) [<a href="/pdf/2405.02366"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02366" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bayesian and Convolutional Networks for Hierarchical
                    Morphological Classification of Galaxies
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/astro-ph?searchtype=author&amp;query=Serrano-P%C3%A9rez%2C+J">Jonathan
                        Serrano-Pérez</a>,
                    <a href="/search/astro-ph?searchtype=author&amp;query=Hern%C3%A1ndez%2C+R+D">Raquel Díaz
                        Hernández</a>,
                    <a href="/search/astro-ph?searchtype=author&amp;query=Sucar%2C+L+E">L. Enrique Sucar</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods
                        for Astrophysics (astro-ph.IM)</span>; Astrophysics of Galaxies (astro-ph.GA); Machine Learning
                    (cs.LG)

                </div>
                <p class="mathjax">This work is focused on the morphological classification of galaxies
                    following the Hubble sequence in which the different classes are arranged in a
                    hierarchy. The proposed method, BCNN, is composed of two main modules. First, a
                    convolutional neural network (CNN) is trained with images of the different
                    classes of galaxies (image augmentation is carried out to balance some
                    classes); the CNN outputs the probability for each class of the hierarchy, and
                    its outputs/predictions feed the second module. The second module consists of a
                    Bayesian network that represents the hierarchy and helps to improve the
                    prediction accuracy by combining the predictions of the first phase while
                    maintaining the hierarchical constraint (in a hierarchy, an instance associated
                    with a node must be associated to all its ancestors), through probabilistic
                    inference over the Bayesian network so that a consistent prediction is
                    obtained. Different images from the Hubble telescope have been collected and
                    labeled by experts, which are used to perform the experiments. The results show
                    that BCNN performed better than several CNNs in multiple evaluation measures,
                    reaching the next scores: 67% in exact match, 78% in accuracy, and 83% in
                    hierarchical F-measure.
                </p>
            </div>
        </dd>
        <dt><a name="item685">[685]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02372"
                    title="Abstract">arXiv:2405.02372</a> (cross-list from stat.ML) [<a href="/pdf/2405.02372"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.02372" title="Download PostScript">ps</a>, <a
                    href="/format/2405.02372" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Triadic-OCD: Asynchronous Online Change Detection with
                    Provable Robustness, Optimality, and Convergence
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Huang%2C+Y">Yancheng Huang</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Yang%2C+K">Kai Yang</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Zhu%2C+Z">Zelin Zhu</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Chen%2C+L">Leian Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at ICML2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">The primary goal of online change detection (OCD) is to promptly identify
                    changes in the data stream. OCD problem find a wide variety of applications in
                    diverse areas, e.g., security detection in smart grids and intrusion detection
                    in communication networks. Prior research usually assumes precise knowledge of
                    the parameters linked to the data stream. Nevertheless, this presumption often
                    proves unattainable in practical scenarios due to factors such as estimation
                    errors, system updates, etc. This paper aims to take the first attempt to
                    develop a triadic-OCD framework with certifiable robustness, provable
                    optimality, and guaranteed convergence. In addition, the proposed triadic-OCD
                    algorithm can be realized in a fully asynchronous distributed manner, easing
                    the necessity of transmitting the data to a single server. This asynchronous
                    mechanism also could mitigate the straggler issue that faced by traditional
                    synchronous algorithm. We then analyze the non-asymptotic convergence property
                    of triadic-OCD and derive its iteration complexity to achieve an
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-352-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2265"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.41em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2266"><span class="mi" id="MathJax-Span-2267"
                                                style="font-family: MathJax_Math-italic;">ϵ</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-352">\epsilon</script>-optimal point. Finally, extensive
                    experiments have been conducted to
                    elucidate the effectiveness of the proposed method.
                </p>
            </div>
        </dd>
        <dt><a name="item686">[686]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02373"
                    title="Abstract">arXiv:2405.02373</a> (cross-list from math.OC) [<a href="/pdf/2405.02373"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02373" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exponentially Weighted Algorithm for Online Network Resource
                    Allocation with Long-Term Constraints
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Sid-Ali%2C+A">Ahmed Sid-Ali</a>,
                    <a href="/search/math?searchtype=author&amp;query=Lambadaris%2C+I">Ioannis Lambadaris</a>,
                    <a href="/search/math?searchtype=author&amp;query=Zhao%2C+Y+Q">Yiqiang Q. Zhao</a>,
                    <a href="/search/math?searchtype=author&amp;query=Shaikhet%2C+G">Gennady Shaikhet</a>,
                    <a href="/search/math?searchtype=author&amp;query=Asgharnia%2C+A">Amirhossein Asgharnia</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a
                        href="/abs/2305.15558">arXiv:2305.15558</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

                </div>
                <p class="mathjax">This paper studies an online optimal resource reservation problem in
                    communication networks with job transfers where the goal is to minimize the
                    reservation cost while maintaining the blocking cost under a certain budget
                    limit. To tackle this problem, we propose a novel algorithm based on a
                    randomized exponentially weighted method that encompasses long-term
                    constraints. We then analyze the performance of our algorithm by establishing
                    an upper bound for the associated regret and the cumulative constraint
                    violations. Finally, we present numerical experiments where we compare the
                    performance of our algorithm with those of reinforcement learning where we show
                    that our algorithm surpasses it.
                </p>
            </div>
        </dd>
        <dt><a name="item687">[687]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02374"
                    title="Abstract">arXiv:2405.02374</a> (cross-list from q-bio.QM) [<a href="/pdf/2405.02374"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02374" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Protein binding affinity prediction under multiple
                    substitutions applying eGNNs on Residue and Atomic graphs combined with Language model information:
                    eGRAL
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/q-bio?searchtype=author&amp;query=Fiorellini-Bernardis%2C+A">Arturo
                        Fiorellini-Bernardis</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Boyer%2C+S">Sebastien Boyer</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Brunken%2C+C">Christoph Brunken</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Diallo%2C+B">Bakary Diallo</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Beguir%2C+K">Karim Beguir</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Lopez-Carranza%2C+N">Nicolas Lopez-Carranza</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Bent%2C+O">Oliver Bent</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods
                        (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Protein-protein interactions (PPIs) play a crucial role in numerous
                    biological processes. Developing methods that predict binding affinity changes
                    under substitution mutations is fundamental for modelling and re-engineering
                    biological systems. Deep learning is increasingly recognized as a powerful tool
                    capable of bridging the gap between in-silico predictions and in-vitro
                    observations. With this contribution, we propose eGRAL, a novel SE(3)
                    equivariant graph neural network (eGNN) architecture designed for predicting
                    binding affinity changes from multiple amino acid substitutions in protein
                    complexes. eGRAL leverages residue, atomic and evolutionary scales, thanks to
                    features extracted from protein large language models. To address the limited
                    availability of large-scale affinity assays with structural information, we
                    generate a simulated dataset comprising approximately 500,000 data points. Our
                    model is pre-trained on this dataset, then fine-tuned and tested on
                    experimental data.
                </p>
            </div>
        </dd>
        <dt><a name="item688">[688]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02383"
                    title="Abstract">arXiv:2405.02383</a> (cross-list from stat.ML) [<a href="/pdf/2405.02383"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02383" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Fresh Look at Sanity Checks for Saliency Maps
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Hedstr%C3%B6m%2C+A">Anna Hedström</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Weber%2C+L">Leander Weber</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>,
                    <a href="/search/stat?searchtype=author&amp;query=H%C3%B6hne%2C+M">Marina Höhne</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a
                        href="/abs/2401.06465">arXiv:2401.06465</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition
                    (cs.CV); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">The Model Parameter Randomisation Test (MPRT) is highly recognised in the
                    eXplainable Artificial Intelligence (XAI) community due to its fundamental
                    evaluative criterion: explanations should be sensitive to the parameters of the
                    model they seek to explain. However, recent studies have raised several
                    methodological concerns for the empirical interpretation of MPRT. In response,
                    we propose two modifications to the original test: Smooth MPRT and Efficient
                    MPRT. The former reduces the impact of noise on evaluation outcomes via
                    sampling, while the latter avoids the need for biased similarity measurements
                    by re-interpreting the test through the increase in explanation complexity
                    after full model randomisation. Our experiments show that these modifications
                    enhance the metric reliability, facilitating a more trustworthy deployment of
                    explanation methods.
                </p>
            </div>
        </dd>
        <dt><a name="item689">[689]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02406"
                    title="Abstract">arXiv:2405.02406</a> (cross-list from quant-ph) [<a href="/pdf/2405.02406"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02406" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Analysis of Asynchronous Protocols for Entanglement
                    Distribution in Quantum Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/quant-ph?searchtype=author&amp;query=Pouryousef%2C+S">Shahrooz Pouryousef</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Shapourian%2C+H">Hassan Shapourian</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Towsley%2C+D">Don Towsley</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics
                        (quant-ph)</span>; Networking and Internet Architecture (cs.NI)

                </div>
                <p class="mathjax">The distribution of entanglement in quantum networks is typically approached
                    under idealized assumptions such as perfect synchronization and centralized
                    control, while classical communication is often neglected. However, these
                    assumptions prove impractical in large-scale networks. In this paper, we
                    present a pragmatic perspective by exploring two minimal asynchronous
                    protocols: a parallel scheme generating entanglement independently at the link
                    level, and a sequential scheme extending entanglement iteratively from one
                    party to the other. Our analysis incorporates non-uniform repeater spacings and
                    classical communications and accounts for quantum memory decoherence. We
                    evaluate network performance using metrics such as entanglement bit rate,
                    end-to-end fidelity, and secret key rate for entanglement-based quantum key
                    distribution. Our findings suggest the sequential scheme's superiority due to
                    comparable performance with the parallel scheme, coupled with simpler
                    implementation. Additionally, we propose a cutoff strategy to improve
                    performance by discarding attempts with prolonged memory idle time, effectively
                    eliminating low-quality entanglement links. Finally, we apply our methods to
                    the real-world topology of SURFnet and report the performance as a function of
                    memory coherence time.
                </p>
            </div>
        </dd>
        <dt><a name="item690">[690]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02436"
                    title="Abstract">arXiv:2405.02436</a> (cross-list from physics.app-ph) [<a href="/pdf/2405.02436"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02436" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Internet of Paint (IoP): Channel Modeling and Capacity
                    Analysis for Terahertz Electromagnetic Nanonetworks Embedded in Paint
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/physics?searchtype=author&amp;query=Wedage%2C+L+T">Lasantha Thakshila Wedage</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Vuran%2C+M+C">Mehmet Can Vuran</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Butler%2C+B">Bernard Butler</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Koucheryavy%2C+Y">Yevgeni Koucheryavy</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Balasubramaniam%2C+S">Sasitharan
                        Balasubramaniam</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 17 figures, accepted for publication in the IEEE
                    Journal on Selected Areas in Communications Special Issue on Electromagnetic Nanonetworks
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics
                        (physics.app-ph)</span>; Emerging Technologies (cs.ET)

                </div>
                <p class="mathjax">This work opens a new chapter in the 100,000 year-old concept of paint, by
                    leveraging innovations in nano-technology in the sub-THz frequency range. More
                    specifically, the groundbreaking concept of Internet of Paint (IoP) is
                    introduced along with a comprehensive channel model and a capacity analysis for
                    nano-scale radios embedded in paint and communicating through paint.
                    Nano-network devices, integrated within a paint medium, communicate via a
                    multipath strategy, encompassing direct waves, reflections from interfaces, and
                    lateral wave propagation. The evaluation incorporates three distinct paint
                    types to assess path losses, received powers, and channel capacity. Analysis of
                    path loss indicates a slight non-linear increase with both frequency and Line
                    of Sight (LoS) distance between transceivers. Notably, paints with high
                    refractive indexes result in the highest path loss. Moreover, burying
                    transceivers at similar depths near the Air-Paint interface showcases promising
                    performance of lateral waves with increasing LoS distance. Increasing paint
                    layer depth leads to amplified attenuation, while total received power exhibits
                    promising results when in close proximity to the Air-Paint interface but
                    steeply declines with burial depth. Additionally, a substantial reduction in
                    channel capacity is observed with LoS distance and burial depth, so
                    transceivers need to be close together and in proximity of the A-P interface to
                    communicate effectively. Comparing paint and air mediums, IoP demonstrates
                    approximately two orders of magnitude reduction in channel capacity compared to
                    air-based communication channels. This paper provides valuable insights into
                    the potential of IoP communication within paint mediums and offers a foundation
                    for further advancements in this emerging field.
                </p>
            </div>
        </dd>
        <dt><a name="item691">[691]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02449"
                    title="Abstract">arXiv:2405.02449</a> (cross-list from stat.ML) [<a href="/pdf/2405.02449"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02449" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Quality-Weighted Vendi Scores And Their Application To
                    Diverse Experimental Design
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Nguyen%2C+Q">Quan Nguyen</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Dieng%2C+A+B">Adji Bousso Dieng</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published in International Conference on Machine Learning,
                    ICML 2024. Code can be found in the Vertaix GitHub: <a
                        href="https://github.com/vertaix/Quality-Weighted-Vendi-Score.">this https URL</a> Paper
                    dedicated to Kwame Nkrumah
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Biomolecules
                    (q-bio.BM)

                </div>
                <p class="mathjax">Experimental design techniques such as active search and Bayesian
                    optimization are widely used in the natural sciences for data collection and
                    discovery. However, existing techniques tend to favor exploitation over
                    exploration of the search space, which causes them to get stuck in local
                    optima. This ``collapse" problem prevents experimental design algorithms from
                    yielding diverse high-quality data. In this paper, we extend the Vendi scores
                    -- a family of interpretable similarity-based diversity metrics -- to account
                    for quality. We then leverage these quality-weighted Vendi scores to tackle
                    experimental design problems across various applications, including drug
                    discovery, materials discovery, and reinforcement learning. We found that
                    quality-weighted Vendi scores allow us to construct policies for experimental
                    design that flexibly balance quality and diversity, and ultimately assemble
                    rich and diverse sets of high-performing data points. Our algorithms led to a
                    70%-170% increase in the number of effective discoveries compared to baselines.
                </p>
            </div>
        </dd>
        <dt><a name="item692">[692]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02456"
                    title="Abstract">arXiv:2405.02456</a> (cross-list from math.OC) [<a href="/pdf/2405.02456"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.02456" title="Download PostScript">ps</a>, <a
                    href="/format/2405.02456" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Natural Policy Gradient and Actor Critic Methods for
                    Constrained Multi-Task Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Zeng%2C+S">Sihan Zeng</a>,
                    <a href="/search/math?searchtype=author&amp;query=Doan%2C+T+T">Thinh T. Doan</a>,
                    <a href="/search/math?searchtype=author&amp;query=Romberg%2C+J">Justin Romberg</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Multi-task reinforcement learning (RL) aims to find a single policy that
                    effectively solves multiple tasks at the same time. This paper presents a
                    constrained formulation for multi-task RL where the goal is to maximize the
                    average performance of the policy across tasks subject to bounds on the
                    performance in each task. We consider solving this problem both in the
                    centralized setting, where information for all tasks is accessible to a single
                    server, and in the decentralized setting, where a network of agents, each given
                    one task and observing local information, cooperate to find the solution of the
                    globally constrained objective using local communication.
                    <br>We first propose a primal-dual algorithm that provably converges to the
                    globally optimal solution of this constrained formulation under exact gradient
                    evaluations. When the gradient is unknown, we further develop a sampled-based
                    actor-critic algorithm that finds the optimal policy using online samples of
                    state, action, and reward. Finally, we study the extension of the algorithm to
                    the linear function approximation setting.
                </p>
            </div>
        </dd>
        <dt><a name="item693">[693]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02462"
                    title="Abstract">arXiv:2405.02462</a> (cross-list from math.ST) [<a href="/pdf/2405.02462"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02462" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Finite Sample Analysis and Bounds of Generalization Error of
                    Gradient Descent in In-Context Linear Regression
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Duraisamy%2C+K">Karthik Duraisamy</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory
                        (math.ST)</span>; Numerical Analysis (math.NA); Probability (math.PR)

                </div>
                <p class="mathjax">Recent studies show that transformer-based architectures emulate gradient
                    descent during a forward pass, contributing to in-context learning capabilities
                    - an ability where the model adapts to new tasks based on a sequence of prompt
                    examples without being explicitly trained or fine tuned to do so. This work
                    investigates the generalization properties of a single step of gradient descent
                    in the context of linear regression with well-specified models. A random design
                    setting is considered and analytical expressions are derived for the
                    statistical properties of generalization error in a non-asymptotic (finite
                    sample) setting. These expressions are notable for avoiding arbitrary
                    constants, and thus offer robust quantitative information and scaling
                    relationships. These results are contrasted with those from classical least
                    squares regression (for which analogous finite sample bounds are also derived),
                    shedding light on systematic and noise components, as well as optimal step
                    sizes. Additionally, identities involving high-order products of Gaussian
                    random matrices are presented as a byproduct of the analysis.
                </p>
            </div>
        </dd>
        <dt><a name="item694">[694]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02480"
                    title="Abstract">arXiv:2405.02480</a> (cross-list from econ.EM) [<a href="/pdf/2405.02480"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02480" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Network Simulation of OTC Markets with Multiple Agents
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/econ?searchtype=author&amp;query=Wilkinson%2C+J+T">James T. Wilkinson</a>,
                    <a href="/search/econ?searchtype=author&amp;query=Kelter%2C+J">Jacob Kelter</a>,
                    <a href="/search/econ?searchtype=author&amp;query=Chen%2C+J">John Chen</a>,
                    <a href="/search/econ?searchtype=author&amp;query=Wilensky%2C+U">Uri Wilensky</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 20 pages, 17 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics
                        (econ.EM)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

                </div>
                <p class="mathjax">We present a novel agent-based approach to simulating an over-the-counter
                    (OTC) financial market in which trades are intermediated solely by market
                    makers and agent visibility is constrained to a network topology. Dynamics,
                    such as changes in price, result from agent-level interactions that
                    ubiquitously occur via market maker agents acting as liquidity providers. Two
                    additional agents are considered: trend investors use a deep convolutional
                    neural network paired with a deep Q-learning framework to inform trading
                    decisions by analysing price history; and value investors use a static
                    price-target to determine their trade directions and sizes. We demonstrate that
                    our novel inclusion of a network topology with market makers facilitates
                    explorations into various market structures. First, we present the model and an
                    overview of its mechanics. Second, we validate our findings via comparison to
                    the real-world: we demonstrate a fat-tailed distribution of price changes,
                    auto-correlated volatility, a skew negatively correlated to market maker
                    positioning, predictable price-history patterns and more. Finally, we
                    demonstrate that our network-based model can lend insights into the effect of
                    market-structure on price-action. For example, we show that markets with
                    sparsely connected intermediaries can have a critical point of fragmentation,
                    beyond which the market forms distinct clusters and arbitrage becomes rapidly
                    possible between the prices of different market makers. A discussion is
                    provided on future work that would be beneficial.
                </p>
            </div>
        </dd>
        <dt><a name="item695">[695]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02488"
                    title="Abstract">arXiv:2405.02488</a> (cross-list from stat.ML) [<a href="/pdf/2405.02488"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02488" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Modelling Sampling Distributions of Test Statistics with
                    Autograd
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Kadhim%2C+A+A">Ali Al Kadhim</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Prosper%2C+H+B">Harrison B. Prosper</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex);
                    Computation (stat.CO)

                </div>
                <p class="mathjax">Simulation-based inference methods that feature correct conditional coverage
                    of confidence sets based on observations that have been compressed to a scalar
                    test statistic require accurate modelling of either the p-value function or the
                    cumulative distribution function (cdf) of the test statistic. If the model of
                    the cdf, which is typically a deep neural network, is a function of the test
                    statistic then the derivative of the neural network with respect to the test
                    statistic furnishes an approximation of the sampling distribution of the test
                    statistic. We explore whether this approach to modelling conditional
                    1-dimensional sampling distributions is a viable alternative to the probability
                    density-ratio method, also known as the likelihood-ratio trick. Relatively
                    simple, yet effective, neural network models are used whose predictive
                    uncertainty is quantified through a variety of methods.
                </p>
            </div>
        </dd>
        <dt><a name="item696">[696]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02497"
                    title="Abstract">arXiv:2405.02497</a> (cross-list from math.OC) [<a href="/pdf/2405.02497"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02497" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Prediction techniques for dynamic imaging with online
                    primal-dual methods
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Dizon%2C+N">Neil Dizon</a>,
                    <a href="/search/math?searchtype=author&amp;query=Jauhiainen%2C+J">Jyrki Jauhiainen</a>,
                    <a href="/search/math?searchtype=author&amp;query=Valkonen%2C+T">Tuomo Valkonen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Online optimisation facilitates the solution of dynamic inverse problems,
                    such as image stabilisation, fluid flow monitoring, and dynamic medical
                    imaging. In this paper, we improve upon previous work on predictive online
                    primal-dual methods on two fronts. Firstly, we provide a more concise analysis
                    that symmetrises previously unsymmetric regret bounds, and relaxes previous
                    restrictive conditions on the dual predictor. Secondly, based on the latter, we
                    develop several improved dual predictors. We numerically demonstrate their
                    efficacy in image stabilisation and dynamic positron emission tomography.
                </p>
            </div>
        </dd>
        <dt><a name="item697">[697]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02504"
                    title="Abstract">arXiv:2405.02504</a> (cross-list from eess.IV) [<a href="/pdf/2405.02504"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02504" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Functional Imaging Constrained Diffusion for Brain PET
                    Synthesis from Structural MRI
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Yu%2C+M">Minhui Yu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wu%2C+M">Mengqi Wu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yue%2C+L">Ling Yue</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Bozoki%2C+A">Andrea Bozoki</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Liu%2C+M">Mingxia Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Magnetic resonance imaging (MRI) and positron emission tomography (PET) are
                    increasingly used in multimodal analysis of neurodegenerative disorders. While
                    MRI is broadly utilized in clinical settings, PET is less accessible. Many
                    studies have attempted to use deep generative models to synthesize PET from MRI
                    scans. However, they often suffer from unstable training and inadequately
                    preserve brain functional information conveyed by PET. To this end, we propose
                    a functional imaging constrained diffusion (FICD) framework for 3D brain PET
                    image synthesis with paired structural MRI as input condition, through a new
                    constrained diffusion model (CDM). The FICD introduces noise to PET and then
                    progressively removes it with CDM, ensuring high output fidelity throughout a
                    stable training phase. The CDM learns to predict denoised PET with a functional
                    imaging constraint introduced to ensure voxel-wise alignment between each
                    denoised PET and its ground truth. Quantitative and qualitative analyses
                    conducted on 293 subjects with paired T1-weighted MRI and
                    18F-fluorodeoxyglucose (FDG)-PET scans suggest that FICD achieves superior
                    performance in generating FDG-PET data compared to state-of-the-art methods. We
                    further validate the effectiveness of the proposed FICD on data from a total of
                    1,262 subjects through three downstream tasks, with experimental results
                    suggesting its utility and generalizability.
                </p>
            </div>
        </dd>
        <dt><a name="item698">[698]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02523"
                    title="Abstract">arXiv:2405.02523</a> (cross-list from quant-ph) [<a href="/pdf/2405.02523"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02523" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Optimal Toffoli-Depth Quantum Adder
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/quant-ph?searchtype=author&amp;query=Wang%2C+S">Siyi Wang</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Deb%2C+S">Suman Deb</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Mondal%2C+A">Ankit Mondal</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Chattopadhyay%2C+A">Anupam Chattopadhyay</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper is under review in ACM Transactions on Quantum
                    Computing
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics
                        (quant-ph)</span>; Emerging Technologies (cs.ET)

                </div>
                <p class="mathjax">Efficient quantum arithmetic circuits are commonly found in numerous quantum
                    algorithms of practical significance. Till date, the logarithmic-depth quantum
                    adders includes a constant coefficient k &gt;= 2 while achieving the Toffoli-Depth
                    of klog n + O(1). In this work, 160 alternative compositions of the
                    carry-propagation structure are comprehensively explored to determine the
                    optimal depth structure for a quantum adder. By extensively studying these
                    structures, it is shown that an exact Toffoli-Depth of log n + O(1) is
                    achievable. This presents a reduction of Toffoli-Depth by almost 50% compared
                    to the best known quantum adder circuits presented till date. We demonstrate a
                    further possible design by incorporating a different expansion of propagate and
                    generate forms, as well as an extension of the modular framework. Our paper
                    elaborates on these designs, supported by detailed theoretical analyses and
                    simulation-based studies, firmly substantiating our claims of optimality. The
                    results also mirror similar improvements, recently reported in classical adder
                    circuit complexity.
                </p>
            </div>
        </dd>
        <dt><a name="item699">[699]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02545"
                    title="Abstract">arXiv:2405.02545</a> (cross-list from astro-ph.SR) [<a href="/pdf/2405.02545"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02545" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Prediction of Space Weather Events through Analysis of Active
                    Region Magnetograms using Convolutional Neural Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/astro-ph?searchtype=author&amp;query=Sakpal%2C+S">Shlesh Sakpal</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages, 12 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar
                        Astrophysics (astro-ph.SR)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Artificial
                    Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Although space weather events may not directly affect human life, they have
                    the potential to inflict significant harm upon our communities. Harmful space
                    weather events can trigger atmospheric changes that result in physical and
                    economic damages on a global scale. In 1989, Earth experienced the effects of a
                    powerful geomagnetic storm that caused satellites to malfunction, while
                    triggering power blackouts in Canada, along with electricity disturbances in
                    the United States and Europe. With the solar cycle peak rapidly approaching,
                    there is an ever-increasing need to prepare and prevent the damages that can
                    occur, especially to modern-day technology, calling for the need of a
                    comprehensive prediction system. This study aims to leverage machine learning
                    techniques to predict instances of space weather (solar flares, coronal mass
                    ejections, geomagnetic storms), based on active region magnetograms of the Sun.
                    This was done through the use of the NASA DONKI service to determine when these
                    solar events occur, then using data from the NASA Solar Dynamics Observatory to
                    compile a dataset that includes magnetograms of active regions of the Sun 24
                    hours before the events. By inputting the magnetograms into a convolutional
                    neural network (CNN) trained from this dataset, it can serve to predict whether
                    a space weather event will occur, and what type of event it will be. The model
                    was designed using a custom architecture CNN, and returned an accuracy of
                    90.27%, a precision of 85.83%, a recall of 91.78%, and an average F1 score of
                    92.14% across each class (Solar flare [Flare], geomagnetic storm [GMS], coronal
                    mass ejection [CME]). Our results show that using magnetogram data as an input
                    for a CNN is a viable method to space weather prediction. Future work can
                    involve prediction of the magnitude of solar events.
                </p>
            </div>
        </dd>
        <dt><a name="item700">[700]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02563"
                    title="Abstract">arXiv:2405.02563</a> (cross-list from eess.SP) [<a href="/pdf/2405.02563"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02563" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Representation Learning-Based Dynamic Trajectory
                    Phenotyping for Acute Respiratory Failure in Medical Intensive Care Units
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Wu%2C+A">Alan Wu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Choudhary%2C+T">Tilendra Choudhary</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Upadhyaya%2C+P">Pulakesh Upadhyaya</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Ali%2C+A">Ayman Ali</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yang%2C+P">Philip Yang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Sepsis-induced acute respiratory failure (ARF) is a serious complication with
                    a poor prognosis. This paper presents a deep representation learningbased
                    phenotyping method to identify distinct groups of clinical trajectories of
                    septic patients with ARF. For this retrospective study, we created a dataset
                    from electronic medical records (EMR) consisting of data from sepsis patients
                    admitted to medical intensive care units who required at least 24 hours of
                    invasive mechanical ventilation at a quarternary care academic hospital in
                    southeast USA for the years 2016-2021. A total of N=3349 patient encounters
                    were included in this study. Clustering Representation Learning on Incomplete
                    Time Series Data (CRLI) algorithm was applied to a parsimonious set of EMR
                    variables in this data set. To validate the optimal number of clusters, the
                    K-means algorithm was used in conjunction with dynamic time warping. Our model
                    yielded four distinct patient phenotypes that were characterized as liver
                    dysfunction/heterogeneous, hypercapnia, hypoxemia, and multiple organ
                    dysfunction syndrome by a critical care expert. A Kaplan-Meier analysis to
                    compare the 28-day mortality trends exhibited significant differences (p &lt;
                    0.005) between the four phenotypes. The study demonstrates the utility of our
                    deep representation learning-based approach in unraveling phenotypes that
                    reflect the heterogeneity in sepsis-induced ARF in terms of different mortality
                    outcomes and severity. These phenotypes might reveal important clinical
                    insights into an effective prognosis and tailored treatment strategies.
                </p>
            </div>
        </dd>
        <dt><a name="item701">[701]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02570"
                    title="Abstract">arXiv:2405.02570</a> (cross-list from q-fin.CP) [<a href="/pdf/2405.02570"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.02570" title="Download PostScript">ps</a>, <a
                    href="/format/2405.02570" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Gradient-enhanced sparse Hermite polynomial expansions for
                    pricing and hedging high-dimensional American options
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/q-fin?searchtype=author&amp;query=Yang%2C+J">Jiefei Yang</a>,
                    <a href="/search/q-fin?searchtype=author&amp;query=Li%2C+G">Guanglian Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance
                        (q-fin.CP)</span>; Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">We propose an efficient and easy-to-implement gradient-enhanced least squares
                    Monte Carlo method for computing price and Greeks (i.e., derivatives of the
                    price function) of high-dimensional American options. It employs the sparse
                    Hermite polynomial expansion as a surrogate model for the continuation value
                    function, and essentially exploits the fast evaluation of gradients. The
                    expansion coefficients are computed by solving a linear least squares problem
                    that is enhanced by gradient information of simulated paths. We analyze the
                    convergence of the proposed method, and establish an error estimate in terms of
                    the best approximation error in the weighted <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-353-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2268"
                                style="width: 1.681em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1001.39em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2269"><span class="msubsup"
                                                id="MathJax-Span-2270"><span
                                                    style="display: inline-block; position: relative; width: 1.392em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2271"
                                                            style="font-family: MathJax_Math-italic;">H<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.987em;"><span
                                                            class="mn" id="MathJax-Span-2272"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-353">H^1</script> space, the statistical error
                    of solving discrete least squares problems, and the time step size. We present
                    comprehensive numerical experiments to illustrate the performance of the
                    proposed method. The results show that it outperforms the state-of-the-art
                    least squares Monte Carlo method with more accurate price, Greeks, and optimal
                    exercise strategies in high dimensions but with nearly identical computational
                    cost, and it can deliver comparable results with recent neural network-based
                    methods up to dimension 100.
                </p>
            </div>
        </dd>
        <dt><a name="item702">[702]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02588"
                    title="Abstract">arXiv:2405.02588</a> (cross-list from math.OC) [<a href="/pdf/2405.02588"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.02588" title="Download PostScript">ps</a>, <a
                    href="/format/2405.02588" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Inexact Adaptive Cubic Regularization Algorithms on
                    Riemannian Manifolds and Application
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Li%2C+Z+Y">Z. Y. Li</a>,
                    <a href="/search/math?searchtype=author&amp;query=Wang%2C+X+M">X. M. Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 1 table
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">The adaptive cubic regularization algorithm employing the inexact gradient
                    and Hessian is proposed on general Riemannian manifolds, together with the
                    iteration complexity to get an approximate second-order optimality under
                    certain assumptions on accuracies about the inexact gradient and Hessian. The
                    algorithm extends the inexact adaptive cubic regularization algorithm under
                    true gradient in [Math. Program., 184(1-2): 35-70, 2020] to more general cases
                    even in Euclidean settings. As an application, the algorithm is applied to
                    solve the joint diagonalization problem on the Stiefel manifold. Numerical
                    experiments illustrate that the algorithm performs better than the inexact
                    trust-region algorithm in [Advances of the neural information processing
                    systems, 31, 2018].
                </p>
            </div>
        </dd>
        <dt><a name="item703">[703]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02603"
                    title="Abstract">arXiv:2405.02603</a> (cross-list from physics.comp-ph) [<a href="/pdf/2405.02603"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02603" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Massively Parallel Performance Portable Free-space Spectral
                    Poisson Solver
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/physics?searchtype=author&amp;query=Mayani%2C+S">Sonali Mayani</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Montanaro%2C+V">Veronica Montanaro</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Cerfon%2C+A">Antoine Cerfon</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Frey%2C+M">Matthias Frey</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Muralikrishnan%2C+S">Sriramkrishnan
                        Muralikrishnan</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Adelmann%2C+A">Andreas Adelmann</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages, 11 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics
                        (physics.comp-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
                <p class="mathjax">Vico et al. (2016) suggest a fast algorithm for computing volume potentials,
                    beneficial to fields with problems requiring the solution of Poisson's equation
                    with free-space boundary conditions, such as the beam and plasma physics
                    communities. Currently, the standard method for solving the free-space Poisson
                    equation is the algorithm of Hockney and Eastwood (1988), which is second order
                    in convergence at best. The algorithm proposed by Vico et al. converges
                    spectrally for sufficiently smooth functions i.e. faster than any fixed order
                    in the number of grid points. In this paper, we implement a performance
                    portable version of the traditional Hockney-Eastwood and the novel
                    Vico-Greengard Poisson solver as part of the IPPL (Independent Parallel
                    Particle Layer) library. For sufficiently smooth source functions, the
                    Vico-Greengard algorithm achieves higher accuracy than the Hockney-Eastwood
                    method with the same grid size, reducing the computational demands of high
                    resolution simulations since one could use coarser grids to achieve them. More
                    concretely, to get a relative error of <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-354-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2273"
                                style="width: 2.376em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.97em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1001.97em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2274"><span class="msubsup"
                                                id="MathJax-Span-2275"><span
                                                    style="display: inline-block; position: relative; width: 1.97em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.99em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-2276"
                                                            style="font-family: MathJax_Main;">10</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.987em;"><span
                                                            class="texatom" id="MathJax-Span-2277"><span class="mrow"
                                                                id="MathJax-Span-2278"><span class="mo"
                                                                    id="MathJax-Span-2279"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-2280"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">4</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-354">10^{-4}</script> between the numerical and
                    analytical solution, one requires only <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-355-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2281"
                                style="width: 1.739em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1001.45em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2282"><span class="msubsup"
                                                id="MathJax-Span-2283"><span
                                                    style="display: inline-block; position: relative; width: 1.45em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.99em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-2284"
                                                            style="font-family: MathJax_Main;">16</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 0.987em;"><span
                                                            class="mn" id="MathJax-Span-2285"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-355">16^3</script> grid points in the former, but
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-356-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2286"
                                style="width: 2.318em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.913em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1001.91em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2287"><span class="msubsup"
                                                id="MathJax-Span-2288"><span
                                                    style="display: inline-block; position: relative; width: 1.913em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1001.45em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-2289"
                                                            style="font-family: MathJax_Main;">128</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.395em; left: 1.508em;"><span
                                                            class="mn" id="MathJax-Span-2290"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.184em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-356">128^3</script> in the latter, more than a 99%
                    memory footprint reduction.
                    Additionally, we propose an algorithmic improvement to the Vico-Greengard
                    method which further reduces its memory footprint. This is particularly
                    important for GPUs which have limited memory resources, and should be taken
                    into account when selecting numerical algorithms for performance portable
                    codes. Finally, we showcase performance through GPU and CPU scaling studies on
                    the Perlmutter (NERSC) supercomputer, with efficiencies staying above 50% in
                    the strong scaling case.
                </p>
            </div>
        </dd>
        <dt><a name="item704">[704]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02621"
                    title="Abstract">arXiv:2405.02621</a> (cross-list from math.CO) [<a href="/pdf/2405.02621"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.02621" title="Download PostScript">ps</a>, <a
                    href="/format/2405.02621" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Intersecting families with covering number <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-357-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2291"
                                style="width: 0.604em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.512em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.391em, 1000.47em, 2.317em, -999.998em); top: -2.174em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2292"><span class="mn" id="MathJax-Span-2293"
                                                style="font-family: MathJax_Main;">3</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.178em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 0.947em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-357">3</script>
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Kupavskii%2C+A">Andrey Kupavskii</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a
                        href="/abs/1810.00920">arXiv:1810.00920</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics
                        (math.CO)</span>; Discrete Mathematics (cs.DM)

                </div>
                <p class="mathjax">A covering number of a family is the size of the smallest set that intersects
                    all sets from the family. In 1978 Frankl determined for <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-358-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2294"
                                style="width: 5.153em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.285em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1004.17em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2295"><span class="mi" id="MathJax-Span-2296"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-2297"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≥</span><span
                                                class="msubsup" id="MathJax-Span-2298"
                                                style="padding-left: 0.292em;"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.58em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2299"
                                                            style="font-family: MathJax_Math-italic;">n</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.582em;"><span
                                                            class="mn" id="MathJax-Span-2300"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">0</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-2301"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-2302"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mo"
                                                id="MathJax-Span-2303"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-358">n\ge n_0(k)</script> the
                    largest intersecting family of <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-359-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2304"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.52em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2305"><span class="mi" id="MathJax-Span-2306"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-359">k</script>-element subsets of <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-360-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2307"
                                style="width: 1.392em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.16em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1001.04em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2308"><span class="mo" id="MathJax-Span-2309"
                                                style="font-family: MathJax_Main;">[</span><span class="mi"
                                                id="MathJax-Span-2310"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-2311"
                                                style="font-family: MathJax_Main;">]</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-360">[n]</script> with covering
                    number <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-361-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2312"
                                style="width: 0.639em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.524em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.334em, 1000.47em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2313"><span class="mn" id="MathJax-Span-2314"
                                                style="font-family: MathJax_Main;">3</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-361">3</script>. In this paper, we essentially settle
                    this problem, showing that the
                    same family is extremal for any <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-362-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2315"
                                style="width: 4.054em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.359em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1003.3em, 2.433em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2316"><span class="mi" id="MathJax-Span-2317"
                                                style="font-family: MathJax_Math-italic;">k</span><span class="mo"
                                                id="MathJax-Span-2318"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">≥</span><span
                                                class="mn" id="MathJax-Span-2319"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">100</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.205em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-362">k\ge 100</script> and <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-363-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2320"
                                style="width: 3.649em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.012em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1003.01em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2321"><span class="mi" id="MathJax-Span-2322"
                                                style="font-family: MathJax_Math-italic;">n</span><span class="mo"
                                                id="MathJax-Span-2323"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">&gt;</span><span
                                                class="mn" id="MathJax-Span-2324"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">2</span><span
                                                class="mi" id="MathJax-Span-2325"
                                                style="font-family: MathJax_Math-italic;">k</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-363">n>2k</script>.
                </p>
            </div>
        </dd>
        <dt><a name="item705">[705]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02630"
                    title="Abstract">arXiv:2405.02630</a> (cross-list from quant-ph) [<a href="/pdf/2405.02630"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02630" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> cuTN-QSVM: cuTensorNet-accelerated Quantum Support Vector
                    Machine with cuQuantum SDK
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/quant-ph?searchtype=author&amp;query=Chen%2C+K">Kuan-Cheng Chen</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Li%2C+T">Tai-Yue Li</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Wang%2C+Y">Yun-Yuan Wang</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=See%2C+S">Simon See</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Wang%2C+C">Chun-Chieh Wang</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Willie%2C+R">Robert Willie</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Chen%2C+N">Nan-Yow Chen</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Yang%2C+A">An-Cheng Yang</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Lin%2C+C">Chun-Yu Lin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 14 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics
                        (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Software Engineering
                    (cs.SE)

                </div>
                <p class="mathjax">This paper investigates the application of Quantum Support Vector Machines
                    (QSVMs) with an emphasis on the computational advancements enabled by NVIDIA's
                    cuQuantum SDK, especially leveraging the cuTensorNet library. We present a
                    simulation workflow that substantially diminishes computational overhead, as
                    evidenced by our experiments, from exponential to quadratic cost. While state
                    vector simulations become infeasible for qubit counts over 50, our evaluation
                    demonstrates that cuTensorNet speeds up simulations to be completed within
                    seconds on the NVIDIA A100 GPU, even for qubit counts approaching 784. By
                    employing multi-GPU processing with Message Passing Interface (MPI), we
                    document a marked decrease in computation times, effectively demonstrating the
                    strong linear speedup of our approach for increasing data sizes. This enables
                    QSVMs to operate efficiently on High-Performance Computing (HPC) systems,
                    thereby opening a new window for researchers to explore complex quantum
                    algorithms that have not yet been investigated. In accuracy assessments, our
                    QSVM achieves up to 95\% on challenging classifications within the MNIST
                    dataset for training sets larger than 100 instances, surpassing the
                    capabilities of classical SVMs. These advancements position cuTensorNet within
                    the cuQuantum SDK as a pivotal tool for scaling quantum machine learning
                    simulations and potentially signpost the seamless integration of such
                    computational strategies as pivotal within the Quantum-HPC ecosystem.
                </p>
            </div>
        </dd>
        <dt><a name="item706">[706]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02679"
                    title="Abstract">arXiv:2405.02679</a> (cross-list from physics.ao-ph) [<a href="/pdf/2405.02679"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02679" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Prévisions météorologiques basées sur l'intelligence
                    artificielle : une révolution peut en cacher une autre
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/physics?searchtype=author&amp;query=Ben-Bouallegue%2C+Z">Zied Ben-Bouallegue</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Clare%2C+M+C+A">Mariana C A Clare</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Chevallier%2C+M">Matthieu Chevallier</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, in French
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic
                        Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Artificial intelligence (AI), based on deep-learning algorithm using
                    high-quality reanalysis datasets, is showing enormous potential for weather
                    forecasting. In this context, the European Centre for Medium-Range Weather
                    Forecasts (ECMWF) is developing a new forecasting system based on AI.
                    Verification results of deterministic forecast for now are promising. However,
                    the realism of weather forecasts based on AI is often questioned. Here,
                    different types of realism are identified and we discuss, in particular, the
                    relationship between structural realism and predictability of weather events.
                    Furthermore, a statistical analysis of deterministic forecasts based on AI
                    points to a realism/performance dilemma that a probabilistic approach should
                    help to solve. -- L'intelligence artificielle (IA) bouleverse aujourd'hui le
                    monde de la pr\'evision m\'et\'eorologique avec l'utilisation d'algorithmes
                    d'apprentissage profond nourris par des champs de r\'eanalyses. Dans ce
                    contexte, le Centre Europ\'een pour les Pr\'evisions M\'et\'eorologiques \`a
                    Moyen Terme (CEPMMT) a d\'ecid\'e de d\'evelopper un nouveau syst\`eme de
                    pr\'evisions resposant sur l'IA. Ces pr\'evisions, pour le moment de type
                    d\'eterministe, montrent des r\'esultats prometteurs. Toutefois, le r\'ealisme
                    de ce type de pr\'evisions reposant sur l'IA est souvent questionn\'e. Ici,
                    nous identifions diff\'erents types de r\'ealisme et interrogeons notamment le
                    rapport entre r\'ealisme structurel et pr\'evisibilit\'e des \'ev\^enements
                    m\'et\'eorologiques. Une analyse statistique de pr\'evisions d\'eterministes
                    reposant sur l'IA laisse apparaitre un dilemme r\'ealisme/performance qu'une
                    approche probabiliste devrait aider \`a r\'esoudre.
                </p>
            </div>
        </dd>
        <dt><a name="item707">[707]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02718"
                    title="Abstract">arXiv:2405.02718</a> (cross-list from eess.SP) [<a href="/pdf/2405.02718"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02718" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Zak-OTFS: Pulse Shaping and the Tradeoff between
                    Time/Bandwidth Expansion and Predictability
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Jayachandran%2C+J">Jinu Jayachandran</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Jaiswal%2C+R+K">Rahul Kumar Jaiswal</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Mohammed%2C+S+K">Saif Khan Mohammed</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Hadani%2C+R">Ronny Hadani</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Chockalingam%2C+A">Ananthanarayanan
                        Chockalingam</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Calderbank%2C+R">Robert Calderbank</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible
                    publication. Copyright may be transferred without notice, after which this version may no longer be
                    accessible
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Information Theory (cs.IT)

                </div>
                <p class="mathjax">The Zak-OTFS input/output (I/O) relation is predictable and non-fading when
                    the delay and Doppler periods are greater than the effective channel delay and
                    Doppler spreads, a condition which we refer to as the crystallization
                    condition. When the crystallization condition is satisfied, we describe how to
                    integrate sensing and communication within a single Zak-OTFS subframe by
                    transmitting a pilot in the center of the subframe and surrounding the pilot
                    with a pilot region and guard band to mitigate interference between data
                    symbols and pilot. At the receiver we first read off the effective channel taps
                    within the pilot region, and then use the estimated channel taps to recover the
                    data from the symbols received outside the pilot region. We introduce a
                    framework for filter design in the delay-Doppler (DD) domain where the
                    symplectic Fourier transform connects aliasing in the DD domain (predictability
                    of the I/O relation) with time/bandwidth expansion. The choice of pulse shaping
                    filter determines the fraction of pilot energy that lies outside the pilot
                    region and the degradation in BER performance that results from the
                    interference to data symbols. We demonstrate that Gaussian filters in the DD
                    domain provide significant improvements in BER performance over the sinc and
                    root raised cosine filters considered in previous work. We also demonstrate
                    that, by limiting DD domain aliasing, Gaussian filters extend the region where
                    the crystallization condition is satisfied. The Gaussian filters considered in
                    this paper are a particular case of factorizable pulse shaping filters in the
                    DD domain, and this family of filters may be of independent interest.
                </p>
            </div>
        </dd>
        <dt><a name="item708">[708]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02753"
                    title="Abstract">arXiv:2405.02753</a> (cross-list from math.OC) [<a href="/pdf/2405.02753"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.02753" title="Download PostScript">ps</a>, <a
                    href="/format/2405.02753" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unscented Trajectory Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Ross%2C+I+M">I. M. Ross</a>,
                    <a href="/search/math?searchtype=author&amp;query=Proulx%2C+R+J">R. J. Proulx</a>,
                    <a href="/search/math?searchtype=author&amp;query=Karpenko%2C+M">M. Karpenko</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 21 pages, 11 figures 2023 AAS/AIAA Astrodynamics
                    Specialist Conference, Big Sky, MT, Aug 13-17, 2023
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Systems and Control (eess.SY); Statistics Theory (math.ST); Computation
                    (stat.CO)

                </div>
                <p class="mathjax">In a nutshell, unscented trajectory optimization is the generation of optimal
                    trajectories through the use of an unscented transform. Although unscented
                    trajectory optimization was introduced by the authors about a decade ago, it is
                    reintroduced in this paper as a special instantiation of tychastic optimal
                    control theory. Tychastic optimal control theory (from \textit{Tyche}, the
                    Greek goddess of chance) avoids the use of a Brownian motion and the resulting
                    It\^{o} calculus even though it uses random variables across the entire
                    spectrum of a problem formulation. This approach circumvents the enormous
                    technical and numerical challenges associated with stochastic trajectory
                    optimization. Furthermore, it is shown how a tychastic optimal control problem
                    that involves nonlinear transformations of the expectation operator can be
                    quickly instantiated using an unscented transform. These nonlinear
                    transformations are particularly useful in managing trajectory dispersions be
                    it associated with path constraints or targeted values of final-time
                    conditions. This paper also presents a systematic and rapid process for
                    formulating and computing the most desirable tychastic trajectory using an
                    unscented transform. Numerical examples are used to illustrate how unscented
                    trajectory optimization may be used for risk reduction and mission recovery
                    caused by uncertainties and failures.
                </p>
            </div>
        </dd>
        <dt><a name="item709">[709]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02783"
                    title="Abstract">arXiv:2405.02783</a> (cross-list from stat.ML) [<a href="/pdf/2405.02783"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02783" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Linear Noise Approximation Assisted Bayesian Inference on
                    Mechanistic Model of Partially Observed Stochastic Reaction Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Xu%2C+W">Wandi Xu</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Xie%2C+W">Wei Xie</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 2 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">To support mechanism online learning and facilitate digital twin development
                    for biomanufacturing processes, this paper develops an efficient Bayesian
                    inference approach for partially observed enzymatic stochastic reaction network
                    (SRN), a fundamental building block of multi-scale bioprocess mechanistic
                    model. To tackle the critical challenges brought by the nonlinear stochastic
                    differential equations (SDEs)-based mechanistic model with partially observed
                    state and having measurement error, an interpretable Bayesian updating linear
                    noise approximation (LNA) metamodel, incorporating the structure information of
                    the mechanistic model, is proposed to approximate the likelihood of
                    observations. Then, an efficient posterior sampling approach is developed by
                    utilizing the gradients of the derived likelihood to speed up the convergence
                    of MCMC. The empirical study demonstrates that the proposed approach has a
                    promising performance.
                </p>
            </div>
        </dd>
        <dt><a name="item710">[710]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02784"
                    title="Abstract">arXiv:2405.02784</a> (cross-list from eess.IV) [<a href="/pdf/2405.02784"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02784" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MR-Transformer: Vision Transformer for Total Knee Replacement
                    Prediction Using Magnetic Resonance Imaging
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+C">Chaojie Zhang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Chen%2C+S">Shengjia Chen</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Cigdem%2C+O">Ozkan Cigdem</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Rajamohan%2C+H+R">Haresh Rengaraj Rajamohan</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Cho%2C+K">Kyunghyun Cho</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Kijowski%2C+R">Richard Kijowski</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Deniz%2C+C+M">Cem M. Deniz</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">A transformer-based deep learning model, MR-Transformer, was developed for
                    total knee replacement (TKR) prediction using magnetic resonance imaging (MRI).
                    The model incorporates the ImageNet pre-training and captures three-dimensional
                    (3D) spatial correlation from the MR images. The performance of the proposed
                    model was compared to existing state-of-the-art deep learning models for knee
                    injury diagnosis using MRI. Knee MR scans of four different tissue contrasts
                    from the Osteoarthritis Initiative and Multicenter Osteoarthritis Study
                    databases were utilized in the study. Experimental results demonstrated the
                    state-of-the-art performance of the proposed model on TKR prediction using MRI.
                </p>
            </div>
        </dd>
        <dt><a name="item711">[711]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02849"
                    title="Abstract">arXiv:2405.02849</a> (cross-list from q-fin.CP) [<a href="/pdf/2405.02849"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02849" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Modelling Opaque Bilateral Market Dynamics in Financial
                    Trading: Insights from a Multi-Agent Simulation Study
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/q-fin?searchtype=author&amp;query=Vidler%2C+A">Alicia Vidler</a>,
                    <a href="/search/q-fin?searchtype=author&amp;query=Walsh%2C+T">Toby Walsh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages, 3 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance
                        (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

                </div>
                <p class="mathjax">Exploring complex adaptive financial trading environments through multi-agent
                    based simulation methods presents an innovative approach within the realm of
                    quantitative finance. Despite the dominance of multi-agent reinforcement
                    learning approaches in financial markets with observable data, there exists a
                    set of systematically significant financial markets that pose challenges due to
                    their partial or obscured data availability. We, therefore, devise a
                    multi-agent simulation approach employing small-scale meta-heuristic methods.
                    This approach aims to represent the opaque bilateral market for Australian
                    government bond trading, capturing the bilateral nature of bank-to-bank
                    trading, also referred to as "over-the-counter" (OTC) trading, and commonly
                    occurring between "market makers". The uniqueness of the bilateral market,
                    characterized by negotiated transactions and a limited number of agents, yields
                    valuable insights for agent-based modelling and quantitative finance. The
                    inherent rigidity of this market structure, which is at odds with the global
                    proliferation of multilateral platforms and the decentralization of finance,
                    underscores the unique insights offered by our agent-based model. We explore
                    the implications of market rigidity on market structure and consider the
                    element of stability, in market design. This extends the ongoing discourse on
                    complex financial trading environments, providing an enhanced understanding of
                    their dynamics and implications.
                </p>
            </div>
        </dd>
        <dt><a name="item712">[712]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02852"
                    title="Abstract">arXiv:2405.02852</a> (cross-list from eess.IV) [<a href="/pdf/2405.02852"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02852" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On Enhancing Brain Tumor Segmentation Across Diverse
                    Populations with Convolutional Neural Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Maani%2C+F">Fadillah Maani</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Hashmi%2C+A+U+R">Anees Ur Rehman Hashmi</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Saeed%2C+N">Numan Saeed</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yaqub%2C+M">Mohammad Yaqub</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Brain tumor segmentation is a fundamental step in assessing a patient's
                    cancer progression. However, manual segmentation demands significant expert
                    time to identify tumors in 3D multimodal brain MRI scans accurately. This
                    reliance on manual segmentation makes the process prone to intra- and
                    inter-observer variability. This work proposes a brain tumor segmentation
                    method as part of the BraTS-GoAT challenge. The task is to segment tumors in
                    brain MRI scans automatically from various populations, such as adults,
                    pediatrics, and underserved sub-Saharan Africa. We employ a recent CNN
                    architecture for medical image segmentation, namely MedNeXt, as our baseline,
                    and we implement extensive model ensembling and postprocessing for inference.
                    Our experiments show that our method performs well on the unseen validation set
                    with an average DSC of 85.54% and HD95 of 27.88. The code is available on
                    https://github.com/BioMedIA-MBZUAI/BraTS2024_BioMedIAMBZ.
                </p>
            </div>
        </dd>
        <dt><a name="item713">[713]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02857"
                    title="Abstract">arXiv:2405.02857</a> (cross-list from eess.IV) [<a href="/pdf/2405.02857"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02857" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> I<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-364-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2326"
                                style="width: 0.512em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.419em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.049em, 1000.42em, 1.16em, -999.998em); top: -1.016em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2327"><span class="msubsup"
                                                id="MathJax-Span-2328"><span
                                                    style="display: inline-block; position: relative; width: 0.419em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.845em, 1000em, 4.123em, -999.998em); top: -3.979em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2329"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span
                                                        style="position: absolute; top: -4.35em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-2330"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.021em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.053em; border-left: 0px solid; width: 0px; height: 1.114em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-364">^3</script>Net: Inter-Intra-slice Interpolation
                    Network for Medical Slice Synthesis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Song%2C+H">Haofei Song</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Mao%2C+X">Xintian Mao</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yu%2C+J">Jing Yu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Li%2C+Q">Qingli Li</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yan Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">Medical imaging is limited by acquisition time and scanning equipment. CT and
                    MR volumes, reconstructed with thicker slices, are anisotropic with high
                    in-plane resolution and low through-plane resolution. We reveal an intriguing
                    phenomenon that due to the mentioned nature of data, performing slice-wise
                    interpolation from the axial view can yield greater benefits than performing
                    super-resolution from other views. Based on this observation, we propose an
                    Inter-Intra-slice Interpolation Network (I<span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-365-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2331"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.41em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2332"><span class="msubsup"
                                                id="MathJax-Span-2333"><span
                                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.822em, 1000em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2334"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-2335"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-365">^3</script>Net), which fully explores
                    information from high in-plane resolution and compensates for low through-plane
                    resolution. The through-plane branch supplements the limited information
                    contained in low through-plane resolution from high in-plane resolution and
                    enables continual and diverse feature learning. In-plane branch transforms
                    features to the frequency domain and enforces an equal learning opportunity for
                    all frequency bands in a global context learning paradigm. We further propose a
                    cross-view block to take advantage of the information from all three views
                    online. Extensive experiments on two public datasets demonstrate the
                    effectiveness of I<span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-366-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2336"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.41em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2337"><span class="msubsup"
                                                id="MathJax-Span-2338"><span
                                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.822em, 1000em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2339"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-2340"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">3</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-366">^3</script>Net, and noticeably outperforms
                    state-of-the-art
                    super-resolution, video frame interpolation and slice interpolation methods by
                    a large margin. We achieve 43.90dB in PSNR, with at least 1.14dB improvement
                    under the upscale factor of <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-367-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2341"
                                style="width: 0.929em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.755em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.508em, 1000.58em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2342"><span class="mo" id="MathJax-Span-2343"
                                                style="font-family: MathJax_Main;">×</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.698em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-367">\times</script>2 on MSD dataset with faster
                    inference.
                    Code is available at
                    https://github.com/DeepMed-Lab-ECNU/Medical-Image-Reconstruction.
                </p>
            </div>
        </dd>
        <dt><a name="item714">[714]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02885"
                    title="Abstract">arXiv:2405.02885</a> (cross-list from eess.SP) [<a href="/pdf/2405.02885"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02885" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Performance Analysis of Underwater Acoustic Channel Amid
                    Jamming by Random Jammers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Aman%2C+W">Waqas Aman</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Al-Kuwari%2C+S">Saif Al-Kuwari</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Qaraqe%2C+M">Marwa Qaraqe</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Emerging Technologies (cs.ET)

                </div>
                <p class="mathjax">Underwater communication networks are increasingly popularized by various
                    important maritime applications. However, this also leads to an increased
                    threat landscape. This letter presents the first study that considers jamming
                    attacks by random jammers present in the surroundings of legitimate
                    transceivers in underwater acoustic communication systems. We investigate the
                    impact of jamming attacks on various performance parameters of the legitimate
                    underwater acoustic communication link. In particular, we investigate the
                    legitimate link using stochastic geometry for important performance parameters,
                    namely coverage probability, average rate, and energy efficiency of the link
                    between two legitimate nodes, i.e., underwater and surface nodes. We then
                    derive and present tractable expressions for these performance parameters.
                    Finally, we performed a Monte Carlo simulation to validate our analysis. We
                    plot the performance metrics against the transmit power, and jamming power for
                    different intensities of the jammers in shallow, mid, and deep water scenarios.
                    Results reveal that on average, jamming in deep water has a relatively high
                    impact on the performance of legitimate link than in shallow water.
                </p>
            </div>
        </dd>
        <dt><a name="item715">[715]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02942"
                    title="Abstract">arXiv:2405.02942</a> (cross-list from physics.optics) [<a href="/pdf/2405.02942"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02942" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Design, analysis, and manufacturing of a glass-plastic hybrid
                    minimalist aspheric panoramic annular lens
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/physics?searchtype=author&amp;query=Gao%2C+S">Shaohua Gao</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Jiang%2C+Q">Qi Jiang</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Liao%2C+Y">Yiqi Liao</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Qiu%2C+Y">Yi Qiu</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Ying%2C+W">Wanglei Ying</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Yang%2C+K">Kailun Yang</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Wang%2C+K">Kaiwei Wang</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Zhang%2C+B">Benhao Zhang</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Bai%2C+J">Jian Bai</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to Optics &amp; Laser Technology
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optics
                        (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO);
                    Image and Video Processing (eess.IV)

                </div>
                <p class="mathjax">We propose a high-performance glass-plastic hybrid minimalist aspheric
                    panoramic annular lens (ASPAL) to solve several major limitations of the
                    traditional panoramic annular lens (PAL), such as large size, high weight, and
                    complex system. The field of view (FoV) of the ASPAL is
                    360{\deg}x(35{\deg}~110{\deg}) and the imaging quality is close to the
                    diffraction limit. This large FoV ASPAL is composed of only 4 lenses. Moreover,
                    we establish a physical structure model of PAL using the ray tracing method and
                    study the influence of its physical parameters on compactness ratio. In
                    addition, for the evaluation of local tolerances of annular surfaces, we
                    propose a tolerance analysis method suitable for ASPAL. This analytical method
                    can effectively analyze surface irregularities on annular surfaces and provide
                    clear guidance on manufacturing tolerances for ASPAL. Benefiting from
                    high-precision glass molding and injection molding aspheric lens manufacturing
                    techniques, we finally manufactured 20 ASPALs in small batches. The weight of
                    an ASPAL prototype is only 8.5 g. Our framework provides promising insights for
                    the application of panoramic systems in space and weight-constrained
                    environmental sensing scenarios such as intelligent security, micro-UAVs, and
                    micro-robots.
                </p>
            </div>
        </dd>
        <dt><a name="item716">[716]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03008"
                    title="Abstract">arXiv:2405.03008</a> (cross-list from eess.IV) [<a href="/pdf/2405.03008"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03008" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DVMSR: Distillated Vision Mamba for Efficient
                    Super-Resolution
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Lei%2C+X">Xiaoyan Lei</a>,
                    <a href="/search/eess?searchtype=author&amp;query=ZHang%2C+W">Wenlong ZHang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Cao%2C+W">Weifeng Cao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 8 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Efficient Image Super-Resolution (SR) aims to accelerate SR network inference
                    by minimizing computational complexity and network parameters while preserving
                    performance. Existing state-of-the-art Efficient Image Super-Resolution methods
                    are based on convolutional neural networks. Few attempts have been made with
                    Mamba to harness its long-range modeling capability and efficient computational
                    complexity, which have shown impressive performance on high-level vision tasks.
                    In this paper, we propose DVMSR, a novel lightweight Image SR network that
                    incorporates Vision Mamba and a distillation strategy. The network of DVMSR
                    consists of three modules: feature extraction convolution, multiple stacked
                    Residual State Space Blocks (RSSBs), and a reconstruction module. Specifically,
                    the deep feature extraction module is composed of several residual state space
                    blocks (RSSB), each of which has several Vision Mamba Moudles(ViMM) together
                    with a residual connection. To achieve efficiency improvement while maintaining
                    comparable performance, we employ a distillation strategy to the vision Mamba
                    network for superior performance. Specifically, we leverage the rich
                    representation knowledge of teacher network as additional supervision for the
                    output of lightweight student networks. Extensive experiments have demonstrated
                    that our proposed DVMSR can outperform state-of-the-art efficient SR methods in
                    terms of model parameters while maintaining the performance of both PSNR and
                    SSIM. The source code is available at https://github.com/nathan66666/DVMSR.git
                </p>
            </div>
        </dd>
        <dt><a name="item717">[717]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03054"
                    title="Abstract">arXiv:2405.03054</a> (cross-list from quant-ph) [<a href="/pdf/2405.03054"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03054" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Greedy Quantum Route-Generation Algorithm
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/quant-ph?searchtype=author&amp;query=Makansi%2C+J">Jordan Makansi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics
                        (quant-ph)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">Routing and scheduling problems with time windows have long been important
                    optimization problems for logistics and planning. Many classical heuristics and
                    exact methods exist for such problems. However, there are no satisfactory
                    methods for generating routes using quantum computing (QC), for mainly two
                    reasons: inequality constraints, and the trade-off of feasibility and solution
                    quality. Inequality constraints are typically handled using slack variables;
                    and feasible solutions are found by filtering samples. These challenges are
                    amplified in the presence of noise inherent in QC. Here, we propose a greedy
                    algorithm that generates routes by using information from all samples obtained
                    from the quantum computer. By noticing the relationship between qubits in our
                    formulation as a directed acyclic graph (DAG), we designed an algorithm that
                    adaptively constructs a feasible solution.
                    <br>We prove its convergence to a feasible solution, and illustrate its efficacy
                    by solving the Fleet Sizing Vehicle Routing Problem with Time Windows
                    (FSVRPTW). Our computational results show that this method obtains a lower
                    objective value than the current state-of-the-art annealing approaches, both
                    classical and hybrid, for the same amount of time using D-Wave Hybrid Solvers.
                    We also show its robustness to noise on D-Wave Advantage 4.1 through
                    computational results as compared to the filtering approach on DWaveSampler,
                    even when the filtering approach is given a longer annealing time, and a larger
                    sample size.
                </p>
            </div>
        </dd>
        <dt><a name="item718">[718]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03063"
                    title="Abstract">arXiv:2405.03063</a> (cross-list from math.ST) [<a href="/pdf/2405.03063"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03063" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Stability of a Generalized Debiased Lasso with Applications
                    to Resampling-Based Variable Selection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Liu%2C+J">Jingbo Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory
                        (math.ST)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Methodology (stat.ME);
                    Machine Learning (stat.ML)

                </div>
                <p class="mathjax">Suppose that we first apply the Lasso to a design matrix, and then update one
                    of its columns. In general, the signs of the Lasso coefficients may change, and
                    there is no closed-form expression for updating the Lasso solution exactly. In
                    this work, we propose an approximate formula for updating a debiased Lasso
                    coefficient. We provide general nonasymptotic error bounds in terms of the
                    norms and correlations of a given design matrix's columns, and then prove
                    asymptotic convergence results for the case of a random design matrix with
                    i.i.d.\ sub-Gaussian row vectors and i.i.d.\ Gaussian noise. Notably, the
                    approximate formula is asymptotically correct for most coordinates in the
                    proportional growth regime, under the mild assumption that each row of the
                    design matrix is sub-Gaussian with a covariance matrix having a bounded
                    condition number. Our proof only requires certain concentration and
                    anti-concentration properties to control various error terms and the number of
                    sign changes. In contrast, rigorously establishing distributional limit
                    properties (e.g.\ Gaussian limits for the debiased Lasso) under similarly
                    general assumptions has been considered open problem in the universality
                    theory. As applications, we show that the approximate formula allows us to
                    reduce the computation complexity of variable selection algorithms that require
                    solving multiple Lasso problems, such as the conditional randomization test and
                    a variant of the knockoff filter.
                </p>
            </div>
        </dd>
        <dt><a name="item719">[719]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03069"
                    title="Abstract">arXiv:2405.03069</a> (cross-list from math.LO) [<a href="/pdf/2405.03069"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.03069" title="Download PostScript">ps</a>, <a
                    href="/format/2405.03069" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On Probabilistic and Causal Reasoning with Summation
                    Operators
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Ibeling%2C+D">Duligur Ibeling</a>,
                    <a href="/search/math?searchtype=author&amp;query=Icard%2C+T+F">Thomas F. Icard</a>,
                    <a href="/search/math?searchtype=author&amp;query=Moss%C3%A9%2C+M">Milan Mossé</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>;
                    Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Logic in Computer Science (cs.LO)

                </div>
                <p class="mathjax">Ibeling et al. (2023). axiomatize increasingly expressive languages of
                    causation and probability, and Mosse et al. (2024) show that reasoning
                    (specifically the satisfiability problem) in each causal language is as
                    difficult, from a computational complexity perspective, as reasoning in its
                    merely probabilistic or "correlational" counterpart. Introducing a summation
                    operator to capture common devices that appear in applications -- such as the
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-368-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2344"
                                style="width: 1.218em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.987em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.99em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2345"><span class="mi" id="MathJax-Span-2346"
                                                style="font-family: MathJax_Math-italic;">d<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mi" id="MathJax-Span-2347"
                                                style="font-family: MathJax_Math-italic;">o</span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-368">do</script>-calculus of Pearl (2009) for causal
                    inference, which makes ample use of
                    marginalization -- van der Zander et al. (2023) partially extend these earlier
                    complexity results to causal and probabilistic languages with marginalization.
                    We complete this extension, fully characterizing the complexity of
                    probabilistic and causal reasoning with summation, demonstrating that these
                    again remain equally difficult. Surprisingly, allowing free variables for
                    random variable values results in a system that is undecidable, so long as the
                    ranges of these random variables are unrestricted. We finally axiomatize these
                    languages featuring marginalization (or more generally summation), resolving
                    open questions posed by Ibeling et al. (2023).
                </p>
            </div>
        </dd>
        <dt><a name="item720">[720]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03083"
                    title="Abstract">arXiv:2405.03083</a> (cross-list from stat.ME) [<a href="/pdf/2405.03083"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03083" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Causal K-Means Clustering
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Kim%2C+K">Kwangho Kim</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Kim%2C+J">Jisu Kim</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Kennedy%2C+E+H">Edward H. Kennedy</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology
                        (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

                </div>
                <p class="mathjax">Causal effects are often characterized with population summaries. These might
                    provide an incomplete picture when there are heterogeneous treatment effects
                    across subgroups. Since the subgroup structure is typically unknown, it is more
                    challenging to identify and evaluate subgroup effects than population effects.
                    We propose a new solution to this problem: Causal k-Means Clustering, which
                    harnesses the widely-used k-means clustering algorithm to uncover the unknown
                    subgroup structure. Our problem differs significantly from the conventional
                    clustering setup since the variables to be clustered are unknown counterfactual
                    functions. We present a plug-in estimator which is simple and readily
                    implementable using off-the-shelf algorithms, and study its rate of
                    convergence. We also develop a new bias-corrected estimator based on
                    nonparametric efficiency theory and double machine learning, and show that this
                    estimator achieves fast root-n rates and asymptotic normality in large
                    nonparametric models. Our proposed methods are especially useful for modern
                    outcome-wide studies with multiple treatment levels. Further, our framework is
                    extensible to clustering with generic pseudo-outcomes, such as partially
                    observed outcomes or otherwise unknown functions. Finally, we explore finite
                    sample properties via simulation, and illustrate the proposed methods in a
                    study of treatment programs for adolescent substance abuse.
                </p>
            </div>
        </dd>
        <dt><a name="item721">[721]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03092"
                    title="Abstract">arXiv:2405.03092</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2405.03092"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03092" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bayesian optimization for stable properties amid processing
                    fluctuations in sputter deposition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cond-mat?searchtype=author&amp;query=Shrivastava%2C+A">Ankit Shrivastava</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Kalaswad%2C+M">Matias Kalaswad</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Custer%2C+J+O">Joyce O. Custer</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Adams%2C+D+P">David P. Adams</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Najm%2C+H+N">Habib N. Najm</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> J. Vac. Sci. Technol. A 1 May 2024; 42 (3): 033408
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science
                        (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

                </div>
                <p class="mathjax">We introduce a Bayesian optimization approach to guide the sputter deposition
                    of molybdenum thin films, aiming to achieve desired residual stress and sheet
                    resistance while minimizing susceptibility to stochastic fluctuations during
                    deposition. Thin films are pivotal in numerous technologies, including
                    semiconductors and optical devices, where their properties are critical.
                    Sputter deposition parameters, such as deposition power, vacuum chamber
                    pressure, and working distance, influence physical properties like residual
                    stress and resistance. Excessive stress and high resistance can impair device
                    performance, necessitating the selection of optimal process parameters.
                    Furthermore, these parameters should ensure the consistency and reliability of
                    thin film properties, assisting in the reproducibility of the devices. However,
                    exploring the multidimensional design space for process optimization is
                    expensive. Bayesian optimization is ideal for optimizing inputs/parameters of
                    general black-box functions without reliance on gradient information. We
                    utilize Bayesian optimization to optimize deposition power and pressure using a
                    custom-built objective function incorporating observed stress and resistance
                    data. Additionally, we integrate prior knowledge of stress variation with
                    pressure into the objective function to prioritize films least affected by
                    stochastic variations. Our findings demonstrate that Bayesian optimization
                    effectively explores the design space and identifies optimal parameter
                    combinations meeting desired stress and resistance specifications.
                </p>
            </div>
        </dd>
        <dt><a name="item722">[722]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03123"
                    title="Abstract">arXiv:2405.03123</a> (cross-list from math.OC) [<a href="/pdf/2405.03123"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03123" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Revealing Decision Conservativeness Through Inverse
                    Distributionally Robust Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Li%2C+Q">Qi Li</a>,
                    <a href="/search/math?searchtype=author&amp;query=Liang%2C+Z">Zhirui Liang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Bernstein%2C+A">Andrey Bernstein</a>,
                    <a href="/search/math?searchtype=author&amp;query=Dvorkin%2C+Y">Yury Dvorkin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">This paper introduces Inverse Distributionally Robust Optimization (I-DRO) as
                    a method to infer the conservativeness level of a decision-maker, represented
                    by the size of a Wasserstein metric-based ambiguity set, from the optimal
                    decisions made using Forward Distributionally Robust Optimization (F-DRO). By
                    leveraging the Karush-Kuhn-Tucker (KKT) conditions of the convex F-DRO model,
                    we formulate I-DRO as a bi-linear program, which can be solved using
                    off-the-shelf optimization solvers. Additionally, this formulation exhibits
                    several advantageous properties. We demonstrate that I-DRO not only guarantees
                    the existence and uniqueness of an optimal solution but also establishes the
                    necessary and sufficient conditions for this optimal solution to accurately
                    match the actual conservativeness level in F-DRO. Furthermore, we identify
                    three extreme scenarios that may impact I-DRO effectiveness. Our case study
                    applies F-DRO for power system scheduling under uncertainty and employs I-DRO
                    to recover the conservativeness level of system operators. Numerical
                    experiments based on an IEEE 5-bus system and a realistic NYISO 11-zone system
                    demonstrate I-DRO performance in both normal and extreme scenarios.
                </p>
            </div>
        </dd>
        <dt><a name="item723">[723]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03129"
                    title="Abstract">arXiv:2405.03129</a> (cross-list from eess.SP) [<a href="/pdf/2405.03129"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03129" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Active Sensing for Multiuser Beam Tracking with
                    Reconfigurable Intelligent Surface
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Han%2C+H">Han Han</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Jiang%2C+T">Tao Jiang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yu%2C+W">Wei Yu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Information Theory (cs.IT)

                </div>
                <p class="mathjax">This paper studies a beam tracking problem in which an access point (AP), in
                    collaboration with a reconfigurable intelligent surface (RIS), dynamically
                    adjusts its downlink beamformers and the reflection pattern at the RIS in order
                    to maintain reliable communications with multiple mobile user equipments (UEs).
                    Specifically, the mobile UEs send uplink pilots to the AP periodically during
                    the channel sensing intervals, the AP then adaptively configures the
                    beamformers and the RIS reflection coefficients for subsequent data
                    transmission based on the received pilots. This is an active sensing problem,
                    because channel sensing involves configuring the RIS coefficients during the
                    pilot stage and the optimal sensing strategy should exploit the trajectory of
                    channel state information (CSI) from previously received pilots. Analytical
                    solution to such an active sensing problem is very challenging. In this paper,
                    we propose a deep learning framework utilizing a recurrent neural network (RNN)
                    to automatically summarize the time-varying CSI obtained from the periodically
                    received pilots into state vectors. These state vectors are then mapped to the
                    AP beamformers and RIS reflection coefficients for subsequent downlink data
                    transmissions, as well as the RIS reflection coefficients for the next round of
                    uplink channel sensing. The mappings from the state vectors to the downlink
                    beamformers and the RIS reflection coefficients for both channel sensing and
                    downlink data transmission are performed using graph neural networks (GNNs) to
                    account for the interference among the UEs. Simulations demonstrate significant
                    and interpretable performance improvement of the proposed approach over the
                    existing data-driven methods with nonadaptive channel sensing schemes.
                </p>
            </div>
        </dd>
        <dt><a name="item724">[724]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03130"
                    title="Abstract">arXiv:2405.03130</a> (cross-list from stat.ML) [<a href="/pdf/2405.03130"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03130" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Learning for Causal Inference: A Comparison of
                    Architectures for Heterogeneous Treatment Effect Estimation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Papakostas%2C+D">Demetrios Papakostas</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Herren%2C+A">Andrew Herren</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Hahn%2C+P+R">P. Richard Hahn</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Castillo%2C+F">Francisco Castillo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Causal inference has gained much popularity in recent years, with interests
                    ranging from academic, to industrial, to educational, and all in between.
                    Concurrently, the study and usage of neural networks has also grown profoundly
                    (albeit at a far faster rate). What we aim to do in this blog write-up is
                    demonstrate a Neural Network causal inference architecture. We develop a fully
                    connected neural network implementation of the popular Bayesian Causal Forest
                    algorithm, a state of the art tree based method for estimating heterogeneous
                    treatment effects. We compare our implementation to existing neural network
                    causal inference methodologies, showing improvements in performance in
                    simulation settings. We apply our method to a dataset examining the effect of
                    stress on sleep.
                </p>
            </div>
        </dd>
        <dt><a name="item725">[725]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03141"
                    title="Abstract">arXiv:2405.03141</a> (cross-list from eess.IV) [<a href="/pdf/2405.03141"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03141" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Automatic Ultrasound Curve Angle Measurement via Affinity
                    Clustering for Adolescent Idiopathic Scoliosis Evaluation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Zhou%2C+Y">Yihao Zhou</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Lee%2C+T+T">Timothy Tin-Yan Lee</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Lai%2C+K+K">Kelly Ka-Lee Lai</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wu%2C+C">Chonglin Wu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Lau%2C+H+T">Hin Ting Lau</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Yang%2C+D">De Yang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Chan%2C+C">Chui-Yi Chan</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Chu%2C+W+C">Winnie Chiu-Wing Chu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Cheng%2C+J+C">Jack Chun-Yiu Cheng</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Lam%2C+T">Tsz-Ping Lam</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Zheng%2C+Y">Yong-Ping Zheng</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition
                    (cs.CV); Medical Physics (physics.med-ph)

                </div>
                <p class="mathjax">The current clinical gold standard for evaluating adolescent idiopathic
                    scoliosis (AIS) is X-ray radiography, using Cobb angle measurement. However,
                    the frequent monitoring of the AIS progression using X-rays poses a challenge
                    due to the cumulative radiation exposure. Although 3D ultrasound has been
                    validated as a reliable and radiation-free alternative for scoliosis
                    assessment, the process of measuring spinal curvature is still carried out
                    manually. Consequently, there is a considerable demand for a fully automatic
                    system that can locate bony landmarks and perform angle measurements. To this
                    end, we introduce an estimation model for automatic ultrasound curve angle
                    (UCA) measurement. The model employs a dual-branch network to detect candidate
                    landmarks and perform vertebra segmentation on ultrasound coronal images. An
                    affinity clustering strategy is utilized within the vertebral segmentation area
                    to illustrate the affinity relationship between candidate landmarks.
                    Subsequently, we can efficiently perform line delineation from a clustered
                    affinity map for UCA measurement. As our method is specifically designed for
                    UCA calculation, this method outperforms other state-of-the-art methods for
                    landmark and line detection tasks. The high correlation between the automatic
                    UCA and Cobb angle (R<span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-369-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2348"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1000.41em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2349"><span class="msubsup"
                                                id="MathJax-Span-2350"><span
                                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.822em, 1000em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2351"></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0em;"><span
                                                            class="mn" id="MathJax-Span-2352"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-369">^2</script>=0.858) suggests that our proposed
                    method can
                    potentially replace manual UCA measurement in ultrasound scoliosis assessment.
                </p>
            </div>
        </dd>
        <dt><a name="item726">[726]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03180"
                    title="Abstract">arXiv:2405.03180</a> (cross-list from stat.ML) [<a href="/pdf/2405.03180"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03180" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Braced Fourier Continuation and Regression for Anomaly
                    Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Sabuda%2C+J">Josef Sabuda</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages, 9 figures, associated Github link: <a
                        href="https://github.com/j4sabuda/Braced-Fourier-Continuation-and-Regression">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">In this work, the concept of Braced Fourier Continuation and Regression
                    (BFCR) is introduced. BFCR is a novel and computationally efficient means of
                    finding nonlinear regressions or trend lines in arbitrary one-dimensional data
                    sets. The Braced Fourier Continuation (BFC) and BFCR algorithms are first
                    outlined, followed by a discussion of the properties of BFCR as well as
                    demonstrations of how BFCR trend lines may be used effectively for anomaly
                    detection both within and at the edges of arbitrary one-dimensional data sets.
                    Finally, potential issues which may arise while using BFCR for anomaly
                    detection as well as possible mitigation techniques are outlined and discussed.
                    All source code and example data sets are either referenced or available via
                    GitHub, and all associated code is written entirely in Python.
                </p>
            </div>
        </dd>
        <dt><a name="item727">[727]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03198"
                    title="Abstract">arXiv:2405.03198</a> (cross-list from stat.ML) [<a href="/pdf/2405.03198"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03198" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Stability Evaluation via Distributional Perturbation Analysis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Blanchet%2C+J">Jose Blanchet</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Cui%2C+P">Peng Cui</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Li%2C+J">Jiajin Li</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Liu%2C+J">Jiashuo Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

                </div>
                <p class="mathjax">The performance of learning models often deteriorates when deployed in
                    out-of-sample environments. To ensure reliable deployment, we propose a
                    stability evaluation criterion based on distributional perturbations.
                    Conceptually, our stability evaluation criterion is defined as the minimal
                    perturbation required on our observed dataset to induce a prescribed
                    deterioration in risk evaluation. In this paper, we utilize the optimal
                    transport (OT) discrepancy with moment constraints on the \textit{(sample,
                    density)} space to quantify this perturbation. Therefore, our stability
                    evaluation criterion can address both \emph{data corruptions} and
                    \emph{sub-population shifts} -- the two most common types of distribution
                    shifts in real-world scenarios. To further realize practical benefits, we
                    present a series of tractable convex formulations and computational methods
                    tailored to different classes of loss functions. The key technical tool to
                    achieve this is the strong duality theorem provided in this paper. Empirically,
                    we validate the practical utility of our stability evaluation criterion across
                    a host of real-world applications. These empirical studies showcase the
                    criterion's ability not only to compare the stability of different learning
                    models and features but also to provide valuable guidelines and strategies to
                    further improve models.
                </p>
            </div>
        </dd>
        <dt><a name="item728">[728]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03230"
                    title="Abstract">arXiv:2405.03230</a> (cross-list from eess.SP) [<a href="/pdf/2405.03230"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03230" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Slicing for Dense Smart Factory Network: Current State,
                    Scenarios, Challenges and Expectations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Ochonu%2C+R">Regina Ochonu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Vidal%2C+J">Josep Vidal</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to IEEE ETFA 2024 - IEEE International
                    Conference on Emerging Technologies and Factory Automation, 8 Pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Systems and Control (eess.SY)

                </div>
                <p class="mathjax">In the era of Industry 4.0, smart factories have emerged as a paradigm shift,
                    redefining manufacturing with the integration of advanced digital technologies.
                    Central to this transformation is the deployment of 5G networks, offering
                    unprecedented levels of connectivity, speed, reliability, and ultra-low
                    latency. Among the revolutionary features of 5G is network slicing, a
                    technology that offers enhanced capabilities through the customization of
                    network resources by allowing multiple logical networks (or slices) to run on
                    top of a shared physical infrastructure. This capability is particularly
                    crucial in the densely packed and highly dynamic environment of smart
                    factories, where diverse applications - from robotic automation to real-time
                    analytics - demand varying network requirements. In this paper, we present a
                    comprehensive overview of the integration of slicing in smart factory networks,
                    emphasizing its critical role in enhancing operational efficiency and
                    supporting the diverse requirements of future manufacturing processes. We
                    elaborate on the recent advances, and technical scenarios, including indoor
                    factory propagation conditions, traffic characteristics, system requirements,
                    slice-aware radio resource management, network elements, enabling technologies
                    and current standardisation efforts. Additionally, we identify open research
                    challenges as well as key technical issues stifling deployments. Finally, we
                    speculate on the future trajectory of slicing-enabled smart factories,
                    emphasizing the need for continuous adaptation to emerging technologies.
                </p>
            </div>
        </dd>
        <dt><a name="item729">[729]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03270"
                    title="Abstract">arXiv:2405.03270</a> (cross-list from math.CO) [<a href="/pdf/2405.03270"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.03270" title="Download PostScript">ps</a>, <a
                    href="/format/2405.03270" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Matroid-reachability-based decomposition into arborescences
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=H%C3%B6rsch%2C+F">Florian Hörsch</a>,
                    <a href="/search/math?searchtype=author&amp;query=Peyrille%2C+B">Benjamin Peyrille</a>,
                    <a href="/search/math?searchtype=author&amp;query=Szigeti%2C+Z">Zoltán Szigeti</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics
                        (math.CO)</span>; Discrete Mathematics (cs.DM)

                </div>
                <p class="mathjax">The problem of matroid-reachability-based packing of arborescences was solved
                    by Kir\'aly. Here we solve the corresponding decomposition problem that turns
                    out to be more complicated. The result is obtained from the solution of the
                    more general problem of matroid-reachability-based <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-370-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2353"
                                style="width: 2.896em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.376em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.26em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2354"><span class="mo" id="MathJax-Span-2355"
                                                style="font-family: MathJax_Main;">(</span><span class="mi"
                                                id="MathJax-Span-2356" style="font-family: MathJax_Main;">ℓ</span><span
                                                class="mo" id="MathJax-Span-2357"
                                                style="font-family: MathJax_Main;">,</span><span class="msup"
                                                id="MathJax-Span-2358" style="padding-left: 0.177em;"><span
                                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2359"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mo" id="MathJax-Span-2360"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">′</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-2361"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-370">(\ell,\ell')</script>-limited
                    packing of arborescences where we are given a lower bound <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-371-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2362"
                                style="width: 0.524em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.408em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.41em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2363"><span class="mi" id="MathJax-Span-2364"
                                                style="font-family: MathJax_Main;">ℓ</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-371">\ell</script> and an upper
                    bound <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-372-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2365"
                                style="width: 0.871em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.061em, 1000.7em, 1.16em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2366"><span class="msup"
                                                id="MathJax-Span-2367"><span
                                                    style="display: inline-block; position: relative; width: 0.697em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.41em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2368"
                                                            style="font-family: MathJax_Main;">ℓ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.408em;"><span
                                                            class="mo" id="MathJax-Span-2369"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">′</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-372">\ell'</script> on the total number of arborescences
                    in the packing. The problem
                    is considered for branchings and in directed hypergraphs as well.
                </p>
            </div>
        </dd>
        <dt><a name="item730">[730]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03293"
                    title="Abstract">arXiv:2405.03293</a> (cross-list from astro-ph.IM) [<a href="/pdf/2405.03293"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03293" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Learning and genetic algorithms for cosmological
                    Bayesian inference speed-up
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/astro-ph?searchtype=author&amp;query=G%C3%B3mez-Vargas%2C+I">Isidro
                        Gómez-Vargas</a>,
                    <a href="/search/astro-ph?searchtype=author&amp;query=V%C3%A1zquez%2C+J+A">J. Alberto Vázquez</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods
                        for Astrophysics (astro-ph.IM)</span>; Cosmology and Nongalactic Astrophysics (astro-ph.CO);
                    Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

                </div>
                <p class="mathjax">In this paper, we present a novel approach to accelerate the Bayesian
                    inference process, focusing specifically on the nested sampling algorithms.
                    Bayesian inference plays a crucial role in cosmological parameter estimation,
                    providing a robust framework for extracting theoretical insights from
                    observational data. However, its computational demands can be substantial,
                    primarily due to the need for numerous likelihood function evaluations. Our
                    proposed method utilizes the power of deep learning, employing feedforward
                    neural networks to approximate the likelihood function dynamically during the
                    Bayesian inference process. Unlike traditional approaches, our method trains
                    neural networks on-the-fly using the current set of live points as training
                    data, without the need for pre-training. This flexibility enables adaptation to
                    various theoretical models and datasets. We perform simple hyperparameter
                    optimization using genetic algorithms to suggest initial neural network
                    architectures for learning each likelihood function. Once sufficient accuracy
                    is achieved, the neural network replaces the original likelihood function. The
                    implementation integrates with nested sampling algorithms and has been
                    thoroughly evaluated using both simple cosmological dark energy models and
                    diverse observational datasets. Additionally, we explore the potential of
                    genetic algorithms for generating initial live points within nested sampling
                    inference, opening up new avenues for enhancing the efficiency and
                    effectiveness of Bayesian inference methods.
                </p>
            </div>
        </dd>
        <dt><a name="item731">[731]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03347"
                    title="Abstract">arXiv:2405.03347</a> (cross-list from math.NT) [<a href="/pdf/2405.03347"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.03347" title="Download PostScript">ps</a>, <a
                    href="/format/2405.03347" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Perfect codes over non-prime power alphabets: an approach
                    based on Diophantine equations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Garc%C3%ADa%2C+P+C">Pedro-José Cazorla García</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory
                        (math.NT)</span>; Information Theory (cs.IT)

                </div>
                <p class="mathjax">The classification of perfect codes over non-prime power alphabets has been
                    an open problem for which there have been no new results in almost <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-373-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2370"
                                style="width: 1.218em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.987em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.93em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2371"><span class="mn" id="MathJax-Span-2372"
                                                style="font-family: MathJax_Main;">50</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-373">50</script> years.
                    In this paper, we show non-existence of perfect <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-374-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2373"
                                style="width: 1.565em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.276em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1001.22em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2374"><span class="mn" id="MathJax-Span-2375"
                                                style="font-family: MathJax_Main;">2</span><span class="mo"
                                                id="MathJax-Span-2376"
                                                style="font-family: MathJax_Main;">−</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-374">2-</script>error correcting codes over
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-375-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2377"
                                style="width: 1.508em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.218em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.392em, 1001.16em, 2.491em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2378"><span class="mi" id="MathJax-Span-2379"
                                                style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span
                                                class="mo" id="MathJax-Span-2380"
                                                style="font-family: MathJax_Main;">−</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 1.045em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-375">q-</script>ary alphabets for more than 170 new
                    values of <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-376-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2381"
                                style="width: 0.582em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.466em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1000.47em, 2.26em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2382"><span class="mi" id="MathJax-Span-2383"
                                                style="font-family: MathJax_Math-italic;">q<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.274em; border-left: 0px solid; width: 0px; height: 0.906em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-376">q</script>. Our methods rely on
                    techniques from the resolution of generalised Ramanujan--Nagell equations and
                    from computational number theory.
                </p>
            </div>
        </dd>
        <dt><a name="item732">[732]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03408"
                    title="Abstract">arXiv:2405.03408</a> (cross-list from astro-ph.IM) [<a href="/pdf/2405.03408"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03408" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Image Quality Evaluation and Masking Algorithm Based On
                    Pre-trained Deep Neural Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/astro-ph?searchtype=author&amp;query=Jia%2C+P">Peng Jia</a>,
                    <a href="/search/astro-ph?searchtype=author&amp;query=Song%2C+Y">Yu Song</a>,
                    <a href="/search/astro-ph?searchtype=author&amp;query=Lv%2C+J">Jiameng Lv</a>,
                    <a href="/search/astro-ph?searchtype=author&amp;query=Ning%2C+R">Runyu Ning</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by the AJ. The code could be downloaded from: <a
                        href="https://nadc.china-vo.org/res/r101415/">this https URL</a> with DOI of: 10.12149/101415
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods
                        for Astrophysics (astro-ph.IM)</span>; Solar and Stellar Astrophysics (astro-ph.SR); Computer
                    Vision and Pattern Recognition (cs.CV)

                </div>
                <p class="mathjax">With the growing amount of astronomical data, there is an increasing need for
                    automated data processing pipelines, which can extract scientific information
                    from observation data without human interventions. A critical aspect of these
                    pipelines is the image quality evaluation and masking algorithm, which
                    evaluates image qualities based on various factors such as cloud coverage, sky
                    brightness, scattering light from the optical system, point spread function
                    size and shape, and read-out noise. Occasionally, the algorithm requires
                    masking of areas severely affected by noise. However, the algorithm often
                    necessitates significant human interventions, reducing data processing
                    efficiency. In this study, we present a deep learning based image quality
                    evaluation algorithm that uses an autoencoder to learn features of high quality
                    astronomical images. The trained autoencoder enables automatic evaluation of
                    image quality and masking of noise affected areas. We have evaluated the
                    performance of our algorithm using two test cases: images with point spread
                    functions of varying full width half magnitude, and images with complex
                    backgrounds. In the first scenario, our algorithm could effectively identify
                    variations of the point spread functions, which can provide valuable reference
                    information for photometry. In the second scenario, our method could
                    successfully mask regions affected by complex regions, which could
                    significantly increase the photometry accuracy. Our algorithm can be employed
                    to automatically evaluate image quality obtained by different sky surveying
                    projects, further increasing the speed and robustness of data processing
                    pipelines.
                </p>
            </div>
        </dd>
        <dt><a name="item733">[733]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03435"
                    title="Abstract">arXiv:2405.03435</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2405.03435"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03435" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A method for quantifying the generalization capabilities of
                    generative models for solving Ising models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cond-mat?searchtype=author&amp;query=Ma%2C+Q">Qunlong Ma</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Ma%2C+Z">Zhi Ma</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Gao%2C+M">Ming Gao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages, 7 figures
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Mach. Learn.: Sci. Technol. 5 (2024) 025011
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and
                        Neural Networks (cond-mat.dis-nn)</span>; Artificial Intelligence (cs.AI); Machine Learning
                    (cs.LG)

                </div>
                <p class="mathjax">For Ising models with complex energy landscapes, whether the ground state can
                    be found by neural networks depends heavily on the Hamming distance between the
                    training datasets and the ground state. Despite the fact that various recently
                    proposed generative models have shown good performance in solving Ising models,
                    there is no adequate discussion on how to quantify their generalization
                    capabilities. Here we design a Hamming distance regularizer in the framework of
                    a class of generative models, variational autoregressive networks (VAN), to
                    quantify the generalization capabilities of various network architectures
                    combined with VAN. The regularizer can control the size of the overlaps between
                    the ground state and the training datasets generated by networks, which,
                    together with the success rates of finding the ground state, form a
                    quantitative metric to quantify their generalization capabilities. We conduct
                    numerical experiments on several prototypical network architectures combined
                    with VAN, including feed-forward neural networks, recurrent neural networks,
                    and graph neural networks, to quantify their generalization capabilities when
                    solving Ising models. Moreover, considering the fact that the quantification of
                    the generalization capabilities of networks on small-scale problems can be used
                    to predict their relative performance on large-scale problems, our method is of
                    great significance for assisting in the Neural Architecture Search field of
                    searching for the optimal network architectures when solving large-scale Ising
                    models.
                </p>
            </div>
        </dd>
        <dt><a name="item734">[734]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03468"
                    title="Abstract">arXiv:2405.03468</a> (cross-list from stat.ML) [<a href="/pdf/2405.03468"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03468" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Hierarchic Flows to Estimate and Sample High-dimensional
                    Probabilities
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Lempereur%2C+E">Etienne Lempereur</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Mallat%2C+S">Stéphane Mallat</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn)

                </div>
                <p class="mathjax">Finding low-dimensional interpretable models of complex physical fields such
                    as turbulence remains an open question, 80 years after the pioneer work of
                    Kolmogorov. Estimating high-dimensional probability distributions from data
                    samples suffers from an optimization and an approximation curse of
                    dimensionality. It may be avoided by following a hierarchic probability flow
                    from coarse to fine scales. This inverse renormalization group is defined by
                    conditional probabilities across scales, renormalized in a wavelet basis. For a
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-377-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2384"
                                style="width: 1.334em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(-0.055em, 1001.1em, 1.392em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2385"><span class="msubsup"
                                                id="MathJax-Span-2386"><span
                                                    style="display: inline-block; position: relative; width: 1.102em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.359em, 1000.64em, 4.401em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2387"
                                                            style="font-family: MathJax_Math-italic;">φ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.639em;"><span
                                                            class="mn" id="MathJax-Span-2388"
                                                            style="font-size: 70.7%; font-family: MathJax_Main;">4</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-377">\varphi^4</script> scalar potential, sampling these
                    hierarchic models avoids the
                    critical slowing down at the phase transition. An outstanding issue is to also
                    approximate non-Gaussian fields having long-range interactions in space and
                    across scales. We introduce low-dimensional models with robust multiscale
                    approximations of high order polynomial energies. They are calculated with a
                    second wavelet transform, which defines interactions over two hierarchies of
                    scales. We estimate and sample these wavelet scattering models to generate 2D
                    vorticity fields of turbulence, and images of dark matter densities.
                </p>
            </div>
        </dd>
        <dt><a name="item735">[735]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03472"
                    title="Abstract">arXiv:2405.03472</a> (cross-list from math.OC) [<a href="/pdf/2405.03472"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03472" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Symplectic Analysis of Alternating Mirror Descent
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Katona%2C+J">Jonas Katona</a>,
                    <a href="/search/math?searchtype=author&amp;query=Wang%2C+X">Xiuyuan Wang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Wibisono%2C+A">Andre Wibisono</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 95 pages, 3 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Dynamical
                    Systems (math.DS); Numerical Analysis (math.NA)

                </div>
                <p class="mathjax">Motivated by understanding the behavior of the Alternating Mirror Descent
                    (AMD) algorithm for bilinear zero-sum games, we study the discretization of
                    continuous-time Hamiltonian flow via the symplectic Euler method. We provide a
                    framework for analysis using results from Hamiltonian dynamics, Lie algebra,
                    and symplectic numerical integrators, with an emphasis on the existence and
                    properties of a conserved quantity, the modified Hamiltonian (MH), for the
                    symplectic Euler method. We compute the MH in closed-form when the original
                    Hamiltonian is a quadratic function, and show that it generally differs from
                    the other conserved quantity known previously in that case. We derive new error
                    bounds on the MH when truncated at orders in the stepsize in terms of the
                    number of iterations, <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-378-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2389"
                                style="width: 1.16em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 0.929em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.045em, 1000.93em, 2.086em, -999.997em); top: -1.907em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2390"><span class="mi" id="MathJax-Span-2391"
                                                style="font-family: MathJax_Math-italic;">K<span
                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.913em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-378">K</script>, and utilize this bound to show an
                    improved
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-379-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2392"
                                style="width: 4.401em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.649em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1003.53em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2393"><span class="texatom"
                                                id="MathJax-Span-2394"><span class="mrow" id="MathJax-Span-2395"><span
                                                        class="mi" id="MathJax-Span-2396"
                                                        style="font-family: MathJax_Caligraphic;">O</span></span></span><span
                                                class="mo" id="MathJax-Span-2397"
                                                style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                id="MathJax-Span-2398"><span
                                                    style="display: inline-block; position: relative; width: 2.086em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2399"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.929em;"><span
                                                            class="texatom" id="MathJax-Span-2400"><span class="mrow"
                                                                id="MathJax-Span-2401"><span class="mn"
                                                                    id="MathJax-Span-2402"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                    class="texatom" id="MathJax-Span-2403"><span
                                                                        class="mrow" id="MathJax-Span-2404"><span
                                                                            class="mo" id="MathJax-Span-2405"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="mn" id="MathJax-Span-2406"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">5</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-2407"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.531em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-379">\mathcal{O}(K^{1/5})</script> total regret bound
                    and an <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-380-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2408"
                                style="width: 5.095em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.227em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1004.11em, 2.549em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2409"><span class="texatom"
                                                id="MathJax-Span-2410"><span class="mrow" id="MathJax-Span-2411"><span
                                                        class="mi" id="MathJax-Span-2412"
                                                        style="font-family: MathJax_Caligraphic;">O</span></span></span><span
                                                class="mo" id="MathJax-Span-2413"
                                                style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                id="MathJax-Span-2414"><span
                                                    style="display: inline-block; position: relative; width: 2.665em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2415"
                                                            style="font-family: MathJax_Math-italic;">K<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -4.337em; left: 0.929em;"><span
                                                            class="texatom" id="MathJax-Span-2416"><span class="mrow"
                                                                id="MathJax-Span-2417"><span class="mo"
                                                                    id="MathJax-Span-2418"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-2419"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">4</span><span
                                                                    class="texatom" id="MathJax-Span-2420"><span
                                                                        class="mrow" id="MathJax-Span-2421"><span
                                                                            class="mo" id="MathJax-Span-2422"
                                                                            style="font-size: 70.7%; font-family: MathJax_Main;">/</span></span></span><span
                                                                    class="mn" id="MathJax-Span-2423"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">5</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                class="mo" id="MathJax-Span-2424"
                                                style="font-family: MathJax_Main;">)</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.531em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-380">\mathcal{O}(K^{-4/5})</script>
                    duality gap of the average iterates for AMD. Finally, we propose a conjecture
                    which, if true, would imply that the total regret for AMD goes as
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-381-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2425"
                                style="width: 3.707em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 3.07em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.95em, 2.607em, -999.997em); top: -2.196em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2426"><span class="texatom"
                                                id="MathJax-Span-2427"><span class="mrow" id="MathJax-Span-2428"><span
                                                        class="mi" id="MathJax-Span-2429"
                                                        style="font-family: MathJax_Caligraphic;">O</span></span></span><span
                                                class="mrow" id="MathJax-Span-2430" style="padding-left: 0.177em;"><span
                                                    class="mo" id="MathJax-Span-2431"
                                                    style="font-family: MathJax_Main;">(</span><span class="msubsup"
                                                    id="MathJax-Span-2432"><span
                                                        style="display: inline-block; position: relative; width: 1.334em; height: 0px;"><span
                                                            style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                class="mi" id="MathJax-Span-2433"
                                                                style="font-family: MathJax_Math-italic;">K<span
                                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                            style="position: absolute; top: -4.337em; left: 0.929em;"><span
                                                                class="texatom" id="MathJax-Span-2434"><span
                                                                    class="mrow" id="MathJax-Span-2435"><span class="mi"
                                                                        id="MathJax-Span-2436"
                                                                        style="font-size: 70.7%; font-family: MathJax_Math-italic;">ε</span></span></span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                    class="mo" id="MathJax-Span-2437"
                                                    style="font-family: MathJax_Main;">)</span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.202em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-381">\mathcal{O}\left(K^{\varepsilon}\right)</script>
                    and the duality gap of the average
                    iterates as <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-382-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2438"
                                style="width: 5.732em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 4.748em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.218em, 1004.58em, 2.781em, -999.997em); top: -2.254em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2439"><span class="texatom"
                                                id="MathJax-Span-2440"><span class="mrow" id="MathJax-Span-2441"><span
                                                        class="mi" id="MathJax-Span-2442"
                                                        style="font-family: MathJax_Caligraphic;">O</span></span></span><span
                                                class="mrow" id="MathJax-Span-2443" style="padding-left: 0.177em;"><span
                                                    class="mo" id="MathJax-Span-2444" style="vertical-align: 0em;"><span
                                                        style="font-family: MathJax_Size1;">(</span></span><span
                                                    class="msubsup" id="MathJax-Span-2445"><span
                                                        style="display: inline-block; position: relative; width: 2.839em; height: 0px;"><span
                                                            style="position: absolute; clip: rect(3.128em, 1000.87em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                                class="mi" id="MathJax-Span-2446"
                                                                style="font-family: MathJax_Math-italic;">K<span
                                                                    style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                            style="position: absolute; top: -4.337em; left: 0.929em;"><span
                                                                class="texatom" id="MathJax-Span-2447"><span
                                                                    class="mrow" id="MathJax-Span-2448"><span class="mo"
                                                                        id="MathJax-Span-2449"
                                                                        style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                        class="mn" id="MathJax-Span-2450"
                                                                        style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span
                                                                        class="mo" id="MathJax-Span-2451"
                                                                        style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span
                                                                        class="mi" id="MathJax-Span-2452"
                                                                        style="font-size: 70.7%; font-family: MathJax_Math-italic;">ε</span></span></span><span
                                                                style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span><span
                                                    class="mo" id="MathJax-Span-2453" style="vertical-align: 0em;"><span
                                                        style="font-family: MathJax_Size1;">)</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 2.26em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.483em; border-left: 0px solid; width: 0px; height: 1.601em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-382">\mathcal{O}\left(K^{-1+\varepsilon}\right)</script>
                    for any
                    <span class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-383-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2454"
                                style="width: 2.781em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.26em, 2.376em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2455"><span class="mi" id="MathJax-Span-2456"
                                                style="font-family: MathJax_Math-italic;">ε</span><span class="mo"
                                                id="MathJax-Span-2457"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">&gt;</span><span
                                                class="mn" id="MathJax-Span-2458"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">0</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.135em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-383">\varepsilon>0</script>, and we can take <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-384-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2459"
                                style="width: 2.781em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 2.318em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.276em, 1002.26em, 2.318em, -999.997em); top: -2.138em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2460"><span class="mi" id="MathJax-Span-2461"
                                                style="font-family: MathJax_Math-italic;">ε</span><span class="mo"
                                                id="MathJax-Span-2462"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">=</span><span
                                                class="mn" id="MathJax-Span-2463"
                                                style="font-family: MathJax_Main; padding-left: 0.292em;">0</span></span><span
                                            style="display: inline-block; width: 0px; height: 2.144em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.066em; border-left: 0px solid; width: 0px; height: 0.976em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-384">\varepsilon=0</script> upon certain convergence
                    conditions for the MH.
                </p>
            </div>
        </dd>
        <dt><a name="item736">[736]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03517"
                    title="Abstract">arXiv:2405.03517</a> (cross-list from math.CO) [<a href="/pdf/2405.03517"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.03517" title="Download PostScript">ps</a>, <a
                    href="/format/2405.03517" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> All <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-385-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2464"
                                style="width: 1.299em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.067em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.188em, 1001.07em, 1.438em, -999.998em); top: -1.016em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2465"><span class="msubsup"
                                                id="MathJax-Span-2466"><span
                                                    style="display: inline-block; position: relative; width: 1.067em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.15em, 1000.65em, 4.123em, -999.998em); top: -3.979em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2467"
                                                            style="font-family: MathJax_Math-italic;">S<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.049em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span><span
                                                        style="position: absolute; top: -3.84em; left: 0.604em;"><span
                                                            class="mi" id="MathJax-Span-2468"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.984em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.021em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.386em; border-left: 0px solid; width: 0px; height: 1.281em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-385">S_p</script> notions of quantum expansion are
                    equivalent
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Guti%C3%A9rrez%2C+F+E">Francisco Escudero
                        Gutiérrez</a>,
                    <a href="/search/math?searchtype=author&amp;query=Muguruza%2C+G">Garazi Muguruza</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics
                        (math.CO)</span>; Discrete Mathematics (cs.DM); Functional Analysis (math.FA); Quantum Physics
                    (quant-ph)

                </div>
                <p class="mathjax">In a recent work Li, Qiao, Wigderson, Wigderson and Zhang introduced notions
                    of quantum expansion based on <span class="MathJax_Preview" style="display: none;"></span><span
                        class="MathJax" id="MathJax-Element-386-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2469"
                                style="width: 1.276em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.119em, 1001.04em, 1.45em, -999.997em); top: -0.981em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2470"><span class="msubsup"
                                                id="MathJax-Span-2471"><span
                                                    style="display: inline-block; position: relative; width: 1.045em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.128em, 1000.64em, 4.17em, -999.997em); top: -3.99em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2472"
                                                            style="font-family: MathJax_Math-italic;">S<span
                                                                style="display: inline-block; overflow: hidden; height: 1px; width: 0.061em;"></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span><span
                                                        style="position: absolute; top: -3.817em; left: 0.639em;"><span
                                                            class="mi" id="MathJax-Span-2473"
                                                            style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span
                                                            style="display: inline-block; width: 0px; height: 3.996em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 0.987em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.413em; border-left: 0px solid; width: 0px; height: 1.323em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-386">S_p</script> norms and posed as an open question if
                    they
                    were all equivalent. We give an affirmative answer to this question.
                </p>
            </div>
        </dd>
        <dt><a name="item737">[737]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03521"
                    title="Abstract">arXiv:2405.03521</a> (cross-list from cond-mat.supr-con) [<a href="/pdf/2405.03521"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03521" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Optimisation challenge for superconducting adiabatic neural
                    network implementing XOR and OR boolean functions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cond-mat?searchtype=author&amp;query=Pashin%2C+D+S">D.S. Pashin</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Bastrakova%2C+M+V">M.V. Bastrakova</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Rybin%2C+D+A">D.A. Rybin</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Soloviev%2C+I+I">I.I. Soloviev</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Schegolev%2C+A+E">A.E. Schegolev</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Klenov%2C+N+V">N.V. Klenov</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 13 pages, 12 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Superconductivity
                        (cond-mat.supr-con)</span>; Artificial Intelligence (cs.AI)

                </div>
                <p class="mathjax">In this article, we consider designs of simple analog artificial neural
                    networks based on adiabatic Josephson cells with a sigmoid activation function.
                    A new approach based on the gradient descent method is developed to adjust the
                    circuit parameters, allowing efficient signal transmission between the network
                    layers. The proposed solution is demonstrated on the example of the system
                    implementing XOR and OR logical operations.
                </p>
            </div>
        </dd>
        <dt><a name="item738">[738]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03542"
                    title="Abstract">arXiv:2405.03542</a> (cross-list from eess.SP) [<a href="/pdf/2405.03542"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03542" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing Channel Estimation in Quantized Systems with a
                    Generative Prior
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Fesl%2C+B">Benedikt Fesl</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Banna%2C+A">Aziz Banna</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Utschick%2C+W">Wolfgang Utschick</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">Channel estimation in quantized systems is challenging, particularly in
                    low-resolution systems. In this work, we propose to leverage a Gaussian mixture
                    model (GMM) as generative prior, capturing the channel distribution of the
                    propagation environment, to enhance a classical estimation technique based on
                    the expectation-maximization (EM) algorithm for one-bit quantization. Thereby,
                    a maximum a posteriori (MAP) estimate of the most responsible mixture component
                    is inferred for a quantized received signal, which is subsequently utilized in
                    the EM algorithm as side information. Numerical results demonstrate the
                    significant performance improvement of our proposed approach over both a
                    simplistic Gaussian prior and current state-of-the-art channel estimators.
                    Furthermore, the proposed estimation framework exhibits adaptability to higher
                    resolution systems and alternative generative priors.
                </p>
            </div>
        </dd>
        <dt><a name="item739">[739]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03543"
                    title="Abstract">arXiv:2405.03543</a> (cross-list from math.LO) [<a href="/pdf/2405.03543"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03543" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Axiomatizing the Logic of Ordinary Discourse
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Greati%2C+V">Vitor Greati</a>,
                    <a href="/search/math?searchtype=author&amp;query=Marcelino%2C+S">Sérgio Marcelino</a>,
                    <a href="/search/math?searchtype=author&amp;query=Rivieccio%2C+U">Umberto Rivieccio</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>;
                    Logic in Computer Science (cs.LO)

                </div>
                <p class="mathjax">Most non-classical logics are subclassical, that is, every inference/theorem
                    they validate is also valid classically. A notable exception is the
                    three-valued propositional Logic of Ordinary Discourse (OL) proposed and
                    extensively motivated by W. S. Cooper as a more adequate candidate for
                    formalizing everyday reasoning (in English). OL challenges classical logic not
                    only by rejecting some theses, but also by accepting non-classically valid
                    principles, such as so-called Aristotle's and Boethius' theses. Formally, OL
                    shows a number of unusual features - it is non-structural, connexive,
                    paraconsistent and contradictory - making it all the more interesting for the
                    mathematical logician. We present our recent findings on OL and its structural
                    companion (that we call sOL). We introduce Hilbert-style multiple-conclusion
                    calculi for OL and sOL that are both modular and analytic, and easily allow us
                    to obtain single-conclusion axiomatizations. We prove that sOL is algebraizable
                    and single out its equivalent semantics, which turns out to be a discriminator
                    variety generated by a three-element algebra. Having observed that sOL can
                    express the connectives of other three-valued logics, we prove that it is
                    definitionally equivalent to an expansion of the three-valued logic J3 of
                    D'Ottaviano and da Costa, itself an axiomatic extension of paraconsistent
                    Nelson logic.
                </p>
            </div>
        </dd>
        <dt><a name="item740">[740]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03549"
                    title="Abstract">arXiv:2405.03549</a> (cross-list from stat.ML) [<a href="/pdf/2405.03549"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03549" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bridging discrete and continuous state spaces: Exploring the
                    Ehrenfest process in time-continuous diffusion models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Winkler%2C+L">Ludwig Winkler</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Richter%2C+L">Lorenz Richter</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Opper%2C+M">Manfred Opper</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Probability (math.PR)

                </div>
                <p class="mathjax">Generative modeling via stochastic processes has led to remarkable empirical
                    results as well as to recent advances in their theoretical understanding. In
                    principle, both space and time of the processes can be discrete or continuous.
                    In this work, we study time-continuous Markov jump processes on discrete state
                    spaces and investigate their correspondence to state-continuous diffusion
                    processes given by SDEs. In particular, we revisit the <span class="MathJax_Preview"
                        style="display: none;"></span><span class="MathJax" id="MathJax-Element-387-Frame" tabindex="0"
                        style="">
                        <nobr><span class="math" id="MathJax-Span-2474"
                                style="width: 9.146em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 7.584em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(1.102em, 1007.58em, 2.376em, -999.997em); top: -1.965em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2475"><span class="texatom"
                                                id="MathJax-Span-2476"><span class="mrow" id="MathJax-Span-2477"><span
                                                        class="mtext" id="MathJax-Span-2478"
                                                        style="font-family: MathJax_Main-italic;">Ehrenfest
                                                        process</span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.97em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.344em; border-left: 0px solid; width: 0px; height: 1.253em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-387">\textit{Ehrenfest
    process}</script>, which converges to an Ornstein-Uhlenbeck process in the infinite
                    state space limit. Likewise, we can show that the time-reversal of the
                    Ehrenfest process converges to the time-reversed Ornstein-Uhlenbeck process.
                    This observation bridges discrete and continuous state spaces and allows to
                    carry over methods from one to the respective other setting. Additionally, we
                    suggest an algorithm for training the time-reversal of Markov jump processes
                    which relies on conditional expectations and can thus be directly related to
                    denoising score matching. We demonstrate our methods in multiple convincing
                    numerical experiments.
                </p>
            </div>
        </dd>
        <dt><a name="item741">[741]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03579"
                    title="Abstract">arXiv:2405.03579</a> (cross-list from stat.AP) [<a href="/pdf/2405.03579"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03579" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Some Statistical and Data Challenges When Building
                    Early-Stage Digital Experimentation and Measurement Capabilities
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Liu%2C+C+H+B">C. H. Bryan Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> PhD thesis. Imperial College London. Official library
                    version available on: <a href="https://spiral.imperial.ac.uk/handle/10044/1/110307">this https
                        URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Applications
                        (stat.AP)</span>; Databases (cs.DB); Methodology (stat.ME)

                </div>
                <p class="mathjax">Digital experimentation and measurement (DEM) capabilities -- the knowledge
                    and tools necessary to run experiments with digital products, services, or
                    experiences and measure their impact -- are fast becoming part of the standard
                    toolkit of digital/data-driven organisations in guiding business decisions.
                    Many large technology companies report having mature DEM capabilities, and
                    several businesses have been established purely to manage experiments for
                    others. Given the growing evidence that data-driven organisations tend to
                    outperform their non-data-driven counterparts, there has never been a greater
                    need for organisations to build/acquire DEM capabilities to thrive in the
                    current digital era.
                    <br>This thesis presents several novel approaches to statistical and data
                    challenges for organisations building DEM capabilities. We focus on the
                    fundamentals associated with building DEM capabilities, which lead to a richer
                    understanding of the underlying assumptions and thus enable us to develop more
                    appropriate capabilities. We address why one should engage in DEM by
                    quantifying the benefits and risks of acquiring DEM capabilities. This is done
                    using a ranking under lower uncertainty model, enabling one to construct a
                    business case. We also examine what ingredients are necessary to run digital
                    experiments. In addition to clarifying the existing literature around
                    statistical tests, datasets, and methods in experimental design and causal
                    inference, we construct an additional dataset and detailed case studies on
                    applying state-of-the-art methods. Finally, we investigate when a digital
                    experiment design would outperform another, leading to an evaluation framework
                    that compares competing designs' data efficiency.
                </p>
            </div>
        </dd>
        <dt><a name="item742">[742]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03587"
                    title="Abstract">arXiv:2405.03587</a> (cross-list from math.CO) [<a href="/pdf/2405.03587"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03587" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Non-detectable patterns hidden within sequences of bits
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Allen%2C+D">David Allen</a>,
                    <a href="/search/math?searchtype=author&amp;query=La+Luz%2C+J+J">Jose J La Luz</a>,
                    <a href="/search/math?searchtype=author&amp;query=Salivia%2C+G">Guarionex Salivia</a>,
                    <a href="/search/math?searchtype=author&amp;query=Hardwick%2C+J">Jonathan Hardwick</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics
                        (math.CO)</span>; Discrete Mathematics (cs.DM)

                </div>
                <p class="mathjax">In this paper we construct families of bit sequences using combinatorial
                    methods. Each sequence is derived by con- verting a collection of numbers
                    encoding certain combinatorial nu- merics from objects exhibiting symmetry in
                    various dimensions. Using the algorithms first described in [1] we show that
                    the NIST testing suite described in publication 800-22 does not detect these
                    symmetries hidden within these sequences.
                </p>
            </div>
        </dd>
        <dt><a name="item743">[743]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.03667"
                    title="Abstract">arXiv:2405.03667</a> (cross-list from eess.SP) [<a href="/pdf/2405.03667"
                    title="Download PDF">pdf</a>, <a href="/format/2405.03667" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fault Detection and Monitoring using an Information-Driven
                    Strategy: Method, Theory, and Application
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Ram%C3%ADrez%2C+C">Camilo Ramírez</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Silva%2C+J+F">Jorge F. Silva</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Tamssaouet%2C+F">Ferhat Tamssaouet</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Rojas%2C+T">Tomás Rojas</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Orchard%2C+M+E">Marcos E. Orchard</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 28 pages, 11 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

                </div>
                <p class="mathjax">The ability to detect when a system undergoes an incipient fault is of
                    paramount importance in preventing a critical failure. In this work, we propose
                    an information-driven fault detection method based on a novel concept drift
                    detector. The method is tailored to identifying drifts in input-output
                    relationships of additive noise models (i.e., model drifts) and is based on a
                    distribution-free mutual information (MI) estimator. Our scheme does not
                    require prior faulty examples and can be applied distribution-free over a large
                    class of system models. Our core contributions are twofold. First, we
                    demonstrate the connection between fault detection, model drift detection, and
                    testing independence between two random variables. Second, we prove several
                    theoretical properties of the proposed MI-based fault detection scheme: (i)
                    strong consistency, (ii) exponentially fast detection of the non-faulty case,
                    and (iii) control of both significance levels and power of the test. To
                    conclude, we validate our theory with synthetic data and the benchmark dataset
                    N-CMAPSS of aircraft turbofan engines. These empirical results support the
                    usefulness of our methodology in many practical and realistic settings, and the
                    theoretical results show performance guarantees that other methods cannot
                    offer.
                </p>
            </div>
        </dd>
    </dl>
    <h3>Replacements for Tue, 7 May 24</h3>
    <dl>
        <dt><a name="item744">[744]</a>&nbsp; <span class="list-identifier"><a href="/abs/0901.1988"
                    title="Abstract">arXiv:0901.1988</a> (replaced) [<a href="/pdf/0901.1988"
                    title="Download PDF">pdf</a>, <a href="/ps/0901.1988" title="Download PostScript">ps</a>, <a
                    href="/format/0901.1988" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Many-Help-One Problem for Gaussian Sources with a Tree
                    Structure on their Correlation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Oohama%2C+Y">Yasutada Oohama</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 21 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item745">[745]</a>&nbsp; <span class="list-identifier"><a href="/abs/1704.04370"
                    title="Abstract">arXiv:1704.04370</a> (replaced) [<a href="/pdf/1704.04370"
                    title="Download PDF">pdf</a>, <a href="/format/1704.04370" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fast Similarity Sketching
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dahlgaard%2C+S">Søren Dahlgaard</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Langhede%2C+M+B+T">Mathias Bæk Tejs Langhede</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Houen%2C+J+B+T">Jakob Bæk Tejs Houen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thorup%2C+M">Mikkel Thorup</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> The original version was directly based on a conference
                    paper of the same title from FOCS'17. This new version is substantially revised with some cleaner
                    and stronger theorems, particularly concerning the high probability domain. Moreover, there is one
                    more author, Jakob Houen. In addition, one of the old authors, Mathias, has changed surname from
                    Knudsen to Langhede
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item746">[746]</a>&nbsp; <span class="list-identifier"><a href="/abs/1902.01353"
                    title="Abstract">arXiv:1902.01353</a> (replaced) [<a href="/pdf/1902.01353"
                    title="Download PDF">pdf</a>, <a href="/format/1902.01353" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Session Type System for Asynchronous Unreliable Broadcast
                    Communication
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kouzapas%2C+D">Dimitrios Kouzapas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gutkovas%2C+R+F">Ramunas Forsberg Gutkovas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Voinea%2C+A+L">A. Laura Voinea</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gay%2C+S+J">Simon J. Gay</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

                </div>
            </div>
        </dd>
        <dt><a name="item747">[747]</a>&nbsp; <span class="list-identifier"><a href="/abs/1905.10951"
                    title="Abstract">arXiv:1905.10951</a> (replaced) [<a href="/pdf/1905.10951"
                    title="Download PDF">pdf</a>, <a href="/format/1905.10951" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the Evaluation Metric for Hashing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Q">Qing-Yuan Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Ming-Wei Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wu-Jun Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item748">[748]</a>&nbsp; <span class="list-identifier"><a href="/abs/2007.10609"
                    title="Abstract">arXiv:2007.10609</a> (replaced) [<a href="/pdf/2007.10609"
                    title="Download PDF">pdf</a>, <a href="/format/2007.10609" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SUBPLEX: Towards a Better Understanding of Black Box Model
                    Explanations at the Subpopulation Level
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+J">Jun Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+G+Y">Gromit Yeuk-Yin Chan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Barr%2C+B">Brian Barr</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Overton%2C+K">Kyle Overton</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rees%2C+K">Kim Rees</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nonato%2C+L+G">Luis Gustavo Nonato</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bertini%2C+E">Enrico Bertini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Silva%2C+C+T">Claudio T. Silva</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item749">[749]</a>&nbsp; <span class="list-identifier"><a href="/abs/2008.01503"
                    title="Abstract">arXiv:2008.01503</a> (replaced) [<a href="/pdf/2008.01503"
                    title="Download PDF">pdf</a>, <a href="/format/2008.01503" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multiple Code Hashing for Efficient Image Retrieval
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Ming-Wei Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Q">Qing-Yuan Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wu-Jun Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 9 figures, 3 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item750">[750]</a>&nbsp; <span class="list-identifier"><a href="/abs/2009.09538"
                    title="Abstract">arXiv:2009.09538</a> (replaced) [<a href="/pdf/2009.09538"
                    title="Download PDF">pdf</a>, <a href="/format/2009.09538" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Regret Bounds and Reinforcement Learning Exploration of
                    EXP-based Algorithms
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+M">Mengfan Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Klabjan%2C+D">Diego Klabjan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 40 pages, 8 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item751">[751]</a>&nbsp; <span class="list-identifier"><a href="/abs/2101.10867"
                    title="Abstract">arXiv:2101.10867</a> (replaced) [<a href="/pdf/2101.10867"
                    title="Download PDF">pdf</a>, <a href="/format/2101.10867" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On metrics robust to noise and deformations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Leeb%2C+W">William Leeb</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis
                        (math.FA)</span>; Numerical Analysis (math.NA)

                </div>
            </div>
        </dd>
        <dt><a name="item752">[752]</a>&nbsp; <span class="list-identifier"><a href="/abs/2108.06009"
                    title="Abstract">arXiv:2108.06009</a> (replaced) [<a href="/pdf/2108.06009"
                    title="Download PDF">pdf</a>, <a href="/ps/2108.06009" title="Download PostScript">ps</a>, <a
                    href="/format/2108.06009" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SAR image matching algorithm based on multi-class features
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Qiang%2C+M">Mazhi Qiang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Zhou%2C+F">Fengming Zhou</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item753">[753]</a>&nbsp; <span class="list-identifier"><a href="/abs/2109.11436"
                    title="Abstract">arXiv:2109.11436</a> (replaced) [<a href="/pdf/2109.11436"
                    title="Download PDF">pdf</a>, <a href="/ps/2109.11436" title="Download PostScript">ps</a>, <a
                    href="/format/2109.11436" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Piecewise Padé-Chebyshev Reconstruction of Bivariate
                    Piecewise Smooth Functions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Singh%2C+A">Akansha Singh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 26 pages, 15 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item754">[754]</a>&nbsp; <span class="list-identifier"><a href="/abs/2109.11762"
                    title="Abstract">arXiv:2109.11762</a> (replaced) [<a href="/pdf/2109.11762"
                    title="Download PDF">pdf</a>, <a href="/format/2109.11762" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LIBRA: Enabling Workload-aware Multi-dimensional Network
                    Topology Optimization for Distributed Training of Large AI Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Won%2C+W">William Won</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rashidi%2C+S">Saeed Rashidi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Srinivasan%2C+S">Sudarshan Srinivasan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Krishna%2C+T">Tushar Krishna</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Contains 10 main pages, 21 figures, 3 tables
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Proceedings of the 2024 IEEE International Symposium on
                    Performance Analysis of Systems and Software (ISPASS '24)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item755">[755]</a>&nbsp; <span class="list-identifier"><a href="/abs/2109.15037"
                    title="Abstract">arXiv:2109.15037</a> (replaced) [<a href="/pdf/2109.15037"
                    title="Download PDF">pdf</a>, <a href="/format/2109.15037" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Group Key Establishment Scheme
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Guzey%2C+S">Sueda Guzey</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kurt%2C+G+K">Gunes Karabulut Kurt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ozdemir%2C+E">Enver Ozdemir</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item756">[756]</a>&nbsp; <span class="list-identifier"><a href="/abs/2110.13452"
                    title="Abstract">arXiv:2110.13452</a> (replaced) [<a href="/pdf/2110.13452"
                    title="Download PDF">pdf</a>, <a href="/format/2110.13452" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the Optimization Landscape of Maximum Mean Discrepancy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Alon%2C+I">Itai Alon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Globerson%2C+A">Amir Globerson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wiesel%2C+A">Ami Wiesel</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item757">[757]</a>&nbsp; <span class="list-identifier"><a href="/abs/2112.06433"
                    title="Abstract">arXiv:2112.06433</a> (replaced) [<a href="/pdf/2112.06433"
                    title="Download PDF">pdf</a>, <a href="/format/2112.06433" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Generate Point Clouds with Multiscale Details from
                    Graph-Represented Structures
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Ximing Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhibo Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+Z">Zhengfu He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+C">Cheng Jin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item758">[758]</a>&nbsp; <span class="list-identifier"><a href="/abs/2112.10625"
                    title="Abstract">arXiv:2112.10625</a> (replaced) [<a href="/pdf/2112.10625"
                    title="Download PDF">pdf</a>, <a href="/format/2112.10625" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Privacy-Preserving Nonlinear Cloud-based Model Predictive
                    Control via Affine Masking
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+K">Kaixiang Zhang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Li%2C+Z">Zhaojian Li</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wang%2C+Y">Yongqiang Wang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Li%2C+N">Nan Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item759">[759]</a>&nbsp; <span class="list-identifier"><a href="/abs/2201.02797"
                    title="Abstract">arXiv:2201.02797</a> (replaced) [<a href="/pdf/2201.02797"
                    title="Download PDF">pdf</a>, <a href="/format/2201.02797" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Unified Review of Deep Learning for Automated Medical
                    Coding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+S">Shaoxiong Ji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+W">Wei Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaobo Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+H">Hang Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Taalas%2C+A">Ara Taalas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yijia Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Honghan Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pitk%C3%A4nen%2C+E">Esa Pitkänen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Marttinen%2C+P">Pekka Marttinen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ACM Computing Surveys
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Information Retrieval (cs.IR)

                </div>
            </div>
        </dd>
        <dt><a name="item760">[760]</a>&nbsp; <span class="list-identifier"><a href="/abs/2201.06317"
                    title="Abstract">arXiv:2201.06317</a> (replaced) [<a href="/pdf/2201.06317"
                    title="Download PDF">pdf</a>, <a href="/format/2201.06317" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Language Model-Based Paired Variational Autoencoders for
                    Robotic Language Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=%C3%96zdemir%2C+O">Ozan Özdemir</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kerzel%2C+M">Matthias Kerzel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Weber%2C+C">Cornelius Weber</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J+H">Jae Hee Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wermter%2C+S">Stefan Wermter</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published in: IEEE Transactions on Cognitive and
                    Developmental Systems, 15:4, 3204452
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> IEEE Transactions on Cognitive and Developmental
                    Systems (Volume:
                    15, Issue: 4, December 2023)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

                </div>
            </div>
        </dd>
        <dt><a name="item761">[761]</a>&nbsp; <span class="list-identifier"><a href="/abs/2202.05420"
                    title="Abstract">arXiv:2202.05420</a> (replaced) [<a href="/pdf/2202.05420"
                    title="Download PDF">pdf</a>, <a href="/format/2202.05420" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Characterization of Semi-Supervised Adversarially-Robust
                    PAC Learnability
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Attias%2C+I">Idan Attias</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hanneke%2C+S">Steve Hanneke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mansour%2C+Y">Yishay Mansour</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> NeurIPS 2022 camera-ready
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item762">[762]</a>&nbsp; <span class="list-identifier"><a href="/abs/2203.07831"
                    title="Abstract">arXiv:2203.07831</a> (replaced) [<a href="/pdf/2203.07831"
                    title="Download PDF">pdf</a>, <a href="/format/2203.07831" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Graph Convolutional Neural Networks Sensitivity under
                    Probabilistic Error Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Wang%2C+X">Xinjue Wang</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Ollila%2C+E">Esa Ollila</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Vorobyov%2C+S+A">Sergiy A. Vorobyov</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item763">[763]</a>&nbsp; <span class="list-identifier"><a href="/abs/2203.11076"
                    title="Abstract">arXiv:2203.11076</a> (replaced) [<a href="/pdf/2203.11076"
                    title="Download PDF">pdf</a>, <a href="/format/2203.11076" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Collaborative Learning for Cyberattack Detection in
                    Blockchain Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Khoa%2C+T+V">Tran Viet Khoa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Son%2C+D+H">Do Hai Son</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hoang%2C+D+T">Dinh Thai Hoang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Trung%2C+N+L">Nguyen Linh Trung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Quynh%2C+T+T+T">Tran Thi Thuy Quynh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+D+N">Diep N. Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ha%2C+N+V">Nguyen Viet Ha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dutkiewicz%2C+E">Eryk Dutkiewicz</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> IEEE Transactions on Systems, Man, and Cybernetics:
                    Systems (2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item764">[764]</a>&nbsp; <span class="list-identifier"><a href="/abs/2203.15968"
                    title="Abstract">arXiv:2203.15968</a> (replaced) [<a href="/pdf/2203.15968"
                    title="Download PDF">pdf</a>, <a href="/format/2203.15968" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Light Clients for Lazy Blockchains
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tas%2C+E+N">Ertem Nusret Tas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tse%2C+D">David Tse</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L">Lei Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zindros%2C+D">Dionysis Zindros</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Financial Cryptography and Data Security 2024 (FC24)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item765">[765]</a>&nbsp; <span class="list-identifier"><a href="/abs/2204.04510"
                    title="Abstract">arXiv:2204.04510</a> (replaced) [<a href="/pdf/2204.04510"
                    title="Download PDF">pdf</a>, <a href="/format/2204.04510" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Translating Subgraphs to Nodes Makes Simple GNNs Strong and
                    Efficient for Subgraph Representation Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">Dongkwan Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Oh%2C+A">Alice Oh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML 2024 (22 pages)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

                </div>
            </div>
        </dd>
        <dt><a name="item766">[766]</a>&nbsp; <span class="list-identifier"><a href="/abs/2204.07756"
                    title="Abstract">arXiv:2204.07756</a> (replaced) [<a href="/pdf/2204.07756"
                    title="Download PDF">pdf</a>, <a href="/format/2204.07756" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Visual Attention Methods in Deep Learning: An In-Depth Survey
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hassanin%2C+M">Mohammed Hassanin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Anwar%2C+S">Saeed Anwar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Radwan%2C+I">Ibrahim Radwan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+F+S">Fahad S Khan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mian%2C+A">Ajmal Mian</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in Information Fusion
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and
                    Video Processing (eess.IV)

                </div>
            </div>
        </dd>
        <dt><a name="item767">[767]</a>&nbsp; <span class="list-identifier"><a href="/abs/2205.05505"
                    title="Abstract">arXiv:2205.05505</a> (replaced) [<a href="/pdf/2205.05505"
                    title="Download PDF">pdf</a>, <a href="/format/2205.05505" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Probability Distribution of Hypervolume Improvement in
                    Bi-objective Bayesian Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+K">Kaifeng Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Affenzeller%2C+M">Michael Affenzeller</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item768">[768]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.00251"
                    title="Abstract">arXiv:2206.00251</a> (replaced) [<a href="/pdf/2206.00251"
                    title="Download PDF">pdf</a>, <a href="/format/2206.00251" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Reactive Synthesis Competition (SYNTCOMP): 2018-2021
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jacobs%2C+S">Swen Jacobs</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Perez%2C+G+A">Guillermo A. Perez</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abraham%2C+R">Remco Abraham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bruyere%2C+V">Veronique Bruyere</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cadilhac%2C+M">Michael Cadilhac</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Colange%2C+M">Maximilien Colange</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Delfosse%2C+C">Charly Delfosse</a>,
                    <a href="/search/cs?searchtype=author&amp;query=van+Dijk%2C+T">Tom van Dijk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Duret-Lutz%2C+A">Alexandre Duret-Lutz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Faymonville%2C+P">Peter Faymonville</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Finkbeiner%2C+B">Bernd Finkbeiner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khalimov%2C+A">Ayrat Khalimov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Klein%2C+F">Felix Klein</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luttenberger%2C+M">Michael Luttenberger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Meyer%2C+K">Klara Meyer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Michaud%2C+T">Thibaud Michaud</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pommellet%2C+A">Adrien Pommellet</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Renkin%2C+F">Florian Renkin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schlehuber-Caissier%2C+P">Philipp
                        Schlehuber-Caissier</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sakr%2C+M">Mouhammad Sakr</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sickert%2C+S">Salomon Sickert</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Staquet%2C+G">Gaetan Staquet</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tamines%2C+C">Clement Tamines</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tentrup%2C+L">Leander Tentrup</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Walker%2C+A">Adam Walker</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> accepted for publication in STTT
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item769">[769]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.01393"
                    title="Abstract">arXiv:2206.01393</a> (replaced) [<a href="/pdf/2206.01393"
                    title="Download PDF">pdf</a>, <a href="/ps/2206.01393" title="Download PostScript">ps</a>, <a
                    href="/format/2206.01393" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Simulation of Crowd Egress with Environmental Stressors
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/physics?searchtype=author&amp;query=Wang%2C+P">Peng Wang</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Wang%2C+X">Xiaoda Wang</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Luh%2C+P">Peter Luh</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Wilkie%2C+C">Christian Wilkie</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Korhonen%2C+T">Timo Korhonen</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Olderman%2C+N">Neal Olderman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 20 pages, 14 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society
                        (physics.soc-ph)</span>; Multiagent Systems (cs.MA); Adaptation and Self-Organizing Systems
                    (nlin.AO)

                </div>
            </div>
        </dd>
        <dt><a name="item770">[770]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.05051"
                    title="Abstract">arXiv:2206.05051</a> (replaced) [<a href="/pdf/2206.05051"
                    title="Download PDF">pdf</a>, <a href="/format/2206.05051" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Temporal Inductive Logic Reasoning over Hypergraphs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuan Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+S">Siheng Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Payani%2C+A">Ali Payani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kerce%2C+J+C">James C Kerce</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fekri%2C+F">Faramarz Fekri</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

                </div>
            </div>
        </dd>
        <dt><a name="item771">[771]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.07705"
                    title="Abstract">arXiv:2206.07705</a> (replaced) [<a href="/pdf/2206.07705"
                    title="Download PDF">pdf</a>, <a href="/format/2206.07705" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LET-3D-AP: Longitudinal Error Tolerant 3D Average Precision
                    for Camera-Only 3D Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hung%2C+W">Wei-Chih Hung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Casser%2C+V">Vincent Casser</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kretzschmar%2C+H">Henrik Kretzschmar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hwang%2C+J">Jyh-Jing Hwang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Anguelov%2C+D">Dragomir Anguelov</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Find the primary metrics for the 2022 Waymo Open Dataset
                    3D Camera-Only Detection Challenge at <a
                        href="https://waymo.com/open/challenges/2022/3d-camera-only-detection/">this https URL</a> .
                    Find the code at <a href="https://github.com/waymo-research/waymo-open-dataset">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item772">[772]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.09418"
                    title="Abstract">arXiv:2206.09418</a> (replaced) [<a href="/pdf/2206.09418"
                    title="Download PDF">pdf</a>, <a href="/format/2206.09418" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LordNet: An Efficient Neural Network for Learning to Solve
                    Parametric Partial Differential Equations without Simulated Data
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xinquan Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+W">Wenlei Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+X">Xiaotian Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+X">Xinran Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jia Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bian%2C+J">Jiang Bian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+M">Mao Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+T">Tie-Yan Liu</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Neural Networks, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item773">[773]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.09821"
                    title="Abstract">arXiv:2206.09821</a> (replaced) [<a href="/pdf/2206.09821"
                    title="Download PDF">pdf</a>, <a href="/format/2206.09821" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exceedance Probability Forecasting via Regression for
                    Significant Wave Height Prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Cerqueira%2C+V">Vitor Cerqueira</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Torgo%2C+L">Luis Torgo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item774">[774]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.10049"
                    title="Abstract">arXiv:2206.10049</a> (replaced) [<a href="/pdf/2206.10049"
                    title="Download PDF">pdf</a>, <a href="/ps/2206.10049" title="Download PostScript">ps</a>, <a
                    href="/format/2206.10049" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Capacity of 3 User Linear Computation Broadcast
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yuhang Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jafar%2C+S+A">Syed A. Jafar</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item775">[775]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.12674"
                    title="Abstract">arXiv:2206.12674</a> (replaced) [<a href="/pdf/2206.12674"
                    title="Download PDF">pdf</a>, <a href="/format/2206.12674" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Guided Exploration in Reinforcement Learning via Monte Carlo
                    Critic Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kuznetsov%2C+I">Igor Kuznetsov</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Short version of this paper is accepted to AAMAS 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item776">[776]</a>&nbsp; <span class="list-identifier"><a href="/abs/2206.12977"
                    title="Abstract">arXiv:2206.12977</a> (replaced) [<a href="/pdf/2206.12977"
                    title="Download PDF">pdf</a>, <a href="/ps/2206.12977" title="Download PostScript">ps</a>, <a
                    href="/format/2206.12977" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adversarially Robust PAC Learnability of Real-Valued
                    Functions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Attias%2C+I">Idan Attias</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hanneke%2C+S">Steve Hanneke</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> accepted to ICML2023
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item777">[777]</a>&nbsp; <span class="list-identifier"><a href="/abs/2207.02410"
                    title="Abstract">arXiv:2207.02410</a> (replaced) [<a href="/pdf/2207.02410"
                    title="Download PDF">pdf</a>, <a href="/format/2207.02410" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Deep Model for Partial Multi-Label Image Classification
                    with Curriculum Based Disambiguation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+F">Feng Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+M">Ming-Kun Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+S">Sheng-Jun Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 5 figures
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Machine Intelligence Research, 2023
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item778">[778]</a>&nbsp; <span class="list-identifier"><a href="/abs/2207.10170"
                    title="Abstract">arXiv:2207.10170</a> (replaced) [<a href="/pdf/2207.10170"
                    title="Download PDF">pdf</a>, <a href="/format/2207.10170" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Illusory Attacks: Information-Theoretic Detectability Matters
                    in Adversarial Attacks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Franzmeyer%2C+T">Tim Franzmeyer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McAleer%2C+S">Stephen McAleer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Henriques%2C+J+F">João F. Henriques</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Foerster%2C+J+N">Jakob N. Foerster</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Torr%2C+P+H+S">Philip H.S. Torr</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bibi%2C+A">Adel Bibi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=de+Witt%2C+C+S">Christian Schroeder de Witt</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024 Spotlight (top 5%)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item779">[779]</a>&nbsp; <span class="list-identifier"><a href="/abs/2207.13526"
                    title="Abstract">arXiv:2207.13526</a> (replaced) [<a href="/pdf/2207.13526"
                    title="Download PDF">pdf</a>, <a href="/format/2207.13526" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> UltimateKalman: Flexible Kalman Filtering and Smoothing Using
                    Orthogonal Transformations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Toledo%2C+S">Sivan Toledo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>; Systems and Control (eess.SY)

                </div>
            </div>
        </dd>
        <dt><a name="item780">[780]</a>&nbsp; <span class="list-identifier"><a href="/abs/2208.00841"
                    title="Abstract">arXiv:2208.00841</a> (replaced) [<a href="/pdf/2208.00841"
                    title="Download PDF">pdf</a>, <a href="/format/2208.00841" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spline-Shaped Microstrip Edge-Fed Antenna for 77 GHz
                    Automotive Radar Systems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Salucci%2C+M">Marco Salucci</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Poli%2C+L">Lorenzo Poli</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Rocca%2C+P">Paolo Rocca</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Massagrande%2C+C">Claudio Massagrande</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Rosatti%2C+P">Pietro Rosatti</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Hannan%2C+M+A">Mohammad Abdul Hannan</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Facchinelli%2C+M">Mirko Facchinelli</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Massa%2C+A">Andrea Massa</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Systems and Control (eess.SY)

                </div>
            </div>
        </dd>
        <dt><a name="item781">[781]</a>&nbsp; <span class="list-identifier"><a href="/abs/2208.05716"
                    title="Abstract">arXiv:2208.05716</a> (replaced) [<a href="/pdf/2208.05716"
                    title="Download PDF">pdf</a>, <a href="/format/2208.05716" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Task Aligned Meta-learning based Augmented Graph for
                    Cold-Start Recommendation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yuxiang Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+Y">Yue Ding</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+B">Bo Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yuyang Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yule Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+R">Ruiming Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+D">Dong Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item782">[782]</a>&nbsp; <span class="list-identifier"><a href="/abs/2208.06348"
                    title="Abstract">arXiv:2208.06348</a> (replaced) [<a href="/pdf/2208.06348"
                    title="Download PDF">pdf</a>, <a href="/format/2208.06348" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Can Brain Signals Reveal Inner Alignment with Human
                    Languages?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/q-bio?searchtype=author&amp;query=Han%2C+W">William Han</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Qiu%2C+J">Jielin Qiu</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Zhu%2C+J">Jiacheng Zhu</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Xu%2C+M">Mengdi Xu</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Weber%2C+D">Douglas Weber</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Li%2C+B">Bo Li</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Zhao%2C+D">Ding Zhao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> EMNLP 2023 Findings
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition
                        (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine
                    Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item783">[783]</a>&nbsp; <span class="list-identifier"><a href="/abs/2209.05428"
                    title="Abstract">arXiv:2209.05428</a> (replaced) [<a href="/pdf/2209.05428"
                    title="Download PDF">pdf</a>, <a href="/format/2209.05428" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Elastic Context: Encoding Elasticity for Data-driven Models
                    of Textiles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Longhini%2C+A">Alberta Longhini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Moletta%2C+M">Marco Moletta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reichlin%2C+A">Alfredo Reichlin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Welle%2C+M+C">Michael C. Welle</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kravberg%2C+A">Alexander Kravberg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yufei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Held%2C+D">David Held</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Erickson%2C+Z">Zackory Erickson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kragic%2C+D">Danica Kragic</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item784">[784]</a>&nbsp; <span class="list-identifier"><a href="/abs/2209.07163"
                    title="Abstract">arXiv:2209.07163</a> (replaced) [<a href="/pdf/2209.07163"
                    title="Download PDF">pdf</a>, <a href="/format/2209.07163" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Morphology-Aware Interactive Keypoint Estimation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jinhee Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+T">Taesung Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+T">Taewoo Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choo%2C+J">Jaegul Choo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">Dong-Wook Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ahn%2C+B">Byungduk Ahn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+I">In-Seok Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yoon-Ji Kim</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> MICCAI 2022. The first two authors contributed equally.
                    The last two authors are the co-corresponding authors
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item785">[785]</a>&nbsp; <span class="list-identifier"><a href="/abs/2209.07577"
                    title="Abstract">arXiv:2209.07577</a> (replaced) [<a href="/pdf/2209.07577"
                    title="Download PDF">pdf</a>, <a href="/format/2209.07577" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Experimental verification of the quantum nature of a neural
                    network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Patrascu%2C+A+T">Andrei T. Patrascu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a
                        href="/abs/2206.00005">arXiv:2206.00005</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Machine Learning (cs.LG); Quantum Physics (quant-ph)

                </div>
            </div>
        </dd>
        <dt><a name="item786">[786]</a>&nbsp; <span class="list-identifier"><a href="/abs/2209.11112"
                    title="Abstract">arXiv:2209.11112</a> (replaced) [<a href="/pdf/2209.11112"
                    title="Download PDF">pdf</a>, <a href="/format/2209.11112" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CMGAN: Conformer-Based Metric-GAN for Monaural Speech
                    Enhancement
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Abdulatif%2C+S">Sherif Abdulatif</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+R">Ruizhe Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+B">Bin Yang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 17 pages, 11 figures, and 6 tables. arXiv admin note: text
                    overlap with <a href="/abs/2203.15149">arXiv:2203.15149</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> IEEE/ACM Transactions on Audio, Speech, and Language
                    Processing,
                    vol. 32, pp. 2477-2493, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

                </div>
            </div>
        </dd>
        <dt><a name="item787">[787]</a>&nbsp; <span class="list-identifier"><a href="/abs/2209.13816"
                    title="Abstract">arXiv:2209.13816</a> (replaced) [<a href="/pdf/2209.13816"
                    title="Download PDF">pdf</a>, <a href="/format/2209.13816" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Revisiting Few-Shot Learning from a Causal Perspective
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+G">Guoliang Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lai%2C+H">Hanjiang Lai</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item788">[788]</a>&nbsp; <span class="list-identifier"><a href="/abs/2210.03327"
                    title="Abstract">arXiv:2210.03327</a> (replaced) [<a href="/pdf/2210.03327"
                    title="Download PDF">pdf</a>, <a href="/format/2210.03327" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enumeration of spatial manipulators by using the concept of
                    Adjacency Matrix
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jacob%2C+A+S">Akkarapakam Suneesh Jacob</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dasgupta%2C+B">Bhaskar Dasgupta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Datta%2C+R">Rituparna Datta</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item789">[789]</a>&nbsp; <span class="list-identifier"><a href="/abs/2210.09430"
                    title="Abstract">arXiv:2210.09430</a> (replaced) [<a href="/pdf/2210.09430"
                    title="Download PDF">pdf</a>, <a href="/format/2210.09430" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Evaluating Search System Explainability with Psychometrics
                    and Crowdsourcing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Catherine Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eickhoff%2C+C">Carsten Eickhoff</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 4 figures, accepted at SIGIR 2024 as full paper
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item790">[790]</a>&nbsp; <span class="list-identifier"><a href="/abs/2210.14972"
                    title="Abstract">arXiv:2210.14972</a> (replaced) [<a href="/pdf/2210.14972"
                    title="Download PDF">pdf</a>, <a href="/format/2210.14972" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Environment Design for Inverse Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Buening%2C+T+K">Thomas Kleine Buening</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Villin%2C+V">Victor Villin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dimitrakakis%2C+C">Christos Dimitrakakis</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> to appear at ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item791">[791]</a>&nbsp; <span class="list-identifier"><a href="/abs/2211.01365"
                    title="Abstract">arXiv:2211.01365</a> (replaced) [<a href="/pdf/2211.01365"
                    title="Download PDF">pdf</a>, <a href="/format/2211.01365" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> QuACK: Accelerating Gradient-Based Quantum Optimization with
                    Koopman Operator Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/quant-ph?searchtype=author&amp;query=Luo%2C+D">Di Luo</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Shen%2C+J">Jiayu Shen</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Dangovski%2C+R">Rumen Dangovski</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Solja%C4%8Di%C4%87%2C+M">Marin Soljačić</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Advances in Neural Information Processing Systems 36
                    (NeurIPS 2023) spotlight
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics
                        (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and
                    Control (math.OC); Computational Physics (physics.comp-ph)

                </div>
            </div>
        </dd>
        <dt><a name="item792">[792]</a>&nbsp; <span class="list-identifier"><a href="/abs/2211.10344"
                    title="Abstract">arXiv:2211.10344</a> (replaced) [<a href="/pdf/2211.10344"
                    title="Download PDF">pdf</a>, <a href="/format/2211.10344" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Physics-informed neural networks for operator equations with
                    stochastic data
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Escapil-Inchausp%C3%A9%2C+P">Paul
                        Escapil-Inchauspé</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ruz%2C+G+A">Gonzalo A. Ruz</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Numerical Analysis (math.NA)

                </div>
            </div>
        </dd>
        <dt><a name="item793">[793]</a>&nbsp; <span class="list-identifier"><a href="/abs/2211.11312"
                    title="Abstract">arXiv:2211.11312</a> (replaced) [<a href="/pdf/2211.11312"
                    title="Download PDF">pdf</a>, <a href="/format/2211.11312" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Understanding the Vulnerability of Skeleton-based Human
                    Activity Recognition via Black-box Attack
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Diao%2C+Y">Yunfeng Diao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">He Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shao%2C+T">Tianjia Shao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yong-Liang Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+K">Kun Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hogg%2C+D">David Hogg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+M">Meng Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in Pattern Recognition. arXiv admin note:
                    substantial text overlap with <a href="/abs/2103.05266">arXiv:2103.05266</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item794">[794]</a>&nbsp; <span class="list-identifier"><a href="/abs/2211.12827"
                    title="Abstract">arXiv:2211.12827</a> (replaced) [<a href="/pdf/2211.12827"
                    title="Download PDF">pdf</a>, <a href="/format/2211.12827" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Video Instance Shadow Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xing%2C+Z">Zhenghao Xing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xiaowei Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Haoran Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+C">Chi-Wing Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Heng%2C+P">Pheng-Ann Heng</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item795">[795]</a>&nbsp; <span class="list-identifier"><a href="/abs/2211.13726"
                    title="Abstract">arXiv:2211.13726</a> (replaced) [<a href="/pdf/2211.13726"
                    title="Download PDF">pdf</a>, <a href="/format/2211.13726" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Lightweight Event-based Optical Flow Estimation via Iterative
                    Deblurring
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yilun Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Paredes-Vall%C3%A9s%2C+F">Federico
                        Paredes-Vallés</a>,
                    <a href="/search/cs?searchtype=author&amp;query=de+Croon%2C+G+C+H+E">Guido C. H. E. de Croon</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to IEEE International Conference on Robotics and
                    Automation (ICRA'24), Yokohama, Japan, May 13-17, 2024. arXiv revision includes additional ablation
                    studies results
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item796">[796]</a>&nbsp; <span class="list-identifier"><a href="/abs/2211.14214"
                    title="Abstract">arXiv:2211.14214</a> (replaced) [<a href="/pdf/2211.14214"
                    title="Download PDF">pdf</a>, <a href="/format/2211.14214" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Complexity Framework for Forbidden Subgraphs II: Edge
                    Subdivision and the "H"-graphs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lozin%2C+V">Vadim Lozin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Martin%2C+B">Barnaby Martin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pandey%2C+S">Sukanya Pandey</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Paulusma%2C+D">Daniel Paulusma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Siggers%2C+M">Mark Siggers</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Smith%2C+S">Siani Smith</a>,
                    <a href="/search/cs?searchtype=author&amp;query=van+Leeuwen%2C+E+J">Erik Jan van Leeuwen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics
                        (cs.DM)</span>; Combinatorics (math.CO)

                </div>
            </div>
        </dd>
        <dt><a name="item797">[797]</a>&nbsp; <span class="list-identifier"><a href="/abs/2212.03932"
                    title="Abstract">arXiv:2212.03932</a> (replaced) [<a href="/pdf/2212.03932"
                    title="Download PDF">pdf</a>, <a href="/format/2212.03932" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Low Variance Off-policy Evaluation with State-based
                    Importance Sampling
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bossens%2C+D+M">David M. Bossens</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thomas%2C+P+S">Philip S. Thomas</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item798">[798]</a>&nbsp; <span class="list-identifier"><a href="/abs/2212.04486"
                    title="Abstract">arXiv:2212.04486</a> (replaced) [<a href="/pdf/2212.04486"
                    title="Download PDF">pdf</a>, <a href="/format/2212.04486" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A New Linear Scaling Rule for Private Adaptive Hyperparameter
                    Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Panda%2C+A">Ashwinee Panda</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+X">Xinyu Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mahloujifar%2C+S">Saeed Mahloujifar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sehwag%2C+V">Vikash Sehwag</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mittal%2C+P">Prateek Mittal</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item799">[799]</a>&nbsp; <span class="list-identifier"><a href="/abs/2212.04497"
                    title="Abstract">arXiv:2212.04497</a> (replaced) [<a href="/pdf/2212.04497"
                    title="Download PDF">pdf</a>, <a href="/format/2212.04497" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> UNETR++: Delving into Efficient and Accurate 3D Medical Image
                    Segmentation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shaker%2C+A">Abdelrahman Shaker</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Maaz%2C+M">Muhammad Maaz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rasheed%2C+H">Hanoona Rasheed</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+S">Salman Khan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+M">Ming-Hsuan Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+F+S">Fahad Shahbaz Khan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at IEEE TMI-2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item800">[800]</a>&nbsp; <span class="list-identifier"><a href="/abs/2212.05728"
                    title="Abstract">arXiv:2212.05728</a> (replaced) [<a href="/pdf/2212.05728"
                    title="Download PDF">pdf</a>, <a href="/format/2212.05728" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Synergy and Redundancy Dominated Effects in Time Series via
                    Transfer Entropy Decompositions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=%C3%98stergaard%2C+J">Jan Østergaard</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boubakani%2C+P">Payam Boubakani</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to be presented at the NeurIT: Information theory
                    in neuroscience and neuroengineering workshop. In connection with ISIT 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item801">[801]</a>&nbsp; <span class="list-identifier"><a href="/abs/2301.02426"
                    title="Abstract">arXiv:2301.02426</a> (replaced) [<a href="/pdf/2301.02426"
                    title="Download PDF">pdf</a>, <a href="/format/2301.02426" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Reversibility of elliptical slice sampling revisited
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Hasenpflug%2C+M">Mareike Hasenpflug</a>,
                    <a href="/search/math?searchtype=author&amp;query=Telezhnikov%2C+V">Viacheslav Telezhnikov</a>,
                    <a href="/search/math?searchtype=author&amp;query=Rudolf%2C+D">Daniel Rudolf</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 25 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory
                        (math.ST)</span>; Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item802">[802]</a>&nbsp; <span class="list-identifier"><a href="/abs/2301.10022"
                    title="Abstract">arXiv:2301.10022</a> (replaced) [<a href="/pdf/2301.10022"
                    title="Download PDF">pdf</a>, <a href="/format/2301.10022" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Koopman neural operator as a mesh-free solver of non-linear
                    partial differential equations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+W">Wei Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaomeng Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Ziyang Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+R">Ruixuan Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+P">Pei Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Y">Yang Tian</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph); Data
                    Analysis, Statistics and Probability (physics.data-an); Fluid Dynamics (physics.flu-dyn)

                </div>
            </div>
        </dd>
        <dt><a name="item803">[803]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.00808"
                    title="Abstract">arXiv:2302.00808</a> (replaced) [<a href="/pdf/2302.00808"
                    title="Download PDF">pdf</a>, <a href="/format/2302.00808" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ACPO: A Policy Optimization Algorithm for Average MDPs with
                    Constraints
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Agnihotri%2C+A">Akhil Agnihotri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jain%2C+R">Rahul Jain</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+H">Haipeng Luo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To appear in Proceedings of the <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-388-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2479"
                                style="width: 1.996em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.674em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0em, 1001.67em, 1.417em, -999.997em); top: -1.025em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2480"><span class="msubsup"
                                                id="MathJax-Span-2481"><span
                                                    style="display: inline-block; position: relative; width: 1.674em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.152em, 1000.97em, 4.373em, -999.997em); top: -3.981em; left: 0em;"><span
                                                            class="texatom" id="MathJax-Span-2482"><span class="mrow"
                                                                id="MathJax-Span-2483"><span class="mn"
                                                                    id="MathJax-Span-2484"
                                                                    style="font-family: MathJax_Main-italic;">41</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.988em;"></span></span><span
                                                        style="position: absolute; top: -4.367em; left: 1.031em;"><span
                                                            class="texatom" id="MathJax-Span-2485"><span class="mrow"
                                                                id="MathJax-Span-2486"><span class="mi"
                                                                    id="MathJax-Span-2487"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">s</span><span
                                                                    class="mi" id="MathJax-Span-2488"
                                                                    style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.988em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.031em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.305em; border-left: 0px solid; width: 0px; height: 1.392em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-388">\mathit{41}^{st}</script> International Conference
                    on Machine Learning (ICML), Vienna, Austria. PMLR 235, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item804">[804]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.06430"
                    title="Abstract">arXiv:2302.06430</a> (replaced) [<a href="/pdf/2302.06430"
                    title="Download PDF">pdf</a>, <a href="/format/2302.06430" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Orthogonal Hypersphere Compression for Anomaly Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yunhe Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yan Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+J">Jinyu Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+J">Jicong Fan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published in ICLR 2024: <a
                        href="https://openreview.net/pdf?id=cJs4oE4m9Q">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item805">[805]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.07751"
                    title="Abstract">arXiv:2302.07751</a> (replaced) [<a href="/pdf/2302.07751"
                    title="Download PDF">pdf</a>, <a href="/ps/2302.07751" title="Download PostScript">ps</a>, <a
                    href="/format/2302.07751" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fully Energy-Efficient Randomized Backoff: Slow Feedback
                    Loops Yield Fast Contention Resolution
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bender%2C+M+A">Michael A. Bender</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fineman%2C+J+T">Jeremy T. Fineman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gilbert%2C+S">Seth Gilbert</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kuszmaul%2C+J">John Kuszmaul</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Young%2C+M">Maxwell Young</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item806">[806]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.08108"
                    title="Abstract">arXiv:2302.08108</a> (replaced) [<a href="/pdf/2302.08108"
                    title="Download PDF">pdf</a>, <a href="/ps/2302.08108" title="Download PostScript">ps</a>, <a
                    href="/format/2302.08108" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> User Response in Ad Auctions: An MDP Formulation of Long-Term
                    Revenue Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+Y">Yang Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Z">Zhe Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liaw%2C+C">Christopher Liaw</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mehta%2C+A">Aranyak Mehta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Velegkas%2C+G">Grigoris Velegkas</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game
                        Theory (cs.GT)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item807">[807]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.08434"
                    title="Abstract">arXiv:2302.08434</a> (replaced) [<a href="/pdf/2302.08434"
                    title="Download PDF">pdf</a>, <a href="/format/2302.08434" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On marginal feature attributions of tree-based models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Filom%2C+K">Khashayar Filom</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Miroshnikov%2C+A">Alexey Miroshnikov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kotsiopoulos%2C+K">Konstandinos Kotsiopoulos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kannan%2C+A+R">Arjun Ravi Kannan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Minor corrections. 30 pages+appendix (64 pages in total),
                    10 figures. To appear in Foundations of Data Science
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

                </div>
            </div>
        </dd>
        <dt><a name="item808">[808]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.10128"
                    title="Abstract">arXiv:2302.10128</a> (replaced) [<a href="/pdf/2302.10128"
                    title="Download PDF">pdf</a>, <a href="/format/2302.10128" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Sketch In, Sketch Out: Accelerating both Learning and
                    Inference for Structured Prediction with Kernels
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Ahmad%2C+T+E">Tamim El Ahmad</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Brogat-Motte%2C+L">Luc Brogat-Motte</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Laforgue%2C+P">Pierre Laforgue</a>,
                    <a href="/search/stat?searchtype=author&amp;query=d%27Alch%C3%A9-Buc%2C+F">Florence d'Alché-Buc</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Proceedings of The 27th International Conference on
                    Artificial
                    Intelligence and Statistics, PMLR 238:109-117, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item809">[809]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.10149"
                    title="Abstract">arXiv:2302.10149</a> (replaced) [<a href="/pdf/2302.10149"
                    title="Download PDF">pdf</a>, <a href="/format/2302.10149" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Poisoning Web-Scale Training Datasets is Practical
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Carlini%2C+N">Nicholas Carlini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jagielski%2C+M">Matthew Jagielski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choquette-Choo%2C+C+A">Christopher A.
                        Choquette-Choo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Paleka%2C+D">Daniel Paleka</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pearce%2C+W">Will Pearce</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Anderson%2C+H">Hyrum Anderson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Terzis%2C+A">Andreas Terzis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thomas%2C+K">Kurt Thomas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tram%C3%A8r%2C+F">Florian Tramèr</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item810">[810]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.10442"
                    title="Abstract">arXiv:2302.10442</a> (replaced) [<a href="/pdf/2302.10442"
                    title="Download PDF">pdf</a>, <a href="/format/2302.10442" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Data-based Adaptive Refinement of Finite Element Thin Plate
                    Spline
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Fang%2C+L">L. Fang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Stals%2C+L">L.Stals</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item811">[811]</a>&nbsp; <span class="list-identifier"><a href="/abs/2302.12461"
                    title="Abstract">arXiv:2302.12461</a> (replaced) [<a href="/pdf/2302.12461"
                    title="Download PDF">pdf</a>, <a href="/format/2302.12461" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Analyzing And Editing Inner Mechanisms Of Backdoored Language
                    Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lamparth%2C+M">Max Lamparth</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reuel%2C+A">Anka Reuel</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Final version accepted at FAccT 24
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> The 2024 ACM Conference on Fairness, Accountability,
                    and
                    Transparency (FAccT 24), June 3-6, 2024, Rio de Janeiro, Brazil
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item812">[812]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.00244"
                    title="Abstract">arXiv:2303.00244</a> (replaced) [<a href="/pdf/2303.00244"
                    title="Download PDF">pdf</a>, <a href="/format/2303.00244" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SUNY: A Visual Interpretation Framework for Convolutional
                    Neural Networks from a Necessary and Sufficient Perspective
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xuan%2C+X">Xiwei Xuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Z">Ziquan Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+H">Hsuan-Tien Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kong%2C+Z">Zhaodan Kong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+K">Kwan-Liu Ma</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> CVPRw 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item813">[813]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.02698"
                    title="Abstract">arXiv:2303.02698</a> (replaced) [<a href="/pdf/2303.02698"
                    title="Download PDF">pdf</a>, <a href="/format/2303.02698" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Robust affine point matching via quadratic assignment on
                    Grassmannians
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kolpakov%2C+A">Alexander Kolpakov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Werman%2C+M">Michael Werman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 23 figures; GitHub repository at (<a
                        href="https://github.com/sashakolpakov/rag">this https URL</a>); Section IV: added comparison to
                    GrassGraph (<a href="https://doi.org/10.1109/TIP.2019.2959722">this https URL</a>); notably,
                    GrassGraph quickly loses accuracy on our test examples with noise and occlusion
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item814">[814]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.03090"
                    title="Abstract">arXiv:2303.03090</a> (replaced) [<a href="/pdf/2303.03090"
                    title="Download PDF">pdf</a>, <a href="/format/2303.03090" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Parallel Optimization with Hard Safety Constraints for
                    Cooperative Planning of Connected Autonomous Vehicles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhenmin Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Haichao Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+S">Shaojie Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+J">Jun Ma</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Multiagent Systems (cs.MA); Systems and Control (eess.SY)

                </div>
            </div>
        </dd>
        <dt><a name="item815">[815]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.03151"
                    title="Abstract">arXiv:2303.03151</a> (replaced) [<a href="/pdf/2303.03151"
                    title="Download PDF">pdf</a>, <a href="/format/2303.03151" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Resource-aware Cyber Deception for Microservice-based
                    Applications
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zambianco%2C+M">Marco Zambianco</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Facchinetti%2C+C">Claudio Facchinetti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Doriguzzi-Corin%2C+R">Roberto Doriguzzi-Corin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Siracusa%2C+D">Domenico Siracusa</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item816">[816]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.08269"
                    title="Abstract">arXiv:2303.08269</a> (replaced) [<a href="/pdf/2303.08269"
                    title="Download PDF">pdf</a>, <a href="/format/2303.08269" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Positive Unlabeled Learning Selected Not At Random (PULSNAR):
                    class proportion estimation when the SCAR assumption does not hold
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+P">Praveen Kumar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lambert%2C+C+G">Christophe G. Lambert</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item817">[817]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.11876"
                    title="Abstract">arXiv:2303.11876</a> (replaced) [<a href="/pdf/2303.11876"
                    title="Download PDF">pdf</a>, <a href="/format/2303.11876" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An implicit function theorem for the stream calculus
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Boreale%2C+M">Michele Boreale</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Collodi%2C+L">Luisa Collodi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gorla%2C+D">Daniele Gorla</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item818">[818]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.14241"
                    title="Abstract">arXiv:2303.14241</a> (replaced) [<a href="/pdf/2303.14241"
                    title="Download PDF">pdf</a>, <a href="/format/2303.14241" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Data Depth and Core-based Trend Detection on Blockchain
                    Transaction Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+J">Jason Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+A">Arijit Khan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Akcora%2C+C+G">Cuneyt Gurcan Akcora</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Frontiers in Blockchain 7 (2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item819">[819]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.16621"
                    title="Abstract">arXiv:2303.16621</a> (replaced) [<a href="/pdf/2303.16621"
                    title="Download PDF">pdf</a>, <a href="/format/2303.16621" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AraSpot: Arabic Spoken Command Spotting
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Salhab%2C+M">Mahmoud Salhab</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Harmanani%2C+H">Haidar Harmanani</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item820">[820]</a>&nbsp; <span class="list-identifier"><a href="/abs/2303.17222"
                    title="Abstract">arXiv:2303.17222</a> (replaced) [<a href="/pdf/2303.17222"
                    title="Download PDF">pdf</a>, <a href="/format/2303.17222" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LatentForensics: Towards frugal deepfake detection in the
                    StyleGAN latent space
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Delmas%2C+M">Matthieu Delmas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kacete%2C+A">Amine Kacete</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Paquelet%2C+S">Stephane Paquelet</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Leglaive%2C+S">Simon Leglaive</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Seguier%2C+R">Renaud Seguier</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 3 figures, 5 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item821">[821]</a>&nbsp; <span class="list-identifier"><a href="/abs/2304.00762"
                    title="Abstract">arXiv:2304.00762</a> (replaced) [<a href="/pdf/2304.00762"
                    title="Download PDF">pdf</a>, <a href="/ps/2304.00762" title="Download PostScript">ps</a>, <a
                    href="/format/2304.00762" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The (r, δ)-Locality of Repeated-Root Cyclic Codes with Prime
                    Power Lengths
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+W">Wei Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Weixian Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+S">Shenghao Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shum%2C+K+W">Kenneth W. Shum</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item822">[822]</a>&nbsp; <span class="list-identifier"><a href="/abs/2304.00962"
                    title="Abstract">arXiv:2304.00962</a> (replaced) [<a href="/pdf/2304.00962"
                    title="Download PDF">pdf</a>, <a href="/format/2304.00962" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> RegionPLC: Regional Point-Language Contrastive Learning for
                    Open-World 3D Scene Understanding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jihan Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+R">Runyu Ding</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+W">Weipeng Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhe Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qi%2C+X">Xiaojuan Qi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To appear in CVPR2024 .project page: <a
                        href="https://jihanyang.github.io/projects/RegionPLC">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item823">[823]</a>&nbsp; <span class="list-identifier"><a href="/abs/2304.03094"
                    title="Abstract">arXiv:2304.03094</a> (replaced) [<a href="/pdf/2304.03094"
                    title="Download PDF">pdf</a>, <a href="/format/2304.03094" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PopulAtion Parameter Averaging (PAPA)
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jolicoeur-Martineau%2C+A">Alexia
                        Jolicoeur-Martineau</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gervais%2C+E">Emy Gervais</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fatras%2C+K">Kilian Fatras</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lacoste-Julien%2C+S">Simon Lacoste-Julien</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Blog post: <a
                        href="https://ajolicoeur.wordpress.com/papa/">this https URL</a>, Code: <a
                        href="https://github.com/SamsungSAILMontreal/PAPA">this https URL</a>, TMLR journal publication:
                    <a href="https://openreview.net/forum?id=cPDVjsOytS">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item824">[824]</a>&nbsp; <span class="list-identifier"><a href="/abs/2304.06883"
                    title="Abstract">arXiv:2304.06883</a> (replaced) [<a href="/pdf/2304.06883"
                    title="Download PDF">pdf</a>, <a href="/format/2304.06883" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Intelligent Reflecting Surface Aided Wireless Communication
                    Systems: Joint Location and Passive Beamforming Design
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+J">Jintao Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yin%2C+S">Sixing Yin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Following the publication of our work, we identified
                    errors in our data analysis process. To uphold the standards of academic integrity and the accuracy
                    of our findings, we feel it necessary to withdraw the current version of our paper. We plan to
                    submit a revised version upon thorough review and correction of these errors
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
            </div>
        </dd>
        <dt><a name="item825">[825]</a>&nbsp; <span class="list-identifier"><a href="/abs/2304.12766"
                    title="Abstract">arXiv:2304.12766</a> (replaced) [<a href="/pdf/2304.12766"
                    title="Download PDF">pdf</a>, <a href="/format/2304.12766" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> QuantProb: Generalizing Probabilities along with Predictions
                    for a Pre-trained Classifier
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Challa%2C+A">Aditya Challa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saha%2C+S">Snehanshu Saha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dhavala%2C+S">Soma Dhavala</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at UAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item826">[826]</a>&nbsp; <span class="list-identifier"><a href="/abs/2304.14724"
                    title="Abstract">arXiv:2304.14724</a> (replaced) [<a href="/pdf/2304.14724"
                    title="Download PDF">pdf</a>, <a href="/format/2304.14724" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Structural Parameterizations for Two Bounded Degree Problems
                    Revisited
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lampis%2C+M">Michael Lampis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vasilakis%2C+M">Manolis Vasilakis</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Abstract shortened to meet arXiv's requirements
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

                </div>
            </div>
        </dd>
        <dt><a name="item827">[827]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.01322"
                    title="Abstract">arXiv:2305.01322</a> (replaced) [<a href="/pdf/2305.01322"
                    title="Download PDF">pdf</a>, <a href="/format/2305.01322" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Autonomous Non-monolithic Agent with Multi-mode
                    Exploration based on Options Framework
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">JaeYoon Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xuan%2C+J">Junyu Xuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liang%2C+C">Christy Liang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hussain%2C+F">Farookh Hussain</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> IEEE IJCNN 2023
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item828">[828]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.01723"
                    title="Abstract">arXiv:2305.01723</a> (replaced) [<a href="/pdf/2305.01723"
                    title="Download PDF">pdf</a>, <a href="/format/2305.01723" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Stance Detection: A Practical Guide to Classifying Political
                    Beliefs in Text
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Burnham%2C+M">Michael Burnham</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item829">[829]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.03122"
                    title="Abstract">arXiv:2305.03122</a> (replaced) [<a href="/pdf/2305.03122"
                    title="Download PDF">pdf</a>, <a href="/ps/2305.03122" title="Download PostScript">ps</a>, <a
                    href="/format/2305.03122" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Capacity of Classical Summation over a Quantum MAC with
                    Arbitrarily Distributed Inputs and Entanglements
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+Y">Yuhang Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jafar%2C+S+A">Syed A. Jafar</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item830">[830]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.03707"
                    title="Abstract">arXiv:2305.03707</a> (replaced) [<a href="/pdf/2305.03707"
                    title="Download PDF">pdf</a>, <a href="/format/2305.03707" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Hardware Honeypot: Setting Sequential Reverse Engineering on
                    a Wrong Track
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Brunner%2C+M">Michaela Brunner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+H+H">Hye Hyun Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hepp%2C+A">Alexander Hepp</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Baehr%2C+J">Johanna Baehr</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sigl%2C+G">Georg Sigl</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> 2024 27th International Symposium on Design &amp;
                    Diagnostics of
                    Electronic Circuits &amp; Systems (DDECS), Kielce, Poland, 2024, pp. 47-52
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item831">[831]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.08088"
                    title="Abstract">arXiv:2305.08088</a> (replaced) [<a href="/pdf/2305.08088"
                    title="Download PDF">pdf</a>, <a href="/format/2305.08088" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Make Prompt-based Black-Box Tuning Colorful: Boosting Model
                    Generalization from Three Orthogonal Perspectives
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qiushi Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+C">Chengcheng Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+N">Nuo Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+R">Renyu Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gong%2C+J">Jingyang Gong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+M">Ming Gao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by LREC-COLING 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item832">[832]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.11731"
                    title="Abstract">arXiv:2305.11731</a> (replaced) [<a href="/pdf/2305.11731"
                    title="Download PDF">pdf</a>, <a href="/ps/2305.11731" title="Download PostScript">ps</a>, <a
                    href="/format/2305.11731" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Persian Typographical Error Type Detection Using Deep Neural
                    Networks on Algorithmically-Generated Misspellings
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dehghani%2C+M">Mohammad Dehghani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Faili%2C+H">Heshaam Faili</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item833">[833]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.12844"
                    title="Abstract">arXiv:2305.12844</a> (replaced) [<a href="/pdf/2305.12844"
                    title="Download PDF">pdf</a>, <a href="/format/2305.12844" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Optimized Ensemble Deep Learning Model For Brain Tumor
                    Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Talukder%2C+M+A">Md. Alamin Talukder</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Islam%2C+M+M">Md. Manowarul Islam</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Uddin%2C+M+A">Md Ashraf Uddin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item834">[834]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.14081"
                    title="Abstract">arXiv:2305.14081</a> (replaced) [<a href="/pdf/2305.14081"
                    title="Download PDF">pdf</a>, <a href="/format/2305.14081" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> How to Solve Few-Shot Abusive Content Detection Using the
                    Data We Actually Have
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hangya%2C+V">Viktor Hangya</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fraser%2C+A">Alexander Fraser</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item835">[835]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.14658"
                    title="Abstract">arXiv:2305.14658</a> (replaced) [<a href="/pdf/2305.14658"
                    title="Download PDF">pdf</a>, <a href="/format/2305.14658" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Evaluate What You Can't Evaluate: Unassessable Quality for
                    Generated Response
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yongkang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+S">Shi Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+D">Daling Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yifei Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sch%C3%BCtze%2C+H">Hinrich Schütze</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> preprint
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item836">[836]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.14685"
                    title="Abstract">arXiv:2305.14685</a> (replaced) [<a href="/pdf/2305.14685"
                    title="Download PDF">pdf</a>, <a href="/format/2305.14685" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fusion-in-T5: Unifying Document Ranking Signals for Improved
                    Information Retrieval
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+S">Shi Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+C">Chenghao Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+C">Chenyan Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+D">David Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiyuan Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhenghao Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> COLING 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item837">[837]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.15957"
                    title="Abstract">arXiv:2305.15957</a> (replaced) [<a href="/pdf/2305.15957"
                    title="Download PDF">pdf</a>, <a href="/format/2305.15957" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DiffCLIP: Leveraging Stable Diffusion for Language Grounded
                    3D Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+S">Sitian Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zilin Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+L">Linqian Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Harry Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xinxiao Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item838">[838]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.18569"
                    title="Abstract">arXiv:2305.18569</a> (replaced) [<a href="/pdf/2305.18569"
                    title="Download PDF">pdf</a>, <a href="/format/2305.18569" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fairness of ChatGPT
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yunqi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lanjing Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yongfeng Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and
                    Society (cs.CY)

                </div>
            </div>
        </dd>
        <dt><a name="item839">[839]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.19872"
                    title="Abstract">arXiv:2305.19872</a> (replaced) [<a href="/pdf/2305.19872"
                    title="Download PDF">pdf</a>, <a href="/format/2305.19872" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spectral Heterogeneous Graph Convolutions via Positive
                    Noncommutative Polynomials
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+M">Mingguo He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zhewei Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+S">Shikun Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhengjie Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Weibin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yu Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+D">Dianhai Yu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> The Web Conference 2024 (12 pages)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item840">[840]</a>&nbsp; <span class="list-identifier"><a href="/abs/2305.20076"
                    title="Abstract">arXiv:2305.20076</a> (replaced) [<a href="/pdf/2305.20076"
                    title="Download PDF">pdf</a>, <a href="/format/2305.20076" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Decision-Oriented Dialogue for Human-AI Collaboration
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+J">Jessy Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tomlin%2C+N">Nicholas Tomlin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Andreas%2C+J">Jacob Andreas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eisner%2C+J">Jason Eisner</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> TACL 2024, pre-MIT Press publication version
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item841">[841]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.01603"
                    title="Abstract">arXiv:2306.01603</a> (replaced) [<a href="/pdf/2306.01603"
                    title="Download PDF">pdf</a>, <a href="/format/2306.01603" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Decentralized Federated Learning: A Survey and Perspective
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+L">Liangqi Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Ziran Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+L">Lichao Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+P+S">Philip S. Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brinton%2C+C+G">Christopher G. Brinton</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computers and Society (cs.CY); Distributed, Parallel, and Cluster Computing
                    (cs.DC); Networking and Internet Architecture (cs.NI)

                </div>
            </div>
        </dd>
        <dt><a name="item842">[842]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.02105"
                    title="Abstract">arXiv:2306.02105</a> (replaced) [<a href="/pdf/2306.02105"
                    title="Download PDF">pdf</a>, <a href="/format/2306.02105" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Advancing African-Accented Speech Recognition: Epistemic
                    Uncertainty-Driven Data Selection for Generalizable ASR Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dossou%2C+B+F+P">Bonaventure F. P. Dossou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tonja%2C+A+L">Atnafu Lambebo Tonja</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Emezue%2C+C+C">Chris Chinenye Emezue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Olatunji%2C+T">Tobi Olatunji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Etori%2C+N+A">Naome A Etori</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Osei%2C+S">Salomey Osei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Adewumi%2C+T">Tosin Adewumi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singh%2C+S">Sahib Singh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at SIGUL-LREC 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

                </div>
            </div>
        </dd>
        <dt><a name="item843">[843]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.02568"
                    title="Abstract">arXiv:2306.02568</a> (replaced) [<a href="/pdf/2306.02568"
                    title="Download PDF">pdf</a>, <a href="/format/2306.02568" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Latent Optimal Paths by Gumbel Propagation for Variational
                    Bayesian Dynamic Programming
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Niu%2C+X">Xinlei Niu</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Walder%2C+C">Christian Walder</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Zhang%2C+J">Jing Zhang</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Martin%2C+C+P">Charles Patrick Martin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item844">[844]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.02786"
                    title="Abstract">arXiv:2306.02786</a> (replaced) [<a href="/pdf/2306.02786"
                    title="Download PDF">pdf</a>, <a href="/format/2306.02786" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Navigating Explanatory Multiverse Through Counterfactual Path
                    Geometry
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sokol%2C+K">Kacper Sokol</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Small%2C+E">Edward Small</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xuan%2C+Y">Yueqing Xuan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Workshop on Counterfactuals in Minds and Machines at 2023
                    International Conference on Machine Learning (ICML)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item845">[845]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.03623"
                    title="Abstract">arXiv:2306.03623</a> (replaced) [<a href="/pdf/2306.03623"
                    title="Download PDF">pdf</a>, <a href="/format/2306.03623" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spike-based computation using classical recurrent neural
                    networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=De+Geeter%2C+F">Florent De Geeter</a> (1),
                    <a href="/search/cs?searchtype=author&amp;query=Ernst%2C+D">Damien Ernst</a> (1 and 2),
                    <a href="/search/cs?searchtype=author&amp;query=Drion%2C+G">Guillaume Drion</a> (1) ((1) Montefiore
                    Institute, University of Liège, Liège, Belgium, (2) LTCI, Télécom Paris, Institut Polytechnique de
                    Paris, France)
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 17 pages, 8 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item846">[846]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.04434"
                    title="Abstract">arXiv:2306.04434</a> (replaced) [<a href="/pdf/2306.04434"
                    title="Download PDF">pdf</a>, <a href="/ps/2306.04434" title="Download PostScript">ps</a>, <a
                    href="/format/2306.04434" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Visions of augmented reality in popular culture: Power and
                    (un)readable identities when the world becomes a screen
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gunderson%2C+M">Marianne Gunderson</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Tidsskrift for Kjoennsforskning volume 45 2021 pages
                    89-104
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>; Social and Information Networks (cs.SI)

                </div>
            </div>
        </dd>
        <dt><a name="item847">[847]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.05426"
                    title="Abstract">arXiv:2306.05426</a> (replaced) [<a href="/pdf/2306.05426"
                    title="Download PDF">pdf</a>, <a href="/format/2306.05426" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SequenceMatch: Imitation Learning for Autoregressive Sequence
                    Modelling with Backtracking
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cundy%2C+C">Chris Cundy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ermon%2C+S">Stefano Ermon</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Poster, ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item848">[848]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.05792"
                    title="Abstract">arXiv:2306.05792</a> (replaced) [<a href="/pdf/2306.05792"
                    title="Download PDF">pdf</a>, <a href="/ps/2306.05792" title="Download PostScript">ps</a>, <a
                    href="/format/2306.05792" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Reinforcement Learning for Mutation Operator Selection in
                    Automated Program Repair
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hanna%2C+C">Carol Hanna</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Blot%2C+A">Aymeric Blot</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Petke%2C+J">Justyna Petke</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item849">[849]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.07209"
                    title="Abstract">arXiv:2306.07209</a> (replaced) [<a href="/pdf/2306.07209"
                    title="Download PDF">pdf</a>, <a href="/format/2306.07209" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Data-Copilot: Bridging Billions of Data and Humans with
                    Autonomous Workflow
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wenqi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yongliang Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+W">Weiming Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+Y">Yueting Zhuang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science
                    (cs.CE)

                </div>
            </div>
        </dd>
        <dt><a name="item850">[850]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.10614"
                    title="Abstract">arXiv:2306.10614</a> (replaced) [<a href="/pdf/2306.10614"
                    title="Download PDF">pdf</a>, <a href="/format/2306.10614" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Identifiable causal inference with noisy treatment and no
                    side information
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=P%C3%B6ll%C3%A4nen%2C+A">Antti Pöllänen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Marttinen%2C+P">Pekka Marttinen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages, 10 figures. Changes consist of polishing the
                    original version. The experiments and results remain the same
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item851">[851]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.11695"
                    title="Abstract">arXiv:2306.11695</a> (replaced) [<a href="/pdf/2306.11695"
                    title="Download PDF">pdf</a>, <a href="/format/2306.11695" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Simple and Effective Pruning Approach for Large Language
                    Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+M">Mingjie Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhuang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bair%2C+A">Anna Bair</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kolter%2C+J+Z">J. Zico Kolter</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024. Website at <a
                        href="https://eric-mingjie.github.io/wanda/home.html">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item852">[852]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.11879"
                    title="Abstract">arXiv:2306.11879</a> (replaced) [<a href="/pdf/2306.11879"
                    title="Download PDF">pdf</a>, <a href="/format/2306.11879" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Open-Domain Text Evaluation via Contrastive Distribution
                    Modeling
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+S">Sidi Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hongyi Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tianlu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+N">Nanyun Peng</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item853">[853]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.12420"
                    title="Abstract">arXiv:2306.12420</a> (replaced) [<a href="/pdf/2306.12420"
                    title="Download PDF">pdf</a>, <a href="/format/2306.12420" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LMFlow: An Extensible Toolkit for Finetuning and Inference of
                    Large Foundation Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Diao%2C+S">Shizhe Diao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pan%2C+R">Rui Pan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+H">Hanze Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shum%2C+K+S">Ka Shun Shum</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jipeng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+W">Wei Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tong Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published in NAACL 2024 Demo Track
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item854">[854]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.12422"
                    title="Abstract">arXiv:2306.12422</a> (replaced) [<a href="/pdf/2306.12422"
                    title="Download PDF">pdf</a>, <a href="/format/2306.12422" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DreamTime: An Improved Optimization Strategy for
                    Diffusion-Guided 3D Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yukun Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jianan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yukai Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+B">Boshi Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qi%2C+X">Xianbiao Qi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item855">[855]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.14222"
                    title="Abstract">arXiv:2306.14222</a> (replaced) [<a href="/pdf/2306.14222"
                    title="Download PDF">pdf</a>, <a href="/format/2306.14222" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unveiling the Potential of Sentiment: Can Large Language
                    Models Predict Chinese Stock Price Movements?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Haohan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hua%2C+F">Fengrui Hua</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Chengjin Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kong%2C+H">Hao Kong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zuo%2C+R">Ruiting Zuo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+J">Jian Guo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Statistical Finance (q-fin.ST)

                </div>
            </div>
        </dd>
        <dt><a name="item856">[856]</a>&nbsp; <span class="list-identifier"><a href="/abs/2306.15447"
                    title="Abstract">arXiv:2306.15447</a> (replaced) [<a href="/pdf/2306.15447"
                    title="Download PDF">pdf</a>, <a href="/format/2306.15447" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Are aligned neural networks adversarially aligned?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Carlini%2C+N">Nicholas Carlini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nasr%2C+M">Milad Nasr</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choquette-Choo%2C+C+A">Christopher A.
                        Choquette-Choo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jagielski%2C+M">Matthew Jagielski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+I">Irena Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Awadalla%2C+A">Anas Awadalla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Koh%2C+P+W">Pang Wei Koh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ippolito%2C+D">Daphne Ippolito</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+K">Katherine Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tramer%2C+F">Florian Tramer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schmidt%2C+L">Ludwig Schmidt</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine
                    Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item857">[857]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.00186"
                    title="Abstract">arXiv:2307.00186</a> (replaced) [<a href="/pdf/2307.00186"
                    title="Download PDF">pdf</a>, <a href="/format/2307.00186" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> How far is Language Model from 100% Few-shot Named Entity
                    Recognition in Medical Domain
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Mingchen Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rui Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published as a journal paper at Journal of the American
                    Medical Informatics Association (JAMIA). arXiv admin note: text overlap with <a
                        href="/abs/2305.18624">arXiv:2305.18624</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item858">[858]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.02629"
                    title="Abstract">arXiv:2307.02629</a> (replaced) [<a href="/pdf/2307.02629"
                    title="Download PDF">pdf</a>, <a href="/format/2307.02629" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The landscape of compressibility measures for two-dimensional
                    data
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Carfagna%2C+L">Lorenzo Carfagna</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Manzini%2C+G">Giovanni Manzini</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Combinatorics (math.CO)

                </div>
            </div>
        </dd>
        <dt><a name="item859">[859]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.02891"
                    title="Abstract">arXiv:2307.02891</a> (replaced) [<a href="/pdf/2307.02891"
                    title="Download PDF">pdf</a>, <a href="/format/2307.02891" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> BaBE: Enhancing Fairness via Estimation of Latent Explaining
                    Variables
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Binkyte%2C+R">Ruta Binkyte</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gorla%2C+D">Daniele Gorla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Palamidessi%2C+C">Catuscia Palamidessi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

                </div>
            </div>
        </dd>
        <dt><a name="item860">[860]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.03195"
                    title="Abstract">arXiv:2307.03195</a> (replaced) [<a href="/pdf/2307.03195"
                    title="Download PDF">pdf</a>, <a href="/format/2307.03195" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Comprehensive Survey of Artificial Intelligence Techniques
                    for Talent Analytics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Qin%2C+C">Chuan Qin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Le Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Y">Yihang Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zha%2C+R">Rui Zha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+D">Dazhong Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Ying Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+C">Chen Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+H">Hengshu Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+H">Hui Xiong</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 61 pages, 15 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item861">[861]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.04085"
                    title="Abstract">arXiv:2307.04085</a> (replaced) [<a href="/pdf/2307.04085"
                    title="Download PDF">pdf</a>, <a href="/format/2307.04085" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Vector Commitments with Efficient Updates
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tas%2C+E+N">Ertem Nusret Tas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boneh%2C+D">Dan Boneh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> In Advances in Financial Technologies - AFT 2023
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item862">[862]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.04599"
                    title="Abstract">arXiv:2307.04599</a> (replaced) [<a href="/pdf/2307.04599"
                    title="Download PDF">pdf</a>, <a href="/format/2307.04599" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bridging MDE and AI: A Systematic Review of Domain-Specific
                    Languages and Model-Driven Practices in AI Software Systems Engineering
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Raedler%2C+S">Simon Raedler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Berardinelli%2C+L">Luca Berardinelli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Winter%2C+K">Karolin Winter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rahimi%2C+A">Abbas Rahimi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rinderle-Ma%2C+S">Stefanie Rinderle-Ma</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 57 pages, 2 figures, 8 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item863">[863]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.04760"
                    title="Abstract">arXiv:2307.04760</a> (replaced) [<a href="/pdf/2307.04760"
                    title="Download PDF">pdf</a>, <a href="/format/2307.04760" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Learning Spatial Features from Audio-Visual Correspondence in
                    Egocentric Videos
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Majumder%2C+S">Sagnik Majumder</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Al-Halah%2C+Z">Ziad Al-Halah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Grauman%2C+K">Kristen Grauman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to CVPR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

                </div>
            </div>
        </dd>
        <dt><a name="item864">[864]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.11880"
                    title="Abstract">arXiv:2307.11880</a> (replaced) [<a href="/pdf/2307.11880"
                    title="Download PDF">pdf</a>, <a href="/ps/2307.11880" title="Download PostScript">ps</a>, <a
                    href="/format/2307.11880" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bans vs. Warning Labels: Examining Support for Community-wide
                    Moderation Interventions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jhaver%2C+S">Shagun Jhaver</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a
                        href="/abs/2301.02208">arXiv:2301.02208</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item865">[865]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.13883"
                    title="Abstract">arXiv:2307.13883</a> (replaced) [<a href="/pdf/2307.13883"
                    title="Download PDF">pdf</a>, <a href="/format/2307.13883" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ExeDec: Execution Decomposition for Compositional
                    Generalization in Neural Program Synthesis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+K">Kensen Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hong%2C+J">Joey Hong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yinlin Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yin%2C+P">Pengcheng Yin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zaheer%2C+M">Manzil Zaheer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sutton%2C+C">Charles Sutton</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Programming Languages (cs.PL)

                </div>
            </div>
        </dd>
        <dt><a name="item866">[866]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.15034"
                    title="Abstract">arXiv:2307.15034</a> (replaced) [<a href="/pdf/2307.15034"
                    title="Download PDF">pdf</a>, <a href="/format/2307.15034" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Guaranteed Approximation Bounds for Mixed-Precision Neural
                    Operators
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tu%2C+R">Renbo Tu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=White%2C+C">Colin White</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kossaifi%2C+J">Jean Kossaifi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bonev%2C+B">Boris Bonev</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kovachki%2C+N">Nikola Kovachki</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pekhimenko%2C+G">Gennady Pekhimenko</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Azizzadenesheli%2C+K">Kamyar Azizzadenesheli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Anandkumar%2C+A">Anima Anandkumar</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Numerical Analysis (math.NA)

                </div>
            </div>
        </dd>
        <dt><a name="item867">[867]</a>&nbsp; <span class="list-identifier"><a href="/abs/2307.16033"
                    title="Abstract">arXiv:2307.16033</a> (replaced) [<a href="/pdf/2307.16033"
                    title="Download PDF">pdf</a>, <a href="/format/2307.16033" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CoVid-19 Detection leveraging Vision Transformers and
                    Explainable AI
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Kumar%2C+P+S">Pangoth Santhosh Kumar</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Supriya%2C+K">Kundrapu Supriya</a>,
                    <a href="/search/eess?searchtype=author&amp;query=K%2C+M+R">Mallikharjuna Rao K</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Malisetti%2C+T+S+K+T">Taraka Satya Krishna Teja
                        Malisetti</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item868">[868]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.01654"
                    title="Abstract">arXiv:2308.01654</a> (replaced) [<a href="/pdf/2308.01654"
                    title="Download PDF">pdf</a>, <a href="/format/2308.01654" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards a Safe Real-Time Motion Planning Framework for
                    Autonomous Driving Systems: An MPPI Approach
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Testouri%2C+M">Mehdi Testouri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Elghazaly%2C+G">Gamal Elghazaly</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Frank%2C+R">Raphael Frank</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item869">[869]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.01987"
                    title="Abstract">arXiv:2308.01987</a> (replaced) [<a href="/pdf/2308.01987"
                    title="Download PDF">pdf</a>, <a href="/format/2308.01987" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bengali Fake Reviews: A Benchmark Dataset and Detection
                    System
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shahariar%2C+G+M">G. M. Shahariar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shawon%2C+M+T+R">Md. Tanvir Rouf Shawon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shah%2C+F+M">Faisal Muhammad Shah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alam%2C+M+S">Mohammad Shafiul Alam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mahbub%2C+M+S">Md. Shahriar Mahbub</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item870">[870]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.02151"
                    title="Abstract">arXiv:2308.02151</a> (replaced) [<a href="/pdf/2308.02151"
                    title="Download PDF">pdf</a>, <a href="/format/2308.02151" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Retroformer: Retrospective Large Language Agents with Policy
                    Gradient Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+W">Weiran Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Heinecke%2C+S">Shelby Heinecke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Niebles%2C+J+C">Juan Carlos Niebles</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiwei Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yihao Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+L">Le Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Murthy%2C+R">Rithesh Murthy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zeyuan Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jianguo Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Arpit%2C+D">Devansh Arpit</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+R">Ran Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mui%2C+P">Phil Mui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Huan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+C">Caiming Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Savarese%2C+S">Silvio Savarese</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item871">[871]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.03314"
                    title="Abstract">arXiv:2308.03314</a> (replaced) [<a href="/pdf/2308.03314"
                    title="Download PDF">pdf</a>, <a href="/format/2308.03314" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GPTScan: Detecting Logic Vulnerabilities in Smart Contracts
                    by Combining GPT with Program Analysis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yuqiang Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+D">Daoyuan Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+Y">Yue Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Han Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haijun Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhengzi Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+X">Xiaofei Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yang Liu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IEEE/ACM ICSE 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

                </div>
            </div>
        </dd>
        <dt><a name="item872">[872]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.04259"
                    title="Abstract">arXiv:2308.04259</a> (replaced) [<a href="/pdf/2308.04259"
                    title="Download PDF">pdf</a>, <a href="/format/2308.04259" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Generalized Forgetting Recursive Least Squares: Stability and
                    Robustness Guarantees
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Lai%2C+B">Brian Lai</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Bernstein%2C+D+S">Dennis S. Bernstein</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to the IEEE Transactions on Automatic Control.
                    Scheduled to appear in the 2024 November issue
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>; Signal Processing (eess.SP)

                </div>
            </div>
        </dd>
        <dt><a name="item873">[873]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.05381"
                    title="Abstract">arXiv:2308.05381</a> (replaced) [<a href="/pdf/2308.05381"
                    title="Download PDF">pdf</a>, <a href="/format/2308.05381" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An Exploratory Study of V-Model in Building ML-Enabled
                    Software: A Systems Engineering Perspective
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J+J">Jie JW Wu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 2 figures, 2 tables. Accepted at CAIN 2024 (3rd
                    International Conference on AI Engineering - Software Engineering for AI)
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> 2024 IEEE/ACM 3rd International Conference on AI
                    Engineering -
                    Software Engineering for AI (CAIN)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item874">[874]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.05882"
                    title="Abstract">arXiv:2308.05882</a> (replaced) [<a href="/pdf/2308.05882"
                    title="Download PDF">pdf</a>, <a href="/format/2308.05882" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GPLaSDI: Gaussian Process-based Interpretable Latent Space
                    Dynamics Identification through Deep Autoencoder
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bonneville%2C+C">Christophe Bonneville</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+Y">Youngsoo Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghosh%2C+D">Debojyoti Ghosh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Belof%2C+J+L">Jonathan L. Belof</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering,
                    418A,
                    116535, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

                </div>
            </div>
        </dd>
        <dt><a name="item875">[875]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.07847"
                    title="Abstract">arXiv:2308.07847</a> (replaced) [<a href="/pdf/2308.07847"
                    title="Download PDF">pdf</a>, <a href="/format/2308.07847" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Robustness Over Time: Understanding Adversarial Examples'
                    Effectiveness on Longitudinal Versions of Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yugeng Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cong%2C+T">Tianshuo Cong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+Z">Zhengyu Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Backes%2C+M">Michael Backes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Y">Yun Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yang Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item876">[876]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.10638"
                    title="Abstract">arXiv:2308.10638</a> (replaced) [<a href="/pdf/2308.10638"
                    title="Download PDF">pdf</a>, <a href="/format/2308.10638" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent
                    Clothed and Textured Human Meshes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sanyal%2C+S">Soubhik Sanyal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghosh%2C+P">Partha Ghosh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jinlong Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Black%2C+M+J">Michael J. Black</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thies%2C+J">Justus Thies</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bolkart%2C+T">Timo Bolkart</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Updated to camera ready version of CVPR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning
                    (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item877">[877]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.11267"
                    title="Abstract">arXiv:2308.11267</a> (replaced) [<a href="/pdf/2308.11267"
                    title="Download PDF">pdf</a>, <a href="/format/2308.11267" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Robust Lagrangian and Adversarial Policy Gradient for Robust
                    Constrained Markov Decision Processes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bossens%2C+D+M">David M. Bossens</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

                </div>
            </div>
        </dd>
        <dt><a name="item878">[878]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.11471"
                    title="Abstract">arXiv:2308.11471</a> (replaced) [<a href="/pdf/2308.11471"
                    title="Download PDF">pdf</a>, <a href="/format/2308.11471" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Dynamic Open Vocabulary Enhanced Safe-landing with
                    Intelligence (DOVESEI)
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bong%2C+H+M">Haechan Mark Bong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Rongge Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=de+Azambuja%2C+R">Ricardo de Azambuja</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Beltrame%2C+G">Giovanni Beltrame</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> IROS 2023 The Last-Mile Robotics Workshop
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item879">[879]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.11647"
                    title="Abstract">arXiv:2308.11647</a> (replaced) [<a href="/pdf/2308.11647"
                    title="Download PDF">pdf</a>, <a href="/format/2308.11647" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Optically-Transparent EM Skins for Outdoor-to-Indoor mm-Wave
                    Wireless Communications
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Oliveri%2C+G">Giacomo Oliveri</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Zardi%2C+F">Francesco Zardi</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Massa%2C+A">Andrea Massa</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> IEEE Access, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Systems and Control (eess.SY); Applied Physics (physics.app-ph)

                </div>
            </div>
        </dd>
        <dt><a name="item880">[880]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.12255"
                    title="Abstract">arXiv:2308.12255</a> (replaced) [<a href="/pdf/2308.12255"
                    title="Download PDF">pdf</a>, <a href="/format/2308.12255" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Absorbing boundary conditions for the Helmholtz equation
                    using Gauss-Legendre quadrature reduced integrations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Sagiyama%2C+K">Koki Sagiyama</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> edit author list and tidy up script
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>; Mathematical Physics (math-ph)

                </div>
            </div>
        </dd>
        <dt><a name="item881">[881]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.12517"
                    title="Abstract">arXiv:2308.12517</a> (replaced) [<a href="/pdf/2308.12517"
                    title="Download PDF">pdf</a>, <a href="/format/2308.12517" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Not Only Rewards But Also Constraints: Applications on Legged
                    Robot Locomotion
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+Y">Yunho Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Oh%2C+H">Hyunsik Oh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Jeonghyun Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+J">Jinhyeok Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+G">Gwanghyeon Ji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jung%2C+M">Moonkyu Jung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Youm%2C+D">Donghoon Youm</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hwangbo%2C+J">Jemin Hwangbo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Robotics (T-RO) 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item882">[882]</a>&nbsp; <span class="list-identifier"><a href="/abs/2308.14104"
                    title="Abstract">arXiv:2308.14104</a> (replaced) [<a href="/pdf/2308.14104"
                    title="Download PDF">pdf</a>, <a href="/format/2308.14104" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards Generalizable Neural Solvers for Vehicle Routing
                    Problems via Ensemble with Transferrable Local Policy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+C">Chengrui Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shang%2C+H">Haopu Shang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+K">Ke Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qian%2C+C">Chao Qian</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item883">[883]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.02050"
                    title="Abstract">arXiv:2309.02050</a> (replaced) [<a href="/pdf/2309.02050"
                    title="Download PDF">pdf</a>, <a href="/format/2309.02050" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Machine learning of network inference enhancement from noisy
                    measurements
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+K">Kai Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuanyuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jing Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information
                        Networks (cs.SI)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item884">[884]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.06837"
                    title="Abstract">arXiv:2309.06837</a> (replaced) [<a href="/pdf/2309.06837"
                    title="Download PDF">pdf</a>, <a href="/format/2309.06837" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Time-Optimal Gate-Traversing Planner for Autonomous Drone
                    Racing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Qin%2C+C">Chao Qin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Michet%2C+M+S+J">Maxime S.J. Michet</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jingxiang Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H+H+-">Hugh H.-T. Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item885">[885]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.07169"
                    title="Abstract">arXiv:2309.07169</a> (replaced) [<a href="/pdf/2309.07169"
                    title="Download PDF">pdf</a>, <a href="/format/2309.07169" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spectral Convergence of Complexon Shift Operators
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+P">Purui Zhang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Jian%2C+X">Xingchao Jian</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Ji%2C+F">Feng Ji</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Tay%2C+W+P">Wee Peng Tay</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wen%2C+B">Bihan Wen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 2 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item886">[886]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.08464"
                    title="Abstract">arXiv:2309.08464</a> (replaced) [<a href="/pdf/2309.08464"
                    title="Download PDF">pdf</a>, <a href="/ps/2309.08464" title="Download PostScript">ps</a>, <a
                    href="/format/2309.08464" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Differentially Private Average Consensus with Improved
                    Accuracy-Privacy Trade-off
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Wang%2C+L">Lei Wang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Liu%2C+W">Weijia Liu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Guo%2C+F">Fanghong Guo</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Qiao%2C+Z">Zixin Qiao</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wu%2C+Z">Zhengguang Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item887">[887]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.09128"
                    title="Abstract">arXiv:2309.09128</a> (replaced) [<a href="/pdf/2309.09128"
                    title="Download PDF">pdf</a>, <a href="/format/2309.09128" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ChainForge: A Visual Toolkit for Prompt Engineering and LLM
                    Hypothesis Testing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Arawjo%2C+I">Ian Arawjo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Swoopes%2C+C">Chelse Swoopes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vaithilingam%2C+P">Priyan Vaithilingam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wattenberg%2C+M">Martin Wattenberg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Glassman%2C+E">Elena Glassman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages, 7 figures, published at CHI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item888">[888]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.10426"
                    title="Abstract">arXiv:2309.10426</a> (replaced) [<a href="/pdf/2309.10426"
                    title="Download PDF">pdf</a>, <a href="/format/2309.10426" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multi-Object Graph Affordance Network: Goal-Oriented Planning
                    through Learned Compound Object Affordances
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Girgin%2C+T">Tuba Girgin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ugur%2C+E">Emre Ugur</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible
                    publication. Copyright may be transferred without notice, after which this version may no longer be
                    accessible
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item889">[889]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.10908"
                    title="Abstract">arXiv:2309.10908</a> (replaced) [<a href="/pdf/2309.10908"
                    title="Download PDF">pdf</a>, <a href="/format/2309.10908" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multicopy Reinforcement Learning Agents
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wolfe%2C+A+P">Alicia P. Wolfe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Diamond%2C+O">Oliver Diamond</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goeler-Slough%2C+B">Brigitte Goeler-Slough</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feuerman%2C+R">Remi Feuerman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kisielinska%2C+M">Magdalena Kisielinska</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Manfredi%2C+V">Victoria Manfredi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Updates from earlier version: added a more basic
                    "multiagent" algorithm to compare to and comparison graphs
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems
                        (cs.MA)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item890">[890]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.11721"
                    title="Abstract">arXiv:2309.11721</a> (replaced) [<a href="/pdf/2309.11721"
                    title="Download PDF">pdf</a>, <a href="/ps/2309.11721" title="Download PostScript">ps</a>, <a
                    href="/format/2309.11721" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Defining and Preventing Asymmetric Mempool DoS in Ethereum
                    with saferAd
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+W">Wanning Ding</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yibo Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Y">Yuzhe Tang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item891">[891]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.13005"
                    title="Abstract">arXiv:2309.13005</a> (replaced) [<a href="/pdf/2309.13005"
                    title="Download PDF">pdf</a>, <a href="/format/2309.13005" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards Counterfactual Fairness-aware Domain Generalization
                    in Changing Environments
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yujie Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chen Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shao%2C+M">Minglai Shao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Meng%2C+B">Baoluo Meng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xujiang Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Haifeng Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

                </div>
            </div>
        </dd>
        <dt><a name="item892">[892]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.13285"
                    title="Abstract">arXiv:2309.13285</a> (replaced) [<a href="/pdf/2309.13285"
                    title="Download PDF">pdf</a>, <a href="/format/2309.13285" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Collision Avoidance and Navigation for a Quadrotor Swarm
                    Using End-to-end Deep Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhehui Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhaojing Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Krupani%2C+R">Rahul Krupani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=%C5%9Eenba%C5%9Flar%2C+B">Baskın Şenbaşlar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Batra%2C+S">Sumeet Batra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sukhatme%2C+G+S">Gaurav S. Sukhatme</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to ICRA 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

                </div>
            </div>
        </dd>
        <dt><a name="item893">[893]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.14091"
                    title="Abstract">arXiv:2309.14091</a> (replaced) [<a href="/pdf/2309.14091"
                    title="Download PDF">pdf</a>, <a href="/format/2309.14091" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the Benefit of Optimal Transport for Curriculum
                    Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Klink%2C+P">Pascal Klink</a>,
                    <a href="/search/cs?searchtype=author&amp;query=D%27Eramo%2C+C">Carlo D'Eramo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peters%2C+J">Jan Peters</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pajarinen%2C+J">Joni Pajarinen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item894">[894]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.14726"
                    title="Abstract">arXiv:2309.14726</a> (replaced) [<a href="/pdf/2309.14726"
                    title="Download PDF">pdf</a>, <a href="/format/2309.14726" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PLMM: Personal Large Language Models on Mobile Devices
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gong%2C+Y">Yuanhao Gong</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a
                        href="/abs/2307.13221">arXiv:2307.13221</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance,
                    and Science (cs.CE); Computation and Language (cs.CL); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item895">[895]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.16482"
                    title="Abstract">arXiv:2309.16482</a> (replaced) [<a href="/pdf/2309.16482"
                    title="Download PDF">pdf</a>, <a href="/ps/2309.16482" title="Download PostScript">ps</a>, <a
                    href="/format/2309.16482" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Meeting Recognition with Continuous Speech Separation and
                    Transcription-Supported Diarization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=von+Neumann%2C+T">Thilo von Neumann</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Boeddeker%2C+C">Christoph Boeddeker</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Cord-Landwehr%2C+T">Tobias Cord-Landwehr</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Delcroix%2C+M">Marc Delcroix</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Haeb-Umbach%2C+R">Reinhold Haeb-Umbach</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at HSCMA Sattelite Workshop at ICASSP 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing
                        (eess.AS)</span>; Sound (cs.SD)

                </div>
            </div>
        </dd>
        <dt><a name="item896">[896]</a>&nbsp; <span class="list-identifier"><a href="/abs/2309.17444"
                    title="Abstract">arXiv:2309.17444</a> (replaced) [<a href="/pdf/2309.17444"
                    title="Download PDF">pdf</a>, <a href="/format/2309.17444" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LLM-grounded Video Diffusion Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lian%2C+L">Long Lian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+B">Baifeng Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yala%2C+A">Adam Yala</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Darrell%2C+T">Trevor Darrell</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Boyi Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024. Project Page: <a
                        href="https://llm-grounded-video-diffusion.github.io/">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item897">[897]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.00809"
                    title="Abstract">arXiv:2310.00809</a> (replaced) [<a href="/pdf/2310.00809"
                    title="Download PDF">pdf</a>, <a href="/format/2310.00809" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards Causal Foundation Model: on Duality between Causal
                    Inference and Attention
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaqi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jennings%2C+J">Joel Jennings</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hilmkil%2C+A">Agrin Hilmkil</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pawlowski%2C+N">Nick Pawlowski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Cheng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+C">Chao Ma</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME); Machine Learning
                    (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item898">[898]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.01055"
                    title="Abstract">arXiv:2310.01055</a> (replaced) [<a href="/pdf/2310.01055"
                    title="Download PDF">pdf</a>, <a href="/format/2310.01055" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improved Crop and Weed Detection with Diverse Data Ensemble
                    Learning in Agriculture
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Asad%2C+M+H">Muhammad Hamza Asad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Anwar%2C+S">Saeed Anwar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bais%2C+A">Abdul Bais</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in CVPR Workshop as an Oral
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item899">[899]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.01288"
                    title="Abstract">arXiv:2310.01288</a> (replaced) [<a href="/pdf/2310.01288"
                    title="Download PDF">pdf</a>, <a href="/format/2310.01288" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Offline Tracking with Object Permanence
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xianzhong Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Caesar%2C+H">Holger Caesar</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IEEE Intelligent Vehicles Symposium (IV 2024).
                    Camera ready version with supplementary material
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item900">[900]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.01352"
                    title="Abstract">arXiv:2310.01352</a> (replaced) [<a href="/pdf/2310.01352"
                    title="Download PDF">pdf</a>, <a href="/format/2310.01352" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> RA-DIT: Retrieval-Augmented Dual Instruction Tuning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+X+V">Xi Victoria Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xilun Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Mingda Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+W">Weijia Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lomeli%2C+M">Maria Lomeli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=James%2C+R">Rich James</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rodriguez%2C+P">Pedro Rodriguez</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kahn%2C+J">Jacob Kahn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Szilvasy%2C+G">Gergely Szilvasy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lewis%2C+M">Mike Lewis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yih%2C+S">Scott Yih</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> v4: ICLR 2024 camera-ready version
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item901">[901]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.01558"
                    title="Abstract">arXiv:2310.01558</a> (replaced) [<a href="/pdf/2310.01558"
                    title="Download PDF">pdf</a>, <a href="/format/2310.01558" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Making Retrieval-Augmented Language Models Robust to
                    Irrelevant Context
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yoran%2C+O">Ori Yoran</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wolfson%2C+T">Tomer Wolfson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ram%2C+O">Ori Ram</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Berant%2C+J">Jonathan Berant</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item902">[902]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.01668"
                    title="Abstract">arXiv:2310.01668</a> (replaced) [<a href="/pdf/2310.01668"
                    title="Download PDF">pdf</a>, <a href="/format/2310.01668" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Locality-Aware Graph-Rewiring in GNNs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Barbero%2C+F">Federico Barbero</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Velingker%2C+A">Ameya Velingker</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saberi%2C+A">Amin Saberi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bronstein%2C+M">Michael Bronstein</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Di+Giovanni%2C+F">Francesco Di Giovanni</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item903">[903]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.02043"
                    title="Abstract">arXiv:2310.02043</a> (replaced) [<a href="/pdf/2310.02043"
                    title="Download PDF">pdf</a>, <a href="/format/2310.02043" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> View-Independent Adjoint Light Tracing for Lighting Design
                    Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lipp%2C+L">Lukas Lipp</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hahn%2C+D">David Hahn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ecormier-Nocca%2C+P">Pierre Ecormier-Nocca</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rist%2C+F">Florian Rist</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wimmer%2C+M">Michael Wimmer</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item904">[904]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.02401"
                    title="Abstract">arXiv:2310.02401</a> (replaced) [<a href="/pdf/2310.02401"
                    title="Download PDF">pdf</a>, <a href="/format/2310.02401" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FT-Shield: A Watermark Against Unauthorized Fine-tuning in
                    Text-to-Image Diffusion Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cui%2C+Y">Yingqian Cui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+J">Jie Ren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yuping Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Han Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+P">Pengfei He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xing%2C+Y">Yue Xing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+L">Lingjuan Lyu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+W">Wenqi Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hui Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+J">Jiliang Tang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item905">[905]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.02671"
                    title="Abstract">arXiv:2310.02671</a> (replaced) [<a href="/pdf/2310.02671"
                    title="Download PDF">pdf</a>, <a href="/format/2310.02671" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Beyond Stationarity: Convergence Analysis of Stochastic
                    Softmax Policy Gradient Methods
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Klein%2C+S">Sara Klein</a>,
                    <a href="/search/math?searchtype=author&amp;query=Weissmann%2C+S">Simon Weissmann</a>,
                    <a href="/search/math?searchtype=author&amp;query=D%C3%B6ring%2C+L">Leif Döring</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 54 pages, 2 figures, ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item906">[906]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.03789"
                    title="Abstract">arXiv:2310.03789</a> (replaced) [<a href="/pdf/2310.03789"
                    title="Download PDF">pdf</a>, <a href="/format/2310.03789" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Grokking as a First Order Phase Transition in Two Layer
                    Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Rubin%2C+N">Noa Rubin</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Seroussi%2C+I">Inbar Seroussi</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Ringel%2C+Z">Zohar Ringel</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning
                    (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item907">[907]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.04966"
                    title="Abstract">arXiv:2310.04966</a> (replaced) [<a href="/pdf/2310.04966"
                    title="Download PDF">pdf</a>, <a href="/format/2310.04966" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improved Active Learning via Dependent Leverage Score
                    Sampling
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shimizu%2C+A">Atsushi Shimizu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+X">Xiaoou Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Musco%2C+C">Christopher Musco</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Weare%2C+J">Jonathan Weare</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To appear at ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item908">[908]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.05175"
                    title="Abstract">arXiv:2310.05175</a> (replaced) [<a href="/pdf/2310.05175"
                    title="Download PDF">pdf</a>, <a href="/format/2310.05175" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret
                    Sauce for Pruning LLMs to High Sparsity
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yin%2C+L">Lu Yin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">You Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhenyu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hsieh%2C+C">Cheng-Yu Hsieh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yaqing Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jia%2C+Y">Yiling Jia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Gen Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jaiswal%2C+A">Ajay Jaiswal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yi Liang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bendersky%2C+M">Michael Bendersky</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhangyang Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shiwei Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item909">[909]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.05440"
                    title="Abstract">arXiv:2310.05440</a> (replaced) [<a href="/pdf/2310.05440"
                    title="Download PDF">pdf</a>, <a href="/format/2310.05440" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Modeling and Simulation of Chemo-Elasto-Plastically Coupled
                    Battery Active Particles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Schoof%2C+R">Raphael Schoof</a>,
                    <a href="/search/math?searchtype=author&amp;query=Niermann%2C+J">Johannes Niermann</a>,
                    <a href="/search/math?searchtype=author&amp;query=Dyck%2C+A">Alexander Dyck</a>,
                    <a href="/search/math?searchtype=author&amp;query=B%C3%B6hlke%2C+T">Thomas Böhlke</a>,
                    <a href="/search/math?searchtype=author&amp;query=D%C3%B6rfler%2C+W">Willy Dörfler</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item910">[910]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.06387"
                    title="Abstract">arXiv:2310.06387</a> (replaced) [<a href="/pdf/2310.06387"
                    title="Download PDF">pdf</a>, <a href="/format/2310.06387" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Jailbreak and Guard Aligned Language Models with Only Few
                    In-Context Demonstrations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Z">Zeming Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yifei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yisen Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography
                    and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item911">[911]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.07298"
                    title="Abstract">arXiv:2310.07298</a> (replaced) [<a href="/pdf/2310.07298"
                    title="Download PDF">pdf</a>, <a href="/format/2310.07298" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Beyond Memorization: Violating Privacy Via Inference with
                    Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Staab%2C+R">Robin Staab</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vero%2C+M">Mark Vero</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Balunovi%C4%87%2C+M">Mislav Balunović</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vechev%2C+M">Martin Vechev</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item912">[912]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.07626"
                    title="Abstract">arXiv:2310.07626</a> (replaced) [<a href="/pdf/2310.07626"
                    title="Download PDF">pdf</a>, <a href="/format/2310.07626" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Learning of Sea Surface Height Interpolation from
                    Multi-variate Simulated Satellite Observations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Archambault%2C+T">Theo Archambault</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Filoche%2C+A">Arthur Filoche</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Charantonis%2C+A">Anastase Charantonis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bereziat%2C+D">Dominique Bereziat</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thiria%2C+S">Sylvie Thiria</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to JAMES. 31 pages, minor revision
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item913">[913]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.08342"
                    title="Abstract">arXiv:2310.08342</a> (replaced) [<a href="/pdf/2310.08342"
                    title="Download PDF">pdf</a>, <a href="/format/2310.08342" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Discontinuous Galerkin approximations of the heterodimer
                    model for protein-protein interaction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Antonietti%2C+P+F">Paola F. Antonietti</a>,
                    <a href="/search/math?searchtype=author&amp;query=Bonizzoni%2C+F">Francesca Bonizzoni</a>,
                    <a href="/search/math?searchtype=author&amp;query=Corti%2C+M">Mattia Corti</a>,
                    <a href="/search/math?searchtype=author&amp;query=Dall%27Olio%2C+A">Agnese Dall'Olio</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item914">[914]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.08744"
                    title="Abstract">arXiv:2310.08744</a> (replaced) [<a href="/pdf/2310.08744"
                    title="Download PDF">pdf</a>, <a href="/format/2310.08744" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Circuit Component Reuse Across Tasks in Transformer Language
                    Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Merullo%2C+J">Jack Merullo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eickhoff%2C+C">Carsten Eickhoff</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pavlick%2C+E">Ellie Pavlick</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item915">[915]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.09453"
                    title="Abstract">arXiv:2310.09453</a> (replaced) [<a href="/e-print/2310.09453"
                    title="Download source">src</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Effects of Same-Race Mentorship Preferences on Academic
                    Performance and Survival
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+M">Meijun Liu</a> (1),
                    <a href="/search/cs?searchtype=author&amp;query=Bu%2C+Y">Yi Bu</a> (2),
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Daifeng Li</a> (3),
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+Y">Ying Ding</a> (4),
                    <a href="/search/cs?searchtype=author&amp;query=Acuna%2C+D+E">Daniel E. Acuna</a> (5) ((1) Institute
                    for Global Public Policy, Fudan University, (2) Department of Information Management, Peking
                    University, (3) School of Information Management, Sun Yat-sen University, (4) School of Information,
                    University of Texas at Austin, (5) Department of Computer Science, University of Colorado at
                    Boulder)
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 1. After further evaluating the race prediction method, we
                    observed unsatisfactory accuracy and F1 scores. The study's findings could be impacted by these
                    subpar predictions. 2. Our study incorporates both US and non-US samples, revealing that non-US
                    samples may introduce outliers and distort the results. We recognize that the study's findings and
                    conclusions might be affected by data quality
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information
                        Networks (cs.SI)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item916">[916]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.10690"
                    title="Abstract">arXiv:2310.10690</a> (replaced) [<a href="/pdf/2310.10690"
                    title="Download PDF">pdf</a>, <a href="/format/2310.10690" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Large Language Models for In-Context Student Modeling:
                    Synthesizing Student's Behavior in Visual Programming
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nguyen%2C+M+H">Manh Hung Nguyen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tschiatschek%2C+S">Sebastian Tschiatschek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singla%2C+A">Adish Singla</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published in International Conference on Educational Data
                    Mining (EDM) 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item917">[917]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.12952"
                    title="Abstract">arXiv:2310.12952</a> (replaced) [<a href="/pdf/2310.12952"
                    title="Download PDF">pdf</a>, <a href="/format/2310.12952" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Cousins Of The Vendi Score: A Family Of Similarity-Based
                    Diversity Metrics For Science And Machine Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pasarkar%2C+A+P">Amey P. Pasarkar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dieng%2C+A+B">Adji Bousso Dieng</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published in the proceedings of Artificial Intelligence
                    and Statistics, AISTATS 2024. This paper is dedicated to Aline Sitoe Diatta. The code can be found
                    on Vertaix's GitHub. Code for evaluating diversity using the Vendi scores can be found at <a
                        href="https://github.com/vertaix/Vendi-Score.">this https URL</a> Code for using the scores
                    within Vendi Sampling can be found at <a href="https://github.com/vertaix/Vendi-Sampling">this https
                        URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Chemical Physics (physics.chem-ph); Populations and Evolution (q-bio.PE)

                </div>
            </div>
        </dd>
        <dt><a name="item918">[918]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.12973"
                    title="Abstract">arXiv:2310.12973</a> (replaced) [<a href="/pdf/2310.12973"
                    title="Download PDF">pdf</a>, <a href="/format/2310.12973" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Frozen Transformers in Language Models Are Effective Visual
                    Encoder Layers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pang%2C+Z">Ziqi Pang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Z">Ziyang Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Man%2C+Y">Yunze Man</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yu-Xiong Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024 Spotlight. 23 pages, 13 figures. Code at <a
                        href="https://github.com/ziqipang/LM4VisualEncoding">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL);
                    Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item919">[919]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.13298"
                    title="Abstract">arXiv:2310.13298</a> (replaced) [<a href="/pdf/2310.13298"
                    title="Download PDF">pdf</a>, <a href="/ps/2310.13298" title="Download PostScript">ps</a>, <a
                    href="/format/2310.13298" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Cache-Aided Communications in MISO Networks with Dynamic User
                    Behavior
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Abolpour%2C+M">Milad Abolpour</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Salehi%2C+M">MohammadJavad Salehi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=T%C3%B6lli%2C+A">Antti Tölli</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in IEEE Transaction On Wireless Communications,
                    2024. arXiv admin note: substantial text overlap with <a href="/abs/2304.11623">arXiv:2304.11623</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item920">[920]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.14157"
                    title="Abstract">arXiv:2310.14157</a> (replaced) [<a href="/pdf/2310.14157"
                    title="Download PDF">pdf</a>, <a href="/format/2310.14157" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Genetic Algorithms with Neural Cost Predictor for Solving
                    Hierarchical Vehicle Routing Problems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sobhanan%2C+A">Abhay Sobhanan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+J">Junyoung Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+J">Jinkyoo Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kwon%2C+C">Changhyun Kwon</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item921">[921]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.15526"
                    title="Abstract">arXiv:2310.15526</a> (replaced) [<a href="/pdf/2310.15526"
                    title="Download PDF">pdf</a>, <a href="/format/2310.15526" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Privacy Amplification for Matrix Mechanisms
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Choquette-Choo%2C+C+A">Christopher A.
                        Choquette-Choo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ganesh%2C+A">Arun Ganesh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Steinke%2C+T">Thomas Steinke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thakurta%2C+A">Abhradeep Thakurta</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Appearing in ICLR 2024. Changes made to match the
                    conference version of the paper
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item922">[922]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.15872"
                    title="Abstract">arXiv:2310.15872</a> (replaced) [<a href="/pdf/2310.15872"
                    title="Download PDF">pdf</a>, <a href="/format/2310.15872" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> KirchhoffNet: A Scalable Ultra Fast Analog Neural Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zhengqi Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+F">Fan-Keng Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rohrer%2C+R">Ron Rohrer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boning%2C+D+S">Duane S. Boning</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 10 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

                </div>
            </div>
        </dd>
        <dt><a name="item923">[923]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.15937"
                    title="Abstract">arXiv:2310.15937</a> (replaced) [<a href="/pdf/2310.15937"
                    title="Download PDF">pdf</a>, <a href="/format/2310.15937" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Behavioral Perspective on Models of Linear Dynamical
                    Networks with Manifest Variables
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Shi%2C+S">Shengling Shi</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Sun%2C+Z">Zhiyong Sun</a>,
                    <a href="/search/eess?searchtype=author&amp;query=De+Schutter%2C+B">Bart De Schutter</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item924">[924]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.16802"
                    title="Abstract">arXiv:2310.16802</a> (replaced) [<a href="/pdf/2310.16802"
                    title="Download PDF">pdf</a>, <a href="/format/2310.16802" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> From Molecules to Materials: Pre-training Large Generalizable
                    Models for Atomic Property Prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shoghi%2C+N">Nima Shoghi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kolluru%2C+A">Adeesh Kolluru</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kitchin%2C+J+R">John R. Kitchin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ulissi%2C+Z+W">Zachary W. Ulissi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zitnick%2C+C+L">C. Lawrence Zitnick</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wood%2C+B+M">Brandon M. Wood</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item925">[925]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.17191"
                    title="Abstract">arXiv:2310.17191</a> (replaced) [<a href="/pdf/2310.17191"
                    title="Download PDF">pdf</a>, <a href="/format/2310.17191" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> How do Language Models Bind Entities in Context?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+J">Jiahai Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Steinhardt%2C+J">Jacob Steinhardt</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item926">[926]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.18042"
                    title="Abstract">arXiv:2310.18042</a> (replaced) [<a href="/pdf/2310.18042"
                    title="Download PDF">pdf</a>, <a href="/format/2310.18042" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Sui Lutris: A Blockchain Combining Broadcast and Consensus
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Blackshear%2C+S">Same Blackshear</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chursin%2C+A">Andrey Chursin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Danezis%2C+G">George Danezis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kichidis%2C+A">Anastasios Kichidis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kokoris-Kogias%2C+L">Lefteris Kokoris-Kogias</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xun Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Logan%2C+M">Mark Logan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Menon%2C+A">Ashok Menon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nowacki%2C+T">Todd Nowacki</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sonnino%2C+A">Alberto Sonnino</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Williams%2C+B">Brandon Williams</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lu Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item927">[927]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.18373"
                    title="Abstract">arXiv:2310.18373</a> (replaced) [<a href="/pdf/2310.18373"
                    title="Download PDF">pdf</a>, <a href="/ps/2310.18373" title="Download PostScript">ps</a>, <a
                    href="/format/2310.18373" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Can LLMs Grade Short-Answer Reading Comprehension Questions :
                    An Empirical Study with a Novel Dataset
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Henkel%2C+O">Owen Henkel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hills%2C+L">Libby Hills</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roberts%2C+B">Bill Roberts</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McGrane%2C+J">Joshua McGrane</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item928">[928]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.18861"
                    title="Abstract">arXiv:2310.18861</a> (replaced) [<a href="/pdf/2310.18861"
                    title="Download PDF">pdf</a>, <a href="/format/2310.18861" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Peer-to-Peer Deep Learning for Beyond-5G IoT
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pranav%2C+S">Srinivasa Pranav</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Moura%2C+J+M+F">José M. F. Moura</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
            </div>
        </dd>
        <dt><a name="item929">[929]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.18936"
                    title="Abstract">arXiv:2310.18936</a> (replaced) [<a href="/pdf/2310.18936"
                    title="Download PDF">pdf</a>, <a href="/ps/2310.18936" title="Download PostScript">ps</a>, <a
                    href="/format/2310.18936" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adversarial Examples Are Not Real Features
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+A">Ang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yifei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Y">Yiwen Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yisen Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> NeurIPS 2023
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item930">[930]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.19041"
                    title="Abstract">arXiv:2310.19041</a> (replaced) [<a href="/pdf/2310.19041"
                    title="Download PDF">pdf</a>, <a href="/format/2310.19041" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On Linear Separation Capacity of Self-Supervised
                    Representation Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Wang%2C+S">Shulei Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

                </div>
            </div>
        </dd>
        <dt><a name="item931">[931]</a>&nbsp; <span class="list-identifier"><a href="/abs/2310.19567"
                    title="Abstract">arXiv:2310.19567</a> (replaced) [<a href="/pdf/2310.19567"
                    title="Download PDF">pdf</a>, <a href="/format/2310.19567" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CreoleVal: Multilingual Multitask Benchmarks for Creoles
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lent%2C+H">Heather Lent</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tatariya%2C+K">Kushal Tatariya</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dabre%2C+R">Raj Dabre</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yiyi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fekete%2C+M">Marcell Fekete</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ploeger%2C+E">Esther Ploeger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+L">Li Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Armstrong%2C+R">Ruth-Ann Armstrong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Eijansantos%2C+A">Abee Eijansantos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Malau%2C+C">Catriona Malau</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Heje%2C+H+E">Hans Erik Heje</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lavrinovics%2C+E">Ernests Lavrinovics</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kanojia%2C+D">Diptesh Kanojia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Belony%2C+P">Paul Belony</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bollmann%2C+M">Marcel Bollmann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Grobol%2C+L">Loïc Grobol</a>,
                    <a href="/search/cs?searchtype=author&amp;query=de+Lhoneux%2C+M">Miryam de Lhoneux</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hershcovich%2C+D">Daniel Hershcovich</a>,
                    <a href="/search/cs?searchtype=author&amp;query=DeGraff%2C+M">Michel DeGraff</a>,
                    <a href="/search/cs?searchtype=author&amp;query=S%C3%B8gaard%2C+A">Anders Søgaard</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bjerva%2C+J">Johannes Bjerva</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to TACL
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item932">[932]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.02198"
                    title="Abstract">arXiv:2311.02198</a> (replaced) [<a href="/pdf/2311.02198"
                    title="Download PDF">pdf</a>, <a href="/format/2311.02198" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Imitation Bootstrapped Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Hengyuan Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mirchandani%2C+S">Suvir Mirchandani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sadigh%2C+D">Dorsa Sadigh</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item933">[933]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.02495"
                    title="Abstract">arXiv:2311.02495</a> (replaced) [<a href="/pdf/2311.02495"
                    title="Download PDF">pdf</a>, <a href="/ps/2311.02495" title="Download PostScript">ps</a>, <a
                    href="/format/2311.02495" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Uncertainty Quantification in Multivariable Regression for
                    Material Property Prediction with Bayesian Neural Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Longze Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+J">Jiang Chang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vakanski%2C+A">Aleksandar Vakanski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yachun Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+T">Tiankai Yao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xian%2C+M">Min Xian</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 24 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

                </div>
            </div>
        </dd>
        <dt><a name="item934">[934]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.02732"
                    title="Abstract">arXiv:2311.02732</a> (replaced) [<a href="/pdf/2311.02732"
                    title="Download PDF">pdf</a>, <a href="/format/2311.02732" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Solving High Dimensional Partial Differential Equations Using
                    Tensor Neural Network and A Posteriori Error Estimators
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Wang%2C+Y">Yifan Wang</a>,
                    <a href="/search/math?searchtype=author&amp;query=Lin%2C+Z">Zhongshuo Lin</a>,
                    <a href="/search/math?searchtype=author&amp;query=Liao%2C+Y">Yangfei Liao</a>,
                    <a href="/search/math?searchtype=author&amp;query=Liu%2C+H">Haochen Liu</a>,
                    <a href="/search/math?searchtype=author&amp;query=Xie%2C+H">Hehu Xie</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 29 pages, 31 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item935">[935]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.02807"
                    title="Abstract">arXiv:2311.02807</a> (replaced) [<a href="/pdf/2311.02807"
                    title="Download PDF">pdf</a>, <a href="/format/2311.02807" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> QualEval: Qualitative Evaluation for Model Improvement
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Murahari%2C+V">Vishvak Murahari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deshpande%2C+A">Ameet Deshpande</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Clark%2C+P">Peter Clark</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rajpurohit%2C+T">Tanmay Rajpurohit</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sabharwal%2C+A">Ashish Sabharwal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Narasimhan%2C+K">Karthik Narasimhan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kalyan%2C+A">Ashwin Kalyan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> NAACL 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item936">[936]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.03309"
                    title="Abstract">arXiv:2311.03309</a> (replaced) [<a href="/pdf/2311.03309"
                    title="Download PDF">pdf</a>, <a href="/format/2311.03309" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Neural Structure Learning with Stochastic Differential
                    Equations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Benjie Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jennings%2C+J">Joel Jennings</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gong%2C+W">Wenbo Gong</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item937">[937]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.03486"
                    title="Abstract">arXiv:2311.03486</a> (replaced) [<a href="/pdf/2311.03486"
                    title="Download PDF">pdf</a>, <a href="/format/2311.03486" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fostering Human Learning in Sequential Decision-Making:
                    Understanding the Role of Evaluative Feedback
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gupta%2C+P">Piyush Gupta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Biswas%2C+S">Subir Biswas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Srivastava%2C+V">Vaibhav Srivastava</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item938">[938]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.04451"
                    title="Abstract">arXiv:2311.04451</a> (replaced) [<a href="/pdf/2311.04451"
                    title="Download PDF">pdf</a>, <a href="/ps/2311.04451" title="Download PostScript">ps</a>, <a
                    href="/format/2311.04451" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Pseduo-Random and de Bruijn Array Codes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Etzion%2C+T">Tuvi Etzion</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item939">[939]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.06141"
                    title="Abstract">arXiv:2311.06141</a> (replaced) [<a href="/pdf/2311.06141"
                    title="Download PDF">pdf</a>, <a href="/format/2311.06141" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Federated Learning Across Decentralized and Unshared Archives
                    for Remote Sensing Image Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=B%C3%BCy%C3%BCkta%C5%9F%2C+B">Barış Büyüktaş</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sumbul%2C+G">Gencer Sumbul</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Demir%2C+B">Begüm Demir</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to the IEEE Geoscience and Remote Sensing
                    Magazine
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item940">[940]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.08306"
                    title="Abstract">arXiv:2311.08306</a> (replaced) [<a href="/pdf/2311.08306"
                    title="Download PDF">pdf</a>, <a href="/format/2311.08306" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On-the-Fly Fusion of Large Language Models and Machine
                    Translation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hoang%2C+H">Hieu Hoang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khayrallah%2C+H">Huda Khayrallah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Junczys-Dowmunt%2C+M">Marcin Junczys-Dowmunt</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item941">[941]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.09592"
                    title="Abstract">arXiv:2311.09592</a> (replaced) [<a href="/pdf/2311.09592"
                    title="Download PDF">pdf</a>, <a href="/format/2311.09592" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Scalable and Adaptively Secure Any-Trust Distributed Key
                    Generation and All-hands Checkpointing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+H">Hanwen Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mai%2C+T">Tiancheng Mai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+Q">Qiang Tang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 21 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
            </div>
        </dd>
        <dt><a name="item942">[942]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.09677"
                    title="Abstract">arXiv:2311.09677</a> (replaced) [<a href="/pdf/2311.09677"
                    title="Download PDF">pdf</a>, <a href="/format/2311.09677" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> R-Tuning: Instructing Large Language Models to Say `I Don't
                    Know'
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hanning Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Diao%2C+S">Shizhe Diao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yong Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fung%2C+Y+R">Yi R. Fung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lian%2C+Q">Qing Lian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xingyao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yangyi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+H">Heng Ji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tong Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> NAACL 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item943">[943]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.10047"
                    title="Abstract">arXiv:2311.10047</a> (replaced) [<a href="/pdf/2311.10047"
                    title="Download PDF">pdf</a>, <a href="/ps/2311.10047" title="Download PostScript">ps</a>, <a
                    href="/format/2311.10047" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Frozen Set Design for Precoded Polar Codes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Miloslavskaya%2C+V">Vera Miloslavskaya</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yonghui Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vucetic%2C+B">Branka Vucetic</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages, 13 figures, submitted to IEEE Transactions on
                    Communications
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item944">[944]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.10093"
                    title="Abstract">arXiv:2311.10093</a> (replaced) [<a href="/pdf/2311.10093"
                    title="Download PDF">pdf</a>, <a href="/format/2311.10093" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Chosen One: Consistent Characters in Text-to-Image
                    Diffusion Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Avrahami%2C+O">Omri Avrahami</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hertz%2C+A">Amir Hertz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vinker%2C+Y">Yael Vinker</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Arar%2C+M">Moab Arar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fruchter%2C+S">Shlomi Fruchter</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fried%2C+O">Ohad Fried</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cohen-Or%2C+D">Daniel Cohen-Or</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lischinski%2C+D">Dani Lischinski</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to SIGGRAPH 2024. Project page is available at <a
                        href="https://omriavrahami.com/the-chosen-one">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item945">[945]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.10361"
                    title="Abstract">arXiv:2311.10361</a> (replaced) [<a href="/pdf/2311.10361"
                    title="Download PDF">pdf</a>, <a href="/format/2311.10361" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Video-based Sequential Bayesian Homography Estimation for
                    Soccer Field Registration
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Claasen%2C+P+J">Paul J. Claasen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=de+Villiers%2C+J+P">J.P. de Villiers</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to Expert Systems with Applications
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item946">[946]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.10781"
                    title="Abstract">arXiv:2311.10781</a> (replaced) [<a href="/pdf/2311.10781"
                    title="Download PDF">pdf</a>, <a href="/format/2311.10781" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Can Language Model Moderators Improve the Health of Online
                    Discourse?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cho%2C+H">Hyundong Cho</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shuai Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+T">Taiwei Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jain%2C+D">Darpan Jain</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rizk%2C+B">Basem Rizk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yuyang Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Z">Zixun Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wen%2C+N">Nuan Wen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gratch%2C+J">Jonathan Gratch</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ferrara%2C+E">Emilio Ferrara</a>,
                    <a href="/search/cs?searchtype=author&amp;query=May%2C+J">Jonathan May</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, NAACL 2024 Main
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item947">[947]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.11385"
                    title="Abstract">arXiv:2311.11385</a> (replaced) [<a href="/pdf/2311.11385"
                    title="Download PDF">pdf</a>, <a href="/format/2311.11385" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multi-Task Reinforcement Learning with Mixture of Orthogonal
                    Experts
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hendawy%2C+A">Ahmed Hendawy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peters%2C+J">Jan Peters</a>,
                    <a href="/search/cs?searchtype=author&amp;query=D%27Eramo%2C+C">Carlo D'Eramo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at the Twelfth International Conference on
                    Learning Representations (ICLR 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item948">[948]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.12015"
                    title="Abstract">arXiv:2311.12015</a> (replaced) [<a href="/pdf/2311.12015"
                    title="Download PDF">pdf</a>, <a href="/format/2311.12015" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> GPT-4V(ision) for Robotics: Multimodal Task Planning from
                    Human Demonstration
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wake%2C+N">Naoki Wake</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kanehira%2C+A">Atsushi Kanehira</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sasabuchi%2C+K">Kazuhiro Sasabuchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Takamatsu%2C+J">Jun Takamatsu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ikeuchi%2C+K">Katsushi Ikeuchi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 12 figures, 2 tables. Last updated on May 6th,
                    2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item949">[949]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.12052"
                    title="Abstract">arXiv:2311.12052</a> (replaced) [<a href="/pdf/2311.12052"
                    title="Download PDF">pdf</a>, <a href="/format/2311.12052" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MagicPose: Realistic Human Poses and Facial Expressions
                    Retargeting with Identity-aware Diffusion
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+D">Di Chang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yichun Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Q">Quankai Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+J">Jessica Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hongyi Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+G">Guoxian Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+Q">Qing Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yizhe Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xiao Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Soleymani%2C+M">Mohammad Soleymani</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML 2024. MagicPose and MagicDance are the
                    same project. Website:<a href="https://boese0601.github.io/magicdance/">this https URL</a> Code:<a
                        href="https://github.com/Boese0601/MagicDance">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item950">[950]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.12609"
                    title="Abstract">arXiv:2311.12609</a> (replaced) [<a href="/pdf/2311.12609"
                    title="Download PDF">pdf</a>, <a href="/format/2311.12609" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Reinforcement Learning for Near-Optimal Design of Zero-Delay
                    Codes for Markov Sources
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cregg%2C+L">Liam Cregg</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Linder%2C+T">Tamas Linder</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuksel%2C+S">Serdar Yuksel</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 25 pages, 3 figures; several presentational changes
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Optimization and Control (math.OC)

                </div>
            </div>
        </dd>
        <dt><a name="item951">[951]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.14213"
                    title="Abstract">arXiv:2311.14213</a> (replaced) [<a href="/pdf/2311.14213"
                    title="Download PDF">pdf</a>, <a href="/format/2311.14213" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Learning to Solve Inverse Problems for Perceptual Sound
                    Matching
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+H">Han Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lostanlen%2C+V">Vincent Lostanlen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lagrange%2C+M">Mathieu Lagrange</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio
                    and Speech Processing (eess.AS)

                </div>
            </div>
        </dd>
        <dt><a name="item952">[952]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.14902"
                    title="Abstract">arXiv:2311.14902</a> (replaced) [<a href="/pdf/2311.14902"
                    title="Download PDF">pdf</a>, <a href="/format/2311.14902" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Parkinson's Disease Classification Using Contrastive Graph
                    Cross-View Learning with Multimodal Fusion of SPECT Images and Clinical Features
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ding%2C+J">Jun-En Ding</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hsu%2C+C">Chien-Chin Hsu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+F">Feng Liu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item953">[953]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.17210"
                    title="Abstract">arXiv:2311.17210</a> (replaced) [<a href="/pdf/2311.17210"
                    title="Download PDF">pdf</a>, <a href="/format/2311.17210" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Ordinals and recursively defined functions on the reals
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Nivasch%2C+G">Gabriel Nivasch</a>,
                    <a href="/search/math?searchtype=author&amp;query=Shiboli%2C+L">Lior Shiboli</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>;
                    Discrete Mathematics (cs.DM)

                </div>
            </div>
        </dd>
        <dt><a name="item954">[954]</a>&nbsp; <span class="list-identifier"><a href="/abs/2311.17834"
                    title="Abstract">arXiv:2311.17834</a> (replaced) [<a href="/pdf/2311.17834"
                    title="Download PDF">pdf</a>, <a href="/format/2311.17834" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spice-E : Structural Priors in 3D Diffusion using
                    Cross-Entity Attention
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sella%2C+E">Etai Sella</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fiebelman%2C+G">Gal Fiebelman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Atia%2C+N">Noam Atia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Project webpage: <a
                        href="https://tau-vailab.github.io/Spice-E">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
            </div>
        </dd>
        <dt><a name="item955">[955]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.00032"
                    title="Abstract">arXiv:2312.00032</a> (replaced) [<a href="/pdf/2312.00032"
                    title="Download PDF">pdf</a>, <a href="/format/2312.00032" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> An algorithm for forensic toolmark comparisons
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cuellar%2C+M">Maria Cuellar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+S">Sheng Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hofmann%2C+H">Heike Hofmann</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG); Applications (stat.AP)

                </div>
            </div>
        </dd>
        <dt><a name="item956">[956]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.01185"
                    title="Abstract">arXiv:2312.01185</a> (replaced) [<a href="/pdf/2312.01185"
                    title="Download PDF">pdf</a>, <a href="/format/2312.01185" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A ripple in time: a discontinuity in American history
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kolpakov%2C+A">Alexander Kolpakov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rivin%2C+I">Igor Rivin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 8 figures; GitHub repository (<a
                        href="https://github.com/sashakolpakov/ripple_in_time">this https URL</a>); Section 3: added
                    comparison to (<a href="https://doi.org/10.1016/j.ins.2019.01.040">this https URL</a>); comments on
                    a misleading accuracy claim in (<a href="https://doi.org/10.1002/asi.23283">this https URL</a>)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and
                    Information Networks (cs.SI)

                </div>
            </div>
        </dd>
        <dt><a name="item957">[957]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.01239"
                    title="Abstract">arXiv:2312.01239</a> (replaced) [<a href="/pdf/2312.01239"
                    title="Download PDF">pdf</a>, <a href="/format/2312.01239" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Motion Informed Needle Segmentation in Ultrasound Images
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Goel%2C+R">Raghavv Goel</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Morales%2C+C">Cecilia Morales</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Singh%2C+M">Manpreet Singh</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Dubrawski%2C+A">Artur Dubrawski</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Galeotti%2C+J">John Galeotti</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Choset%2C+H">Howie Choset</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 4 figures, accepted at ISBI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item958">[958]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.01606"
                    title="Abstract">arXiv:2312.01606</a> (replaced) [<a href="/pdf/2312.01606"
                    title="Download PDF">pdf</a>, <a href="/ps/2312.01606" title="Download PostScript">ps</a>, <a
                    href="/format/2312.01606" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Investigating the ability of deep learning to predict Welding
                    Depth and Pore Volume in Hairpin Welding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Darwish%2C+A">Amena Darwish</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ericson%2C+S">Stefan Ericson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghasemi%2C+R">Rohollah Ghasemi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Andersson%2C+T">Tobias Andersson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=L%C3%B6nn%2C+D">Dan Lönn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lassila%2C+A+A">Andreas Andersson Lassila</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Salomonsson%2C+K">Kent Salomonsson</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item959">[959]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.02052"
                    title="Abstract">arXiv:2312.02052</a> (replaced) [<a href="/pdf/2312.02052"
                    title="Download PDF">pdf</a>, <a href="/format/2312.02052" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DUCK: Distance-based Unlearning via Centroid Kinematics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cotogni%2C+M">Marco Cotogni</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bonato%2C+J">Jacopo Bonato</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sabetta%2C+L">Luigi Sabetta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pelosin%2C+F">Francesco Pelosin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nicolosi%2C+A">Alessandro Nicolosi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item960">[960]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.02445"
                    title="Abstract">arXiv:2312.02445</a> (replaced) [<a href="/pdf/2312.02445"
                    title="Download PDF">pdf</a>, <a href="/format/2312.02445" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LLaRA: Large Language-Recommendation Assistant
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liao%2C+J">Jiayi Liao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+S">Sihang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zhengyi Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiancan Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yancheng Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiang Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+X">Xiangnan He</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item961">[961]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.02959"
                    title="Abstract">arXiv:2312.02959</a> (replaced) [<a href="/pdf/2312.02959"
                    title="Download PDF">pdf</a>, <a href="/format/2312.02959" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Detecting algorithmic bias in medical-AI models using trees
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Smith%2C+J">Jeffrey Smith</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Holder%2C+A">Andre Holder</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Xie%2C+Y">Yao Xie</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 26 pages, 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Applications
                    (stat.AP)

                </div>
            </div>
        </dd>
        <dt><a name="item962">[962]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.05586"
                    title="Abstract">arXiv:2312.05586</a> (replaced) [<a href="/pdf/2312.05586"
                    title="Download PDF">pdf</a>, <a href="/format/2312.05586" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deeper Understanding of Black-box Predictions via Generalized
                    Influence Functions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+H">Hyeonsu Lyu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jang%2C+J">Jonggyu Jang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ryu%2C+S">Sehyun Ryu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H+J">Hyun Jong Yang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages, 6 figures, and 2 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item963">[963]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.09950"
                    title="Abstract">arXiv:2312.09950</a> (replaced) [<a href="/pdf/2312.09950"
                    title="Download PDF">pdf</a>, <a href="/format/2312.09950" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Peer Learning: Learning Complex Policies in Groups from
                    Scratch via Action Recommendations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Derstroff%2C+C">Cedric Derstroff</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cerrato%2C+M">Mattia Cerrato</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brugger%2C+J">Jannis Brugger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peters%2C+J">Jan Peters</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kramer%2C+S">Stefan Kramer</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 9 pages, 7 figures, AAAI-24
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> AAAI, vol. 38, no. 10, pp. 11766-11774, Mar. 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

                </div>
            </div>
        </dd>
        <dt><a name="item964">[964]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.10136"
                    title="Abstract">arXiv:2312.10136</a> (replaced) [<a href="/pdf/2312.10136"
                    title="Download PDF">pdf</a>, <a href="/format/2312.10136" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Gradient-based Parameter Selection for Efficient Fine-Tuning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qizhe Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Z">Zijun Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Renrui Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shutova%2C+E">Ekaterina Shutova</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+S">Shiji Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shanghang Zhang</a>
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> CVPR2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item965">[965]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.10561"
                    title="Abstract">arXiv:2312.10561</a> (replaced) [<a href="/pdf/2312.10561"
                    title="Download PDF">pdf</a>, <a href="/format/2312.10561" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enabling Accelerators for Graph Computing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shivdikar%2C+K">Kaustubh Shivdikar</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Northeastern University Doctoral Dissertation
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture
                        (cs.AR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing
                    (cs.DC); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item966">[966]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.11387"
                    title="Abstract">arXiv:2312.11387</a> (replaced) [<a href="/pdf/2312.11387"
                    title="Download PDF">pdf</a>, <a href="/format/2312.11387" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Data-Driven Continuous-Time Framework for
                    Frequency-Constrained Unit Commitment
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Rajabdorri%2C+M">Mohammad Rajabdorri</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Lobato%2C+E">Enrique Lobato</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Sigrist%2C+L">Lukas Sigrist</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Aghaei%2C+J">Jamshid Aghaei</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item967">[967]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.11831"
                    title="Abstract">arXiv:2312.11831</a> (replaced) [<a href="/pdf/2312.11831"
                    title="Download PDF">pdf</a>, <a href="/ps/2312.11831" title="Download PostScript">ps</a>, <a
                    href="/format/2312.11831" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Locally-Minimal Probabilistic Explanations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Izza%2C+Y">Yacine Izza</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Meel%2C+K+S">Kuldeep S. Meel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Marques-Silva%2C+J">Joao Marques-Silva</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item968">[968]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.13034"
                    title="Abstract">arXiv:2312.13034</a> (replaced) [<a href="/pdf/2312.13034"
                    title="Download PDF">pdf</a>, <a href="/format/2312.13034" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Modelling reliability of reversible circuits with 2D
                    second-order cellular automata
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/nlin?searchtype=author&amp;query=Vlasov%2C+A+Y">Alexander Yu. Vlasov</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 34+1 pages, 21 figures, accepted in Physica D
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cellular Automata and
                        Lattice Gases (nlin.CG)</span>; Discrete Mathematics (cs.DM); Mathematical Physics (math-ph)

                </div>
            </div>
        </dd>
        <dt><a name="item969">[969]</a>&nbsp; <span class="list-identifier"><a href="/abs/2312.14385"
                    title="Abstract">arXiv:2312.14385</a> (replaced) [<a href="/pdf/2312.14385"
                    title="Download PDF">pdf</a>, <a href="/format/2312.14385" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Generative AI Beyond LLMs: System Implications of Multi-Modal
                    Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Golden%2C+A">Alicia Golden</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hsia%2C+S">Samuel Hsia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+F">Fei Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Acun%2C+B">Bilge Acun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hosmer%2C+B">Basil Hosmer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+Y">Yejin Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=DeVito%2C+Z">Zachary DeVito</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Johnson%2C+J">Jeff Johnson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+G">Gu-Yeon Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brooks%2C+D">David Brooks</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Carole-Jean Wu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published at 2024 IEEE International Symposium on
                    Performance Analysis of Systems and Software (ISPASS)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

                </div>
            </div>
        </dd>
        <dt><a name="item970">[970]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.00595"
                    title="Abstract">arXiv:2401.00595</a> (replaced) [<a href="/pdf/2401.00595"
                    title="Download PDF">pdf</a>, <a href="/format/2401.00595" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> State of What Art? A Call for Multi-Prompt LLM Evaluation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mizrahi%2C+M">Moran Mizrahi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kaplan%2C+G">Guy Kaplan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Malkin%2C+D">Dan Malkin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dror%2C+R">Rotem Dror</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shahaf%2C+D">Dafna Shahaf</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stanovsky%2C+G">Gabriel Stanovsky</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at TACL; pre-MIT Press publication version
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item971">[971]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.00813"
                    title="Abstract">arXiv:2401.00813</a> (replaced) [<a href="/pdf/2401.00813"
                    title="Download PDF">pdf</a>, <a href="/format/2401.00813" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Ultraspherical/Gegenbauer polynomials to unify 2D/3D
                    Ambisonic directivity designs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Zotter%2C+F">Franz Zotter</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 56 pages, 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing
                        (eess.AS)</span>; Sound (cs.SD)

                </div>
            </div>
        </dd>
        <dt><a name="item972">[972]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.00847"
                    title="Abstract">arXiv:2401.00847</a> (replaced) [<a href="/pdf/2401.00847"
                    title="Download PDF">pdf</a>, <a href="/format/2401.00847" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mocap Everyone Everywhere: Lightweight Motion Capture With
                    Smartwatches and a Head-Mounted Camera
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J">Jiye Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Joo%2C+H">Hanbyul Joo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to CVPR 2024; Project page: <a
                        href="https://jiyewise.github.io/projects/MocapEvery/">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
            </div>
        </dd>
        <dt><a name="item973">[973]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.01823"
                    title="Abstract">arXiv:2401.01823</a> (replaced) [<a href="/pdf/2401.01823"
                    title="Download PDF">pdf</a>, <a href="/format/2401.01823" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Detours for Navigating Instructional Videos
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ashutosh%2C+K">Kumar Ashutosh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+Z">Zihui Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nagarajan%2C+T">Tushar Nagarajan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Grauman%2C+K">Kristen Grauman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> CVPR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item974">[974]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.01970"
                    title="Abstract">arXiv:2401.01970</a> (replaced) [<a href="/pdf/2401.01970"
                    title="Download PDF">pdf</a>, <a href="/format/2401.01970" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FMGS: Foundation Model Embedded 3D Gaussian Splatting for
                    Holistic 3D Scene Understanding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zuo%2C+X">Xingxing Zuo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Samangouei%2C+P">Pouya Samangouei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yunwen Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Di%2C+Y">Yan Di</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Mingyang Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Project page: <a
                        href="https://xingxingzuo.github.io/fmgs">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item975">[975]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.03470"
                    title="Abstract">arXiv:2401.03470</a> (replaced) [<a href="/pdf/2401.03470"
                    title="Download PDF">pdf</a>, <a href="/format/2401.03470" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FurniScene: A Large-scale 3D Room Dataset with Intricate
                    Furnishing Scenes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Genghao Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuxi Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+C">Chuanchen Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+S">Shibiao Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhaoxiang Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+M">Man Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+J">Junran Peng</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item976">[976]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.05235"
                    title="Abstract">arXiv:2401.05235</a> (replaced) [<a href="/pdf/2401.05235"
                    title="Download PDF">pdf</a>, <a href="/format/2401.05235" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Survey on Optimization Studies of Group Centrality Metrics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Camur%2C+M+C">Mustafa Can Camur</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vogiatzis%2C+C">Chrysafis Vogiatzis</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information
                        Networks (cs.SI)</span>; Optimization and Control (math.OC)

                </div>
            </div>
        </dd>
        <dt><a name="item977">[977]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.05377"
                    title="Abstract">arXiv:2401.05377</a> (replaced) [<a href="/pdf/2401.05377"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.05377" title="Download PostScript">ps</a>, <a
                    href="/format/2401.05377" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The impact of generative artificial intelligence on
                    socioeconomic inequalities and policy making
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Capraro%2C+V">Valerio Capraro</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lentsch%2C+A">Austin Lentsch</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Acemoglu%2C+D">Daron Acemoglu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Akgun%2C+S">Selin Akgun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Akhmedova%2C+A">Aisel Akhmedova</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bilancini%2C+E">Ennio Bilancini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bonnefon%2C+J">Jean-François Bonnefon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bra%C3%B1as-Garza%2C+P">Pablo Brañas-Garza</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Butera%2C+L">Luigi Butera</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Douglas%2C+K+M">Karen M. Douglas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Everett%2C+J+A+C">Jim A.C. Everett</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gigerenzer%2C+G">Gerd Gigerenzer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Greenhow%2C+C">Christine Greenhow</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hashimoto%2C+D+A">Daniel A. Hashimoto</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Holt-Lunstad%2C+J">Julianne Holt-Lunstad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jetten%2C+J">Jolanda Jetten</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Johnson%2C+S">Simon Johnson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Longoni%2C+C">Chiara Longoni</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lunn%2C+P">Pete Lunn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Natale%2C+S">Simone Natale</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rahwan%2C+I">Iyad Rahwan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Selwyn%2C+N">Neil Selwyn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singh%2C+V">Vivek Singh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Suri%2C+S">Siddharth Suri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sutcliffe%2C+J">Jennifer Sutcliffe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tomlinson%2C+J">Joe Tomlinson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=van+der+Linden%2C+S">Sander van der Linden</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Van+Lange%2C+P+A+M">Paul A. M. Van Lange</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wall%2C+F">Friederike Wall</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Van+Bavel%2C+J+J">Jay J. Van Bavel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Viale%2C+R">Riccardo Viale</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> PNAS Nexus, in press
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item978">[978]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.05609"
                    title="Abstract">arXiv:2401.05609</a> (replaced) [<a href="/pdf/2401.05609"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.05609" title="Download PostScript">ps</a>, <a
                    href="/format/2401.05609" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A cable finite element formulation based on exact tension
                    field for static nonlinear analysis of cable structures
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+W">Wenxiong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Q">Qikun Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Suiyin Chen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item979">[979]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.06462"
                    title="Abstract">arXiv:2401.06462</a> (replaced) [<a href="/pdf/2401.06462"
                    title="Download PDF">pdf</a>, <a href="/format/2401.06462" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AttributionScanner: A Visual Analytics System for Model
                    Validation with Metadata-Free Slice Finding
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xuan%2C+X">Xiwei Xuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ono%2C+J+P">Jorge Piazentin Ono</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gou%2C+L">Liang Gou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+K">Kwan-Liu Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+L">Liu Ren</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 12 figures, 3 tables. This manuscript is under
                    review by the IEEE Transactions on Visualization and Computer Graphics (TVCG)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

                </div>
            </div>
        </dd>
        <dt><a name="item980">[980]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.06874"
                    title="Abstract">arXiv:2401.06874</a> (replaced) [<a href="/pdf/2401.06874"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.06874" title="Download PostScript">ps</a>, <a
                    href="/format/2401.06874" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Joint Code and Belief Propagation Decoder Design for
                    Quantum LDPC Codes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Miao%2C+S">Sisi Miao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mandelbaum%2C+J">Jonathan Mandelbaum</a>,
                    <a href="/search/cs?searchtype=author&amp;query=J%C3%A4kel%2C+H">Holger Jäkel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schmalen%2C+L">Laurent Schmalen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ISIT 2024 accepted version
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Quantum Physics (quant-ph)

                </div>
            </div>
        </dd>
        <dt><a name="item981">[981]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.07085"
                    title="Abstract">arXiv:2401.07085</a> (replaced) [<a href="/pdf/2401.07085"
                    title="Download PDF">pdf</a>, <a href="/format/2401.07085" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Three Mechanisms of Feature Learning in the Exact Solution of
                    a Latent Variable Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yizhou Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ziyin%2C+L">Liu Ziyin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item982">[982]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.07644"
                    title="Abstract">arXiv:2401.07644</a> (replaced) [<a href="/pdf/2401.07644"
                    title="Download PDF">pdf</a>, <a href="/format/2401.07644" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Resource Allocation in STAR-RIS-Aided SWIPT with RSMA via
                    Meta-Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Amiri%2C+M">Mojtaba Amiri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vaezpour%2C+E">Elaheh Vaezpour</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Javadi%2C+S">Sepideh Javadi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mili%2C+M+R">Mohammad Robat Mili</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bennis%2C+M">Mehdi Bennis</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Signal Processing (eess.SP)

                </div>
            </div>
        </dd>
        <dt><a name="item983">[983]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.08019"
                    title="Abstract">arXiv:2401.08019</a> (replaced) [<a href="/pdf/2401.08019"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.08019" title="Download PostScript">ps</a>, <a
                    href="/format/2401.08019" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Centrality of shortest paths: Algorithms and complexity
                    results
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Phosavanh%2C+J">Johnson Phosavanh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matsypura%2C+D">Dmytro Matsypura</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Optimization and Control (math.OC)

                </div>
            </div>
        </dd>
        <dt><a name="item984">[984]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.08392"
                    title="Abstract">arXiv:2401.08392</a> (replaced) [<a href="/pdf/2401.08392"
                    title="Download PDF">pdf</a>, <a href="/format/2401.08392" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DoraemonGPT: Toward Understanding Dynamic Scenes with Large
                    Language Models (Exemplified as A Video Agent)
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zongxin Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+G">Guikun Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaodi Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Wenguan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yi Yang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item985">[985]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.08925"
                    title="Abstract">arXiv:2401.08925</a> (replaced) [<a href="/pdf/2401.08925"
                    title="Download PDF">pdf</a>, <a href="/format/2401.08925" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> RandOhm: Mitigating Impedance Side-channel Attacks using
                    Randomized Circuit Configurations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Monfared%2C+S+K">Saleh Khalaj Monfared</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Forte%2C+D">Domenic Forte</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tajik%2C+S">Shahin Tajik</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item986">[986]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.09241"
                    title="Abstract">arXiv:2401.09241</a> (replaced) [<a href="/pdf/2401.09241"
                    title="Download PDF">pdf</a>, <a href="/format/2401.09241" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Biased-MPPI: Informing Sampling-Based Model Predictive
                    Control by Fusing Ancillary Controllers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Trevisan%2C+E">Elia Trevisan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for Robotics and Automation Letters, April 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item987">[987]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.09243"
                    title="Abstract">arXiv:2401.09243</a> (replaced) [<a href="/pdf/2401.09243"
                    title="Download PDF">pdf</a>, <a href="/format/2401.09243" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> DiffClone: Enhanced Behaviour Cloning in Robotics with
                    Diffusion-Driven Policy Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mani%2C+S">Sabariswaran Mani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chandra%2C+A">Abhranil Chandra</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Venkataraman%2C+S">Sreyas Venkataraman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rizvi%2C+A">Adyan Rizvi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sirvi%2C+Y">Yash Sirvi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bhattacharya%2C+S">Soumojit Bhattacharya</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hazra%2C+A">Aritra Hazra</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> NeurIPS 2023 Train Offline Test Online Workshop and
                    Competition (Best Paper Oral Presentation Winning Competition Submission)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item988">[988]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.09919"
                    title="Abstract">arXiv:2401.09919</a> (replaced) [<a href="/pdf/2401.09919"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.09919" title="Download PostScript">ps</a>, <a
                    href="/format/2401.09919" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Tractability of linear ill-posed problems in Hilbert space
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Math%C3%A9%2C+P">Peter Mathé</a>,
                    <a href="/search/math?searchtype=author&amp;query=Hofmann%2C+B">Bernd Hofmann</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 19 pages, final version, accepted for publication
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item989">[989]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.10539"
                    title="Abstract">arXiv:2401.10539</a> (replaced) [<a href="/pdf/2401.10539"
                    title="Download PDF">pdf</a>, <a href="/format/2401.10539" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Quality-Diversity Algorithms Can Provably Be Helpful for
                    Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Qian%2C+C">Chao Qian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+K">Ke Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+R">Ren-Jian Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> The conference version of this paper has appeared at
                    IJCAI'24. This version contains all the proof details
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item990">[990]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.10566"
                    title="Abstract">arXiv:2401.10566</a> (replaced) [<a href="/pdf/2401.10566"
                    title="Download PDF">pdf</a>, <a href="/format/2401.10566" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Robust Multi-Modal Density Estimation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=M%C3%A9sz%C3%A1ros%2C+A">Anna Mészáros</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schumann%2C+J+F">Julian F. Schumann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zgonnikov%2C+A">Arkady Zgonnikov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kober%2C+J">Jens Kober</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item991">[991]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.10731"
                    title="Abstract">arXiv:2401.10731</a> (replaced) [<a href="/pdf/2401.10731"
                    title="Download PDF">pdf</a>, <a href="/format/2401.10731" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Removal and Selection: Improving RGB-Infrared Object
                    Detection via Coarse-to-Fine Fusion
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+T">Tianyi Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+M">Maoxun Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+F">Feng Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+N">Nan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+X">Xingxing Wei</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11pages, 11figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item992">[992]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.11458"
                    title="Abstract">arXiv:2401.11458</a> (replaced) [<a href="/pdf/2401.11458"
                    title="Download PDF">pdf</a>, <a href="/format/2401.11458" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Linear Alignment: A Closed-form Solution for Aligning Human
                    Preferences without Tuning and Feedback
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+S">Songyang Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ge%2C+Q">Qiming Ge</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+W">Wei Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dou%2C+S">Shihan Dou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+J">Junjie Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+R">Rui Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zou%2C+Y">Yicheng Zou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhi Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+H">Hang Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+D">Dahua Lin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item993">[993]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.11708"
                    title="Abstract">arXiv:2401.11708</a> (replaced) [<a href="/pdf/2401.11708"
                    title="Download PDF">pdf</a>, <a href="/format/2401.11708" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mastering Text-to-Image Diffusion: Recaptioning, Planning,
                    and Generating with Multimodal LLMs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+L">Ling Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Z">Zhaochen Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Meng%2C+C">Chenlin Meng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+M">Minkai Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ermon%2C+S">Stefano Ermon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cui%2C+B">Bin Cui</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML 2024. Project: <a
                        href="https://github.com/YangLing0818/RPG-DiffusionMaster">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item994">[994]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.13516"
                    title="Abstract">arXiv:2401.13516</a> (replaced) [<a href="/pdf/2401.13516"
                    title="Download PDF">pdf</a>, <a href="/format/2401.13516" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Delocate: Detection and Localization for Deepfake Videos with
                    Randomly-Located Tampered Traces
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+J">Juan Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liao%2C+X">Xin Liao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+D">Difei Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tsutsui%2C+S">Satoshi Tsutsui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qian Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qin%2C+Z">Zheng Qin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shou%2C+M+Z">Mike Zheng Shou</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a
                        href="/abs/2308.09921">arXiv:2308.09921</a>, <a href="/abs/2305.05943">arXiv:2305.05943</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item995">[995]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.13539"
                    title="Abstract">arXiv:2401.13539</a> (replaced) [<a href="/pdf/2401.13539"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.13539" title="Download PostScript">ps</a>, <a
                    href="/format/2401.13539" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Dynamic Risk Management in Cyber Physical Systems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Schneider%2C+D">Daniel Schneider</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Reich%2C+J">Jan Reich</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Adler%2C+R">Rasmus Adler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liggesmeyer%2C+P">Peter Liggesmeyer</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item996">[996]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.13605"
                    title="Abstract">arXiv:2401.13605</a> (replaced) [<a href="/pdf/2401.13605"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.13605" title="Download PostScript">ps</a>, <a
                    href="/format/2401.13605" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Regulating AI-Based Remote Biometric Identification.
                    Investigating the Public Demand for Bans, Audits, and Public Database Registrations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kieslich%2C+K">Kimon Kieslich</a>,
                    <a href="/search/cs?searchtype=author&amp;query=L%C3%BCnich%2C+M">Marco Lünich</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item997">[997]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.14423"
                    title="Abstract">arXiv:2401.14423</a> (replaced) [<a href="/pdf/2401.14423"
                    title="Download PDF">pdf</a>, <a href="/format/2401.14423" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Prompt Design and Engineering: Introduction and Advanced
                    Methods
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Amatriain%2C+X">Xavier Amatriain</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item998">[998]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.15647"
                    title="Abstract">arXiv:2401.15647</a> (replaced) [<a href="/pdf/2401.15647"
                    title="Download PDF">pdf</a>, <a href="/format/2401.15647" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> UP-CrackNet: Unsupervised Pixel-Wise Road Crack Detection via
                    Adversarial Image Restoration
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+N">Nachuan Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+R">Rui Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+L">Lihua Xie</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing
                    (eess.IV)

                </div>
            </div>
        </dd>
        <dt><a name="item999">[999]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.16250"
                    title="Abstract">arXiv:2401.16250</a> (replaced) [<a href="/pdf/2401.16250"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.16250" title="Download PostScript">ps</a>, <a
                    href="/format/2401.16250" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient solution of ill-posed integral equations through
                    averaging
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Griebel%2C+M">Michael Griebel</a>,
                    <a href="/search/math?searchtype=author&amp;query=Jahn%2C+T">Tim Jahn</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 38 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis
                        (math.NA)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1000">[1000]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.16417"
                    title="Abstract">arXiv:2401.16417</a> (replaced) [<a href="/pdf/2401.16417"
                    title="Download PDF">pdf</a>, <a href="/ps/2401.16417" title="Download PostScript">ps</a>, <a
                    href="/format/2401.16417" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Channel Coding with Mean and Variance Cost Constraints
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mahmood%2C+A">Adeel Mahmood</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wagner%2C+A+B">Aaron B. Wagner</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1001">[1001]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.16579"
                    title="Abstract">arXiv:2401.16579</a> (replaced) [<a href="/pdf/2401.16579"
                    title="Download PDF">pdf</a>, <a href="/format/2401.16579" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On Channel Simulation with Causal Rejection Samplers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Goc%2C+D">Daniel Goc</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Flamich%2C+G">Gergely Flamich</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to IEEE ISIT 2024, camera-ready version. 11
                    pages, 1 figure
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1002">[1002]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.16663"
                    title="Abstract">arXiv:2401.16663</a> (replaced) [<a href="/pdf/2401.16663"
                    title="Download PDF">pdf</a>, <a href="/format/2401.16663" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> VR-GS: A Physical Dynamics-Aware Interactive Gaussian
                    Splatting System in Virtual Reality
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Ying Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+C">Chang Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+T">Tianyi Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yutao Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Huamin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+M">Minchen Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lau%2C+H">Henry Lau</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+F">Feng Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yin Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+C">Chenfanfu Jiang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item1003">[1003]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.16977"
                    title="Abstract">arXiv:2401.16977</a> (replaced) [<a href="/pdf/2401.16977"
                    title="Download PDF">pdf</a>, <a href="/format/2401.16977" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Performance Analysis of Generalized Product Codes with
                    Irregular Degree Distribution
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Miao%2C+S">Sisi Miao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mandelbaum%2C+J">Jonathan Mandelbaum</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rapp%2C+L">Lukas Rapp</a>,
                    <a href="/search/cs?searchtype=author&amp;query=J%C3%A4kel%2C+H">Holger Jäkel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Schmalen%2C+L">Laurent Schmalen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ISIT 2024 accepted version
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1004">[1004]</a>&nbsp; <span class="list-identifier"><a href="/abs/2401.17791"
                    title="Abstract">arXiv:2401.17791</a> (replaced) [<a href="/pdf/2401.17791"
                    title="Download PDF">pdf</a>, <a href="/format/2401.17791" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Graph Transformers without Positional Encodings
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Garg%2C+A">Ayush Garg</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Independent Research
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1005">[1005]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.00253"
                    title="Abstract">arXiv:2402.00253</a> (replaced) [<a href="/pdf/2402.00253"
                    title="Download PDF">pdf</a>, <a href="/format/2402.00253" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Survey on Hallucination in Large Vision-Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hanchao Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+W">Wenyuan Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yifei Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+D">Dapeng Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xiutian Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+K">Ke Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hou%2C+L">Liping Hou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Rongjun Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+W">Wei Peng</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1006">[1006]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.01327"
                    title="Abstract">arXiv:2402.01327</a> (replaced) [<a href="/pdf/2402.01327"
                    title="Download PDF">pdf</a>, <a href="/format/2402.01327" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Supervised Algorithmic Fairness in Distribution Shifts: A
                    Survey
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shao%2C+M">Minglai Shao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+D">Dong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+C">Chen Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xintao Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+Y">Yujie Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Q">Qin Tian</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

                </div>
            </div>
        </dd>
        <dt><a name="item1007">[1007]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.02338"
                    title="Abstract">arXiv:2402.02338</a> (replaced) [<a href="/pdf/2402.02338"
                    title="Download PDF">pdf</a>, <a href="/format/2402.02338" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> NetLLM: Adapting Large Language Models for Networking
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+D">Duo Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xianda Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yaqi Qiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhi Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+J">Junchen Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cui%2C+S">Shuguang Cui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+F">Fangxin Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper has been accepted by ACM SIGCOMM 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1008">[1008]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.02619"
                    title="Abstract">arXiv:2402.02619</a> (replaced) [<a href="/pdf/2402.02619"
                    title="Download PDF">pdf</a>, <a href="/format/2402.02619" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Increasing Trust in Language Models through the Reuse of
                    Verified Circuits
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Quirke%2C+P">Philip Quirke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Neo%2C+C">Clement Neo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Barez%2C+F">Fazl Barez</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 10 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item1009">[1009]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.02771"
                    title="Abstract">arXiv:2402.02771</a> (replaced) [<a href="/pdf/2402.02771"
                    title="Download PDF">pdf</a>, <a href="/format/2402.02771" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TensoSDF: Roughness-aware Tensorial Representation for Robust
                    Geometry and Material Reconstruction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jia Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Lu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lei Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Beibei Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by SIGGRAPH 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1010">[1010]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.03162"
                    title="Abstract">arXiv:2402.03162</a> (replaced) [<a href="/pdf/2402.03162"
                    title="Download PDF">pdf</a>, <a href="/format/2402.03162" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Direct-a-Video: Customized Video Generation with
                    User-Directed Camera Movement and Object Motion
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+S">Shiyuan Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hou%2C+L">Liang Hou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+H">Haibin Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+C">Chongyang Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wan%2C+P">Pengfei Wan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+D">Di Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+X">Xiaodong Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liao%2C+J">Jing Liao</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1011">[1011]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.03383"
                    title="Abstract">arXiv:2402.03383</a> (replaced) [<a href="/pdf/2402.03383"
                    title="Download PDF">pdf</a>, <a href="/ps/2402.03383" title="Download PostScript">ps</a>, <a
                    href="/format/2402.03383" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Collaborative Model-driven Network for MRI Reconstruction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Qiao%2C+X">Xiaoyu Qiao</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Li%2C+W">Weisheng Li</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wang%2C+G">Guofen Wang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Huang%2C+Y">Yuping Huang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item1012">[1012]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.03554"
                    title="Abstract">arXiv:2402.03554</a> (replaced) [<a href="/pdf/2402.03554"
                    title="Download PDF">pdf</a>, <a href="/ps/2402.03554" title="Download PostScript">ps</a>, <a
                    href="/format/2402.03554" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Explicit Formula for Partial Information Decomposition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lyu%2C+A">Aobo Lyu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Clark%2C+A">Andrew Clark</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Raviv%2C+N">Netanel Raviv</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Probability (math.PR)

                </div>
            </div>
        </dd>
        <dt><a name="item1013">[1013]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.04400"
                    title="Abstract">arXiv:2402.04400</a> (replaced) [<a href="/pdf/2402.04400"
                    title="Download PDF">pdf</a>, <a href="/format/2402.04400" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CEHR-GPT: Generating Electronic Health Records with
                    Chronological Patient Timelines
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pang%2C+C">Chao Pang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xinzhuo Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pavinkurve%2C+N+P">Nishanth Parameshwar
                        Pavinkurve</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kalluri%2C+K+S">Krishna S. Kalluri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Minto%2C+E+L">Elise L. Minto</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Patterson%2C+J">Jason Patterson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Linying Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hripcsak%2C+G">George Hripcsak</a>,
                    <a href="/search/cs?searchtype=author&amp;query=G%C3%BCrsoy%2C+G">Gamze Gürsoy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Elhadad%2C+N">Noémie Elhadad</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Natarajan%2C+K">Karthik Natarajan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

                </div>
            </div>
        </dd>
        <dt><a name="item1014">[1014]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.05957"
                    title="Abstract">arXiv:2402.05957</a> (replaced) [<a href="/pdf/2402.05957"
                    title="Download PDF">pdf</a>, <a href="/format/2402.05957" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Accelerating PDE Data Generation via Differential Operator
                    Action in Solution Space
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+H">Huanshuo Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Haoyang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+J">Jian Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jie Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1015">[1015]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.06357"
                    title="Abstract">arXiv:2402.06357</a> (replaced) [<a href="/pdf/2402.06357"
                    title="Download PDF">pdf</a>, <a href="/format/2402.06357" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The SkipSponge Attack: Sponge Weight Poisoning of Deep Neural
                    Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lintelo%2C+J+t">Jona te Lintelo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Koffas%2C+S">Stefanos Koffas</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Picek%2C+S">Stjepan Picek</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1016">[1016]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.07138"
                    title="Abstract">arXiv:2402.07138</a> (replaced) [<a href="/pdf/2402.07138"
                    title="Download PDF">pdf</a>, <a href="/format/2402.07138" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unprecedented Code Change Automation: The Fusion of LLMs and
                    Transformation by Example
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dilhara%2C+M">Malinda Dilhara</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bellur%2C+A">Abhiram Bellur</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bryksin%2C+T">Timofey Bryksin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dig%2C+D">Danny Dig</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper is accepted to Proceedings of the 32nd ACM
                    Symposium on the Foundations of Software Engineering (FSE - 2024), This is an author copy
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1017">[1017]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.07270"
                    title="Abstract">arXiv:2402.07270</a> (replaced) [<a href="/pdf/2402.07270"
                    title="Download PDF">pdf</a>, <a href="/format/2402.07270" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Open-ended VQA benchmarking of Vision-Language models by
                    exploiting Classification datasets and their semantic hierarchy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ging%2C+S">Simon Ging</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bravo%2C+M+A">María A. Bravo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brox%2C+T">Thomas Brox</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted as Spotlight Paper for ICLR 2024. The first two
                    authors contributed equally to this work
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1018">[1018]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.07739"
                    title="Abstract">arXiv:2402.07739</a> (replaced) [<a href="/pdf/2402.07739"
                    title="Download PDF">pdf</a>, <a href="/format/2402.07739" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Task-conditioned adaptation of visual features in multi-task
                    policy learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Marza%2C+P">Pierre Marza</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matignon%2C+L">Laetitia Matignon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Simonin%2C+O">Olivier Simonin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wolf%2C+C">Christian Wolf</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

                </div>
            </div>
        </dd>
        <dt><a name="item1019">[1019]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.08193"
                    title="Abstract">arXiv:2402.08193</a> (replaced) [<a href="/pdf/2402.08193"
                    title="Download PDF">pdf</a>, <a href="/format/2402.08193" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Gaussian Ensemble Belief Propagation for Efficient Inference
                    in High-Dimensional Systems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=MacKinlay%2C+D">Dan MacKinlay</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tsuchida%2C+R">Russell Tsuchida</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pagendam%2C+D">Dan Pagendam</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kuhnert%2C+P">Petra Kuhnert</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Under conference submission
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item1020">[1020]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.08318"
                    title="Abstract">arXiv:2402.08318</a> (replaced) [<a href="/pdf/2402.08318"
                    title="Download PDF">pdf</a>, <a href="/format/2402.08318" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Values That Are Explicitly Present in Fairy Tales: Comparing
                    Samples from German, Italian and Portuguese Traditions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Diaz-Faes%2C+A+M">Alba Morollon Diaz-Faes</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Murteira%2C+C+S+R">Carla Sofia Ribeiro Murteira</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ruskov%2C+M">Martin Ruskov</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> In Proceedings of the Joint 3rd International Conference
                    on Natural Language Processing for Digital Humanities and 8th International Workshop on
                    Computational Linguistics for Uralic Languages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Computers and Society (cs.CY)

                </div>
            </div>
        </dd>
        <dt><a name="item1021">[1021]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.08907"
                    title="Abstract">arXiv:2402.08907</a> (replaced) [<a href="/pdf/2402.08907"
                    title="Download PDF">pdf</a>, <a href="/format/2402.08907" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Subgraph Pooling: Tackling Negative Transfer on Graphs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zehong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zheyuan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chuxu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+Y">Yanfang Ye</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IJCAI 24
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

                </div>
            </div>
        </dd>
        <dt><a name="item1022">[1022]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.09809"
                    title="Abstract">arXiv:2402.09809</a> (replaced) [<a href="/pdf/2402.09809"
                    title="Download PDF">pdf</a>, <a href="/ps/2402.09809" title="Download PostScript">ps</a>, <a
                    href="/format/2402.09809" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Effective and Scalable Math Support: Evidence on the Impact
                    of an AI- Tutor on Math Achievement in Ghana
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Henkel%2C+O">Owen Henkel</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Horne-Robinson%2C+H">Hannah Horne-Robinson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kozhakhmetova%2C+N">Nessie Kozhakhmetova</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+A">Amanda Lee</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1023">[1023]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.10481"
                    title="Abstract">arXiv:2402.10481</a> (replaced) [<a href="/pdf/2402.10481"
                    title="Download PDF">pdf</a>, <a href="/ps/2402.10481" title="Download PostScript">ps</a>, <a
                    href="/format/2402.10481" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Emoji Driven Crypto Assets Market Reactions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/q-fin?searchtype=author&amp;query=Zuo%2C+X">Xiaorui Zuo</a>,
                    <a href="/search/q-fin?searchtype=author&amp;query=Chen%2C+Y">Yao-Tsung Chen</a>,
                    <a href="/search/q-fin?searchtype=author&amp;query=H%C3%A4rdle%2C+W+K">Wolfgang Karl Härdle</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance
                        (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine
                    Learning (cs.LG); Statistical Finance (q-fin.ST)

                </div>
            </div>
        </dd>
        <dt><a name="item1024">[1024]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.10517"
                    title="Abstract">arXiv:2402.10517</a> (replaced) [<a href="/pdf/2402.10517"
                    title="Download PDF">pdf</a>, <a href="/format/2402.10517" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Any-Precision LLM: Low-Cost Deployment of Multiple,
                    Different-Sized LLMs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+Y">Yeonhong Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hyun%2C+J">Jake Hyun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cho%2C+S">SangLyul Cho</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sim%2C+B">Bonggeun Sim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+J+W">Jae W. Lee</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To appear at ICML 2024. Code is available at <a
                        href="https://github.com/SNU-ARC/any-precision-llm">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1025">[1025]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.13008"
                    title="Abstract">arXiv:2402.13008</a> (replaced) [<a href="/pdf/2402.13008"
                    title="Download PDF">pdf</a>, <a href="/format/2402.13008" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient Enumeration of Large Maximal k-Plexes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+Q">Qihao Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+D">Da Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+T">Tianhao Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+L">Lyuheng Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Ji Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhongyi Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Y">Yang Zhou</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
            </div>
        </dd>
        <dt><a name="item1026">[1026]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.14693"
                    title="Abstract">arXiv:2402.14693</a> (replaced) [<a href="/pdf/2402.14693"
                    title="Download PDF">pdf</a>, <a href="/ps/2402.14693" title="Download PostScript">ps</a>, <a
                    href="/format/2402.14693" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Joint AP-UE Association and Power Factor Optimization for
                    Distributed Massive MIMO
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+M+S+A">Mohd Saif Ali Khan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Agnihotri%2C+S">Samar Agnihotri</a>,
                    <a href="/search/cs?searchtype=author&amp;query=M%2C+K+R">Karthik R.M</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>; Information Theory (cs.IT)

                </div>
            </div>
        </dd>
        <dt><a name="item1027">[1027]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.16310"
                    title="Abstract">arXiv:2402.16310</a> (replaced) [<a href="/pdf/2402.16310"
                    title="Download PDF">pdf</a>, <a href="/format/2402.16310" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> REPLAY: Modeling Time-Varying Temporal Regularities of Human
                    Mobility for Location Prediction over Sparse Trajectories
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+B">Bangchao Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qu%2C+B">Bingqing Qu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+P">Pengyang Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+D">Dingqi Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fankhauser%2C+B">Benjamin Fankhauser</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cudre-Mauroux%2C+P">Philippe Cudre-Mauroux</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1028">[1028]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.17152"
                    title="Abstract">arXiv:2402.17152</a> (replaced) [<a href="/pdf/2402.17152"
                    title="Download PDF">pdf</a>, <a href="/format/2402.17152" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Actions Speak Louder than Words: Trillion-Parameter
                    Sequential Transducers for Generative Recommendations
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhai%2C+J">Jiaqi Zhai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liao%2C+L">Lucy Liao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+X">Xing Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yueming Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Rui Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+X">Xuan Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+L">Leon Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gong%2C+Z">Zhaojie Gong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+F">Fangda Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+M">Michael He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yinghai Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Y">Yu Shi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 26 pages, 13 figures. ICML'24. Code available at <a
                        href="https://github.com/facebookresearch/generative-recommenders">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Information Retrieval (cs.IR)

                </div>
            </div>
        </dd>
        <dt><a name="item1029">[1029]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.17220"
                    title="Abstract">arXiv:2402.17220</a> (replaced) [<a href="/pdf/2402.17220"
                    title="Download PDF">pdf</a>, <a href="/ps/2402.17220" title="Download PostScript">ps</a>, <a
                    href="/format/2402.17220" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the probability of a Pareto record
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Fill%2C+J+A">James Allen Fill</a> (1),
                    <a href="/search/math?searchtype=author&amp;query=Sun%2C+A">Ao Sun</a> (1) ((1) The Johns Hopkins
                    University)
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages, 1 figure; this revision responds to three
                    anonymous reviews; paper accepted to Probability in the Engineering and Informational Sciences
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Probability
                        (math.PR)</span>; Data Structures and Algorithms (cs.DS)

                </div>
            </div>
        </dd>
        <dt><a name="item1030">[1030]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.17493"
                    title="Abstract">arXiv:2402.17493</a> (replaced) [<a href="/pdf/2402.17493"
                    title="Download PDF">pdf</a>, <a href="/ps/2402.17493" title="Download PostScript">ps</a>, <a
                    href="/format/2402.17493" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Predicting postoperative risks using large language models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+B">Bing Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Alba%2C+C">Charles Alba</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abraham%2C+J">Joanna Abraham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kannampallil%2C+T">Thomas Kannampallil</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+C">Chenyang Lu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Supplemental file available at: <a
                        href="https://sites.wustl.edu/alba/files/2024/04/supplemental_materials-283eb0c14629614c.pdf">this
                        https URL</a> models publicly available at: <a
                        href="https://huggingface.co/cja5553/BJH-perioperative-notes-bioGPT">this https URL</a> AND <a
                        href="https://huggingface.co/cja5553/BJH-perioperative-notes-bioGPT">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1031">[1031]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.17613"
                    title="Abstract">arXiv:2402.17613</a> (replaced) [<a href="/pdf/2402.17613"
                    title="Download PDF">pdf</a>, <a href="/format/2402.17613" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Neural Automated Writing Evaluation with Corrective Feedback
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+I+X">Izia Xiaoxiao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xihan Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Coates%2C+E">Edith Coates</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+M">Min Zeng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kuang%2C+J">Jiexin Kuang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Siliang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+M">Mengyang Qiu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+J">Jungyeul Park</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Supported by the SoTL Seed Program at UBC
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1032">[1032]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.18312"
                    title="Abstract">arXiv:2402.18312</a> (replaced) [<a href="/pdf/2402.18312"
                    title="Download PDF">pdf</a>, <a href="/format/2402.18312" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> How to think step-by-step: A mechanistic understanding of
                    chain-of-thought reasoning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dutta%2C+S">Subhabrata Dutta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singh%2C+J">Joykirat Singh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chakrabarti%2C+S">Soumen Chakrabarti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1033">[1033]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.19146"
                    title="Abstract">arXiv:2402.19146</a> (replaced) [<a href="/pdf/2402.19146"
                    title="Download PDF">pdf</a>, <a href="/format/2402.19146" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Computing Longest Common Subsequence under Cartesian-Tree
                    Matching Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tsujimoto%2C+T">Taketo Tsujimoto</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shibata%2C+H">Hiroki Shibata</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mieno%2C+T">Takuya Mieno</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nakashima%2C+Y">Yuto Nakashima</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Inenaga%2C+S">Shunsuke Inenaga</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1034">[1034]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.19379"
                    title="Abstract">arXiv:2402.19379</a> (replaced) [<a href="/pdf/2402.19379"
                    title="Download PDF">pdf</a>, <a href="/format/2402.19379" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Wisdom of the Silicon Crowd: LLM Ensemble Prediction
                    Capabilities Rival Human Crowd Accuracy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Schoenegger%2C+P">Philipp Schoenegger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tuminauskaite%2C+I">Indre Tuminauskaite</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+P+S">Peter S. Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tetlock%2C+P+E">Philip E. Tetlock</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 20 pages; 13 visualizations (nine figures, four tables)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine
                    Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1035">[1035]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.19404"
                    title="Abstract">arXiv:2402.19404</a> (replaced) [<a href="/pdf/2402.19404"
                    title="Download PDF">pdf</a>, <a href="/format/2402.19404" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> EAMA : Entity-Aware Multimodal Alignment Based Approach for
                    News Image Captioning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junzhe Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huixuan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yin%2C+X">Xunjian Yin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wan%2C+X">Xiaojun Wan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item1036">[1036]</a>&nbsp; <span class="list-identifier"><a href="/abs/2402.19422"
                    title="Abstract">arXiv:2402.19422</a> (replaced) [<a href="/pdf/2402.19422"
                    title="Download PDF">pdf</a>, <a href="/format/2402.19422" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PEM: Prototype-based Efficient MaskFormer for Image
                    Segmentation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cavagnero%2C+N">Niccolò Cavagnero</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rosi%2C+G">Gabriele Rosi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cuttano%2C+C">Claudia Cuttano</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pistilli%2C+F">Francesca Pistilli</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ciccone%2C+M">Marco Ciccone</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Averta%2C+G">Giuseppe Averta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cermelli%2C+F">Fabio Cermelli</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> CVPR 2024. Project page: <a
                        href="https://niccolocavagnero.github.io/PEM">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1037">[1037]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.00170"
                    title="Abstract">arXiv:2403.00170</a> (replaced) [<a href="/pdf/2403.00170"
                    title="Download PDF">pdf</a>, <a href="/format/2403.00170" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AlloyASG: Alloy Predicate Code Representation as a Compact
                    Structurally Balanced Graph
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+G">Guanxuan Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sullivan%2C+A">Allison Sullivan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Programming Languages (cs.PL)

                </div>
            </div>
        </dd>
        <dt><a name="item1038">[1038]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.00540"
                    title="Abstract">arXiv:2403.00540</a> (replaced) [<a href="/pdf/2403.00540"
                    title="Download PDF">pdf</a>, <a href="/format/2403.00540" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Epsilon-Greedy Thompson Sampling to Bayesian Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Do%2C+B">Bach Do</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Adebiyi%2C+T">Taiwo Adebiyi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruda Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item1039">[1039]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.01106"
                    title="Abstract">arXiv:2403.01106</a> (replaced) [<a href="/pdf/2403.01106"
                    title="Download PDF">pdf</a>, <a href="/format/2403.01106" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Distilling Text Style Transfer With Self-Explanation From
                    LLMs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Chiyu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+H">Honglong Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuezhang">Yuezhang</a> (Music)Li,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yuexin Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hou%2C+L">Le Hou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Abdul-Mageed%2C+M">Muhammad Abdul-Mageed</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by NAACL Student Research Workshop 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1040">[1040]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.01150"
                    title="Abstract">arXiv:2403.01150</a> (replaced) [<a href="/pdf/2403.01150"
                    title="Download PDF">pdf</a>, <a href="/format/2403.01150" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Singularity and Error Analysis of a Simple Quaternion
                    Estimator
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/stat?searchtype=author&amp;query=Peng%2C+C">Caitong Peng</a>,
                    <a href="/search/stat?searchtype=author&amp;query=Choukroun%2C+D">Daniel Choukroun</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology
                        (stat.ME)</span>; Systems and Control (eess.SY)

                </div>
            </div>
        </dd>
        <dt><a name="item1041">[1041]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.01296"
                    title="Abstract">arXiv:2403.01296</a> (replaced) [<a href="/pdf/2403.01296"
                    title="Download PDF">pdf</a>, <a href="/ps/2403.01296" title="Download PostScript">ps</a>, <a
                    href="/format/2403.01296" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Rate-limited Shuffling for Distributed Computing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sasi%2C+S">Shanuja Sasi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=G%C3%BCnl%C3%BC%2C+O">Onur Günlü</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 6 pages and 2 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
            </div>
        </dd>
        <dt><a name="item1042">[1042]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.01353"
                    title="Abstract">arXiv:2403.01353</a> (replaced) [<a href="/pdf/2403.01353"
                    title="Download PDF">pdf</a>, <a href="/format/2403.01353" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Spatially parallel decoding for multi-qubit lattice surgery
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/quant-ph?searchtype=author&amp;query=Lin%2C+S+F">Sophia Fuhui Lin</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Peterson%2C+E+C">Eric C. Peterson</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Sankar%2C+K">Krishanu Sankar</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Sivarajah%2C+P">Prasahnt Sivarajah</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics
                        (quant-ph)</span>; Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)

                </div>
            </div>
        </dd>
        <dt><a name="item1043">[1043]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.01373"
                    title="Abstract">arXiv:2403.01373</a> (replaced) [<a href="/pdf/2403.01373"
                    title="Download PDF">pdf</a>, <a href="/format/2403.01373" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Quantity Matters: Towards Assessing and Mitigating Number
                    Hallucination in Large Vision-Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Huixuan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Junzhe Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wan%2C+X">Xiaojun Wan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 10 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1044">[1044]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.01384"
                    title="Abstract">arXiv:2403.01384</a> (replaced) [<a href="/pdf/2403.01384"
                    title="Download PDF">pdf</a>, <a href="/format/2403.01384" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the Compressibility of Quantized Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mao%2C+Y">Yu Mao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Weilan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Du%2C+H">Hongchao Du</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guan%2C+N">Nan Guan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+C+J">Chun Jason Xue</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item1045">[1045]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.02622"
                    title="Abstract">arXiv:2403.02622</a> (replaced) [<a href="/pdf/2403.02622"
                    title="Download PDF">pdf</a>, <a href="/format/2403.02622" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> World Models for Autonomous Driving: An Initial Survey
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Guan%2C+Y">Yanchen Guan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liao%2C+H">Haicheng Liao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhenning Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guohui Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Chengzhong Xu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

                </div>
            </div>
        </dd>
        <dt><a name="item1046">[1046]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.02795"
                    title="Abstract">arXiv:2403.02795</a> (replaced) [<a href="/pdf/2403.02795"
                    title="Download PDF">pdf</a>, <a href="/format/2403.02795" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Evaluating and Optimizing Educational Content with Large
                    Language Model Judgments
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=He-Yueya%2C+J">Joy He-Yueya</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goodman%2C+N+D">Noah D. Goodman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brunskill%2C+E">Emma Brunskill</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 11 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item1047">[1047]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.03134"
                    title="Abstract">arXiv:2403.03134</a> (replaced) [<a href="/pdf/2403.03134"
                    title="Download PDF">pdf</a>, <a href="/format/2403.03134" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Simplicity in Complexity : Explaining Visual Complexity using
                    Deep Segmentation Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+T">Tingke Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nath%2C+S+S">Surabhi S Nath</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Brielmann%2C+A">Aenne Brielmann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dayan%2C+P">Peter Dayan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

                </div>
            </div>
        </dd>
        <dt><a name="item1048">[1048]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.03205"
                    title="Abstract">arXiv:2403.03205</a> (replaced) [<a href="/pdf/2403.03205"
                    title="Download PDF">pdf</a>, <a href="/format/2403.03205" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Finding Super-spreaders in Network Cascades
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Mossel%2C+E">Elchanan Mossel</a>,
                    <a href="/search/math?searchtype=author&amp;query=Sridhar%2C+A">Anirudh Sridhar</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 32 pages, 3 figures. Main updates are (1) a relaxation of
                    graph assumptions and (2) a slight sharpening of previous techniques that allows us to estimate the
                    infection time of high-degree vertices from a single cascade
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory
                        (math.ST)</span>; Information Theory (cs.IT); Social and Information Networks (cs.SI);
                    Probability (math.PR)

                </div>
            </div>
        </dd>
        <dt><a name="item1049">[1049]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.03655"
                    title="Abstract">arXiv:2403.03655</a> (replaced) [<a href="/pdf/2403.03655"
                    title="Download PDF">pdf</a>, <a href="/format/2403.03655" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Kronos: A Secure and Generic Sharding Blockchain Consensus
                    with Optimized Overhead
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yizhong Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+A">Andi Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Y">Yuan Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pan%2C+Z">Zhuocheng Pan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yinuo Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jianwei Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bian%2C+S">Song Bian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Conti%2C+M">Mauro Conti</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1050">[1050]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.04161"
                    title="Abstract">arXiv:2403.04161</a> (replaced) [<a href="/pdf/2403.04161"
                    title="Download PDF">pdf</a>, <a href="/format/2403.04161" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SWAP-NAS: sample-wise activation patterns for ultra-fast NAS
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yameng Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+A">Andy Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fayek%2C+H+M">Haytham M. Fayek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ciesielski%2C+V">Vic Ciesielski</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+X">Xiaojun Chang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICLR2024 Spotlight
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary
                    Computing (cs.NE)

                </div>
            </div>
        </dd>
        <dt><a name="item1051">[1051]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.04306"
                    title="Abstract">arXiv:2403.04306</a> (replaced) [<a href="/pdf/2403.04306"
                    title="Download PDF">pdf</a>, <a href="/format/2403.04306" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Effectiveness Assessment of Recent Large Vision-Language
                    Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Y">Yao Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+X">Xinyu Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+G">Ge-Peng Ji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+K">Keren Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+M">Meijun Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+H">Huan Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+D">Deng-Ping Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+F+S">Fahad Shahbaz Khan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1052">[1052]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.04307"
                    title="Abstract">arXiv:2403.04307</a> (replaced) [<a href="/pdf/2403.04307"
                    title="Download PDF">pdf</a>, <a href="/format/2403.04307" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> HaluEval-Wild: Evaluating Hallucinations of Language Models
                    in the Wild
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Z">Zhiying Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yiming Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhiqing Sun</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1053">[1053]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.05370"
                    title="Abstract">arXiv:2403.05370</a> (replaced) [<a href="/pdf/2403.05370"
                    title="Download PDF">pdf</a>, <a href="/format/2403.05370" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> On the Certification of the Kinematics of 3-DOF Spherical
                    Parallel Manipulators
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=L%C3%AA%2C+A">Alexandre Lê</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rance%2C+G">Guillaume Rance</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rouillier%2C+F">Fabrice Rouillier</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chablat%2C+D">Damien Chablat</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Systems and Control (eess.SY)

                </div>
            </div>
        </dd>
        <dt><a name="item1054">[1054]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.05771"
                    title="Abstract">arXiv:2403.05771</a> (replaced) [<a href="/pdf/2403.05771"
                    title="Download PDF">pdf</a>, <a href="/format/2403.05771" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Providing Safety Assurances for Systems with Unknown Dynamics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Hao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Borquez%2C+J">Javier Borquez</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bansal%2C+S">Somil Bansal</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Submitted to L-CSS/CDC
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Systems and Control (eess.SY)

                </div>
            </div>
        </dd>
        <dt><a name="item1055">[1055]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.05890"
                    title="Abstract">arXiv:2403.05890</a> (replaced) [<a href="/e-print/2403.05890"
                    title="Download source">src</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards Efficient Replay in Federated Incremental Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yichen Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Q">Qunwei Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haozhao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+R">Ruixuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+W">Wenliang Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guannan Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> We are a collaborative article with a company, and the
                    company needs to revise and verify the relevant information of the article before publishing it,
                    including acknowledgments, authors, and some details
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
            </div>
        </dd>
        <dt><a name="item1056">[1056]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.06172"
                    title="Abstract">arXiv:2403.06172</a> (replaced) [<a href="/pdf/2403.06172"
                    title="Download PDF">pdf</a>, <a href="/format/2403.06172" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Understanding Parents' Perceptions and Practices Toward
                    Children's Security and Privacy in Virtual Reality
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+J">Jiaxun Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=B.%2C+A+S">Abhinaya S. B.</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Das%2C+A">Anupam Das</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Emami-Naeini%2C+P">Pardis Emami-Naeini</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To appear in the IEEE Symposium on Security &amp; Privacy
                    (S&amp;P), May 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1057">[1057]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.06321"
                    title="Abstract">arXiv:2403.06321</a> (replaced) [<a href="/pdf/2403.06321"
                    title="Download PDF">pdf</a>, <a href="/format/2403.06321" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Vertex Block Descent
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+A+H">Anka He Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Ziheng Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yin Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuksel%2C+C">Cem Yuksel</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1058">[1058]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.06659"
                    title="Abstract">arXiv:2403.06659</a> (replaced) [<a href="/pdf/2403.06659"
                    title="Download PDF">pdf</a>, <a href="/format/2403.06659" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Zero-Shot ECG Classification with Multimodal Learning and
                    Test-time Clinical Knowledge Enhancement
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Liu%2C+C">Che Liu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wan%2C+Z">Zhongwei Wan</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Ouyang%2C+C">Cheng Ouyang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Shah%2C+A">Anand Shah</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Bai%2C+W">Wenjia Bai</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Arcucci%2C+R">Rossella Arcucci</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1059">[1059]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.08002"
                    title="Abstract">arXiv:2403.08002</a> (replaced) [<a href="/pdf/2403.08002"
                    title="Download PDF">pdf</a>, <a href="/format/2403.08002" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards a clinically accessible radiology foundation model:
                    open-access and lightweight, with automated evaluation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chaves%2C+J+M+Z">Juan Manuel Zambrano Chaves</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+S">Shih-Cheng Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yanbo Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+H">Hanwen Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Usuyama%2C+N">Naoto Usuyama</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Sheng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+F">Fei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Y">Yujia Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khademi%2C+M">Mahmoud Khademi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Ziyi Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Awadalla%2C+H">Hany Awadalla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gong%2C+J">Julia Gong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Houdong Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jianwei Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+C">Chunyuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+J">Jianfeng Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+Y">Yu Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wong%2C+C">Cliff Wong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+M">Mu Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Naumann%2C+T">Tristan Naumann</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Muhao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lungren%2C+M+P">Matthew P. Lungren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yeung-Levy%2C+S">Serena Yeung-Levy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Langlotz%2C+C+P">Curtis P. Langlotz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Sheng Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Poon%2C+H">Hoifung Poon</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item1060">[1060]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.08056"
                    title="Abstract">arXiv:2403.08056</a> (replaced) [<a href="/pdf/2403.08056"
                    title="Download PDF">pdf</a>, <a href="/format/2403.08056" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Improving Memory Dependence Prediction with Static Analysis
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Panayi%2C+L">Luke Panayi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gandhi%2C+R">Rohan Gandhi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Whittaker%2C+J">Jim Whittaker</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chouliaras%2C+V">Vassilios Chouliaras</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Berger%2C+M">Martin Berger</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kelly%2C+P">Paul Kelly</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages
                        (cs.PL)</span>; Hardware Architecture (cs.AR)

                </div>
            </div>
        </dd>
        <dt><a name="item1061">[1061]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.08063"
                    title="Abstract">arXiv:2403.08063</a> (replaced) [<a href="/pdf/2403.08063"
                    title="Download PDF">pdf</a>, <a href="/format/2403.08063" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards Code Generation for Octree-Based Multigrid Solvers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Angersbach%2C+R">Richard Angersbach</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kuckuck%2C+S">Sebastian Kuckuck</a>,
                    <a href="/search/cs?searchtype=author&amp;query=K%C3%B6stler%2C+H">Harald Köstler</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering,
                        Finance, and Science (cs.CE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1062">[1062]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.08384"
                    title="Abstract">arXiv:2403.08384</a> (replaced) [<a href="/e-print/2403.08384"
                    title="Download source">src</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AADNet: Attention aware Demoiréing Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Reddy%2C+M+R">M Rakesh Reddy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mandloi%2C+S">Shubham Mandloi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+A">Aman Kumar</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Due to unauthorized access and upload, this paper has been
                    withdrawn. It does not reflect the contributions or approval
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1063">[1063]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.08694"
                    title="Abstract">arXiv:2403.08694</a> (replaced) [<a href="/pdf/2403.08694"
                    title="Download PDF">pdf</a>, <a href="/format/2403.08694" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TeaMs-RL: Teaching LLMs to Teach Themselves Better
                    Instructions via Reinforcement Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+S">Shangding Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Knoll%2C+A">Alois Knoll</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+M">Ming Jin</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1064">[1064]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.09053"
                    title="Abstract">arXiv:2403.09053</a> (replaced) [<a href="/pdf/2403.09053"
                    title="Download PDF">pdf</a>, <a href="/format/2403.09053" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards a theory of model distillation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Boix-Adsera%2C+E">Enric Boix-Adsera</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 46 pages, 5 figures. Please reach out with comments!
                    Feedback is welcome
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

                </div>
            </div>
        </dd>
        <dt><a name="item1065">[1065]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.09858"
                    title="Abstract">arXiv:2403.09858</a> (replaced) [<a href="/pdf/2403.09858"
                    title="Download PDF">pdf</a>, <a href="/format/2403.09858" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FakeWatch: A Framework for Detecting Fake News to Ensure
                    Credible Elections
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Raza%2C+S">Shaina Raza</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khan%2C+T">Tahniat Khan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chatrath%2C+V">Veronica Chatrath</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Paulen-Patterson%2C+D">Drai Paulen-Patterson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rahman%2C+M">Mizanur Rahman</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bamgbose%2C+O">Oluwanifemi Bamgbose</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a
                        href="/abs/2312.03730">arXiv:2312.03730</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1066">[1066]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.10318"
                    title="Abstract">arXiv:2403.10318</a> (replaced) [<a href="/pdf/2403.10318"
                    title="Download PDF">pdf</a>, <a href="/format/2403.10318" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Anytime Neural Architecture Search on Tabular Data
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xing%2C+N">Naili Xing</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+S">Shaofeng Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+Z">Zhaojing Luo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ooi%2C+B+C">Beng Chin Ooi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pei%2C+J">Jian Pei</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1067">[1067]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.10522"
                    title="Abstract">arXiv:2403.10522</a> (replaced) [<a href="/pdf/2403.10522"
                    title="Download PDF">pdf</a>, <a href="/format/2403.10522" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Ordinal Classification with Distance Regularization for
                    Robust Brain Age Prediction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Shah%2C+J">Jay Shah</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Siddiquee%2C+M+M+R">Md Mahfuzur Rahman
                        Siddiquee</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Su%2C+Y">Yi Su</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wu%2C+T">Teresa Wu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Li%2C+B">Baoxin Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in WACV 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item1068">[1068]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.12421"
                    title="Abstract">arXiv:2403.12421</a> (replaced) [<a href="/pdf/2403.12421"
                    title="Download PDF">pdf</a>, <a href="/format/2403.12421" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Dexterous Functional Pre-Grasp Manipulation with Diffusion
                    Policy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+T">Tianhao Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gan%2C+Y">Yunchong Gan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+M">Mingdong Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+J">Jingbo Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yaodong Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhu%2C+Y">Yixin Zhu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+H">Hao Dong</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1069">[1069]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.14020"
                    title="Abstract">arXiv:2403.14020</a> (replaced) [<a href="/pdf/2403.14020"
                    title="Download PDF">pdf</a>, <a href="/format/2403.14020" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Zero-Knowledge Proof of Distinct Identity: a
                    Standard-compatible Sybil-resistant Pseudonym Extension for C-ITS
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tao%2C+Y">Ye Tao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Hongyi Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Javanmardi%2C+E">Ehsan Javanmardi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tsukada%2C+M">Manabu Tsukada</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Esaki%2C+H">Hiroshi Esaki</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for publication at IEEE IV 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

                </div>
            </div>
        </dd>
        <dt><a name="item1070">[1070]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.14176"
                    title="Abstract">arXiv:2403.14176</a> (replaced) [<a href="/pdf/2403.14176"
                    title="Download PDF">pdf</a>, <a href="/format/2403.14176" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ReFeree: Radar-based efficient global descriptor using a
                    Feature and Free space for Place Recognition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+B">Byunghee Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+H">Hogyun Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cho%2C+Y">Younggun Cho</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 5 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1071">[1071]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.15064"
                    title="Abstract">arXiv:2403.15064</a> (replaced) [<a href="/pdf/2403.15064"
                    title="Download PDF">pdf</a>, <a href="/format/2403.15064" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Recent Trends in 3D Reconstruction of General Non-Rigid
                    Scenes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yunus%2C+R">Raza Yunus</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lenssen%2C+J+E">Jan Eric Lenssen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Niemeyer%2C+M">Michael Niemeyer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liao%2C+Y">Yiyi Liao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rupprecht%2C+C">Christian Rupprecht</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Theobalt%2C+C">Christian Theobalt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pons-Moll%2C+G">Gerard Pons-Moll</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jia-Bin Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Golyanik%2C+V">Vladislav Golyanik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ilg%2C+E">Eddy Ilg</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 42 pages, 18 figures, 5 tables; State-of-the-Art Report at
                    EUROGRAPHICS 2024. Project page: <a href="https://razayunus.github.io/non-rigid-star">this https
                        URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR)

                </div>
            </div>
        </dd>
        <dt><a name="item1072">[1072]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.15246"
                    title="Abstract">arXiv:2403.15246</a> (replaced) [<a href="/pdf/2403.15246"
                    title="Download PDF">pdf</a>, <a href="/format/2403.15246" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FollowIR: Evaluating and Teaching Information Retrieval
                    Models to Follow Instructions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Weller%2C+O">Orion Weller</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+B">Benjamin Chang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=MacAvaney%2C+S">Sean MacAvaney</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lo%2C+K">Kyle Lo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cohan%2C+A">Arman Cohan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Van+Durme%2C+B">Benjamin Van Durme</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lawrie%2C+D">Dawn Lawrie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1073">[1073]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.15400"
                    title="Abstract">arXiv:2403.15400</a> (replaced) [<a href="/pdf/2403.15400"
                    title="Download PDF">pdf</a>, <a href="/format/2403.15400" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient Weighting Schemes for Auditing Instant-Runoff
                    Voting Elections
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ek%2C+A">Alexander Ek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stark%2C+P+B">Philip B. Stark</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stuckey%2C+P+J">Peter J. Stuckey</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vukcevic%2C+D">Damjan Vukcevic</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 4, figures, presented at Voting'24. The current
                    version includes some improved wording and fixes a few errors
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society
                        (cs.CY)</span>; Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT);
                    Applications (stat.AP)

                </div>
            </div>
        </dd>
        <dt><a name="item1074">[1074]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.15676"
                    title="Abstract">arXiv:2403.15676</a> (replaced) [<a href="/pdf/2403.15676"
                    title="Download PDF">pdf</a>, <a href="/format/2403.15676" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> AC4: Algebraic Computation Checker for Circuit Constraints in
                    ZKPs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Hao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Minyu Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+R">Ruibang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+G">Guoqiang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+S">Sinka Gao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 20 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item1075">[1075]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.16167"
                    title="Abstract">arXiv:2403.16167</a> (replaced) [<a href="/pdf/2403.16167"
                    title="Download PDF">pdf</a>, <a href="/format/2403.16167" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploiting Semantic Reconstruction to Mitigate Hallucinations
                    in Vision-Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+M">Minchan Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+M">Minyeong Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bae%2C+J">Junik Bae</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+S">Suhwan Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+S">Sungkyung Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chang%2C+B">Buru Chang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item1076">[1076]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.17141"
                    title="Abstract">arXiv:2403.17141</a> (replaced) [<a href="/pdf/2403.17141"
                    title="Download PDF">pdf</a>, <a href="/format/2403.17141" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MetaAligner: Towards Generalizable Multi-Objective Alignment
                    of Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+K">Kailai Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Z">Zhiwei Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Q">Qianqian Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jimin Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+T">Tianlin Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ananiadou%2C+S">Sophia Ananiadou</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Work in progress
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1077">[1077]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.18104"
                    title="Abstract">arXiv:2403.18104</a> (replaced) [<a href="/pdf/2403.18104"
                    title="Download PDF">pdf</a>, <a href="/format/2403.18104" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mathematical Foundation and Corrections for Full Range Head
                    Pose Estimation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+H">Huei-Chung Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+X">Xuyang Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yuan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yi Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Hsin-Tai Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1078">[1078]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.18415"
                    title="Abstract">arXiv:2403.18415</a> (replaced) [<a href="/e-print/2403.18415"
                    title="Download source">src</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Topos of Transformer Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Villani%2C+M+J">Mattia Jacopo Villani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McBurney%2C+P">Peter McBurney</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Requires major revision
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Category Theory (math.CT)

                </div>
            </div>
        </dd>
        <dt><a name="item1079">[1079]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.18453"
                    title="Abstract">arXiv:2403.18453</a> (replaced) [<a href="/pdf/2403.18453"
                    title="Download PDF">pdf</a>, <a href="/format/2403.18453" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Annotating Slack Directly on Your Verilog: Fine-Grained RTL
                    Timing Evaluation for Early Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+W">Wenji Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+S">Shang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hongce Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+Z">Zhiyao Xie</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Published as a conference paper at Design Automation
                    Conference (DAC) 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture
                        (cs.AR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1080">[1080]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.18604"
                    title="Abstract">arXiv:2403.18604</a> (replaced) [<a href="/pdf/2403.18604"
                    title="Download PDF">pdf</a>, <a href="/format/2403.18604" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Modeling Sustainable City Trips: Integrating CO2e Emissions,
                    Popularity, and Seasonality into Tourism Recommender Systems
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Banerjee%2C+A">Ashmi Banerjee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mahmudov%2C+T">Tunar Mahmudov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Adler%2C+E">Emil Adler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Aisyah%2C+F+N">Fitri Nur Aisyah</a>,
                    <a href="/search/cs?searchtype=author&amp;query=W%C3%B6rndl%2C+W">Wolfgang Wörndl</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1081">[1081]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.19680"
                    title="Abstract">arXiv:2403.19680</a> (replaced) [<a href="/pdf/2403.19680"
                    title="Download PDF">pdf</a>, <a href="/format/2403.19680" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A (1.999999)-approximation ratio for vertex cover problem
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zohrehbandian%2C+M">Majid Zohrehbandian</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity
                        (cs.CC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1082">[1082]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.19902"
                    title="Abstract">arXiv:2403.19902</a> (replaced) [<a href="/pdf/2403.19902"
                    title="Download PDF">pdf</a>, <a href="/format/2403.19902" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Heterogeneous Network Based Contrastive Learning Method for
                    PolSAR Land Cover Classification
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+J">Jianfeng Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yue Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Z">Zhixi Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+S">Shuyuan Yang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1083">[1083]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.19924"
                    title="Abstract">arXiv:2403.19924</a> (replaced) [<a href="/pdf/2403.19924"
                    title="Download PDF">pdf</a>, <a href="/format/2403.19924" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SceneTracker: Long-term Scene Flow Estimation Network
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bo Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+J">Jian Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yang Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+L">Li Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Z">Zhenping Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+D">Dewen Hu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1084">[1084]</a>&nbsp; <span class="list-identifier"><a href="/abs/2403.20288"
                    title="Abstract">arXiv:2403.20288</a> (replaced) [<a href="/pdf/2403.20288"
                    title="Download PDF">pdf</a>, <a href="/format/2403.20288" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Can LLMs Correct Physicians, Yet? Investigating Effective
                    Interaction Methods in the Medical Domain
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sayin%2C+B">Burcu Sayin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Minervini%2C+P">Pasquale Minervini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Staiano%2C+J">Jacopo Staiano</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Passerini%2C+A">Andrea Passerini</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for oral presentation at NAACL 2024, The 6th
                    Clinical Natural Language Processing Workshop
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1085">[1085]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.00897"
                    title="Abstract">arXiv:2404.00897</a> (replaced) [<a href="/pdf/2404.00897"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.00897" title="Download PostScript">ps</a>, <a
                    href="/format/2404.00897" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Machine Learning Robustness: A Primer
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Braiek%2C+H+B">Houssem Ben Braiek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Khomh%2C+F">Foutse Khomh</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

                </div>
            </div>
        </dd>
        <dt><a name="item1086">[1086]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.01078"
                    title="Abstract">arXiv:2404.01078</a> (replaced) [<a href="/pdf/2404.01078"
                    title="Download PDF">pdf</a>, <a href="/format/2404.01078" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Energy-based Model for Accurate Shapley Value Estimation in
                    Interpretable Deep Learning Predictive Modeling
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+C">Cheng Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+J">Jiusun Zeng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+Y">Yu Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+J">Jinhui Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Luo%2C+S">Shihua Luo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1087">[1087]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.01568"
                    title="Abstract">arXiv:2404.01568</a> (replaced) [<a href="/pdf/2404.01568"
                    title="Download PDF">pdf</a>, <a href="/format/2404.01568" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Linear Time and Space Local Point Cloud Geometry Encoder
                    via Vectorized Kernel Mixture (VecKM)
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+D">Dehao Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ferm%C3%BCller%2C+C">Cornelia Fermüller</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rabbani%2C+T">Tahseen Rabbani</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+F">Furong Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Aloimonos%2C+Y">Yiannis Aloimonos</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML2024 Conference Paper
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Computational Geometry (cs.CG)

                </div>
            </div>
        </dd>
        <dt><a name="item1088">[1088]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.03191"
                    title="Abstract">arXiv:2404.03191</a> (replaced) [<a href="/pdf/2404.03191"
                    title="Download PDF">pdf</a>, <a href="/format/2404.03191" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> CORP: A Multi-Modal Dataset for Campus-Oriented Roadside
                    Perception Tasks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Beibei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Meng%2C+S">Shuang Meng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chenjie Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+J">Jingjing Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yao Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ren%2C+H">Haojie Ren</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiao%2C+Y">Yuxuan Xiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+Y">Yuru Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+J">Jianmin Ji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yu Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yanyong Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1089">[1089]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.03208"
                    title="Abstract">arXiv:2404.03208</a> (replaced) [<a href="/pdf/2404.03208"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.03208" title="Download PostScript">ps</a>, <a
                    href="/format/2404.03208" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> HiMAL: A Multimodal Hierarchical Multi-task Auxiliary
                    Learning framework for predicting and explaining Alzheimer disease progression
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kumar%2C+S">Sayantan Kumar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+S">Sean Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Michelson%2C+A">Andrew Michelson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kannampallil%2C+T">Thomas Kannampallil</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Payne%2C+P">Philip Payne</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Currently under review in Journal of Medical Informatics
                    Association (JAMIA). 6 figures, 3 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1090">[1090]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.03295"
                    title="Abstract">arXiv:2404.03295</a> (replaced) [<a href="/pdf/2404.03295"
                    title="Download PDF">pdf</a>, <a href="/format/2404.03295" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The power of a single Haar random state: constructing and
                    separating quantum pseudorandomness
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/quant-ph?searchtype=author&amp;query=Chen%2C+B">Boyang Chen</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Coladangelo%2C+A">Andrea Coladangelo</a>,
                    <a href="/search/quant-ph?searchtype=author&amp;query=Sattath%2C+O">Or Sattath</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics
                        (quant-ph)</span>; Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item1091">[1091]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.03304"
                    title="Abstract">arXiv:2404.03304</a> (replaced) [<a href="/pdf/2404.03304"
                    title="Download PDF">pdf</a>, <a href="/format/2404.03304" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Concept -- An Evaluation Protocol on Conversational
                    Recommender Systems with System-centric and User-centric Factors
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+C">Chen Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qin%2C+P">Peixin Qin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Y">Yang Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lei%2C+W">Wenqiang Lei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lv%2C+J">Jiancheng Lv</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chua%2C+T">Tat-Seng Chua</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 33 pages, 18 tables, and 10 figures. Our code is available
                    at <a href="https://github.com/huangzichun/Concept4CRS">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1092">[1092]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.04069"
                    title="Abstract">arXiv:2404.04069</a> (replaced) [<a href="/pdf/2404.04069"
                    title="Download PDF">pdf</a>, <a href="/format/2404.04069" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Bidirectional Human Interactive AI Framework for Social Robot
                    Navigation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Girgin%2C+T">Tuba Girgin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Girgin%2C+E">Emre Girgin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yildirim%2C+Y">Yigit Yildirim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ugur%2C+E">Emre Ugur</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Haklidir%2C+M">Mehmet Haklidir</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by Robot Trust for Symbiotic Societies (RTSS)
                    Workshop at ICRA 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1093">[1093]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.04244"
                    title="Abstract">arXiv:2404.04244</a> (replaced) [<a href="/pdf/2404.04244"
                    title="Download PDF">pdf</a>, <a href="/format/2404.04244" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fast Diffeomorphic Image Registration using Patch based Fully
                    Convolutional Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Jiong Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+S">Shuang Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+L">Li Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tan%2C+W">Wenxue Tan</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1094">[1094]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.04346"
                    title="Abstract">arXiv:2404.04346</a> (replaced) [<a href="/pdf/2404.04346"
                    title="Download PDF">pdf</a>, <a href="/format/2404.04346" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Koala: Key frame-conditioned long video-LLM
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tan%2C+R">Reuben Tan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+X">Ximeng Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+P">Ping Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+J">Jui-hsien Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deilamsalehy%2C+H">Hanieh Deilamsalehy</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Plummer%2C+B+A">Bryan A. Plummer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Russell%2C+B">Bryan Russell</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saenko%2C+K">Kate Saenko</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at CVPR 2024 as a poster highlight
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1095">[1095]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.04653"
                    title="Abstract">arXiv:2404.04653</a> (replaced) [<a href="/pdf/2404.04653"
                    title="Download PDF">pdf</a>, <a href="/format/2404.04653" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> HawkDrive: A Transformer-driven Visual Perception System for
                    Autonomous Driving in Night Scene
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Z">Ziang Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Perminov%2C+S">Stepan Perminov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Konenkov%2C+M">Mikhail Konenkov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tsetserukou%2C+D">Dzmitry Tsetserukou</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IEEE IV 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Robotics (cs.RO)

                </div>
            </div>
        </dd>
        <dt><a name="item1096">[1096]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.04956"
                    title="Abstract">arXiv:2404.04956</a> (replaced) [<a href="/pdf/2404.04956"
                    title="Download PDF">pdf</a>, <a href="/format/2404.04956" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Gaussian Shading: Provable Performance-Lossless Image
                    Watermarking for Diffusion Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Z">Zijin Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zeng%2C+K">Kai Zeng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K">Kejiang Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+H">Han Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Weiming Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+N">Nenghai Yu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 17 pages, 11 figures, accepted by CVPR 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item1097">[1097]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.05184"
                    title="Abstract">arXiv:2404.05184</a> (replaced) [<a href="/pdf/2404.05184"
                    title="Download PDF">pdf</a>, <a href="/format/2404.05184" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Predicting the Geothermal Gradient in Colombia: a Machine
                    Learning Approach
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/physics?searchtype=author&amp;query=Mej%C3%ADa-Fragoso%2C+J+C">Juan C.
                        Mejía-Fragoso</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Florez%2C+M+A">Manuel A. Florez</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Bernal-Olaya%2C+R">Rocío Bernal-Olaya</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This is the version we re-submitted to the journal after
                    addressing all the peer review requirements
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics
                        (physics.geo-ph)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1098">[1098]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.05468"
                    title="Abstract">arXiv:2404.05468</a> (replaced) [<a href="/pdf/2404.05468"
                    title="Download PDF">pdf</a>, <a href="/format/2404.05468" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mind-to-Image: Projecting Visual Mental Imagination of the
                    Brain from fMRI
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/q-bio?searchtype=author&amp;query=Caselles-Dupr%C3%A9%2C+H">Hugo
                        Caselles-Dupré</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Mellerio%2C+C">Charles Mellerio</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=H%C3%A9rent%2C+P">Paul Hérent</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Lopez-Persem%2C+A">Alizée Lopez-Persem</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=B%C3%A9ranger%2C+B">Benoit Béranger</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Soularue%2C+M">Mathieu Soularue</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Fautrel%2C+P">Pierre Fautrel</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Vernier%2C+G">Gauthier Vernier</a>,
                    <a href="/search/q-bio?searchtype=author&amp;query=Cord%2C+M">Matthieu Cord</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Pre-print to be updated. Work in progress
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition
                        (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1099">[1099]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.05696"
                    title="Abstract">arXiv:2404.05696</a> (replaced) [<a href="/pdf/2404.05696"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.05696" title="Download PostScript">ps</a>, <a
                    href="/format/2404.05696" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> BOLD v4: A Centralized Bioinformatics Platform for DNA-based
                    Biodiversity Data
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Ratnasingham%2C+S">Sujeevan Ratnasingham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+C">Catherine Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chan%2C+D">Dean Chan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Agda%2C+J">Jireh Agda</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Agda%2C+J">Josh Agda</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ballesteros-Mejia%2C+L">Liliana
                        Ballesteros-Mejia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boutou%2C+H+A">Hamza Ait Boutou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bastami%2C+Z+M+E">Zak Mohammad El Bastami</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+E">Eddie Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Manjunath%2C+R">Ramya Manjunath</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rea%2C+D">Dana Rea</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ho%2C+C">Chris Ho</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Telfer%2C+A">Angela Telfer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McKeowan%2C+J">Jaclyn McKeowan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rahulan%2C+M">Miduna Rahulan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Steinke%2C+C">Claudia Steinke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dorsheimer%2C+J">Justin Dorsheimer</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Milton%2C+M">Megan Milton</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hebert%2C+P+D+N">Paul D. N. Hebert</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>;
                    Quantitative Methods (q-bio.QM)

                </div>
            </div>
        </dd>
        <dt><a name="item1100">[1100]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.05717"
                    title="Abstract">arXiv:2404.05717</a> (replaced) [<a href="/pdf/2404.05717"
                    title="Download PDF">pdf</a>, <a href="/format/2404.05717" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SwapAnything: Enabling Arbitrary Object Swapping in
                    Personalized Visual Editing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+J">Jing Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yilin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+N">Nanxuan Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+W">Wei Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Q">Qing Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Z">Zhifei Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">He Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jianming Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jung%2C+H">HyunJoon Jung</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X+E">Xin Eric Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 18 pages, 16 figures, 3 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1101">[1101]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.06728"
                    title="Abstract">arXiv:2404.06728</a> (replaced) [<a href="/pdf/2404.06728"
                    title="Download PDF">pdf</a>, <a href="/format/2404.06728" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Data Efficient Framework for Learning Local Heuristics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Veerapaneni%2C+R">Rishi Veerapaneni</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Park%2C+J">Jonathan Park</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saleem%2C+M+S">Muhammad Suhail Saleem</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Likhachev%2C+M">Maxim Likhachev</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in the 17th International Symposium on
                    Combinatorial Search (SoCS 2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1102">[1102]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.06884"
                    title="Abstract">arXiv:2404.06884</a> (replaced) [<a href="/pdf/2404.06884"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.06884" title="Download PostScript">ps</a>, <a
                    href="/format/2404.06884" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Demand Private Coded Caching: the Two-File Case
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+Q">Qinyi Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+N">Nan Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kang%2C+W">Wei Kang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1103">[1103]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.07831"
                    title="Abstract">arXiv:2404.07831</a> (replaced) [<a href="/pdf/2404.07831"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.07831" title="Download PostScript">ps</a>, <a
                    href="/format/2404.07831" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Protected QR Code-based Anti-counterfeit System for
                    Pharmaceutical Manufacturing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Aulia%2C+M+M">Md Masruk Aulia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saha%2C+N">Nitol Saha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rahman%2C+M+M">Md. Mostafizur Rahman</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1104">[1104]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.08132"
                    title="Abstract">arXiv:2404.08132</a> (replaced) [<a href="/pdf/2404.08132"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.08132" title="Download PostScript">ps</a>, <a
                    href="/format/2404.08132" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Goppa Codes: Key to High Efficiency and Reliability in
                    Communications
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mosallaei%2C+B">Behrooz Mosallaei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghanbari%2C+F">Farzaneh Ghanbari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Farivar%2C+S">Sepideh Farivar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nourozi%2C+V">Vahid Nourozi</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> isnt complete
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; Algebraic Geometry (math.AG)

                </div>
            </div>
        </dd>
        <dt><a name="item1105">[1105]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.08472"
                    title="Abstract">arXiv:2404.08472</a> (replaced) [<a href="/pdf/2404.08472"
                    title="Download PDF">pdf</a>, <a href="/format/2404.08472" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TSLANet: Rethinking Transformers for Time Series
                    Representation Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Eldele%2C+E">Emadeldeen Eldele</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ragab%2C+M">Mohamed Ragab</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhenghua Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+M">Min Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaoli Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item1106">[1106]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.09491"
                    title="Abstract">arXiv:2404.09491</a> (replaced) [<a href="/pdf/2404.09491"
                    title="Download PDF">pdf</a>, <a href="/format/2404.09491" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Large Language Models Can Automatically Engineer Features for
                    Few-Shot Tabular Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+S">Sungwon Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yoon%2C+J">Jinsung Yoon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Arik%2C+S+O">Sercan O Arik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pfister%2C+T">Tomas Pfister</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted to ICML, 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1107">[1107]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.10346"
                    title="Abstract">arXiv:2404.10346</a> (replaced) [<a href="/pdf/2404.10346"
                    title="Download PDF">pdf</a>, <a href="/format/2404.10346" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Self-Explore to Avoid the Pit: Improving the Reasoning
                    Capabilities of Language Models with Fine-grained Rewards
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Hwang%2C+H">Hyeonbin Hwang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+D">Doyoung Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+S">Seungone Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+S">Seonghyeon Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Seo%2C+M">Minjoon Seo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Preprint Under Review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1108">[1108]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.10490"
                    title="Abstract">arXiv:2404.10490</a> (replaced) [<a href="/pdf/2404.10490"
                    title="Download PDF">pdf</a>, <a href="/format/2404.10490" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhancing Sign Language Teaching: A Mixed Reality Approach
                    for Immersive Learning and Multi-Dimensional Feedback
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wen%2C+H">Hongli Wen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Y">Yang Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Lin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ru%2C+X">Xudong Ru</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xingce Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Z">Zhongke Wu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 8 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1109">[1109]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.10616"
                    title="Abstract">arXiv:2404.10616</a> (replaced) [<a href="/pdf/2404.10616"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.10616" title="Download PostScript">ps</a>, <a
                    href="/format/2404.10616" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> One is all you need: Second-order Unification without
                    First-order Variables
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cerna%2C+D+M">David M. Cerna</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Parsert%2C+J">Julian Parsert</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Under review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1110">[1110]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.10861"
                    title="Abstract">arXiv:2404.10861</a> (replaced) [<a href="/pdf/2404.10861"
                    title="Download PDF">pdf</a>, <a href="/format/2404.10861" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Trackable Agent-based Evolution Models at Wafer Scale
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Moreno%2C+M+A">Matthew Andres Moreno</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+C">Connor Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dolson%2C+E">Emily Dolson</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zaman%2C+L">Luis Zaman</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

                </div>
            </div>
        </dd>
        <dt><a name="item1111">[1111]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.11054"
                    title="Abstract">arXiv:2404.11054</a> (replaced) [<a href="/pdf/2404.11054"
                    title="Download PDF">pdf</a>, <a href="/format/2404.11054" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multilateral Temporal-view Pyramid Transformer for Video
                    Inpainting Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Ying Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuezun Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+B">Bo Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jiaran Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+H">Huiyu Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+J">Junyu Dong</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1112">[1112]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.11565"
                    title="Abstract">arXiv:2404.11565</a> (replaced) [<a href="/pdf/2404.11565"
                    title="Download PDF">pdf</a>, <a href="/format/2404.11565" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MoA: Mixture-of-Attention for Subject-Context Disentanglement
                    in Personalized Image Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+K">Kuan-Chieh Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ostashev%2C+D">Daniil Ostashev</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yuwei Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tulyakov%2C+S">Sergey Tulyakov</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Aberman%2C+K">Kfir Aberman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Project Website: <a
                        href="https://snap-research.github.io/mixture-of-attention">this https URL</a>, Same as previous
                    version, only updated metadata because bib was missing an author name
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

                </div>
            </div>
        </dd>
        <dt><a name="item1113">[1113]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.11982"
                    title="Abstract">arXiv:2404.11982</a> (replaced) [<a href="/pdf/2404.11982"
                    title="Download PDF">pdf</a>, <a href="/format/2404.11982" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SIGformer: Sign-aware Graph Transformer for Recommendation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+S">Sirui Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jiawei Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+S">Sheng Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+B">Bohao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+S">Shen Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Su%2C+C">Chanfei Su</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yuqing Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Can Wang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by SIGIR2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1114">[1114]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.12135"
                    title="Abstract">arXiv:2404.12135</a> (replaced) [<a href="/pdf/2404.12135"
                    title="Download PDF">pdf</a>, <a href="/format/2404.12135" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> mABC: multi-Agent Blockchain-Inspired Collaboration for root
                    cause analysis in micro-services architecture
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+W">Wei Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+H">Hongcheng Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+J">Jian Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yi Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+C">Chaoran Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tian%2C+Z">Zhoujin Tian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+H">Hangyuan Ji</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhoujun Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+T">Tongliang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+T">Tieqiao Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+C">Chao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liang%2C+Y">Yi Liang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+X">Xu Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zheng%2C+L">Liangfan Zheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+B">Bo Zhang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems
                        (cs.MA)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing
                    (cs.DC)

                </div>
            </div>
        </dd>
        <dt><a name="item1115">[1115]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.12390"
                    title="Abstract">arXiv:2404.12390</a> (replaced) [<a href="/pdf/2404.12390"
                    title="Download PDF">pdf</a>, <a href="/format/2404.12390" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> BLINK: Multimodal Large Language Models Can See but Not
                    Perceive
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+X">Xingyu Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yushi Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bangzheng Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+Y">Yu Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">Haoyu Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+X">Xudong Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Roth%2C+D">Dan Roth</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Smith%2C+N+A">Noah A. Smith</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+W">Wei-Chiu Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Krishna%2C+R">Ranjay Krishna</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Multimodal Benchmark, Project Url: <a
                        href="https://zeyofu.github.io/blink/">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item1116">[1116]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.12678"
                    title="Abstract">arXiv:2404.12678</a> (replaced) [<a href="/e-print/2404.12678"
                    title="Download source">src</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Exploring Interactive Semantic Alignment for Efficient HOI
                    Detection with Vision-language Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+J">Jihao Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pan%2C+R">Renjie Pan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+H">Hua Yang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> There are issues with the experimental results
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1117">[1117]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.12725"
                    title="Abstract">arXiv:2404.12725</a> (replaced) [<a href="/pdf/2404.12725"
                    title="Download PDF">pdf</a>, <a href="/format/2404.12725" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Separate in the Speech Chain: Cross-Modal Conditional
                    Audio-Visual Target Speech Extraction
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mu%2C+Z">Zhaoxi Mu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+X">Xinyu Yang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM); Audio
                    and Speech Processing (eess.AS)

                </div>
            </div>
        </dd>
        <dt><a name="item1118">[1118]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.13179"
                    title="Abstract">arXiv:2404.13179</a> (replaced) [<a href="/pdf/2404.13179"
                    title="Download PDF">pdf</a>, <a href="/format/2404.13179" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> When Computing follows Vehicles: Decentralized Mobility-Aware
                    Resource Allocation for Edge-to-Cloud Continuum
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Nezami%2C+Z">Zeinab Nezami</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chaniotakis%2C+E">Emmanouil Chaniotakis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pournaras%2C+E">Evangelos Pournaras</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and
                        Cluster Computing (cs.DC)</span>; Multiagent Systems (cs.MA)

                </div>
            </div>
        </dd>
        <dt><a name="item1119">[1119]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.13288"
                    title="Abstract">arXiv:2404.13288</a> (replaced) [<a href="/pdf/2404.13288"
                    title="Download PDF">pdf</a>, <a href="/format/2404.13288" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PoseINN: Realtime Visual-based Pose Regression and
                    Localization with Invertible Neural Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zang%2C+Z">Zirui Zang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Amine%2C+A">Ahmad Amine</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mangharam%2C+R">Rahul Mangharam</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item1120">[1120]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.13624"
                    title="Abstract">arXiv:2404.13624</a> (replaced) [<a href="/pdf/2404.13624"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.13624" title="Download PostScript">ps</a>, <a
                    href="/format/2404.13624" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Necessary and Sufficient Conditions for Capacity-Achieving
                    Private Information Retrieval with Non-Colluding and Colluding Servers
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Miki%2C+A">Atsushi Miki</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Morishita%2C+Y">Yusuke Morishita</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matsushima%2C+T">Toshiyasu Matsushima</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 16 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1121">[1121]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.13733"
                    title="Abstract">arXiv:2404.13733</a> (replaced) [<a href="/pdf/2404.13733"
                    title="Download PDF">pdf</a>, <a href="/format/2404.13733" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Elucidating the Design Space of Dataset Condensation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shao%2C+S">Shitong Shao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+Z">Zikai Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+H">Huanran Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+Z">Zhiqiang Shen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item1122">[1122]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.13872"
                    title="Abstract">arXiv:2404.13872</a> (replaced) [<a href="/pdf/2404.13872"
                    title="Download PDF">pdf</a>, <a href="/format/2404.13872" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FreqBlender: Enhancing DeepFake Detection by Blending
                    Frequency Knowledge
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+H">Hanzhe Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuezun Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jiaran Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+B">Bin Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+J">Junyu Dong</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1123">[1123]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.13873"
                    title="Abstract">arXiv:2404.13873</a> (replaced) [<a href="/pdf/2404.13873"
                    title="Download PDF">pdf</a>, <a href="/format/2404.13873" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Texture-aware and Shape-guided Transformer for Sequential
                    DeepFake Detection
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yunfei Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yuezun Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jiaran Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+J">Junyu Dong</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1124">[1124]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.13904"
                    title="Abstract">arXiv:2404.13904</a> (replaced) [<a href="/pdf/2404.13904"
                    title="Download PDF">pdf</a>, <a href="/format/2404.13904" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Deep Regression Representation Learning with Topology
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Shihao Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=kawaguchi%2C+k">kenji kawaguchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yao%2C+A">Angela Yao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICML2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item1125">[1125]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.13945"
                    title="Abstract">arXiv:2404.13945</a> (replaced) [<a href="/pdf/2404.13945"
                    title="Download PDF">pdf</a>, <a href="/format/2404.13945" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> How do LLMs Support Deep Learning Testing? A Comprehensive
                    Study Through the Lens of Image Mutation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Liwen Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yuan%2C+Y">Yuanyuan Yuan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+A">Ao Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zongjie Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+P">Pingchuan Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+D">Daoyuan Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+S">Shuai Wang</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1126">[1126]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.14066"
                    title="Abstract">arXiv:2404.14066</a> (replaced) [<a href="/pdf/2404.14066"
                    title="Download PDF">pdf</a>, <a href="/format/2404.14066" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SHE-Net: Syntax-Hierarchy-Enhanced Text-Video Retrieval
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+X">Xuzheng Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+C">Chen Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+X">Xingning Dong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gan%2C+T">Tian Gan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+M">Ming Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+Q">Qingpei Guo</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

                </div>
            </div>
        </dd>
        <dt><a name="item1127">[1127]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.14146"
                    title="Abstract">arXiv:2404.14146</a> (replaced) [<a href="/pdf/2404.14146"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.14146" title="Download PostScript">ps</a>, <a
                    href="/format/2404.14146" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Physics-based reward driven image analysis in microscopy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cond-mat?searchtype=author&amp;query=Barakati%2C+K">Kamyar Barakati</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Yuan%2C+H">Hui Yuan</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Goyal%2C+A">Amit Goyal</a>,
                    <a href="/search/cond-mat?searchtype=author&amp;query=Kalinin%2C+S+V">Sergei V. Kalinin</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 4 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science
                        (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1128">[1128]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.14162"
                    title="Abstract">arXiv:2404.14162</a> (replaced) [<a href="/pdf/2404.14162"
                    title="Download PDF">pdf</a>, <a href="/format/2404.14162" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FLDM-VTON: Faithful Latent Diffusion Model for Virtual Try-on
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chenhui Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhihao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Z">Zhizhong Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+T">Taoran Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Q">Qi Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shan%2C+H">Hongming Shan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by IJCAI 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1129">[1129]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.14665"
                    title="Abstract">arXiv:2404.14665</a> (replaced) [<a href="/pdf/2404.14665"
                    title="Download PDF">pdf</a>, <a href="/format/2404.14665" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Illuminating the Unseen: Investigating the Context-induced
                    Harms in Behavioral Sensing
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Han Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Swain%2C+V+D">Vedant Das Swain</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+L">Leijie Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+N">Nan Gao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sheng%2C+Y">Yilun Sheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+X">Xuhai Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Salim%2C+F+D">Flora D. Salim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Saha%2C+K">Koustuv Saha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dey%2C+A+K">Anind K. Dey</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mankoff%2C+J">Jennifer Mankoff</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 26 pages, 8 tables, and 1 figure (excluding appendix)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1130">[1130]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.15001"
                    title="Abstract">arXiv:2404.15001</a> (replaced) [<a href="/pdf/2404.15001"
                    title="Download PDF">pdf</a>, <a href="/format/2404.15001" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unknown Object Grasping for Assistive Robotics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Miller%2C+E">Elle Miller</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Durner%2C+M">Maximilian Durner</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Humt%2C+M">Matthias Humt</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Quere%2C+G">Gabriel Quere</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Boerdijk%2C+W">Wout Boerdijk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sundaram%2C+A+M">Ashok M. Sundaram</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Stulp%2C+F">Freek Stulp</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Vogel%2C+J">Jorn Vogel</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1131">[1131]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.15135"
                    title="Abstract">arXiv:2404.15135</a> (replaced) [<a href="/pdf/2404.15135"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.15135" title="Download PostScript">ps</a>, <a
                    href="/format/2404.15135" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Linear-Function Correcting Codes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Premlal%2C+R">Rohit Premlal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Rajan%2C+B+S">B. Sundar Rajan</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Some minor errors corrected. 11 pages and 3 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1132">[1132]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.15777"
                    title="Abstract">arXiv:2404.15777</a> (replaced) [<a href="/pdf/2404.15777"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.15777" title="Download PostScript">ps</a>, <a
                    href="/format/2404.15777" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Comprehensive Survey on Evaluating Large Language Model
                    Applications in the Medical Industry
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yining Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+K">Keke Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Meilian Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 28 pages
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1133">[1133]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.15855"
                    title="Abstract">arXiv:2404.15855</a> (replaced) [<a href="/pdf/2404.15855"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.15855" title="Download PostScript">ps</a>, <a
                    href="/format/2404.15855" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Taking Bi-Intuitionistic Logic First-Order: A Proof-Theoretic
                    Investigation via Polytree Sequents
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lyon%2C+T+S">Tim S. Lyon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shillito%2C+I">Ian Shillito</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tiu%2C+A">Alwen Tiu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science
                        (cs.LO)</span>; Logic (math.LO)

                </div>
            </div>
        </dd>
        <dt><a name="item1134">[1134]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.16471"
                    title="Abstract">arXiv:2404.16471</a> (replaced) [<a href="/pdf/2404.16471"
                    title="Download PDF">pdf</a>, <a href="/format/2404.16471" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> COBRA - COnfidence score Based on shape Regression Analysis
                    for method-independent quality assessment of object pose estimation from single images
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sapoutzoglou%2C+P">Panagiotis Sapoutzoglou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tzintanos%2C+G+G">Georgios Giapitzakis
                        Tzintanos</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Terzakis%2C+G">George Terzakis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pateraki%2C+M">Maria Pateraki</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1135">[1135]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.16663"
                    title="Abstract">arXiv:2404.16663</a> (replaced) [<a href="/pdf/2404.16663"
                    title="Download PDF">pdf</a>, <a href="/format/2404.16663" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Formal Specification, Assessment, and Enforcement of Fairness
                    for Generative AIs
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Cheng%2C+C">Chih-Hong Cheng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Changshun Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ruess%2C+H">Harald Ruess</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xingyu Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bensalem%2C+S">Saddek Bensalem</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Logic in
                    Computer Science (cs.LO); Software Engineering (cs.SE)

                </div>
            </div>
        </dd>
        <dt><a name="item1136">[1136]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.16706"
                    title="Abstract">arXiv:2404.16706</a> (replaced) [<a href="/pdf/2404.16706"
                    title="Download PDF">pdf</a>, <a href="/format/2404.16706" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient and Near-Optimal Noise Generation for Streaming
                    Differential Privacy
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Dvijotham%2C+K">Krishnamurthy Dvijotham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=McMahan%2C+H+B">H. Brendan McMahan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pillutla%2C+K">Krishna Pillutla</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Steinke%2C+T">Thomas Steinke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Thakurta%2C+A">Abhradeep Thakurta</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and
                        Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR);
                    Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1137">[1137]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.16895"
                    title="Abstract">arXiv:2404.16895</a> (replaced) [<a href="/pdf/2404.16895"
                    title="Download PDF">pdf</a>, <a href="/format/2404.16895" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> QuERLoc: Towards Next-Generation Localization with
                    Quantum-Enhanced Ranging
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+E">Entong He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+Y">Yuxiang Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+C">Chenshu Wu</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies
                        (cs.ET)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1138">[1138]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.17465"
                    title="Abstract">arXiv:2404.17465</a> (replaced) [<a href="/pdf/2404.17465"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.17465" title="Download PostScript">ps</a>, <a
                    href="/format/2404.17465" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Fast Abstracts and Student Forum Proceedings -- EDCC 2024 --
                    19th European Dependable Computing Conference
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bernardi%2C+S">Simona Bernardi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zoppi%2C+T">Tommaso Zoppi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Computers and Society (cs.CY); Distributed, Parallel, and Cluster Computing
                    (cs.DC); Machine Learning (cs.LG); Robotics (cs.RO)

                </div>
            </div>
        </dd>
        <dt><a name="item1139">[1139]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.17723"
                    title="Abstract">arXiv:2404.17723</a> (replaced) [<a href="/pdf/2404.17723"
                    title="Download PDF">pdf</a>, <a href="/format/2404.17723" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Retrieval-Augmented Generation with Knowledge Graphs for
                    Customer Service Question Answering
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+Z">Zhentao Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cruz%2C+M+J">Mark Jerome Cruz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guevara%2C+M">Matthew Guevara</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+T">Tie Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deshpande%2C+M">Manasi Deshpande</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xiaofeng Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zheng Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval
                        (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine
                    Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1140">[1140]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.17781"
                    title="Abstract">arXiv:2404.17781</a> (replaced) [<a href="/pdf/2404.17781"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.17781" title="Download PostScript">ps</a>, <a
                    href="/format/2404.17781" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Value-Oriented Investigation of Photoshop's Generative Fill
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Swift%2C+I+P">Ian P. Swift</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chattopadhyay%2C+D">Debaleena Chattopadhyay</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1141">[1141]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18030"
                    title="Abstract">arXiv:2404.18030</a> (replaced) [<a href="/pdf/2404.18030"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18030" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Parallel Adaptive Anisotropic Meshing on cc-NUMA Machines
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tsolakis%2C+C">Christos Tsolakis</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chrisochoides%2C+N">Nikos Chrisochoides</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry
                        (cs.CG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1142">[1142]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18074"
                    title="Abstract">arXiv:2404.18074</a> (replaced) [<a href="/pdf/2404.18074"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18074" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MMAC-Copilot: Multi-modal Agent Collaboration Operating
                    System Copilot
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+Z">Zirui Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yaohang Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+M">Meng Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Zhenhao Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+Z">Zecheng Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+Y">Yuan Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Ling Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> In processing
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Human-Computer Interaction (cs.HC)

                </div>
            </div>
        </dd>
        <dt><a name="item1143">[1143]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18253"
                    title="Abstract">arXiv:2404.18253</a> (replaced) [<a href="/pdf/2404.18253"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18253" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Efficient Remote Sensing with Harmonized Transfer Learning
                    and Modality Alignment
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+T">Tengjun Huang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by the Twelfth International Conference on
                    Learning Representations (ICLR) Workshop
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1144">[1144]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18255"
                    title="Abstract">arXiv:2404.18255</a> (replaced) [<a href="/pdf/2404.18255"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18255" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> PatentGPT: A Large Language Model for Intellectual Property
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Bai%2C+Z">Zilong Bai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+R">Ruiji Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Linqing Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cai%2C+Q">Qijun Cai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhong%2C+Y">Yuan Zhong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Cong Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+Y">Yan Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fang%2C+J">Jie Fang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+J">Jing Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Weikuan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+L">Lizhi Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hua%2C+H">Haoran Hua</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiu%2C+T">Tian Qiu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+C">Chaochao Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+C">Cheng Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+J">Jianping Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yixin Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+Y">Yubin Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+M">Meng Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Haowen Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+P">Peng Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+L">Licong Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bian%2C+F">Fu Bian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gu%2C+X">Xiaolong Gu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Lisha Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+W">Weilei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tu%2C+C">Changyang Tu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 19 pages, 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1145">[1145]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18311"
                    title="Abstract">arXiv:2404.18311</a> (replaced) [<a href="/pdf/2404.18311"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.18311" title="Download PostScript">ps</a>, <a
                    href="/format/2404.18311" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards Incremental Learning in Large Language Models: A
                    Critical Review
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jovanovic%2C+M">Mladjan Jovanovic</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Voss%2C+P">Peter Voss</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

                </div>
            </div>
        </dd>
        <dt><a name="item1146">[1146]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18316"
                    title="Abstract">arXiv:2404.18316</a> (replaced) [<a href="/pdf/2404.18316"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18316" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Position paper: Do not explain (vision models) without
                    context
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tomaszewska%2C+P">Paulina Tomaszewska</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Biecek%2C+P">Przemysław Biecek</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1147">[1147]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18321"
                    title="Abstract">arXiv:2404.18321</a> (replaced) [<a href="/pdf/2404.18321"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18321" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Riemannian Optimization for Active Mapping with Robot Teams
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Asgharivaskasi%2C+A">Arash Asgharivaskasi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Girke%2C+F">Fritz Girke</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Atanasov%2C+N">Nikolay Atanasov</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1148">[1148]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18405"
                    title="Abstract">arXiv:2404.18405</a> (replaced) [<a href="/pdf/2404.18405"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.18405" title="Download PostScript">ps</a>, <a
                    href="/format/2404.18405" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Understanding and Shaping Human-Technology Assemblages in the
                    Age of Generative AI
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Andres%2C+J">Josh Andres</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Danta%2C+C">Chris Danta</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bianchi%2C+A">Andrea Bianchi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hong%2C+S">Sungyeon Hong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Z">Zhuying Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sandoval%2C+E+B">Eduardo B. Sandoval</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Martin%2C+C">Charles Martin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cooper%2C+N">Ned Cooper</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction
                        (cs.HC)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1149">[1149]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18423"
                    title="Abstract">arXiv:2404.18423</a> (replaced) [<a href="/pdf/2404.18423"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18423" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unsupervised Dynamics Prediction with Object-Centric
                    Kinematics
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+Y">Yeon-Ji Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Choi%2C+S">Suhyung Choi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jaein Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kim%2C+J">Jin-Hwa Kim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+B">Byoung-Tak Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 15 pages, 6 figures, 4 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1150">[1150]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18530"
                    title="Abstract">arXiv:2404.18530</a> (replaced) [<a href="/pdf/2404.18530"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18530" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Predicting PDEs Fast and Efficiently with Equivariant Extreme
                    Learning Machines
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Harder%2C+H">Hans Harder</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peitz%2C+S">Sebastian Peitz</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1151">[1151]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18654"
                    title="Abstract">arXiv:2404.18654</a> (replaced) [<a href="/pdf/2404.18654"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18654" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Scoping Review on Simulation-based Design Optimization in
                    Marine Engineering: Trends, Best Practices, and Gaps
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Serani%2C+A">Andrea Serani</a>,
                    <a href="/search/math?searchtype=author&amp;query=Scholcz%2C+T">Thomas Scholcz</a>,
                    <a href="/search/math?searchtype=author&amp;query=Vanzi%2C+V">Valentina Vanzi</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)

                </div>
            </div>
        </dd>
        <dt><a name="item1152">[1152]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18909"
                    title="Abstract">arXiv:2404.18909</a> (replaced) [<a href="/pdf/2404.18909"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18909" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Sample-Efficient Robust Multi-Agent Reinforcement Learning in
                    the Face of Environmental Uncertainty
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+L">Laixi Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mazumdar%2C+E">Eric Mazumdar</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chi%2C+Y">Yuejie Chi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wierman%2C+A">Adam Wierman</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by Conference on Neural Information Processing
                    Systems (NeurIPS), 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Multiagent Systems (cs.MA); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item1153">[1153]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.18947"
                    title="Abstract">arXiv:2404.18947</a> (replaced) [<a href="/pdf/2404.18947"
                    title="Download PDF">pdf</a>, <a href="/format/2404.18947" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Multimodal Fusion on Low-quality Data: A Comprehensive Survey
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+Q">Qingyang Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+Y">Yake Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Han%2C+Z">Zongbo Han</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fu%2C+H">Huazhu Fu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Peng%2C+X">Xi Peng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+C">Cheng Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Q">Qinghua Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Cai Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wen%2C+J">Jie Wen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+D">Di Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Changqing Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Feel free to comment on our manuscript:
                    qingyangzhang@tju.edu.cn
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1154">[1154]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.19028"
                    title="Abstract">arXiv:2404.19028</a> (replaced) [<a href="/pdf/2404.19028"
                    title="Download PDF">pdf</a>, <a href="/format/2404.19028" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Adaptive Regulated Sparsity Promoting Approach for
                    Data-Driven Modeling and Control of Grid-Connected Solar Photovoltaic Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Zhang%2C+Z">Zhongtian Zhang</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Khazaei%2C+J">Javad Khazaei</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Blum%2C+R+S">Rick S. Blum</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control
                        (eess.SY)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1155">[1155]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.19500"
                    title="Abstract">arXiv:2404.19500</a> (replaced) [<a href="/pdf/2404.19500"
                    title="Download PDF">pdf</a>, <a href="/format/2404.19500" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Towards Real-world Video Face Restoration: A New Benchmark
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Z">Ziyan Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=He%2C+J">Jingwen He</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lin%2C+X">Xinqi Lin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Qiao%2C+Y">Yu Qiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dong%2C+C">Chao Dong</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Project page: <a
                        href="https://ziyannchen.github.io/projects/VFRxBenchmark/">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Image and Video
                    Processing (eess.IV)

                </div>
            </div>
        </dd>
        <dt><a name="item1156">[1156]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.19556"
                    title="Abstract">arXiv:2404.19556</a> (replaced) [<a href="/pdf/2404.19556"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.19556" title="Download PostScript">ps</a>, <a
                    href="/format/2404.19556" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A logarithmic approximation of linearly-ordered colourings
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=H%C3%A5stad%2C+J">Johan Håstad</a>,
                    <a href="/search/math?searchtype=author&amp;query=Martinsson%2C+B">Björn Martinsson</a>,
                    <a href="/search/math?searchtype=author&amp;query=Nakajima%2C+T">Tamio-Vesa Nakajima</a>,
                    <a href="/search/math?searchtype=author&amp;query=%C5%BDivn%C3%BD%2C+S">Stanislav Živný</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> This paper is a merger of independent work by H{\aa}stad
                    and Martinsson, and by Nakajima and \v{Z}ivn\'y respectively
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics
                        (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

                </div>
            </div>
        </dd>
        <dt><a name="item1157">[1157]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.19652"
                    title="Abstract">arXiv:2404.19652</a> (replaced) [<a href="/pdf/2404.19652"
                    title="Download PDF">pdf</a>, <a href="/format/2404.19652" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> VimTS: A Unified Video and Image Text Spotter for Enhancing
                    the Cross-domain Generalization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yuliang Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+M">Mingxin Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yan%2C+H">Hao Yan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+L">Linger Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+W">Weijia Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+H">Hao Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shen%2C+C">Chunhua Shen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jin%2C+L">Lianwen Jin</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bai%2C+X">Xiang Bai</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1158">[1158]</a>&nbsp; <span class="list-identifier"><a href="/abs/2404.19713"
                    title="Abstract">arXiv:2404.19713</a> (replaced) [<a href="/pdf/2404.19713"
                    title="Download PDF">pdf</a>, <a href="/ps/2404.19713" title="Download PostScript">ps</a>, <a
                    href="/format/2404.19713" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Automated Generation of High-Quality Medical Simulation
                    Scenarios Through Integration of Semi-Structured Data and Large Language Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sumpter%2C+S">Scott Sumpter</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 22 pages but 12 are appendices which are examples of the
                    main text. 3 figures, 4 tables
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1159">[1159]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00136"
                    title="Abstract">arXiv:2405.00136</a> (replaced) [<a href="/pdf/2405.00136"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00136" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Data-Driven Permissible Safe Control with Barrier
                    Certificates
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mazouz%2C+R">Rayan Mazouz</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Skovbekk%2C+J">John Skovbekk</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mathiesen%2C+F+B">Frederik Baymler Mathiesen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Frew%2C+E">Eric Frew</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Laurenti%2C+L">Luca Laurenti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lahijanian%2C+M">Morteza Lahijanian</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

                </div>
            </div>
        </dd>
        <dt><a name="item1160">[1160]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00181"
                    title="Abstract">arXiv:2405.00181</a> (replaced) [<a href="/pdf/2405.00181"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00181" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Uncovering What, Why and How: A Comprehensive Benchmark for
                    Causation Understanding of Video Anomaly
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Du%2C+H">Hang Du</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+S">Sicheng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+B">Binzhu Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Nan%2C+G">Guoshun Nan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiayang Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+J">Junrui Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Hangyu Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Leng%2C+S">Sicong Leng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+J">Jiangming Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Fan%2C+H">Hehe Fan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+D">Dajiu Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Feng%2C+J">Jing Feng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+L">Linli Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+C">Can Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xuhuan Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+H">Hao Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+J">Jianhang Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cui%2C+Q">Qimei Cui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tao%2C+X">Xiaofeng Tao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted in CVPR2024, Codebase: <a
                        href="https://github.com/fesvhtr/CUVA">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1161">[1161]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00316"
                    title="Abstract">arXiv:2405.00316</a> (replaced) [<a href="/pdf/2405.00316"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00316" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Enhance Planning with Physics-informed Safety Controller for
                    End-to-end Autonomous Driving
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+H">Hang Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+H">Haichao Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+H">Hongliang Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+D">Dan Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+J">Jun Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ji%2C+Y">Yiding Ji</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Systems and Control (eess.SY)

                </div>
            </div>
        </dd>
        <dt><a name="item1162">[1162]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00344"
                    title="Abstract">arXiv:2405.00344</a> (replaced) [<a href="/pdf/2405.00344"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00344" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Expert Insight-Enhanced Follow-up Chest X-Ray Summary
                    Generation
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Z">Zhichuan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lee%2C+K">Kinhei Lee</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Deng%2C+Q">Qiao Deng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=So%2C+T+Y">Tiffany Y. So</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chiu%2C+W+H">Wan Hang Chiu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hui%2C+Y+Y">Yeung Yu Hui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+B">Bingjing Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hui%2C+E+S">Edward S. Hui</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> accepted by 22nd International Conference on Artificial
                    Intelligence in medicine (AIME2024)
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1163">[1163]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00349"
                    title="Abstract">arXiv:2405.00349</a> (replaced) [<a href="/pdf/2405.00349"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00349" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A Self-explaining Neural Architecture for Generalizable
                    Concept Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sinha%2C+S">Sanchit Sinha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xiong%2C+G">Guangzhi Xiong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+A">Aidong Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> IJCAI 2024. 16 pages (7 main content, 2 references, 7
                    Appendix) Code available at <a href="https://github.com/sanchit97/secl">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1164">[1164]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00712"
                    title="Abstract">arXiv:2405.00712</a> (replaced) [<a href="/pdf/2405.00712"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00712" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SoK: Behind the Accuracy of Complex Human Activity
                    Recognition Using Deep Learning
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Nguyen%2C+D">Duc-Anh Nguyen</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Le-Khac%2C+N">Nhien-An Le-Khac</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1165">[1165]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00727"
                    title="Abstract">arXiv:2405.00727</a> (replaced) [<a href="/pdf/2405.00727"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00727" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Generalised envelope spectrum-based signal-to-noise
                    objectives: Formulation, optimisation and application for gear fault detection under time-varying
                    speed conditions
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Schmidt%2C+S">Stephan Schmidt</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Wilke%2C+D+N">Daniel N. Wilke</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Gryllias%2C+K+C">Konstantinos C. Gryllias</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 27 pages, 15 figures, tables 1, submitted MSSP review
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing
                        (eess.SP)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

                </div>
            </div>
        </dd>
        <dt><a name="item1166">[1166]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00740"
                    title="Abstract">arXiv:2405.00740</a> (replaced) [<a href="/pdf/2405.00740"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00740" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Modeling Caption Diversity in Contrastive Vision-Language
                    Pretraining
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lavoie%2C+S">Samuel Lavoie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kirichenko%2C+P">Polina Kirichenko</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ibrahim%2C+M">Mark Ibrahim</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Assran%2C+M">Mahmoud Assran</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wildon%2C+A+G">Andrew Gordon Wildon</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Courville%2C+A">Aaron Courville</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ballas%2C+N">Nicolas Ballas</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 8 figures, 7 tables, to be published at ICML2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL);
                    Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1167">[1167]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00801"
                    title="Abstract">arXiv:2405.00801</a> (replaced) [<a href="/pdf/2405.00801"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.00801" title="Download PostScript">ps</a>, <a
                    href="/format/2405.00801" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> "Ask Me Anything": How Comcast Uses LLMs to Assist Agents in
                    Real Time
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Rome%2C+S">Scott Rome</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+T">Tianwen Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+R">Raphael Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+L">Luwei Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ture%2C+F">Ferhan Ture</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1168">[1168]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00900"
                    title="Abstract">arXiv:2405.00900</a> (replaced) [<a href="/pdf/2405.00900"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00900" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LidaRF: Delving into Lidar for Neural Radiance Field on
                    Street Scenes
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+S">Shanlin Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhuang%2C+B">Bingbing Zhuang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+Z">Ziyu Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liu%2C+B">Buyu Liu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+X">Xiaohui Xie</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chandraker%2C+M">Manmohan Chandraker</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> CVPR2024 Highlights
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1169">[1169]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.00914"
                    title="Abstract">arXiv:2405.00914</a> (replaced) [<a href="/pdf/2405.00914"
                    title="Download PDF">pdf</a>, <a href="/format/2405.00914" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Accelerated Fully First-Order Methods for Bilevel and Minimax
                    Optimization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/math?searchtype=author&amp;query=Li%2C+C+J">Chris Junchi Li</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Minor typographical updates. arXiv admin note: text
                    overlap with <a href="/abs/2307.00126">arXiv:2307.00126</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control
                        (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item1170">[1170]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01029"
                    title="Abstract">arXiv:2405.01029</a> (replaced) [<a href="/pdf/2405.01029"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01029" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> MVMoE: Multi-Task Vehicle Routing Solver with
                    Mixture-of-Experts
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhou%2C+J">Jianan Zhou</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cao%2C+Z">Zhiguang Cao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+Y">Yaoxin Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Song%2C+W">Wen Song</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ma%2C+Y">Yining Ma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jie Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+C">Chi Xu</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence
                        (cs.AI)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1171">[1171]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01066"
                    title="Abstract">arXiv:2405.01066</a> (replaced) [<a href="/pdf/2405.01066"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01066" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> HandSSCA: 3D Hand Mesh Reconstruction with State Space
                    Channel Attention from RGB images
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jiao%2C+Z">Zixun Jiao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+X">Xihan Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gao%2C+Q">Quanli Gao</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 12 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

                </div>
            </div>
        </dd>
        <dt><a name="item1172">[1172]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01103"
                    title="Abstract">arXiv:2405.01103</a> (replaced) [<a href="/pdf/2405.01103"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01103" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> LLM Security Guard for Code
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Kavian%2C+A">Arya Kavian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kallehbasti%2C+M+M+P">Mohammad Mehdi Pourhashem
                        Kallehbasti</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kazemi%2C+S">Sajjad Kazemi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Firouzi%2C+E">Ehsan Firouzi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghafari%2C+M">Mohammad Ghafari</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> SECUTE, EASE 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>; Cryptography and Security (cs.CR)

                </div>
            </div>
        </dd>
        <dt><a name="item1173">[1173]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01111"
                    title="Abstract">arXiv:2405.01111</a> (replaced) [<a href="/pdf/2405.01111"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01111" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Mining REST APIs for Potential Mass Assignment
                    Vulnerabilities
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Mazidi%2C+A">Arash Mazidi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Corradini%2C+D">Davide Corradini</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ghafari%2C+M">Mohammad Ghafari</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> EASE 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1174">[1174]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01196"
                    title="Abstract">arXiv:2405.01196</a> (replaced) [<a href="/pdf/2405.01196"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01196" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Decoupling Feature Extraction and Classification Layers for
                    Calibrated Neural Networks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Jordahn%2C+M">Mikkel Jordahn</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Olmos%2C+P+M">Pablo M. Olmos</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Proceedings of the 41 st International Conference on
                    Machine Learning (ICML) 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Machine Learning (stat.ML)

                </div>
            </div>
        </dd>
        <dt><a name="item1175">[1175]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01242"
                    title="Abstract">arXiv:2405.01242</a> (replaced) [<a href="/pdf/2405.01242"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01242" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> TRAMBA: A Hybrid Transformer and Mamba Architecture for
                    Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable
                    Platforms
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Sui%2C+Y">Yueyuan Sui</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhao%2C+M">Minghui Zhao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+J">Junxi Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jiang%2C+X">Xiaofan Jiang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+S">Stephen Xia</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

                </div>
            </div>
        </dd>
        <dt><a name="item1176">[1176]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01460"
                    title="Abstract">arXiv:2405.01460</a> (replaced) [<a href="/pdf/2405.01460"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01460" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Purify Unlearnable Examples via Rate-Constrained Variational
                    Autoencoders
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+Y">Yi Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+Y">Yufei Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xia%2C+S">Song Xia</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yang%2C+W">Wenhan Yang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lu%2C+S">Shijian Lu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Tan%2C+Y">Yap-Peng Tan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kot%2C+A+C">Alex C. Kot</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted by ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition
                    (cs.CV); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1177">[1177]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01491"
                    title="Abstract">arXiv:2405.01491</a> (replaced) [<a href="/pdf/2405.01491"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01491" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> FeNNol: an Efficient and Flexible Library for Building
                    Force-field-enhanced Neural Network Potentials
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/physics?searchtype=author&amp;query=Pl%C3%A9%2C+T">Thomas Plé</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Adjoua%2C+O">Olivier Adjoua</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Lagard%C3%A8re%2C+L">Louis Lagardère</a>,
                    <a href="/search/physics?searchtype=author&amp;query=Piquemal%2C+J">Jean-Philip Piquemal</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics
                        (physics.chem-ph)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1178">[1178]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01510"
                    title="Abstract">arXiv:2405.01510</a> (replaced) [<a href="/pdf/2405.01510"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01510" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Reverse Influential Community Search Over Social Networks
                    (Technical Report)
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Wen%2C+Q">Qi Wen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+N">Nan Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ye%2C+Y">Yutong Ye</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Lian%2C+X">Xiang Lian</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+M">Mingsong Chen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information
                        Networks (cs.SI)</span>; Databases (cs.DB)

                </div>
            </div>
        </dd>
        <dt><a name="item1179">[1179]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01555"
                    title="Abstract">arXiv:2405.01555</a> (replaced) [<a href="/pdf/2405.01555"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.01555" title="Download PostScript">ps</a>, <a
                    href="/format/2405.01555" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Digital Twin-Empowered Task Assignment in Aerial MEC Network:
                    A Resource Coalition Cooperation Approach with Generative Model
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tang%2C+X">Xin Tang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Q">Qian Chen</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+R">Rong Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+X">Xiaohuan Li</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet
                        Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1180">[1180]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01558"
                    title="Abstract">arXiv:2405.01558</a> (replaced) [<a href="/pdf/2405.01558"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01558" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Configurable Learned Holography
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhan%2C+Y">Yicheng Zhan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shi%2C+L">Liang Shi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matusik%2C+W">Wojciech Matusik</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qi Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ak%C5%9Fit%2C+K">Kaan Akşit</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG); Image and Video
                    Processing (eess.IV); Optics (physics.optics)

                </div>
            </div>
        </dd>
        <dt><a name="item1181">[1181]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01673"
                    title="Abstract">arXiv:2405.01673</a> (replaced) [<a href="/pdf/2405.01673"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01673" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> ShadowNav: Autonomous Global Localization for Lunar
                    Navigation in Darkness
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Atha%2C+D">Deegan Atha</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Swan%2C+R+M">R. Michael Swan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cauligi%2C+A">Abhishek Cauligi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bettens%2C+A">Anne Bettens</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Goh%2C+E">Edwin Goh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Kogan%2C+D">Dima Kogan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Matthies%2C+L">Larry Matthies</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Ono%2C+M">Masahiro Ono</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 21 pages, 13 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>;
                    Computer Vision and Pattern Recognition (cs.CV)

                </div>
            </div>
        </dd>
        <dt><a name="item1182">[1182]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01699"
                    title="Abstract">arXiv:2405.01699</a> (replaced) [<a href="/pdf/2405.01699"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01699" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SOAR: Advancements in Small Body Object Detection for Aerial
                    Imagery Using State Space Models and Programmable Gradients
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Verma%2C+T">Tushar Verma</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singh%2C+J">Jyotsna Singh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bhartari%2C+Y">Yash Bhartari</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Jarwal%2C+R">Rishi Jarwal</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singh%2C+S">Suraj Singh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Singh%2C+S">Shubhkarman Singh</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 7 pages, 5 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1183">[1183]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01719"
                    title="Abstract">arXiv:2405.01719</a> (replaced) [<a href="/pdf/2405.01719"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01719" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Inherent Trade-Offs between Diversity and Stability in
                    Multi-Task Benchmarks
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+G">Guanhua Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hardt%2C+M">Moritz Hardt</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> To be published in ICML 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1184">[1184]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01726"
                    title="Abstract">arXiv:2405.01726</a> (replaced) [<a href="/pdf/2405.01726"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.01726" title="Download PostScript">ps</a>, <a
                    href="/format/2405.01726" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> SSUMamba: Spatial-Spectral Selective State Space Model for
                    Hyperspectral Image Denoising
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/eess?searchtype=author&amp;query=Fu%2C+G">Guanyiman Fu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Xiong%2C+F">Fengchao Xiong</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Lu%2C+J">Jianfeng Lu</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Zhou%2C+J">Jun Zhou</a>,
                    <a href="/search/eess?searchtype=author&amp;query=Qian%2C+Y">Yuntao Qian</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing
                        (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1185">[1185]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01765"
                    title="Abstract">arXiv:2405.01765</a> (replaced) [<a href="/pdf/2405.01765"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01765" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Early years of Biased Random-Key Genetic Algorithms: A
                    systematic review
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Londe%2C+M+A">Mariana A. Londe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Pessoa%2C+L+S">Luciana S. Pessoa</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Andrade%2C+C+E">Cartlos E. Andrade</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Resende%2C+M+G+C">Mauricio G.C. Resende</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 24 pages, 9 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary
                        Computing (cs.NE)</span>; Optimization and Control (math.OC)

                </div>
            </div>
        </dd>
        <dt><a name="item1186">[1186]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01775"
                    title="Abstract">arXiv:2405.01775</a> (replaced) [<a href="/pdf/2405.01775"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01775" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Torch2Chip: An End-to-end Customizable Deep Neural Network
                    Compression and Deployment Toolkit for Prototype Hardware Accelerator Design
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Meng%2C+J">Jian Meng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Liao%2C+Y">Yuan Liao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Anupreetham%2C+A">Anupreetham Anupreetham</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hasssan%2C+A">Ahmed Hasssan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Yu%2C+S">Shixing Yu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Suh%2C+H">Han-sok Suh</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+X">Xiaofeng Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Seo%2C+J">Jae-sun Seo</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted for publication at MLSys 2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture
                        (cs.AR)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1187">[1187]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01798"
                    title="Abstract">arXiv:2405.01798</a> (replaced) [<a href="/pdf/2405.01798"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01798" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> The Economy and Public Diplomacy: An Analysis of RT's
                    Economic Content and Context on Facebook
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Lokmanoglu%2C+A+D">Ayse D. Lokmanoglu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Winkler%2C+C+K">Carol K. Winkler</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Damanhoury%2C+K+E">Kareem El Damanhoury</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Massignan%2C+V">Virginia Massignan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Villa-Turek%2C+E">Esteban Villa-Turek</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+K+A">Keyu Alexander Chen</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 14 pages, 6 figures
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory
                        (cs.IT)</span>; General Economics (econ.GN)

                </div>
            </div>
        </dd>
        <dt><a name="item1188">[1188]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01803"
                    title="Abstract">arXiv:2405.01803</a> (replaced) [<a href="/pdf/2405.01803"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01803" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> How to Gain Commit Rights in Modern Top Open Source
                    Communities?
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Tan%2C+X">Xin Tan</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Gong%2C+Y">Yan Gong</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Huang%2C+G">Geyu Huang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+H">Haohua Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+L">Li Zhang</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 23 pages,5 figures,FSE 2024
                </div>
                <div class="list-journal-ref">
                    <span class="descriptor">Journal-ref:</span> Proceedings of the ACM on Software Engineering (PACMSE)
                    Issue FSE
                    2024
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering
                        (cs.SE)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1189">[1189]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01843"
                    title="Abstract">arXiv:2405.01843</a> (replaced) [<a href="/pdf/2405.01843"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.01843" title="Download PostScript">ps</a>, <a
                    href="/format/2405.01843" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Closing the Gap: Achieving Global Convergence (Last Iterate)
                    of Actor-Critic under Markovian Sampling with Neural Network Parametrization
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Gaur%2C+M">Mudit Gaur</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Bedi%2C+A+S">Amrit Singh Bedi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+D">Di Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Aggarwal%2C+V">Vaneet Aggarwal</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> Accepted at ICML 2024. This is a revised version of <a
                        href="/abs/2306.10486">arXiv:2306.10486</a>, where we have gone from finite action space to
                    continuous action space, from average iterate convergence to last iterate convergence and from <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-389-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2489"
                                style="width: 1.738em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.417em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1001.42em, 1.224em, -999.997em); top: -1.025em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2490"><span class="msubsup"
                                                id="MathJax-Span-2491"><span
                                                    style="display: inline-block; position: relative; width: 1.417em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.345em, 1000.39em, 4.181em, -999.997em); top: -3.981em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2492"
                                                            style="font-family: MathJax_Math-italic;">ϵ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.988em;"></span></span><span
                                                        style="position: absolute; top: -4.367em; left: 0.389em;"><span
                                                            class="texatom" id="MathJax-Span-2493"><span class="mrow"
                                                                id="MathJax-Span-2494"><span class="mo"
                                                                    id="MathJax-Span-2495"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-2496"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">4</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.988em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.031em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.073em; border-left: 0px solid; width: 0px; height: 1.161em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-389">\epsilon^{-4}</script> to <span
                        class="MathJax_Preview" style="display: none;"></span><span class="MathJax"
                        id="MathJax-Element-390-Frame" tabindex="0" style="">
                        <nobr><span class="math" id="MathJax-Span-2497"
                                style="width: 1.738em; display: inline-block;"><span
                                    style="display: inline-block; position: relative; width: 1.417em; height: 0px; font-size: 120%;"><span
                                        style="position: absolute; clip: rect(0.003em, 1001.42em, 1.224em, -999.997em); top: -1.025em; left: 0em;"><span
                                            class="mrow" id="MathJax-Span-2498"><span class="msubsup"
                                                id="MathJax-Span-2499"><span
                                                    style="display: inline-block; position: relative; width: 1.417em; height: 0px;"><span
                                                        style="position: absolute; clip: rect(3.345em, 1000.39em, 4.181em, -999.997em); top: -3.981em; left: 0em;"><span
                                                            class="mi" id="MathJax-Span-2500"
                                                            style="font-family: MathJax_Math-italic;">ϵ</span><span
                                                            style="display: inline-block; width: 0px; height: 3.988em;"></span></span><span
                                                        style="position: absolute; top: -4.367em; left: 0.389em;"><span
                                                            class="texatom" id="MathJax-Span-2501"><span class="mrow"
                                                                id="MathJax-Span-2502"><span class="mo"
                                                                    id="MathJax-Span-2503"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span
                                                                    class="mn" id="MathJax-Span-2504"
                                                                    style="font-size: 70.7%; font-family: MathJax_Main;">3</span></span></span><span
                                                            style="display: inline-block; width: 0px; height: 3.988em;"></span></span></span></span></span><span
                                            style="display: inline-block; width: 0px; height: 1.031em;"></span></span></span><span
                                    style="display: inline-block; overflow: hidden; vertical-align: -0.073em; border-left: 0px solid; width: 0px; height: 1.161em;"></span></span>
                        </nobr>
                    </span>
                    <script type="math/tex" id="MathJax-Element-390">\epsilon^{-3}</script> sample complexity
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning
                        (cs.LG)</span>; Artificial Intelligence (cs.AI)

                </div>
            </div>
        </dd>
        <dt><a name="item1190">[1190]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01881"
                    title="Abstract">arXiv:2405.01881</a> (replaced) [<a href="/pdf/2405.01881"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.01881" title="Download PostScript">ps</a>, <a
                    href="/format/2405.01881" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Explainable Risk Classification in Financial Reports
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/q-fin?searchtype=author&amp;query=Tan%2C+X+W">Xue Wen Tan</a>,
                    <a href="/search/q-fin?searchtype=author&amp;query=Kok%2C+S">Stanley Kok</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> ICIS 2023 Proceedings. 3. <a
                        href="https://aisel.aisnet.org/icis2023/blockchain/blockchain/3">this https URL</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management
                        (q-fin.RM)</span>; Machine Learning (cs.LG)

                </div>
            </div>
        </dd>
        <dt><a name="item1191">[1191]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.01972"
                    title="Abstract">arXiv:2405.01972</a> (replaced) [<a href="/pdf/2405.01972"
                    title="Download PDF">pdf</a>, <a href="/format/2405.01972" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> A quantitative and typological study of Early Slavic
                    participle clauses and their competition
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pedrazzini%2C+N">Nilo Pedrazzini</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> 259 pages, 138 figures. DPhil Thesis in Linguistics
                    submitted and defended at the University of Oxford (December 2023). This manuscript is a version
                    formatted for improved readability and broader dissemination
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language
                        (cs.CL)</span>; Information Retrieval (cs.IR)

                </div>
            </div>
        </dd>
        <dt><a name="item1192">[1192]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02023"
                    title="Abstract">arXiv:2405.02023</a> (replaced) [<a href="/pdf/2405.02023"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02023" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> IFNet: Deep Imaging and Focusing for Handheld SAR with
                    Millimeter-wave Signals
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yadong Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Zhang%2C+D">Dongheng Zhang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Geng%2C+R">Ruixu Geng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wu%2C+J">Jincheng Wu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yang Hu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Sun%2C+Q">Qibin Sun</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Chen%2C+Y">Yan Chen</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern
                        Recognition (cs.CV)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1193">[1193]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02106"
                    title="Abstract">arXiv:2405.02106</a> (replaced) [<a href="/pdf/2405.02106"
                    title="Download PDF">pdf</a>, <a href="/ps/2405.02106" title="Download PostScript">ps</a>, <a
                    href="/format/2405.02106" title="Other formats">other</a>]</span></dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Got Root? A Linux Priv-Esc Benchmark
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Happe%2C+A">Andreas Happe</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cito%2C+J">Jürgen Cito</a>
                </div>
                <div class="list-comments mathjax">
                    <span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a
                        href="/abs/2310.11409">arXiv:2310.11409</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security
                        (cs.CR)</span>

                </div>
            </div>
        </dd>
        <dt><a name="item1194">[1194]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02132"
                    title="Abstract">arXiv:2405.02132</a> (replaced) [<a href="/pdf/2405.02132"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02132" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Unveiling the Potential of LLM-Based ASR on Chinese
                    Open-Source Datasets
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Geng%2C+X">Xuelong Geng</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xu%2C+T">Tianyi Xu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wei%2C+K">Kun Wei</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Mu%2C+B">Bingshen Mu</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xue%2C+H">Hongfei Xue</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Wang%2C+H">He Wang</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+Y">Yangze Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Guo%2C+P">Pengcheng Guo</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Dai%2C+Y">Yuhang Dai</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Li%2C+L">Longhao Li</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Shao%2C+M">Mingchen Shao</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Xie%2C+L">Lei Xie</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

                </div>
            </div>
        </dd>
        <dt><a name="item1195">[1195]</a>&nbsp; <span class="list-identifier"><a href="/abs/2405.02179"
                    title="Abstract">arXiv:2405.02179</a> (replaced) [<a href="/pdf/2405.02179"
                    title="Download PDF">pdf</a>, <a href="/format/2405.02179" title="Other formats">other</a>]</span>
        </dt>
        <dd>
            <div class="meta">
                <div class="list-title mathjax">
                    <span class="descriptor">Title:</span> Training-Free Deepfake Voice Recognition by Leveraging
                    Large-Scale Pre-Trained Models
                </div>
                <div class="list-authors">
                    <span class="descriptor">Authors:</span>
                    <a href="/search/cs?searchtype=author&amp;query=Pianese%2C+A">Alessandro Pianese</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Cozzolino%2C+D">Davide Cozzolino</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Poggi%2C+G">Giovanni Poggi</a>,
                    <a href="/search/cs?searchtype=author&amp;query=Verdoliva%2C+L">Luisa Verdoliva</a>
                </div>
                <div class="list-subjects">
                    <span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>;
                    Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

                </div>
            </div>
        </dd>
    </dl>
    <ul>
        <li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
        <li><a href="#item681">Cross-lists</a></li>
        <li><a href="#item744">Replacements</a></li>
    </ul>
    <small>[ total of 1195 entries: <b>1-1195</b> ]</small><br>
    <small>[ showing up to 2000 entries per page: <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> | <font
            color="#999999">more</font> ]</small><br>
</div>